=================================================
Executing 2BodyForcesNUFFT_Per.py following Np2_Ncells10_Per_mu_1_longRange.json
2020-03-26 04:22:53.490790: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-03-26 04:22:53.686344: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:84:00.0
2020-03-26 04:22:53.869771: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-03-26 04:22:55.456541: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-03-26 04:22:57.494644: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-03-26 04:22:57.713638: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-03-26 04:23:00.662234: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-03-26 04:23:01.414477: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-03-26 04:23:03.619797: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 04:23:03.670484: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-03-26 04:23:03.831561: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-03-26 04:23:05.250038: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299945000 Hz
2020-03-26 04:23:05.252253: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e25d14c9e0 executing computations on platform Host. Devices:
2020-03-26 04:23:05.253281: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-03-26 04:23:05.293784: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:84:00.0
2020-03-26 04:23:05.294535: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-03-26 04:23:05.295112: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-03-26 04:23:05.295664: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-03-26 04:23:05.296351: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-03-26 04:23:05.296809: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-03-26 04:23:05.297503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-03-26 04:23:05.298514: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-03-26 04:23:05.301016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-03-26 04:23:05.301985: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-03-26 04:23:05.461189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-03-26 04:23:05.461719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-03-26 04:23:05.494246: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-03-26 04:23:05.561503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:84:00.0, compute capability: 6.1)
2020-03-26 04:23:05.671819: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55e25e42d050 executing computations on platform CUDA. Devices:
2020-03-26 04:23:05.672428: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2020-03-26 04:23:40.064118: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-03-26 04:23:42.044890: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
=================================================
We are using the random seed 1234567891011121314
Using data in ../../data/data_Periodic_Ncells_10_Np_2_mu_1_minDelta_0.2000_Nsamples_10000.h5
Data file does not exist, we create a new one
mean of the forces is 0.00000000
std of the forces is 3.28106090
mean of the inputs are 1.52882421 and 0.88816905
std of the inputs are 0.98857456 and 0.42468333
xLims = 0.000000, 10.000000
building the channels
computing the FFT
applying the multipliers
(10, 1, 1001)
inverse fft
Model: "deepMDsimpleForces"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
pyramid_layer (pyramidLayer) multiple                  744       
_________________________________________________________________
pyramid_layer_1 (pyramidLaye multiple                  744       
_________________________________________________________________
nufft_layer_multi_channel_in multiple                  4004      
_________________________________________________________________
pyramid_layer_2 (pyramidLaye multiple                  746       
_________________________________________________________________
pyramid_layer_3 (pyramidLaye multiple                  8384      
_________________________________________________________________
my_dense_layer (MyDenseLayer multiple                  33        
=================================================================
Total params: 14,655
Trainable params: 14,655
Non-trainable params: 0
_________________________________________________________________
Directory  checkpoints/  already exists :)
Training cycles in number of epochs
[200, 400, 800, 1600]
Training batch sizes for each cycle
[8, 16, 32, 64]
++++++++++++++++++++++++++++++
Start of cycle 0
Total number of epochs in this cycle: 200
Batch size in this cycle: 8
============================
WARNING:tensorflow:Layer deepMDsimpleForces is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

Start of epoch 0
computing the FFT
applying the multipliers
(8, 1, 1001)
inverse fft
step 0: mean loss = 132.79333
step 100: mean loss = 2.6685247
step 200: mean loss = 1.3594015
step 300: mean loss = 0.91671276
step 400: mean loss = 0.69369817
step 500: mean loss = 0.5589635
step 600: mean loss = 0.46884695
step 700: mean loss = 0.4043337
step 800: mean loss = 0.35585278
step 900: mean loss = 0.318019
step 1000: mean loss = 0.28776956
step 1100: mean loss = 0.26293734
step 1200: mean loss = 0.2421872
epoch 0: mean loss = 0.23320256  learning rate = 0.001
============================
Start of epoch 1
step 0: mean loss = 0.012684578
step 100: mean loss = 0.013587465
step 200: mean loss = 0.013090332
step 300: mean loss = 0.013037265
step 400: mean loss = 0.013138491
step 500: mean loss = 0.013022515
step 600: mean loss = 0.012906592
step 700: mean loss = 0.012870747
step 800: mean loss = 0.012818036
step 900: mean loss = 0.0127046
step 1000: mean loss = 0.012582509
step 1100: mean loss = 0.012521562
step 1200: mean loss = 0.01242825
epoch 1: mean loss = 0.012403484  learning rate = 0.001
============================
Start of epoch 2
step 0: mean loss = 0.013687575
step 100: mean loss = 0.0115876375
step 200: mean loss = 0.011162204
step 300: mean loss = 0.01092476
step 400: mean loss = 0.010930034
step 500: mean loss = 0.010923092
step 600: mean loss = 0.010861662
step 700: mean loss = 0.010866472
step 800: mean loss = 0.010844594
step 900: mean loss = 0.010777893
step 1000: mean loss = 0.010780773
step 1100: mean loss = 0.0107206805
step 1200: mean loss = 0.010704235
epoch 2: mean loss = 0.010662568  learning rate = 0.001
============================
Start of epoch 3
step 0: mean loss = 0.012937844
step 100: mean loss = 0.010311096
step 200: mean loss = 0.010095471
step 300: mean loss = 0.010297016
step 400: mean loss = 0.010149311
step 500: mean loss = 0.01019333
step 600: mean loss = 0.010097065
step 700: mean loss = 0.010127948
step 800: mean loss = 0.010023642
step 900: mean loss = 0.00995161
step 1000: mean loss = 0.009964365
step 1100: mean loss = 0.009911559
step 1200: mean loss = 0.009872241
epoch 3: mean loss = 0.009829807  learning rate = 0.001
============================
Start of epoch 4
step 0: mean loss = 0.011504744
step 100: mean loss = 0.009445021
step 200: mean loss = 0.009288808
step 300: mean loss = 0.009133581
step 400: mean loss = 0.009163605
step 500: mean loss = 0.009069609
step 600: mean loss = 0.009131606
step 700: mean loss = 0.00925233
step 800: mean loss = 0.009394809
step 900: mean loss = 0.009393085
step 1000: mean loss = 0.009385978
step 1100: mean loss = 0.009486005
step 1200: mean loss = 0.009487795
epoch 4: mean loss = 0.009458137  learning rate = 0.001
============================
Start of epoch 5
step 0: mean loss = 0.008216999
step 100: mean loss = 0.009222567
step 200: mean loss = 0.009203246
step 300: mean loss = 0.009369907
step 400: mean loss = 0.009280906
step 500: mean loss = 0.009395126
step 600: mean loss = 0.009441664
step 700: mean loss = 0.009414576
step 800: mean loss = 0.009405678
step 900: mean loss = 0.009386072
step 1000: mean loss = 0.009380483
step 1100: mean loss = 0.009427452
step 1200: mean loss = 0.009469811
epoch 5: mean loss = 0.009442073  learning rate = 0.001
============================
Start of epoch 6
step 0: mean loss = 0.009624895
step 100: mean loss = 0.009696346
step 200: mean loss = 0.009375754
step 300: mean loss = 0.00921487
step 400: mean loss = 0.009193681
step 500: mean loss = 0.009164453
step 600: mean loss = 0.00921697
step 700: mean loss = 0.00923297
step 800: mean loss = 0.009279641
step 900: mean loss = 0.009304056
step 1000: mean loss = 0.00934176
step 1100: mean loss = 0.009388259
step 1200: mean loss = 0.009358945
epoch 6: mean loss = 0.009358159  learning rate = 0.001
============================
Start of epoch 7
step 0: mean loss = 0.0073262895
step 100: mean loss = 0.008894824
step 200: mean loss = 0.009272157
step 300: mean loss = 0.009291447
step 400: mean loss = 0.009220057
step 500: mean loss = 0.009189033
step 600: mean loss = 0.009161887
step 700: mean loss = 0.009125115
step 800: mean loss = 0.009134279
step 900: mean loss = 0.009137382
step 1000: mean loss = 0.009179452
step 1100: mean loss = 0.009204694
step 1200: mean loss = 0.0092568165
epoch 7: mean loss = 0.009313807  learning rate = 0.001
============================
Start of epoch 8
step 0: mean loss = 0.014619597
step 100: mean loss = 0.009454262
step 200: mean loss = 0.009215898
step 300: mean loss = 0.009126948
step 400: mean loss = 0.009034833
step 500: mean loss = 0.009088634
step 600: mean loss = 0.009083704
step 700: mean loss = 0.009038018
step 800: mean loss = 0.00899165
step 900: mean loss = 0.008942689
step 1000: mean loss = 0.00890156
step 1100: mean loss = 0.008915353
step 1200: mean loss = 0.008898312
epoch 8: mean loss = 0.008904048  learning rate = 0.001
============================
Start of epoch 9
step 0: mean loss = 0.007944981
step 100: mean loss = 0.008444279
step 200: mean loss = 0.008635858
step 300: mean loss = 0.008661774
step 400: mean loss = 0.008713182
step 500: mean loss = 0.008763751
step 600: mean loss = 0.008777771
step 700: mean loss = 0.008800926
step 800: mean loss = 0.008781703
step 900: mean loss = 0.008760986
step 1000: mean loss = 0.008817563
step 1100: mean loss = 0.008790422
step 1200: mean loss = 0.008738776
epoch 9: mean loss = 0.008772158  learning rate = 0.00094999996
============================
Start of epoch 10
step 0: mean loss = 0.0074467007
step 100: mean loss = 0.007917526
step 200: mean loss = 0.008310189
step 300: mean loss = 0.008213009
step 400: mean loss = 0.008133094
step 500: mean loss = 0.008176059
step 600: mean loss = 0.008409449
step 700: mean loss = 0.008381919
step 800: mean loss = 0.008307152
step 900: mean loss = 0.008387548
step 1000: mean loss = 0.008391244
step 1100: mean loss = 0.008321638
step 1200: mean loss = 0.00836942
epoch 10: mean loss = 0.008369114  learning rate = 0.00094999996
============================
Start of epoch 11
step 0: mean loss = 0.008888089
step 100: mean loss = 0.008062101
step 200: mean loss = 0.008326101
step 300: mean loss = 0.008290585
step 400: mean loss = 0.008184777
step 500: mean loss = 0.008160436
step 600: mean loss = 0.008136293
step 700: mean loss = 0.008174996
step 800: mean loss = 0.00810465
step 900: mean loss = 0.008047396
step 1000: mean loss = 0.008112968
step 1100: mean loss = 0.008071675
step 1200: mean loss = 0.008021386
epoch 11: mean loss = 0.008009378  learning rate = 0.00094999996
============================
Start of epoch 12
step 0: mean loss = 0.008219814
step 100: mean loss = 0.0073260223
step 200: mean loss = 0.0073993024
step 300: mean loss = 0.0075959857
step 400: mean loss = 0.007617252
step 500: mean loss = 0.0077654566
step 600: mean loss = 0.007800853
step 700: mean loss = 0.0077647096
step 800: mean loss = 0.007693102
step 900: mean loss = 0.0076549067
step 1000: mean loss = 0.0076650083
step 1100: mean loss = 0.007685735
step 1200: mean loss = 0.0077155754
epoch 12: mean loss = 0.007684662  learning rate = 0.00094999996
============================
Start of epoch 13
step 0: mean loss = 0.009240137
step 100: mean loss = 0.0068898355
step 200: mean loss = 0.0071852403
step 300: mean loss = 0.0073764515
step 400: mean loss = 0.007422613
step 500: mean loss = 0.007472662
step 600: mean loss = 0.00740697
step 700: mean loss = 0.0073410347
step 800: mean loss = 0.0073627364
step 900: mean loss = 0.0073212027
step 1000: mean loss = 0.007277013
step 1100: mean loss = 0.0072613354
step 1200: mean loss = 0.0072440784
epoch 13: mean loss = 0.0072337347  learning rate = 0.00094999996
============================
Start of epoch 14
step 0: mean loss = 0.0047457987
step 100: mean loss = 0.006971077
step 200: mean loss = 0.00697313
step 300: mean loss = 0.006985334
step 400: mean loss = 0.0069600805
step 500: mean loss = 0.006923468
step 600: mean loss = 0.006922088
step 700: mean loss = 0.0068906737
step 800: mean loss = 0.006891778
step 900: mean loss = 0.006910548
step 1000: mean loss = 0.006852171
step 1100: mean loss = 0.0068250992
step 1200: mean loss = 0.0068204943
epoch 14: mean loss = 0.0068113795  learning rate = 0.00094999996
============================
Start of epoch 15
step 0: mean loss = 0.00414755
step 100: mean loss = 0.0060642427
step 200: mean loss = 0.006174617
step 300: mean loss = 0.0062596705
step 400: mean loss = 0.006394113
step 500: mean loss = 0.0064150672
step 600: mean loss = 0.00638784
step 700: mean loss = 0.0064639496
step 800: mean loss = 0.006449361
step 900: mean loss = 0.006403162
step 1000: mean loss = 0.0064338716
step 1100: mean loss = 0.0064206393
step 1200: mean loss = 0.006410869
epoch 15: mean loss = 0.0063854232  learning rate = 0.00094999996
============================
Start of epoch 16
step 0: mean loss = 0.004970641
step 100: mean loss = 0.0066509177
step 200: mean loss = 0.0062422766
step 300: mean loss = 0.0062208693
step 400: mean loss = 0.006199136
step 500: mean loss = 0.0062553976
step 600: mean loss = 0.0062683094
step 700: mean loss = 0.006297429
step 800: mean loss = 0.0063072196
step 900: mean loss = 0.006296479
step 1000: mean loss = 0.0062782904
step 1100: mean loss = 0.006226339
step 1200: mean loss = 0.0061833737
epoch 16: mean loss = 0.006181634  learning rate = 0.00094999996
============================
Start of epoch 17
step 0: mean loss = 0.0059840158
step 100: mean loss = 0.0062006754
step 200: mean loss = 0.006340794
step 300: mean loss = 0.006037017
step 400: mean loss = 0.006000889
step 500: mean loss = 0.005970187
step 600: mean loss = 0.005895501
step 700: mean loss = 0.0058780415
step 800: mean loss = 0.0058213263
step 900: mean loss = 0.005825072
step 1000: mean loss = 0.0058722217
step 1100: mean loss = 0.00585711
step 1200: mean loss = 0.0058142073
epoch 17: mean loss = 0.0057997317  learning rate = 0.00094999996
============================
Start of epoch 18
step 0: mean loss = 0.0038800011
step 100: mean loss = 0.0053093364
step 200: mean loss = 0.005487343
step 300: mean loss = 0.005440284
step 400: mean loss = 0.0055423756
step 500: mean loss = 0.0054546413
step 600: mean loss = 0.005444711
step 700: mean loss = 0.005418055
step 800: mean loss = 0.0054094074
step 900: mean loss = 0.00540843
step 1000: mean loss = 0.0053953896
step 1100: mean loss = 0.0053946455
step 1200: mean loss = 0.0054052505
epoch 18: mean loss = 0.005407058  learning rate = 0.00094999996
============================
Start of epoch 19
step 0: mean loss = 0.004305019
step 100: mean loss = 0.0052978834
step 200: mean loss = 0.005406222
step 300: mean loss = 0.0053637014
step 400: mean loss = 0.005277632
step 500: mean loss = 0.0052400073
step 600: mean loss = 0.0053280746
step 700: mean loss = 0.0052952785
step 800: mean loss = 0.0053571113
step 900: mean loss = 0.0053555085
step 1000: mean loss = 0.0053621773
step 1100: mean loss = 0.005365552
step 1200: mean loss = 0.0053521725
epoch 19: mean loss = 0.005325658  learning rate = 0.00090249995
============================
Start of epoch 20
step 0: mean loss = 0.0052586175
step 100: mean loss = 0.0047630845
step 200: mean loss = 0.0049124267
step 300: mean loss = 0.004897336
step 400: mean loss = 0.0048972843
step 500: mean loss = 0.0048881094
step 600: mean loss = 0.0048694527
step 700: mean loss = 0.004862265
step 800: mean loss = 0.0048483983
step 900: mean loss = 0.0048163706
step 1000: mean loss = 0.004798166
step 1100: mean loss = 0.0047579054
step 1200: mean loss = 0.004755085
epoch 20: mean loss = 0.004747456  learning rate = 0.00090249995
============================
Start of epoch 21
step 0: mean loss = 0.004489062
step 100: mean loss = 0.0046210038
step 200: mean loss = 0.0045498284
step 300: mean loss = 0.004797381
step 400: mean loss = 0.004880427
step 500: mean loss = 0.004873098
step 600: mean loss = 0.004786373
step 700: mean loss = 0.004767916
step 800: mean loss = 0.004788981
step 900: mean loss = 0.0047713886
step 1000: mean loss = 0.0047398196
step 1100: mean loss = 0.00472249
step 1200: mean loss = 0.004673683
epoch 21: mean loss = 0.004649111  learning rate = 0.00090249995
============================
Start of epoch 22
step 0: mean loss = 0.0035834676
step 100: mean loss = 0.004288165
step 200: mean loss = 0.004469106
step 300: mean loss = 0.0044528036
step 400: mean loss = 0.0044410215
step 500: mean loss = 0.004397285
step 600: mean loss = 0.0043977476
step 700: mean loss = 0.004391309
step 800: mean loss = 0.004372546
step 900: mean loss = 0.004346213
step 1000: mean loss = 0.00432252
step 1100: mean loss = 0.0043718102
step 1200: mean loss = 0.0043485058
epoch 22: mean loss = 0.0043523647  learning rate = 0.00090249995
============================
Start of epoch 23
step 0: mean loss = 0.0054109907
step 100: mean loss = 0.004171301
step 200: mean loss = 0.0041067214
step 300: mean loss = 0.004134318
step 400: mean loss = 0.004182594
step 500: mean loss = 0.0041072685
step 600: mean loss = 0.0040838704
step 700: mean loss = 0.0040814644
step 800: mean loss = 0.0040699425
step 900: mean loss = 0.004067031
step 1000: mean loss = 0.0041003413
step 1100: mean loss = 0.004108501
step 1200: mean loss = 0.004084137
epoch 23: mean loss = 0.004072966  learning rate = 0.00090249995
============================
Start of epoch 24
step 0: mean loss = 0.0048072203
step 100: mean loss = 0.003864282
step 200: mean loss = 0.004009115
step 300: mean loss = 0.0040754476
step 400: mean loss = 0.004073967
step 500: mean loss = 0.0040328284
step 600: mean loss = 0.003971032
step 700: mean loss = 0.003912156
step 800: mean loss = 0.003899821
step 900: mean loss = 0.003912281
step 1000: mean loss = 0.0039068954
step 1100: mean loss = 0.0038939384
step 1200: mean loss = 0.0038875705
epoch 24: mean loss = 0.0038864259  learning rate = 0.00090249995
============================
Start of epoch 25
step 0: mean loss = 0.0039668083
step 100: mean loss = 0.0039067627
step 200: mean loss = 0.0036868756
step 300: mean loss = 0.0037838165
step 400: mean loss = 0.003828972
step 500: mean loss = 0.0037975176
step 600: mean loss = 0.0037778649
step 700: mean loss = 0.003748265
step 800: mean loss = 0.003739137
step 900: mean loss = 0.0037089286
step 1000: mean loss = 0.003687042
step 1100: mean loss = 0.0036652866
step 1200: mean loss = 0.003683138
epoch 25: mean loss = 0.003680173  learning rate = 0.00090249995
============================
Start of epoch 26
step 0: mean loss = 0.0038038848
step 100: mean loss = 0.0036073038
step 200: mean loss = 0.003509312
step 300: mean loss = 0.003469432
step 400: mean loss = 0.0034589758
step 500: mean loss = 0.0034749757
step 600: mean loss = 0.003523329
step 700: mean loss = 0.0035616695
step 800: mean loss = 0.0035157367
step 900: mean loss = 0.0035044686
step 1000: mean loss = 0.0035097192
step 1100: mean loss = 0.0034991305
step 1200: mean loss = 0.0034837746
epoch 26: mean loss = 0.0034720586  learning rate = 0.00090249995
============================
Start of epoch 27
step 0: mean loss = 0.0034317106
step 100: mean loss = 0.0034613279
step 200: mean loss = 0.0033466413
step 300: mean loss = 0.0033596552
step 400: mean loss = 0.0033400145
step 500: mean loss = 0.003304048
step 600: mean loss = 0.0032897433
step 700: mean loss = 0.0032588616
step 800: mean loss = 0.0032678067
step 900: mean loss = 0.0032506795
step 1000: mean loss = 0.0032571221
step 1100: mean loss = 0.0032469577
step 1200: mean loss = 0.0032431616
epoch 27: mean loss = 0.0032454988  learning rate = 0.00090249995
============================
Start of epoch 28
step 0: mean loss = 0.0031560035
step 100: mean loss = 0.0031107399
step 200: mean loss = 0.003241418
step 300: mean loss = 0.00322141
step 400: mean loss = 0.0031375312
step 500: mean loss = 0.0031862846
step 600: mean loss = 0.0031591577
step 700: mean loss = 0.003122535
step 800: mean loss = 0.0031032213
step 900: mean loss = 0.0030907139
step 1000: mean loss = 0.0031153222
step 1100: mean loss = 0.0031126272
step 1200: mean loss = 0.0030959824
epoch 28: mean loss = 0.0030985195  learning rate = 0.00090249995
============================
Start of epoch 29
step 0: mean loss = 0.002229435
step 100: mean loss = 0.002795549
step 200: mean loss = 0.0029008528
step 300: mean loss = 0.002913143
step 400: mean loss = 0.0028792762
step 500: mean loss = 0.0028959652
step 600: mean loss = 0.0028727138
step 700: mean loss = 0.0028567195
step 800: mean loss = 0.002854255
step 900: mean loss = 0.002859108
step 1000: mean loss = 0.0028507134
step 1100: mean loss = 0.00285882
step 1200: mean loss = 0.002878656
epoch 29: mean loss = 0.002885159  learning rate = 0.0008573749
============================
Start of epoch 30
step 0: mean loss = 0.003719379
step 100: mean loss = 0.002637609
step 200: mean loss = 0.0026759931
step 300: mean loss = 0.002717641
step 400: mean loss = 0.0027344546
step 500: mean loss = 0.0027454353
step 600: mean loss = 0.0027673442
step 700: mean loss = 0.0027314667
step 800: mean loss = 0.002722068
step 900: mean loss = 0.0027015659
step 1000: mean loss = 0.0026723926
step 1100: mean loss = 0.0026614987
step 1200: mean loss = 0.002663143
epoch 30: mean loss = 0.0026611052  learning rate = 0.0008573749
============================
Start of epoch 31
step 0: mean loss = 0.0025871806
step 100: mean loss = 0.0024792852
step 200: mean loss = 0.002673572
step 300: mean loss = 0.0025672591
step 400: mean loss = 0.0025499482
step 500: mean loss = 0.0025110117
step 600: mean loss = 0.0025284474
step 700: mean loss = 0.0025158473
step 800: mean loss = 0.002499728
step 900: mean loss = 0.002491144
step 1000: mean loss = 0.0025114717
step 1100: mean loss = 0.0025318174
step 1200: mean loss = 0.0025457859
epoch 31: mean loss = 0.0025432566  learning rate = 0.0008573749
============================
Start of epoch 32
step 0: mean loss = 0.0028361734
step 100: mean loss = 0.0022695153
step 200: mean loss = 0.0023991948
step 300: mean loss = 0.0024065233
step 400: mean loss = 0.0023857458
step 500: mean loss = 0.002364261
step 600: mean loss = 0.0023695235
step 700: mean loss = 0.0024299088
step 800: mean loss = 0.0024108915
step 900: mean loss = 0.0024078493
step 1000: mean loss = 0.0024206568
step 1100: mean loss = 0.00240668
step 1200: mean loss = 0.0023940825
epoch 32: mean loss = 0.0023891835  learning rate = 0.0008573749
============================
Start of epoch 33
step 0: mean loss = 0.0015194362
step 100: mean loss = 0.0022341476
step 200: mean loss = 0.002155471
step 300: mean loss = 0.002309024
step 400: mean loss = 0.0023091545
step 500: mean loss = 0.005166843
step 600: mean loss = 0.005616349
step 700: mean loss = 0.0057535614
step 800: mean loss = 0.0057859696
step 900: mean loss = 0.0056381575
step 1000: mean loss = 0.0054083746
step 1100: mean loss = 0.005170121
step 1200: mean loss = 0.004949299
epoch 33: mean loss = 0.0048446967  learning rate = 0.0008573749
============================
Start of epoch 34
step 0: mean loss = 0.0030302536
step 100: mean loss = 0.002197493
step 200: mean loss = 0.002217593
step 300: mean loss = 0.002253853
step 400: mean loss = 0.0022675507
step 500: mean loss = 0.0022576326
step 600: mean loss = 0.0022384375
step 700: mean loss = 0.0022344196
step 800: mean loss = 0.002219675
step 900: mean loss = 0.002304423
step 1000: mean loss = 0.0023386667
step 1100: mean loss = 0.0023551206
step 1200: mean loss = 0.0023533416
epoch 34: mean loss = 0.0023424767  learning rate = 0.0008573749
============================
Start of epoch 35
step 0: mean loss = 0.0018130364
step 100: mean loss = 0.0020695573
step 200: mean loss = 0.002170679
step 300: mean loss = 0.0021971327
step 400: mean loss = 0.002230554
step 500: mean loss = 0.0023009593
step 600: mean loss = 0.0023698611
step 700: mean loss = 0.0023632678
step 800: mean loss = 0.002345945
step 900: mean loss = 0.0023300317
step 1000: mean loss = 0.0023058113
step 1100: mean loss = 0.0022949143
step 1200: mean loss = 0.002759259
epoch 35: mean loss = 0.002863746  learning rate = 0.0008573749
============================
Start of epoch 36
step 0: mean loss = 0.0053908248
step 100: mean loss = 0.0035684817
step 200: mean loss = 0.0031012858
step 300: mean loss = 0.0027741003
step 400: mean loss = 0.0026472718
step 500: mean loss = 0.0025453165
step 600: mean loss = 0.0025160213
step 700: mean loss = 0.0024816084
step 800: mean loss = 0.0024476033
step 900: mean loss = 0.002864555
step 1000: mean loss = 0.0029061593
step 1100: mean loss = 0.002873648
step 1200: mean loss = 0.0030709852
epoch 36: mean loss = 0.0030618177  learning rate = 0.0008573749
============================
Start of epoch 37
step 0: mean loss = 0.0028819824
step 100: mean loss = 0.0049885046
step 200: mean loss = 0.0037891157
step 300: mean loss = 0.003648168
step 400: mean loss = 0.0034334187
step 500: mean loss = 0.0031684553
step 600: mean loss = 0.0029871997
step 700: mean loss = 0.0028677112
step 800: mean loss = 0.0027779774
step 900: mean loss = 0.0027055012
step 1000: mean loss = 0.0026406352
step 1100: mean loss = 0.0025850837
step 1200: mean loss = 0.0025489826
epoch 37: mean loss = 0.002530494  learning rate = 0.0008573749
============================
Start of epoch 38
step 0: mean loss = 0.002830374
step 100: mean loss = 0.0029381127
step 200: mean loss = 0.00249471
step 300: mean loss = 0.0031991678
step 400: mean loss = 0.0032589375
step 500: mean loss = 0.0030849539
step 600: mean loss = 0.002933791
step 700: mean loss = 0.002806194
step 800: mean loss = 0.0027051049
step 900: mean loss = 0.0026382224
step 1000: mean loss = 0.002581001
step 1100: mean loss = 0.0025322132
step 1200: mean loss = 0.0024897642
epoch 38: mean loss = 0.0024782477  learning rate = 0.0008573749
============================
Start of epoch 39
step 0: mean loss = 0.0017227335
step 100: mean loss = 0.002257345
step 200: mean loss = 0.0021056882
step 300: mean loss = 0.002063604
step 400: mean loss = 0.0020905228
step 500: mean loss = 0.0020701475
step 600: mean loss = 0.0020670404
step 700: mean loss = 0.0020967964
step 800: mean loss = 0.0021429243
step 900: mean loss = 0.0021458296
step 1000: mean loss = 0.0021535314
step 1100: mean loss = 0.0021476683
step 1200: mean loss = 0.0021532981
epoch 39: mean loss = 0.0021520571  learning rate = 0.0008145062
============================
Start of epoch 40
step 0: mean loss = 0.002129062
step 100: mean loss = 0.0019954063
step 200: mean loss = 0.0019125473
step 300: mean loss = 0.0019578233
step 400: mean loss = 0.0020494158
step 500: mean loss = 0.0021059841
step 600: mean loss = 0.0020766861
step 700: mean loss = 0.0020588986
step 800: mean loss = 0.0020417992
step 900: mean loss = 0.002037934
step 1000: mean loss = 0.0020437962
step 1100: mean loss = 0.002042244
step 1200: mean loss = 0.002032379
epoch 40: mean loss = 0.0020293014  learning rate = 0.0008145062
============================
Start of epoch 41
step 0: mean loss = 0.0019395731
step 100: mean loss = 0.0019288498
step 200: mean loss = 0.0019210659
step 300: mean loss = 0.0019042167
step 400: mean loss = 0.0019298415
step 500: mean loss = 0.0019488746
step 600: mean loss = 0.0019695961
step 700: mean loss = 0.0019746271
step 800: mean loss = 0.001954413
step 900: mean loss = 0.0019418873
step 1000: mean loss = 0.001954748
step 1100: mean loss = 0.0019602862
step 1200: mean loss = 0.0019481771
epoch 41: mean loss = 0.0019467202  learning rate = 0.0008145062
============================
Start of epoch 42
step 0: mean loss = 0.0013454786
step 100: mean loss = 0.0019390637
step 200: mean loss = 0.0019197448
step 300: mean loss = 0.0018857201
step 400: mean loss = 0.001859984
step 500: mean loss = 0.001890349
step 600: mean loss = 0.0018982608
step 700: mean loss = 0.0019041053
step 800: mean loss = 0.0018996387
step 900: mean loss = 0.0019165592
step 1000: mean loss = 0.0019296127
step 1100: mean loss = 0.0019163429
step 1200: mean loss = 0.0019187451
epoch 42: mean loss = 0.0019127191  learning rate = 0.0008145062
============================
Start of epoch 43
step 0: mean loss = 0.001125003
step 100: mean loss = 0.0018052716
step 200: mean loss = 0.0017318958
step 300: mean loss = 0.0017651492
step 400: mean loss = 0.0018027736
step 500: mean loss = 0.0017990068
step 600: mean loss = 0.0017810586
step 700: mean loss = 0.0017609058
step 800: mean loss = 0.0017828176
step 900: mean loss = 0.0017972033
step 1000: mean loss = 0.0017961244
step 1100: mean loss = 0.0017980391
step 1200: mean loss = 0.0018088446
epoch 43: mean loss = 0.0018016899  learning rate = 0.0008145062
============================
Start of epoch 44
step 0: mean loss = 0.0013967018
step 100: mean loss = 0.0016062894
step 200: mean loss = 0.001706871
step 300: mean loss = 0.0017298079
step 400: mean loss = 0.0018241513
step 500: mean loss = 0.0018051028
step 600: mean loss = 0.0017793867
step 700: mean loss = 0.0017809075
step 800: mean loss = 0.0018030291
step 900: mean loss = 0.0017961069
step 1000: mean loss = 0.0017918706
step 1100: mean loss = 0.0017769635
step 1200: mean loss = 0.0017693152
epoch 44: mean loss = 0.0017722116  learning rate = 0.0008145062
============================
Start of epoch 45
step 0: mean loss = 0.0011930133
step 100: mean loss = 0.0017122184
step 200: mean loss = 0.0017126898
step 300: mean loss = 0.001783223
step 400: mean loss = 0.0017594275
step 500: mean loss = 0.0017800995
step 600: mean loss = 0.001776722
step 700: mean loss = 0.0017534326
step 800: mean loss = 0.0017389234
step 900: mean loss = 0.0017379349
step 1000: mean loss = 0.0017434504
step 1100: mean loss = 0.0017379944
step 1200: mean loss = 0.0017245624
epoch 45: mean loss = 0.0017182726  learning rate = 0.0008145062
============================
Start of epoch 46
step 0: mean loss = 0.001636717
step 100: mean loss = 0.0015600093
step 200: mean loss = 0.0016840685
step 300: mean loss = 0.0017410215
step 400: mean loss = 0.0017257562
step 500: mean loss = 0.0017183628
step 600: mean loss = 0.0017101802
step 700: mean loss = 0.0017247804
step 800: mean loss = 0.0017247006
step 900: mean loss = 0.0017140865
step 1000: mean loss = 0.001737604
step 1100: mean loss = 0.0017387791
step 1200: mean loss = 0.0017427984
epoch 46: mean loss = 0.0017343177  learning rate = 0.0008145062
============================
Start of epoch 47
step 0: mean loss = 0.0014588151
step 100: mean loss = 0.001561058
step 200: mean loss = 0.0016403855
step 300: mean loss = 0.0016336264
step 400: mean loss = 0.0016512471
step 500: mean loss = 0.0016424998
step 600: mean loss = 0.0016176502
step 700: mean loss = 0.0016427229
step 800: mean loss = 0.0016382927
step 900: mean loss = 0.0016342662
step 1000: mean loss = 0.001640764
step 1100: mean loss = 0.0016487809
step 1200: mean loss = 0.0016302698
epoch 47: mean loss = 0.0016263389  learning rate = 0.0008145062
============================
Start of epoch 48
step 0: mean loss = 0.00134993
step 100: mean loss = 0.0016135995
step 200: mean loss = 0.0016451483
step 300: mean loss = 0.0016329691
step 400: mean loss = 0.001678368
step 500: mean loss = 0.0016953307
step 600: mean loss = 0.0016690287
step 700: mean loss = 0.0016538609
step 800: mean loss = 0.0016526498
step 900: mean loss = 0.0016607217
step 1000: mean loss = 0.0016529413
step 1100: mean loss = 0.0016305809
step 1200: mean loss = 0.0016263752
epoch 48: mean loss = 0.001633184  learning rate = 0.0008145062
============================
Start of epoch 49
step 0: mean loss = 0.0016647889
step 100: mean loss = 0.001653085
step 200: mean loss = 0.001630586
step 300: mean loss = 0.0015991003
step 400: mean loss = 0.0015732612
step 500: mean loss = 0.0015907282
step 600: mean loss = 0.0016040384
step 700: mean loss = 0.0016031767
step 800: mean loss = 0.001598206
step 900: mean loss = 0.0015874115
step 1000: mean loss = 0.0015881167
step 1100: mean loss = 0.0015726441
step 1200: mean loss = 0.001573303
epoch 49: mean loss = 0.0015825216  learning rate = 0.00077378086
============================
Start of epoch 50
step 0: mean loss = 0.0019121622
step 100: mean loss = 0.0017345056
step 200: mean loss = 0.0016044844
step 300: mean loss = 0.0015839592
step 400: mean loss = 0.0016030152
step 500: mean loss = 0.0015528796
step 600: mean loss = 0.0015574988
step 700: mean loss = 0.0015452796
step 800: mean loss = 0.0015320297
step 900: mean loss = 0.0015426708
step 1000: mean loss = 0.0015426564
step 1100: mean loss = 0.0015250855
step 1200: mean loss = 0.0015230145
epoch 50: mean loss = 0.0015296784  learning rate = 0.00077378086
============================
Start of epoch 51
step 0: mean loss = 0.0016925433
step 100: mean loss = 0.0015481982
step 200: mean loss = 0.0015072401
step 300: mean loss = 0.0014700465
step 400: mean loss = 0.0014589309
step 500: mean loss = 0.0014495489
step 600: mean loss = 0.0014782784
step 700: mean loss = 0.0014697466
step 800: mean loss = 0.00147036
step 900: mean loss = 0.001477058
step 1000: mean loss = 0.0014795085
step 1100: mean loss = 0.0014792511
step 1200: mean loss = 0.001484927
epoch 51: mean loss = 0.0014844071  learning rate = 0.00077378086
============================
Start of epoch 52
step 0: mean loss = 0.0019996236
step 100: mean loss = 0.0013752534
step 200: mean loss = 0.0014174504
step 300: mean loss = 0.001413385
step 400: mean loss = 0.0013935895
step 500: mean loss = 0.0013889014
step 600: mean loss = 0.0014040507
step 700: mean loss = 0.0013945842
step 800: mean loss = 0.0014166159
step 900: mean loss = 0.0014211974
step 1000: mean loss = 0.0014176823
step 1100: mean loss = 0.001411334
step 1200: mean loss = 0.0014250313
epoch 52: mean loss = 0.0014311314  learning rate = 0.00077378086
============================
Start of epoch 53
step 0: mean loss = 0.0017123189
step 100: mean loss = 0.0014575276
step 200: mean loss = 0.0013729827
step 300: mean loss = 0.0013769513
step 400: mean loss = 0.0013785396
step 500: mean loss = 0.0013813695
step 600: mean loss = 0.001378404
step 700: mean loss = 0.0013809353
step 800: mean loss = 0.001399261
step 900: mean loss = 0.0014161175
step 1000: mean loss = 0.0014152642
step 1100: mean loss = 0.0014131634
step 1200: mean loss = 0.0014127269
epoch 53: mean loss = 0.0014147374  learning rate = 0.00077378086
============================
Start of epoch 54
step 0: mean loss = 0.0019697049
step 100: mean loss = 0.0014119853
step 200: mean loss = 0.0013680012
step 300: mean loss = 0.001353741
step 400: mean loss = 0.0013809769
step 500: mean loss = 0.0013826768
step 600: mean loss = 0.0013738637
step 700: mean loss = 0.0013854401
step 800: mean loss = 0.0013863208
step 900: mean loss = 0.0013757634
step 1000: mean loss = 0.001378936
step 1100: mean loss = 0.0013910151
step 1200: mean loss = 0.0013855901
epoch 54: mean loss = 0.001388251  learning rate = 0.00077378086
============================
Start of epoch 55
step 0: mean loss = 0.001591563
step 100: mean loss = 0.0012844095
step 200: mean loss = 0.0013160483
step 300: mean loss = 0.0013584559
step 400: mean loss = 0.0013523208
step 500: mean loss = 0.0013721876
step 600: mean loss = 0.001365915
step 700: mean loss = 0.0013754491
step 800: mean loss = 0.0013647669
step 900: mean loss = 0.0013603475
step 1000: mean loss = 0.0013619366
step 1100: mean loss = 0.0013558931
step 1200: mean loss = 0.0013517912
epoch 55: mean loss = 0.0013502701  learning rate = 0.00077378086
============================
Start of epoch 56
step 0: mean loss = 0.0013958742
step 100: mean loss = 0.001461608
step 200: mean loss = 0.0014081555
step 300: mean loss = 0.0013631579
step 400: mean loss = 0.001358885
step 500: mean loss = 0.0014007771
step 600: mean loss = 0.0013840732
step 700: mean loss = 0.0013615374
step 800: mean loss = 0.0013570881
step 900: mean loss = 0.0013609831
step 1000: mean loss = 0.0013627332
step 1100: mean loss = 0.0013608696
step 1200: mean loss = 0.0013650638
epoch 56: mean loss = 0.0013595686  learning rate = 0.00077378086
============================
Start of epoch 57
step 0: mean loss = 0.00078435754
step 100: mean loss = 0.0012292714
step 200: mean loss = 0.0012211833
step 300: mean loss = 0.0012643173
step 400: mean loss = 0.0012853559
step 500: mean loss = 0.001269595
step 600: mean loss = 0.00127733
step 700: mean loss = 0.0012983852
step 800: mean loss = 0.001307817
step 900: mean loss = 0.0013239685
step 1000: mean loss = 0.0013358202
step 1100: mean loss = 0.0013367751
step 1200: mean loss = 0.0013434861
epoch 57: mean loss = 0.001344557  learning rate = 0.00077378086
============================
Start of epoch 58
step 0: mean loss = 0.0013099391
step 100: mean loss = 0.0012577878
step 200: mean loss = 0.0012467026
step 300: mean loss = 0.0012771845
step 400: mean loss = 0.0012689233
step 500: mean loss = 0.0012788243
step 600: mean loss = 0.0012742218
step 700: mean loss = 0.0012683261
step 800: mean loss = 0.0012679988
step 900: mean loss = 0.001275605
step 1000: mean loss = 0.0012958194
step 1100: mean loss = 0.0013098118
step 1200: mean loss = 0.0013018717
epoch 58: mean loss = 0.0013045202  learning rate = 0.00077378086
============================
Start of epoch 59
step 0: mean loss = 0.0017359081
step 100: mean loss = 0.0012745062
step 200: mean loss = 0.0012551496
step 300: mean loss = 0.0012897042
step 400: mean loss = 0.001259402
step 500: mean loss = 0.001282746
step 600: mean loss = 0.0012756777
step 700: mean loss = 0.001262976
step 800: mean loss = 0.0012649294
step 900: mean loss = 0.0012687234
step 1000: mean loss = 0.0012735565
step 1100: mean loss = 0.0012664044
step 1200: mean loss = 0.0012793555
epoch 59: mean loss = 0.0012770204  learning rate = 0.00073509186
============================
Start of epoch 60
step 0: mean loss = 0.0012679567
step 100: mean loss = 0.0012054692
step 200: mean loss = 0.0012496681
step 300: mean loss = 0.0012319065
step 400: mean loss = 0.0012131705
step 500: mean loss = 0.0012429105
step 600: mean loss = 0.001238713
step 700: mean loss = 0.0012354554
step 800: mean loss = 0.0012282301
step 900: mean loss = 0.0012256418
step 1000: mean loss = 0.0012341399
step 1100: mean loss = 0.0012272
step 1200: mean loss = 0.0012266507
epoch 60: mean loss = 0.0012259631  learning rate = 0.00073509186
============================
Start of epoch 61
step 0: mean loss = 0.001591208
step 100: mean loss = 0.0011310388
step 200: mean loss = 0.0012115825
step 300: mean loss = 0.0012156772
step 400: mean loss = 0.0012076865
step 500: mean loss = 0.0011960636
step 600: mean loss = 0.001196778
step 700: mean loss = 0.001190602
step 800: mean loss = 0.0011834357
step 900: mean loss = 0.0011835658
step 1000: mean loss = 0.0011781276
step 1100: mean loss = 0.0011732584
step 1200: mean loss = 0.0011731256
epoch 61: mean loss = 0.0011739024  learning rate = 0.00073509186
============================
Start of epoch 62
step 0: mean loss = 0.0013078176
step 100: mean loss = 0.0011139921
step 200: mean loss = 0.0011012012
step 300: mean loss = 0.001124865
step 400: mean loss = 0.001133424
step 500: mean loss = 0.0011532656
step 600: mean loss = 0.0011777008
step 700: mean loss = 0.0011782125
step 800: mean loss = 0.0011708828
step 900: mean loss = 0.0011752547
step 1000: mean loss = 0.0011807559
step 1100: mean loss = 0.0011953353
step 1200: mean loss = 0.0012019655
epoch 62: mean loss = 0.0011974071  learning rate = 0.00073509186
============================
Start of epoch 63
step 0: mean loss = 0.0010611616
step 100: mean loss = 0.0010599584
step 200: mean loss = 0.0011378207
step 300: mean loss = 0.001198754
step 400: mean loss = 0.0011718803
step 500: mean loss = 0.0011780652
step 600: mean loss = 0.0011834897
step 700: mean loss = 0.0011736703
step 800: mean loss = 0.0011623922
step 900: mean loss = 0.0011620655
step 1000: mean loss = 0.0011624912
step 1100: mean loss = 0.0011562373
step 1200: mean loss = 0.0011595822
epoch 63: mean loss = 0.0011571766  learning rate = 0.00073509186
============================
Start of epoch 64
step 0: mean loss = 0.00074285886
step 100: mean loss = 0.0011259486
step 200: mean loss = 0.0011684311
step 300: mean loss = 0.001195953
step 400: mean loss = 0.0012233875
step 500: mean loss = 0.001214381
step 600: mean loss = 0.0012443648
step 700: mean loss = 0.0012151186
step 800: mean loss = 0.0012022807
step 900: mean loss = 0.0011951807
step 1000: mean loss = 0.0011910126
step 1100: mean loss = 0.001181497
step 1200: mean loss = 0.0011815525
epoch 64: mean loss = 0.0011826925  learning rate = 0.00073509186
============================
Start of epoch 65
step 0: mean loss = 0.0012118528
step 100: mean loss = 0.0010991402
step 200: mean loss = 0.0010822631
step 300: mean loss = 0.0010897228
step 400: mean loss = 0.0011186661
step 500: mean loss = 0.001113791
step 600: mean loss = 0.0011221917
step 700: mean loss = 0.0011152246
step 800: mean loss = 0.0011089261
step 900: mean loss = 0.0011279914
step 1000: mean loss = 0.0011204459
step 1100: mean loss = 0.0011265813
step 1200: mean loss = 0.0011265822
epoch 65: mean loss = 0.0011272891  learning rate = 0.00073509186
============================
Start of epoch 66
step 0: mean loss = 0.0010687136
step 100: mean loss = 0.0012357682
step 200: mean loss = 0.001175521
step 300: mean loss = 0.0011283935
step 400: mean loss = 0.001110261
step 500: mean loss = 0.0011167073
step 600: mean loss = 0.0011403376
step 700: mean loss = 0.0011416246
step 800: mean loss = 0.0011372218
step 900: mean loss = 0.0011284052
step 1000: mean loss = 0.0011139323
step 1100: mean loss = 0.0011207612
step 1200: mean loss = 0.0011162303
epoch 66: mean loss = 0.0011186346  learning rate = 0.00073509186
============================
Start of epoch 67
step 0: mean loss = 0.0012959719
step 100: mean loss = 0.0010960178
step 200: mean loss = 0.0011170227
step 300: mean loss = 0.0010829717
step 400: mean loss = 0.001100679
step 500: mean loss = 0.0010934412
step 600: mean loss = 0.0010920741
step 700: mean loss = 0.0010829571
step 800: mean loss = 0.0010849029
step 900: mean loss = 0.0010953342
step 1000: mean loss = 0.0011039202
step 1100: mean loss = 0.0011091356
step 1200: mean loss = 0.0011026628
epoch 67: mean loss = 0.0011005048  learning rate = 0.00073509186
============================
Start of epoch 68
step 0: mean loss = 0.00097223505
step 100: mean loss = 0.0009820756
step 200: mean loss = 0.0010109046
step 300: mean loss = 0.0010521058
step 400: mean loss = 0.0010590047
step 500: mean loss = 0.0010687166
step 600: mean loss = 0.0010854424
step 700: mean loss = 0.0010855986
step 800: mean loss = 0.0011023412
step 900: mean loss = 0.0011267412
step 1000: mean loss = 0.0011236576
step 1100: mean loss = 0.0011233548
step 1200: mean loss = 0.0011153781
epoch 68: mean loss = 0.0011171615  learning rate = 0.00073509186
============================
Start of epoch 69
step 0: mean loss = 0.0009028213
step 100: mean loss = 0.0010490295
step 200: mean loss = 0.0010184413
step 300: mean loss = 0.0010897865
step 400: mean loss = 0.0011005267
step 500: mean loss = 0.0010873275
step 600: mean loss = 0.0010761768
step 700: mean loss = 0.0010826805
step 800: mean loss = 0.0010780744
step 900: mean loss = 0.00108591
step 1000: mean loss = 0.0010917375
step 1100: mean loss = 0.001085837
step 1200: mean loss = 0.0010830937
epoch 69: mean loss = 0.0010823944  learning rate = 0.0006983372
============================
Start of epoch 70
step 0: mean loss = 0.0008106863
step 100: mean loss = 0.0010491639
step 200: mean loss = 0.0010353974
step 300: mean loss = 0.0010019573
step 400: mean loss = 0.001005658
step 500: mean loss = 0.0010342526
step 600: mean loss = 0.0010273242
step 700: mean loss = 0.0010304291
step 800: mean loss = 0.001024969
step 900: mean loss = 0.0010161953
step 1000: mean loss = 0.001020441
step 1100: mean loss = 0.0010278126
step 1200: mean loss = 0.0010289847
epoch 70: mean loss = 0.0010291351  learning rate = 0.0006983372
============================
Start of epoch 71
step 0: mean loss = 0.00048317655
step 100: mean loss = 0.000965431
step 200: mean loss = 0.00097583805
step 300: mean loss = 0.0009961344
step 400: mean loss = 0.0009855283
step 500: mean loss = 0.0009776857
step 600: mean loss = 0.000999354
step 700: mean loss = 0.0009919103
step 800: mean loss = 0.0009882767
step 900: mean loss = 0.0009925113
step 1000: mean loss = 0.0009921662
step 1100: mean loss = 0.0009945172
step 1200: mean loss = 0.001001816
epoch 71: mean loss = 0.0010004097  learning rate = 0.0006983372
============================
Start of epoch 72
step 0: mean loss = 0.0011160745
step 100: mean loss = 0.0010058432
step 200: mean loss = 0.0010532164
step 300: mean loss = 0.0010553843
step 400: mean loss = 0.0010507578
step 500: mean loss = 0.0010639867
step 600: mean loss = 0.00105279
step 700: mean loss = 0.0010446687
step 800: mean loss = 0.0010353355
step 900: mean loss = 0.0010251277
step 1000: mean loss = 0.0010184583
step 1100: mean loss = 0.0010108434
step 1200: mean loss = 0.0010142354
epoch 72: mean loss = 0.0010092322  learning rate = 0.0006983372
============================
Start of epoch 73
step 0: mean loss = 0.0007147297
step 100: mean loss = 0.0009654683
step 200: mean loss = 0.0010216717
step 300: mean loss = 0.0010220979
step 400: mean loss = 0.0010355676
step 500: mean loss = 0.001021261
step 600: mean loss = 0.0010022542
step 700: mean loss = 0.0009950129
step 800: mean loss = 0.0009881983
step 900: mean loss = 0.0009906468
step 1000: mean loss = 0.0009853487
step 1100: mean loss = 0.0009903334
step 1200: mean loss = 0.0009903869
epoch 73: mean loss = 0.0009855957  learning rate = 0.0006983372
============================
Start of epoch 74
step 0: mean loss = 0.0009887075
step 100: mean loss = 0.0010160656
step 200: mean loss = 0.001039564
step 300: mean loss = 0.0010292963
step 400: mean loss = 0.0010393838
step 500: mean loss = 0.0010297266
step 600: mean loss = 0.0010250628
step 700: mean loss = 0.0010390452
step 800: mean loss = 0.0010298181
step 900: mean loss = 0.0010196287
step 1000: mean loss = 0.0010180136
step 1100: mean loss = 0.0010231694
step 1200: mean loss = 0.0010162047
epoch 74: mean loss = 0.0010123223  learning rate = 0.0006983372
============================
Start of epoch 75
step 0: mean loss = 0.0011571025
step 100: mean loss = 0.0009209848
step 200: mean loss = 0.00092190143
step 300: mean loss = 0.0009243949
step 400: mean loss = 0.0009194395
step 500: mean loss = 0.00092755683
step 600: mean loss = 0.00095597777
step 700: mean loss = 0.00095969223
step 800: mean loss = 0.00095713243
step 900: mean loss = 0.00095382833
step 1000: mean loss = 0.00096108374
step 1100: mean loss = 0.0009630113
step 1200: mean loss = 0.0009659485
epoch 75: mean loss = 0.00096707547  learning rate = 0.0006983372
============================
Start of epoch 76
step 0: mean loss = 0.0011843215
step 100: mean loss = 0.0009477092
step 200: mean loss = 0.000995983
step 300: mean loss = 0.00095868774
step 400: mean loss = 0.0009429656
step 500: mean loss = 0.0009449004
step 600: mean loss = 0.0009616389
step 700: mean loss = 0.00097268616
step 800: mean loss = 0.00097439525
step 900: mean loss = 0.0009632637
step 1000: mean loss = 0.0009650366
step 1100: mean loss = 0.00096256717
step 1200: mean loss = 0.00095536956
epoch 76: mean loss = 0.00095601176  learning rate = 0.0006983372
============================
Start of epoch 77
step 0: mean loss = 0.00084754045
step 100: mean loss = 0.0009281109
step 200: mean loss = 0.0009233298
step 300: mean loss = 0.0009473075
step 400: mean loss = 0.0009401942
step 500: mean loss = 0.00094492064
step 600: mean loss = 0.0009617979
step 700: mean loss = 0.00095644285
step 800: mean loss = 0.00096477655
step 900: mean loss = 0.00096995005
step 1000: mean loss = 0.0009709969
step 1100: mean loss = 0.0009697275
step 1200: mean loss = 0.00097537925
epoch 77: mean loss = 0.00097459747  learning rate = 0.0006983372
============================
Start of epoch 78
step 0: mean loss = 0.0010035946
step 100: mean loss = 0.0009377345
step 200: mean loss = 0.000910598
step 300: mean loss = 0.0009556633
step 400: mean loss = 0.0009422636
step 500: mean loss = 0.00094365556
step 600: mean loss = 0.00094778655
step 700: mean loss = 0.00096060964
step 800: mean loss = 0.00094908365
step 900: mean loss = 0.0009404035
step 1000: mean loss = 0.00093470945
step 1100: mean loss = 0.0009399125
step 1200: mean loss = 0.0009375846
epoch 78: mean loss = 0.0009381768  learning rate = 0.0006983372
============================
Start of epoch 79
step 0: mean loss = 0.0012030695
step 100: mean loss = 0.0009206163
step 200: mean loss = 0.0009221522
step 300: mean loss = 0.0009415288
step 400: mean loss = 0.00096016744
step 500: mean loss = 0.0009527428
step 600: mean loss = 0.0009403299
step 700: mean loss = 0.00094144506
step 800: mean loss = 0.0009412673
step 900: mean loss = 0.0009358488
step 1000: mean loss = 0.00094456965
step 1100: mean loss = 0.0009444699
step 1200: mean loss = 0.0009448427
epoch 79: mean loss = 0.0009450197  learning rate = 0.00066342036
============================
Start of epoch 80
step 0: mean loss = 0.0007777035
step 100: mean loss = 0.0008259993
step 200: mean loss = 0.0008246381
step 300: mean loss = 0.00084579404
step 400: mean loss = 0.0008731533
step 500: mean loss = 0.0008816214
step 600: mean loss = 0.000881623
step 700: mean loss = 0.00088231097
step 800: mean loss = 0.00088250375
step 900: mean loss = 0.000877422
step 1000: mean loss = 0.0008763962
step 1100: mean loss = 0.0008731318
step 1200: mean loss = 0.0008753141
epoch 80: mean loss = 0.00087705266  learning rate = 0.00066342036
============================
Start of epoch 81
step 0: mean loss = 0.0009776708
step 100: mean loss = 0.0007969596
step 200: mean loss = 0.0008639262
step 300: mean loss = 0.00086345227
step 400: mean loss = 0.00088638085
step 500: mean loss = 0.00088541885
step 600: mean loss = 0.0008810352
step 700: mean loss = 0.0008729346
step 800: mean loss = 0.00086916715
step 900: mean loss = 0.00086673524
step 1000: mean loss = 0.0008786311
step 1100: mean loss = 0.00087979133
step 1200: mean loss = 0.0008772817
epoch 81: mean loss = 0.00087813433  learning rate = 0.00066342036
============================
Start of epoch 82
step 0: mean loss = 0.0010664589
step 100: mean loss = 0.0010138664
step 200: mean loss = 0.00093638065
step 300: mean loss = 0.00089066837
step 400: mean loss = 0.00090240035
step 500: mean loss = 0.00087924063
step 600: mean loss = 0.0008655637
step 700: mean loss = 0.0008599003
step 800: mean loss = 0.00086318585
step 900: mean loss = 0.0008745314
step 1000: mean loss = 0.00088270666
step 1100: mean loss = 0.00088648393
step 1200: mean loss = 0.0008862741
epoch 82: mean loss = 0.0008916405  learning rate = 0.00066342036
============================
Start of epoch 83
step 0: mean loss = 0.0009955524
step 100: mean loss = 0.00082902506
step 200: mean loss = 0.0008859794
step 300: mean loss = 0.0008710884
step 400: mean loss = 0.00086168904
step 500: mean loss = 0.0008694642
step 600: mean loss = 0.0008672083
step 700: mean loss = 0.00086643983
step 800: mean loss = 0.00086702243
step 900: mean loss = 0.00086876855
step 1000: mean loss = 0.00086825993
step 1100: mean loss = 0.00087260385
step 1200: mean loss = 0.0008696934
epoch 83: mean loss = 0.000870158  learning rate = 0.00066342036
============================
Start of epoch 84
step 0: mean loss = 0.00067371863
step 100: mean loss = 0.0008736754
step 200: mean loss = 0.0008854842
step 300: mean loss = 0.0008685881
step 400: mean loss = 0.0008668255
step 500: mean loss = 0.0008585672
step 600: mean loss = 0.0008662104
step 700: mean loss = 0.0008664684
step 800: mean loss = 0.0008663581
step 900: mean loss = 0.00086169376
step 1000: mean loss = 0.000860482
step 1100: mean loss = 0.0008570222
step 1200: mean loss = 0.00085890817
epoch 84: mean loss = 0.0008616123  learning rate = 0.00066342036
============================
Start of epoch 85
step 0: mean loss = 0.0010777144
step 100: mean loss = 0.0008637298
step 200: mean loss = 0.00088292634
step 300: mean loss = 0.00092176313
step 400: mean loss = 0.0009039517
step 500: mean loss = 0.00091967505
step 600: mean loss = 0.000911709
step 700: mean loss = 0.0008977356
step 800: mean loss = 0.0008843944
step 900: mean loss = 0.00088067184
step 1000: mean loss = 0.0008776671
step 1100: mean loss = 0.0008740993
step 1200: mean loss = 0.0008701235
epoch 85: mean loss = 0.0008682272  learning rate = 0.00066342036
============================
Start of epoch 86
step 0: mean loss = 0.0005780017
step 100: mean loss = 0.0007730893
step 200: mean loss = 0.0008132612
step 300: mean loss = 0.00086407864
step 400: mean loss = 0.00086578884
step 500: mean loss = 0.00085901655
step 600: mean loss = 0.0008579435
step 700: mean loss = 0.0008596148
step 800: mean loss = 0.0008519634
step 900: mean loss = 0.0008453179
step 1000: mean loss = 0.0008455769
step 1100: mean loss = 0.00084923726
step 1200: mean loss = 0.0008531681
epoch 86: mean loss = 0.0008525039  learning rate = 0.00066342036
============================
Start of epoch 87
step 0: mean loss = 0.0008451552
step 100: mean loss = 0.00082967133
step 200: mean loss = 0.0007940213
step 300: mean loss = 0.0008141453
step 400: mean loss = 0.00081641047
step 500: mean loss = 0.0008209943
step 600: mean loss = 0.0008269718
step 700: mean loss = 0.0008269209
step 800: mean loss = 0.00082715927
step 900: mean loss = 0.00084354915
step 1000: mean loss = 0.00084555056
step 1100: mean loss = 0.00084809953
step 1200: mean loss = 0.00084211683
epoch 87: mean loss = 0.0008417368  learning rate = 0.00066342036
============================
Start of epoch 88
step 0: mean loss = 0.0009139711
step 100: mean loss = 0.0009197819
step 200: mean loss = 0.0008664028
step 300: mean loss = 0.0008523482
step 400: mean loss = 0.00085059454
step 500: mean loss = 0.0008525163
step 600: mean loss = 0.00086063304
step 700: mean loss = 0.00085370237
step 800: mean loss = 0.00084241485
step 900: mean loss = 0.00084052776
step 1000: mean loss = 0.0008436716
step 1100: mean loss = 0.000835863
step 1200: mean loss = 0.00083077943
epoch 88: mean loss = 0.0008289417  learning rate = 0.00066342036
============================
Start of epoch 89
step 0: mean loss = 0.0008869887
step 100: mean loss = 0.0008297363
step 200: mean loss = 0.00083228137
step 300: mean loss = 0.0008417064
step 400: mean loss = 0.00085517473
step 500: mean loss = 0.0008402751
step 600: mean loss = 0.000832306
step 700: mean loss = 0.00084123353
step 800: mean loss = 0.0008369495
step 900: mean loss = 0.000844504
step 1000: mean loss = 0.00085834885
step 1100: mean loss = 0.0008481134
step 1200: mean loss = 0.00084638
epoch 89: mean loss = 0.00084171316  learning rate = 0.0006302493
============================
Start of epoch 90
step 0: mean loss = 0.0005000342
step 100: mean loss = 0.0006882746
step 200: mean loss = 0.00069859973
step 300: mean loss = 0.000720954
step 400: mean loss = 0.000750575
step 500: mean loss = 0.0007568613
step 600: mean loss = 0.0007536014
step 700: mean loss = 0.0007623574
step 800: mean loss = 0.0007720771
step 900: mean loss = 0.0007776752
step 1000: mean loss = 0.0007806398
step 1100: mean loss = 0.0007812884
step 1200: mean loss = 0.0007821844
epoch 90: mean loss = 0.0007867665  learning rate = 0.0006302493
============================
Start of epoch 91
step 0: mean loss = 0.0008506809
step 100: mean loss = 0.00074821856
step 200: mean loss = 0.00075342605
step 300: mean loss = 0.00076990674
step 400: mean loss = 0.00079436944
step 500: mean loss = 0.0007903904
step 600: mean loss = 0.0008003255
step 700: mean loss = 0.0007996122
step 800: mean loss = 0.0007876577
step 900: mean loss = 0.00078607583
step 1000: mean loss = 0.00077572186
step 1100: mean loss = 0.0007725408
step 1200: mean loss = 0.00077451306
epoch 91: mean loss = 0.0007776167  learning rate = 0.0006302493
============================
Start of epoch 92
step 0: mean loss = 0.00070112094
step 100: mean loss = 0.0007650303
step 200: mean loss = 0.0007914847
step 300: mean loss = 0.0008039878
step 400: mean loss = 0.0007894527
step 500: mean loss = 0.0007753575
step 600: mean loss = 0.00077143323
step 700: mean loss = 0.0007761676
step 800: mean loss = 0.0007911894
step 900: mean loss = 0.0007865258
step 1000: mean loss = 0.00078883173
step 1100: mean loss = 0.0007861659
step 1200: mean loss = 0.0007848391
epoch 92: mean loss = 0.0007817767  learning rate = 0.0006302493
============================
Start of epoch 93
step 0: mean loss = 0.00062086154
step 100: mean loss = 0.0006890971
step 200: mean loss = 0.00072000915
step 300: mean loss = 0.0007264615
step 400: mean loss = 0.00074072555
step 500: mean loss = 0.0007535441
step 600: mean loss = 0.00077057787
step 700: mean loss = 0.00077646645
step 800: mean loss = 0.0007866416
step 900: mean loss = 0.0007929642
step 1000: mean loss = 0.000790762
step 1100: mean loss = 0.00079578627
step 1200: mean loss = 0.0007919545
epoch 93: mean loss = 0.0007931667  learning rate = 0.0006302493
============================
Start of epoch 94
step 0: mean loss = 0.00082316
step 100: mean loss = 0.00067158125
step 200: mean loss = 0.0007194622
step 300: mean loss = 0.00075829093
step 400: mean loss = 0.0007574585
step 500: mean loss = 0.00076569594
step 600: mean loss = 0.00075680995
step 700: mean loss = 0.00076645706
step 800: mean loss = 0.0007676237
step 900: mean loss = 0.0007644837
step 1000: mean loss = 0.0007677895
step 1100: mean loss = 0.0007698209
step 1200: mean loss = 0.0007706629
epoch 94: mean loss = 0.0007710314  learning rate = 0.0006302493
============================
Start of epoch 95
step 0: mean loss = 0.00093646266
step 100: mean loss = 0.00075248594
step 200: mean loss = 0.00073551165
step 300: mean loss = 0.00074477715
step 400: mean loss = 0.0007370492
step 500: mean loss = 0.0007458046
step 600: mean loss = 0.0007456492
step 700: mean loss = 0.00076136267
step 800: mean loss = 0.0007624953
step 900: mean loss = 0.0007688536
step 1000: mean loss = 0.0007774133
step 1100: mean loss = 0.0007804039
step 1200: mean loss = 0.0007749236
epoch 95: mean loss = 0.00077365834  learning rate = 0.0006302493
============================
Start of epoch 96
step 0: mean loss = 0.00052696373
step 100: mean loss = 0.0007219586
step 200: mean loss = 0.00073063886
step 300: mean loss = 0.0007199843
step 400: mean loss = 0.00074093783
step 500: mean loss = 0.0007461597
step 600: mean loss = 0.0007543706
step 700: mean loss = 0.0007544716
step 800: mean loss = 0.00074851036
step 900: mean loss = 0.00074356986
step 1000: mean loss = 0.0007575968
step 1100: mean loss = 0.00075234135
step 1200: mean loss = 0.0007540188
epoch 96: mean loss = 0.00075465866  learning rate = 0.0006302493
============================
Start of epoch 97
step 0: mean loss = 0.0010327585
step 100: mean loss = 0.00077887025
step 200: mean loss = 0.0007365243
step 300: mean loss = 0.0007293336
step 400: mean loss = 0.000737546
step 500: mean loss = 0.0007438196
step 600: mean loss = 0.0007450408
step 700: mean loss = 0.0007425523
step 800: mean loss = 0.0007441956
step 900: mean loss = 0.0007394148
step 1000: mean loss = 0.0007432982
step 1100: mean loss = 0.0007387778
step 1200: mean loss = 0.0007421657
epoch 97: mean loss = 0.00074165454  learning rate = 0.0006302493
============================
Start of epoch 98
step 0: mean loss = 0.00067878526
step 100: mean loss = 0.000710512
step 200: mean loss = 0.00075812446
step 300: mean loss = 0.0007818481
step 400: mean loss = 0.0007705025
step 500: mean loss = 0.0007546339
step 600: mean loss = 0.00075862097
step 700: mean loss = 0.0007528711
step 800: mean loss = 0.00075136946
step 900: mean loss = 0.00075127906
step 1000: mean loss = 0.0007587944
step 1100: mean loss = 0.00076327426
step 1200: mean loss = 0.0007654019
epoch 98: mean loss = 0.0007648097  learning rate = 0.0006302493
============================
Start of epoch 99
step 0: mean loss = 0.0007747449
step 100: mean loss = 0.0007732384
step 200: mean loss = 0.00077865657
step 300: mean loss = 0.0007620718
step 400: mean loss = 0.0007544704
step 500: mean loss = 0.0007558632
step 600: mean loss = 0.0007604473
step 700: mean loss = 0.00074761105
step 800: mean loss = 0.0007490645
step 900: mean loss = 0.000751067
step 1000: mean loss = 0.00075409445
step 1100: mean loss = 0.0007517808
step 1200: mean loss = 0.00075504574
epoch 99: mean loss = 0.00075665925  learning rate = 0.00059873686
============================
Start of epoch 100
step 0: mean loss = 0.0007421528
step 100: mean loss = 0.0006806278
step 200: mean loss = 0.0006689198
step 300: mean loss = 0.0006918548
step 400: mean loss = 0.00070517376
step 500: mean loss = 0.00071180856
step 600: mean loss = 0.0007065757
step 700: mean loss = 0.0006969408
step 800: mean loss = 0.00070291455
step 900: mean loss = 0.0007051515
step 1000: mean loss = 0.00070287695
step 1100: mean loss = 0.0007104124
step 1200: mean loss = 0.00070734305
epoch 100: mean loss = 0.0007063751  learning rate = 0.00059873686
============================
Start of epoch 101
step 0: mean loss = 0.000716581
step 100: mean loss = 0.000729442
step 200: mean loss = 0.0007357674
step 300: mean loss = 0.00074930175
step 400: mean loss = 0.00072104903
step 500: mean loss = 0.00072421756
step 600: mean loss = 0.0007235059
step 700: mean loss = 0.0007246117
step 800: mean loss = 0.00072569435
step 900: mean loss = 0.00072582194
step 1000: mean loss = 0.0007217956
step 1100: mean loss = 0.0007235453
step 1200: mean loss = 0.000720149
epoch 101: mean loss = 0.00071860844  learning rate = 0.00059873686
============================
Start of epoch 102
step 0: mean loss = 0.0006282226
step 100: mean loss = 0.00065352855
step 200: mean loss = 0.00069523026
step 300: mean loss = 0.0007032305
step 400: mean loss = 0.0007051761
step 500: mean loss = 0.0007210906
step 600: mean loss = 0.0007183842
step 700: mean loss = 0.00071823504
step 800: mean loss = 0.0007064323
step 900: mean loss = 0.00071304495
step 1000: mean loss = 0.00071069313
step 1100: mean loss = 0.00071866676
step 1200: mean loss = 0.0007143806
epoch 102: mean loss = 0.0007158849  learning rate = 0.00059873686
============================
Start of epoch 103
step 0: mean loss = 0.0006376617
step 100: mean loss = 0.00068730646
step 200: mean loss = 0.00067354925
step 300: mean loss = 0.0007106476
step 400: mean loss = 0.0006999933
step 500: mean loss = 0.00068936736
step 600: mean loss = 0.0006856187
step 700: mean loss = 0.0006808082
step 800: mean loss = 0.00067532255
step 900: mean loss = 0.00067840115
step 1000: mean loss = 0.0006844953
step 1100: mean loss = 0.0006869474
step 1200: mean loss = 0.00068762666
epoch 103: mean loss = 0.00069030386  learning rate = 0.00059873686
============================
Start of epoch 104
step 0: mean loss = 0.00087592175
step 100: mean loss = 0.00073874515
step 200: mean loss = 0.0007371076
step 300: mean loss = 0.0007372516
step 400: mean loss = 0.00071492477
step 500: mean loss = 0.00070784293
step 600: mean loss = 0.0007060133
step 700: mean loss = 0.00071677525
step 800: mean loss = 0.00072194455
step 900: mean loss = 0.0007132775
step 1000: mean loss = 0.0007093898
step 1100: mean loss = 0.0007072016
step 1200: mean loss = 0.0007078017
epoch 104: mean loss = 0.00070557406  learning rate = 0.00059873686
============================
Start of epoch 105
step 0: mean loss = 0.00065195444
step 100: mean loss = 0.0007447332
step 200: mean loss = 0.00069661497
step 300: mean loss = 0.00069232413
step 400: mean loss = 0.0006862796
step 500: mean loss = 0.00069569086
step 600: mean loss = 0.0006933235
step 700: mean loss = 0.00069021096
step 800: mean loss = 0.0006938098
step 900: mean loss = 0.00069877063
step 1000: mean loss = 0.00070039416
step 1100: mean loss = 0.0007025338
step 1200: mean loss = 0.0007028995
epoch 105: mean loss = 0.0007004408  learning rate = 0.00059873686
============================
Start of epoch 106
step 0: mean loss = 0.00048567168
step 100: mean loss = 0.00069475645
step 200: mean loss = 0.0006491108
step 300: mean loss = 0.000633994
step 400: mean loss = 0.000646374
step 500: mean loss = 0.0006509714
step 600: mean loss = 0.0006681676
step 700: mean loss = 0.0006779395
step 800: mean loss = 0.00067696196
step 900: mean loss = 0.0006807896
step 1000: mean loss = 0.00068674434
step 1100: mean loss = 0.0006866032
step 1200: mean loss = 0.00068873697
epoch 106: mean loss = 0.00068810204  learning rate = 0.00059873686
============================
Start of epoch 107
step 0: mean loss = 0.0006584176
step 100: mean loss = 0.000762574
step 200: mean loss = 0.0007113489
step 300: mean loss = 0.00070480513
step 400: mean loss = 0.00069919176
step 500: mean loss = 0.00070241594
step 600: mean loss = 0.0007129712
step 700: mean loss = 0.0007136556
step 800: mean loss = 0.00070285023
step 900: mean loss = 0.00070548884
step 1000: mean loss = 0.00070331764
step 1100: mean loss = 0.0007062452
step 1200: mean loss = 0.0007057928
epoch 107: mean loss = 0.00070404256  learning rate = 0.00059873686
============================
Start of epoch 108
step 0: mean loss = 0.00068307173
step 100: mean loss = 0.0006747266
step 200: mean loss = 0.00065980427
step 300: mean loss = 0.0006489252
step 400: mean loss = 0.0006460069
step 500: mean loss = 0.00064771244
step 600: mean loss = 0.00065312476
step 700: mean loss = 0.00066695333
step 800: mean loss = 0.0006664615
step 900: mean loss = 0.00067490817
step 1000: mean loss = 0.00067930744
step 1100: mean loss = 0.0006845545
step 1200: mean loss = 0.0006804262
epoch 108: mean loss = 0.0006791019  learning rate = 0.00059873686
============================
Start of epoch 109
step 0: mean loss = 0.0006648053
step 100: mean loss = 0.0006613008
step 200: mean loss = 0.00067681354
step 300: mean loss = 0.000669646
step 400: mean loss = 0.00067333784
step 500: mean loss = 0.00067541155
step 600: mean loss = 0.0006766139
step 700: mean loss = 0.0006797953
step 800: mean loss = 0.0006747384
step 900: mean loss = 0.0006787856
step 1000: mean loss = 0.0006812231
step 1100: mean loss = 0.00067657867
step 1200: mean loss = 0.00067401887
epoch 109: mean loss = 0.00067512476  learning rate = 0.0005688
============================
Start of epoch 110
step 0: mean loss = 0.00070523727
step 100: mean loss = 0.0006421421
step 200: mean loss = 0.0006330948
step 300: mean loss = 0.00065467606
step 400: mean loss = 0.0006383031
step 500: mean loss = 0.00064397027
step 600: mean loss = 0.00064152584
step 700: mean loss = 0.0006422103
step 800: mean loss = 0.00064373435
step 900: mean loss = 0.00064920925
step 1000: mean loss = 0.0006458979
step 1100: mean loss = 0.00064923277
step 1200: mean loss = 0.00064929057
epoch 110: mean loss = 0.00065134757  learning rate = 0.0005688
============================
Start of epoch 111
step 0: mean loss = 0.00063206453
step 100: mean loss = 0.0006250284
step 200: mean loss = 0.00060568895
step 300: mean loss = 0.00062208076
step 400: mean loss = 0.0006173895
step 500: mean loss = 0.0006210299
step 600: mean loss = 0.000628667
step 700: mean loss = 0.0006297375
step 800: mean loss = 0.0006313013
step 900: mean loss = 0.00063493155
step 1000: mean loss = 0.0006356294
step 1100: mean loss = 0.0006434959
step 1200: mean loss = 0.0006469532
epoch 111: mean loss = 0.0006454281  learning rate = 0.0005688
============================
Start of epoch 112
step 0: mean loss = 0.0006505166
step 100: mean loss = 0.0006066403
step 200: mean loss = 0.0006157341
step 300: mean loss = 0.0006216472
step 400: mean loss = 0.0006233308
step 500: mean loss = 0.00063286
step 600: mean loss = 0.00062864803
step 700: mean loss = 0.00062964996
step 800: mean loss = 0.00063474616
step 900: mean loss = 0.0006367749
step 1000: mean loss = 0.00063924276
step 1100: mean loss = 0.0006463456
step 1200: mean loss = 0.0006471458
epoch 112: mean loss = 0.0006487215  learning rate = 0.0005688
============================
Start of epoch 113
step 0: mean loss = 0.0005589596
step 100: mean loss = 0.00063191855
step 200: mean loss = 0.0006513346
step 300: mean loss = 0.00065413787
step 400: mean loss = 0.00064210483
step 500: mean loss = 0.0006458002
step 600: mean loss = 0.0006540149
step 700: mean loss = 0.00064672437
step 800: mean loss = 0.0006427618
step 900: mean loss = 0.00063842104
step 1000: mean loss = 0.00064407114
step 1100: mean loss = 0.0006440712
step 1200: mean loss = 0.0006414643
epoch 113: mean loss = 0.00064547505  learning rate = 0.0005688
============================
Start of epoch 114
step 0: mean loss = 0.000502076
step 100: mean loss = 0.00063780445
step 200: mean loss = 0.0006242193
step 300: mean loss = 0.00061820267
step 400: mean loss = 0.00062766304
step 500: mean loss = 0.0006249833
step 600: mean loss = 0.00064453617
step 700: mean loss = 0.0006410448
step 800: mean loss = 0.0006439461
step 900: mean loss = 0.0006508669
step 1000: mean loss = 0.0006503498
step 1100: mean loss = 0.00065118866
step 1200: mean loss = 0.0006470107
epoch 114: mean loss = 0.00064445543  learning rate = 0.0005688
============================
Start of epoch 115
step 0: mean loss = 0.0005200017
step 100: mean loss = 0.00057264685
step 200: mean loss = 0.00059821736
step 300: mean loss = 0.0006009694
step 400: mean loss = 0.0006055247
step 500: mean loss = 0.00060642505
step 600: mean loss = 0.000605654
step 700: mean loss = 0.0006034483
step 800: mean loss = 0.0006081783
step 900: mean loss = 0.00060799974
step 1000: mean loss = 0.00061297836
step 1100: mean loss = 0.0006247802
step 1200: mean loss = 0.00061946595
epoch 115: mean loss = 0.0006189547  learning rate = 0.0005688
============================
Start of epoch 116
step 0: mean loss = 0.0005480511
step 100: mean loss = 0.00066159526
step 200: mean loss = 0.0006830608
step 300: mean loss = 0.00066119246
step 400: mean loss = 0.0006508904
step 500: mean loss = 0.00063393096
step 600: mean loss = 0.00063101447
step 700: mean loss = 0.0006277666
step 800: mean loss = 0.00063452544
step 900: mean loss = 0.0006351452
step 1000: mean loss = 0.0006318013
step 1100: mean loss = 0.00062854565
step 1200: mean loss = 0.00062718213
epoch 116: mean loss = 0.00062770856  learning rate = 0.0005688
============================
Start of epoch 117
step 0: mean loss = 0.0006888114
step 100: mean loss = 0.00058873254
step 200: mean loss = 0.00059807254
step 300: mean loss = 0.00060185615
step 400: mean loss = 0.0006002325
step 500: mean loss = 0.00060974446
step 600: mean loss = 0.0006125008
step 700: mean loss = 0.0006244484
step 800: mean loss = 0.00061889127
step 900: mean loss = 0.00062021666
step 1000: mean loss = 0.00062813424
step 1100: mean loss = 0.00062927837
step 1200: mean loss = 0.00063102506
epoch 117: mean loss = 0.0006284361  learning rate = 0.0005688
============================
Start of epoch 118
step 0: mean loss = 0.0006436381
step 100: mean loss = 0.0006089729
step 200: mean loss = 0.0006329577
step 300: mean loss = 0.0006153675
step 400: mean loss = 0.00060761196
step 500: mean loss = 0.00061474496
step 600: mean loss = 0.0006218892
step 700: mean loss = 0.00062113686
step 800: mean loss = 0.0006257292
step 900: mean loss = 0.00062356045
step 1000: mean loss = 0.0006216711
step 1100: mean loss = 0.00061855227
step 1200: mean loss = 0.00061429007
epoch 118: mean loss = 0.00061518466  learning rate = 0.0005688
============================
Start of epoch 119
step 0: mean loss = 0.0006035213
step 100: mean loss = 0.0006148694
step 200: mean loss = 0.00061838765
step 300: mean loss = 0.00059265614
step 400: mean loss = 0.00058337813
step 500: mean loss = 0.0005818669
step 600: mean loss = 0.0005956735
step 700: mean loss = 0.0005997307
step 800: mean loss = 0.0006008718
step 900: mean loss = 0.0006012555
step 1000: mean loss = 0.0006052048
step 1100: mean loss = 0.0006101743
step 1200: mean loss = 0.00061012956
epoch 119: mean loss = 0.00060925086  learning rate = 0.00054036005
============================
Start of epoch 120
step 0: mean loss = 0.0005779084
step 100: mean loss = 0.0005880479
step 200: mean loss = 0.0006070688
step 300: mean loss = 0.0005846939
step 400: mean loss = 0.0005775818
step 500: mean loss = 0.0005692179
step 600: mean loss = 0.00057187956
step 700: mean loss = 0.0005759876
step 800: mean loss = 0.00057411805
step 900: mean loss = 0.0005769938
step 1000: mean loss = 0.00057644217
step 1100: mean loss = 0.0005807207
step 1200: mean loss = 0.00057721906
epoch 120: mean loss = 0.0005796081  learning rate = 0.00054036005
============================
Start of epoch 121
step 0: mean loss = 0.0007635979
step 100: mean loss = 0.0006694982
step 200: mean loss = 0.0006885721
step 300: mean loss = 0.00064804597
step 400: mean loss = 0.00063296634
step 500: mean loss = 0.0006187031
step 600: mean loss = 0.0006056493
step 700: mean loss = 0.0006009336
step 800: mean loss = 0.0006065348
step 900: mean loss = 0.00060058665
step 1000: mean loss = 0.0006029537
step 1100: mean loss = 0.00059922173
step 1200: mean loss = 0.0005970122
epoch 121: mean loss = 0.0005952365  learning rate = 0.00054036005
============================
Start of epoch 122
step 0: mean loss = 0.000916166
step 100: mean loss = 0.0005609996
step 200: mean loss = 0.0005967899
step 300: mean loss = 0.00059508806
step 400: mean loss = 0.0005796198
step 500: mean loss = 0.0005753956
step 600: mean loss = 0.00058422575
step 700: mean loss = 0.00058667845
step 800: mean loss = 0.0005890828
step 900: mean loss = 0.00058424135
step 1000: mean loss = 0.0005820293
step 1100: mean loss = 0.00058134925
step 1200: mean loss = 0.0005842506
epoch 122: mean loss = 0.00058270065  learning rate = 0.00054036005
============================
Start of epoch 123
step 0: mean loss = 0.00047253782
step 100: mean loss = 0.00052638125
step 200: mean loss = 0.0005411074
step 300: mean loss = 0.0005587889
step 400: mean loss = 0.00057037326
step 500: mean loss = 0.00055652804
step 600: mean loss = 0.00056739233
step 700: mean loss = 0.00056873454
step 800: mean loss = 0.00056906714
step 900: mean loss = 0.0005682332
step 1000: mean loss = 0.00056973303
step 1100: mean loss = 0.00057304924
step 1200: mean loss = 0.0005760308
epoch 123: mean loss = 0.00057371653  learning rate = 0.00054036005
============================
Start of epoch 124
step 0: mean loss = 0.00056531787
step 100: mean loss = 0.0005054653
step 200: mean loss = 0.00051926967
step 300: mean loss = 0.0005256867
step 400: mean loss = 0.0005221138
step 500: mean loss = 0.00053780817
step 600: mean loss = 0.0005511925
step 700: mean loss = 0.000559972
step 800: mean loss = 0.0005553585
step 900: mean loss = 0.00055658544
step 1000: mean loss = 0.0005606703
step 1100: mean loss = 0.0005601413
step 1200: mean loss = 0.0005638621
epoch 124: mean loss = 0.0005659291  learning rate = 0.00054036005
============================
Start of epoch 125
step 0: mean loss = 0.00050949614
step 100: mean loss = 0.0005384933
step 200: mean loss = 0.0005280625
step 300: mean loss = 0.0005611937
step 400: mean loss = 0.0005464227
step 500: mean loss = 0.0005441582
step 600: mean loss = 0.000540119
step 700: mean loss = 0.00054523535
step 800: mean loss = 0.0005451437
step 900: mean loss = 0.0005535463
step 1000: mean loss = 0.0005521341
step 1100: mean loss = 0.000550143
step 1200: mean loss = 0.0005501207
epoch 125: mean loss = 0.00055122166  learning rate = 0.00054036005
============================
Start of epoch 126
step 0: mean loss = 0.00046627678
step 100: mean loss = 0.0004937008
step 200: mean loss = 0.00057261786
step 300: mean loss = 0.0005734475
step 400: mean loss = 0.0005834989
step 500: mean loss = 0.0005769004
step 600: mean loss = 0.000578431
step 700: mean loss = 0.0005747667
step 800: mean loss = 0.0005690355
step 900: mean loss = 0.0005692404
step 1000: mean loss = 0.0005672262
step 1100: mean loss = 0.00056287105
step 1200: mean loss = 0.00057042734
epoch 126: mean loss = 0.0005705449  learning rate = 0.00054036005
============================
Start of epoch 127
step 0: mean loss = 0.00064070104
step 100: mean loss = 0.00058030814
step 200: mean loss = 0.000558459
step 300: mean loss = 0.0005605552
step 400: mean loss = 0.0005673781
step 500: mean loss = 0.00058598845
step 600: mean loss = 0.00057621277
step 700: mean loss = 0.0005750508
step 800: mean loss = 0.0005804458
step 900: mean loss = 0.0005778843
step 1000: mean loss = 0.0005770698
step 1100: mean loss = 0.0005786652
step 1200: mean loss = 0.00057731644
epoch 127: mean loss = 0.00057743094  learning rate = 0.00054036005
============================
Start of epoch 128
step 0: mean loss = 0.0006133141
step 100: mean loss = 0.0005026826
step 200: mean loss = 0.0005049207
step 300: mean loss = 0.00051101146
step 400: mean loss = 0.0005503854
step 500: mean loss = 0.0005468837
step 600: mean loss = 0.0005509753
step 700: mean loss = 0.0005552224
step 800: mean loss = 0.0005549262
step 900: mean loss = 0.0005492275
step 1000: mean loss = 0.0005467819
step 1100: mean loss = 0.00054976554
step 1200: mean loss = 0.00054688944
epoch 128: mean loss = 0.0005460222  learning rate = 0.00054036005
============================
Start of epoch 129
step 0: mean loss = 0.00042146578
step 100: mean loss = 0.00055017497
step 200: mean loss = 0.00053939584
step 300: mean loss = 0.0005393242
step 400: mean loss = 0.00055303855
step 500: mean loss = 0.0005465823
step 600: mean loss = 0.000547303
step 700: mean loss = 0.0005453238
step 800: mean loss = 0.00054361636
step 900: mean loss = 0.0005410496
step 1000: mean loss = 0.0005394464
step 1100: mean loss = 0.0005391639
step 1200: mean loss = 0.0005419659
epoch 129: mean loss = 0.0005417491  learning rate = 0.000513342
============================
Start of epoch 130
step 0: mean loss = 0.0004628574
step 100: mean loss = 0.0004867607
step 200: mean loss = 0.00048565632
step 300: mean loss = 0.00051154813
step 400: mean loss = 0.0005141197
step 500: mean loss = 0.00051105063
step 600: mean loss = 0.0005113146
step 700: mean loss = 0.0005115383
step 800: mean loss = 0.00050987507
step 900: mean loss = 0.0005107903
step 1000: mean loss = 0.000510022
step 1100: mean loss = 0.00051242096
step 1200: mean loss = 0.00051362213
epoch 130: mean loss = 0.0005132733  learning rate = 0.000513342
============================
Start of epoch 131
step 0: mean loss = 0.00044473237
step 100: mean loss = 0.00052235863
step 200: mean loss = 0.00051172066
step 300: mean loss = 0.00051249645
step 400: mean loss = 0.0005216175
step 500: mean loss = 0.0005222791
step 600: mean loss = 0.0005225159
step 700: mean loss = 0.00052669103
step 800: mean loss = 0.00052670256
step 900: mean loss = 0.00052716077
step 1000: mean loss = 0.0005254116
step 1100: mean loss = 0.00052454165
step 1200: mean loss = 0.0005210445
epoch 131: mean loss = 0.00051905215  learning rate = 0.000513342
============================
Start of epoch 132
step 0: mean loss = 0.0004239547
step 100: mean loss = 0.00048236828
step 200: mean loss = 0.00050356705
step 300: mean loss = 0.00051294616
step 400: mean loss = 0.0004987333
step 500: mean loss = 0.0005138466
step 600: mean loss = 0.00051136996
step 700: mean loss = 0.000517214
step 800: mean loss = 0.0005162511
step 900: mean loss = 0.00051722885
step 1000: mean loss = 0.0005224693
step 1100: mean loss = 0.0005269312
step 1200: mean loss = 0.00052603905
epoch 132: mean loss = 0.000524175  learning rate = 0.000513342
============================
Start of epoch 133
step 0: mean loss = 0.0005231142
step 100: mean loss = 0.00053715723
step 200: mean loss = 0.00053098454
step 300: mean loss = 0.00053032965
step 400: mean loss = 0.0005359196
step 500: mean loss = 0.00053752435
step 600: mean loss = 0.0005250802
step 700: mean loss = 0.0005140723
step 800: mean loss = 0.00051229226
step 900: mean loss = 0.00052058476
step 1000: mean loss = 0.00051882054
step 1100: mean loss = 0.00051636307
step 1200: mean loss = 0.00051845214
epoch 133: mean loss = 0.0005157559  learning rate = 0.000513342
============================
Start of epoch 134
step 0: mean loss = 0.00027072523
step 100: mean loss = 0.0005156968
step 200: mean loss = 0.000506739
step 300: mean loss = 0.0005046147
step 400: mean loss = 0.00051556615
step 500: mean loss = 0.00051307236
step 600: mean loss = 0.0005062733
step 700: mean loss = 0.00051007693
step 800: mean loss = 0.0005091824
step 900: mean loss = 0.00050926965
step 1000: mean loss = 0.00051307835
step 1100: mean loss = 0.00051649485
step 1200: mean loss = 0.0005126138
epoch 134: mean loss = 0.0005118749  learning rate = 0.000513342
============================
Start of epoch 135
step 0: mean loss = 0.0003702416
step 100: mean loss = 0.0005178526
step 200: mean loss = 0.0005169549
step 300: mean loss = 0.0005234063
step 400: mean loss = 0.0005170345
step 500: mean loss = 0.0005234802
step 600: mean loss = 0.0005226344
step 700: mean loss = 0.0005127276
step 800: mean loss = 0.0005134703
step 900: mean loss = 0.0005115395
step 1000: mean loss = 0.0005155033
step 1100: mean loss = 0.000515053
step 1200: mean loss = 0.00051317125
epoch 135: mean loss = 0.0005133224  learning rate = 0.000513342
============================
Start of epoch 136
step 0: mean loss = 0.0005699195
step 100: mean loss = 0.0005275661
step 200: mean loss = 0.0005047389
step 300: mean loss = 0.00049947813
step 400: mean loss = 0.0005003826
step 500: mean loss = 0.00050248305
step 600: mean loss = 0.0005063869
step 700: mean loss = 0.0005028097
step 800: mean loss = 0.00050659437
step 900: mean loss = 0.0005081166
step 1000: mean loss = 0.0005065415
step 1100: mean loss = 0.00051302655
step 1200: mean loss = 0.0005127589
epoch 136: mean loss = 0.0005123959  learning rate = 0.000513342
============================
Start of epoch 137
step 0: mean loss = 0.00034395445
step 100: mean loss = 0.00043600705
step 200: mean loss = 0.00045233523
step 300: mean loss = 0.00047051397
step 400: mean loss = 0.00048706375
step 500: mean loss = 0.0004971039
step 600: mean loss = 0.00050211337
step 700: mean loss = 0.000496295
step 800: mean loss = 0.000498673
step 900: mean loss = 0.0005032562
step 1000: mean loss = 0.00050222035
step 1100: mean loss = 0.0005018952
step 1200: mean loss = 0.00050083507
epoch 137: mean loss = 0.00050065445  learning rate = 0.000513342
============================
Start of epoch 138
step 0: mean loss = 0.0004921939
step 100: mean loss = 0.00046237474
step 200: mean loss = 0.0004712407
step 300: mean loss = 0.0004899463
step 400: mean loss = 0.0004961247
step 500: mean loss = 0.00049723015
step 600: mean loss = 0.0004944283
step 700: mean loss = 0.0004931847
step 800: mean loss = 0.0004973374
step 900: mean loss = 0.000500265
step 1000: mean loss = 0.00049705146
step 1100: mean loss = 0.0004961827
step 1200: mean loss = 0.00049644994
epoch 138: mean loss = 0.0004988767  learning rate = 0.000513342
============================
Start of epoch 139
step 0: mean loss = 0.00044929946
step 100: mean loss = 0.0004950963
step 200: mean loss = 0.00050396833
step 300: mean loss = 0.0005113751
step 400: mean loss = 0.00050632283
step 500: mean loss = 0.00049985753
step 600: mean loss = 0.0005036202
step 700: mean loss = 0.00050227484
step 800: mean loss = 0.0005009286
step 900: mean loss = 0.0005028935
step 1000: mean loss = 0.00050798664
step 1100: mean loss = 0.00050790666
step 1200: mean loss = 0.00050253776
epoch 139: mean loss = 0.0005088248  learning rate = 0.00048767496
============================
Start of epoch 140
step 0: mean loss = 0.0006425432
step 100: mean loss = 0.0005532181
step 200: mean loss = 0.0005360158
step 300: mean loss = 0.00050334696
step 400: mean loss = 0.0004829309
step 500: mean loss = 0.00047471523
step 600: mean loss = 0.00047017954
step 700: mean loss = 0.00047761228
step 800: mean loss = 0.0004812558
step 900: mean loss = 0.00048328313
step 1000: mean loss = 0.00048108152
step 1100: mean loss = 0.00047710887
step 1200: mean loss = 0.0004788153
epoch 140: mean loss = 0.0004801927  learning rate = 0.00048767496
============================
Start of epoch 141
step 0: mean loss = 0.00046843494
step 100: mean loss = 0.00045036818
step 200: mean loss = 0.0004593654
step 300: mean loss = 0.0004587725
step 400: mean loss = 0.00047837544
step 500: mean loss = 0.0004821515
step 600: mean loss = 0.0004913447
step 700: mean loss = 0.0004912305
step 800: mean loss = 0.00048791448
step 900: mean loss = 0.00048289428
step 1000: mean loss = 0.0004813338
step 1100: mean loss = 0.0004819162
step 1200: mean loss = 0.00048140273
epoch 141: mean loss = 0.0004822853  learning rate = 0.00048767496
============================
Start of epoch 142
step 0: mean loss = 0.00056660513
step 100: mean loss = 0.0004973914
step 200: mean loss = 0.00046327768
step 300: mean loss = 0.00045611366
step 400: mean loss = 0.00046319052
step 500: mean loss = 0.00046437635
step 600: mean loss = 0.00046315932
step 700: mean loss = 0.00046601193
step 800: mean loss = 0.00046437027
step 900: mean loss = 0.0004616995
step 1000: mean loss = 0.00046170648
step 1100: mean loss = 0.00046734637
step 1200: mean loss = 0.00047317997
epoch 142: mean loss = 0.0004747566  learning rate = 0.00048767496
============================
Start of epoch 143
step 0: mean loss = 0.00027082136
step 100: mean loss = 0.00051839236
step 200: mean loss = 0.000503843
step 300: mean loss = 0.00050776044
step 400: mean loss = 0.0004902507
step 500: mean loss = 0.00048595676
step 600: mean loss = 0.00048157256
step 700: mean loss = 0.00047369627
step 800: mean loss = 0.00046889455
step 900: mean loss = 0.00046973396
step 1000: mean loss = 0.00046962142
step 1100: mean loss = 0.00046813514
step 1200: mean loss = 0.00047007648
epoch 143: mean loss = 0.0004705059  learning rate = 0.00048767496
============================
Start of epoch 144
step 0: mean loss = 0.00040772915
step 100: mean loss = 0.00046393217
step 200: mean loss = 0.00047790073
step 300: mean loss = 0.00047281603
step 400: mean loss = 0.0004703067
step 500: mean loss = 0.00048605565
step 600: mean loss = 0.00048449577
step 700: mean loss = 0.0004782442
step 800: mean loss = 0.00047520935
step 900: mean loss = 0.00047161337
step 1000: mean loss = 0.00047078595
step 1100: mean loss = 0.0004758118
step 1200: mean loss = 0.0004817961
epoch 144: mean loss = 0.00048243656  learning rate = 0.00048767496
============================
Start of epoch 145
step 0: mean loss = 0.00042264542
step 100: mean loss = 0.00046192453
step 200: mean loss = 0.0004599241
step 300: mean loss = 0.0004640524
step 400: mean loss = 0.00047127606
step 500: mean loss = 0.00047693486
step 600: mean loss = 0.00047418376
step 700: mean loss = 0.0004708465
step 800: mean loss = 0.00046828
step 900: mean loss = 0.000467703
step 1000: mean loss = 0.00046483323
step 1100: mean loss = 0.00046507295
step 1200: mean loss = 0.00046685073
epoch 145: mean loss = 0.0004650288  learning rate = 0.00048767496
============================
Start of epoch 146
step 0: mean loss = 0.0003123496
step 100: mean loss = 0.00042307196
step 200: mean loss = 0.00045109255
step 300: mean loss = 0.0004708507
step 400: mean loss = 0.00048322347
step 500: mean loss = 0.00049632206
step 600: mean loss = 0.00048863963
step 700: mean loss = 0.0004844865
step 800: mean loss = 0.00047831525
step 900: mean loss = 0.00048329408
step 1000: mean loss = 0.0004790126
step 1100: mean loss = 0.00047522658
step 1200: mean loss = 0.00047116587
epoch 146: mean loss = 0.00047037125  learning rate = 0.00048767496
============================
Start of epoch 147
step 0: mean loss = 0.00035003302
step 100: mean loss = 0.00041692134
step 200: mean loss = 0.0004578486
step 300: mean loss = 0.00046968568
step 400: mean loss = 0.000466599
step 500: mean loss = 0.0004650166
step 600: mean loss = 0.0004663492
step 700: mean loss = 0.00047030087
step 800: mean loss = 0.0004717145
step 900: mean loss = 0.0004668078
step 1000: mean loss = 0.00046654246
step 1100: mean loss = 0.00046723004
step 1200: mean loss = 0.00046798823
epoch 147: mean loss = 0.00046825508  learning rate = 0.00048767496
============================
Start of epoch 148
step 0: mean loss = 0.00032331963
step 100: mean loss = 0.00046859382
step 200: mean loss = 0.00046959028
step 300: mean loss = 0.00045682892
step 400: mean loss = 0.00044892405
step 500: mean loss = 0.00045061123
step 600: mean loss = 0.00046366663
step 700: mean loss = 0.0004661787
step 800: mean loss = 0.00046858646
step 900: mean loss = 0.00046749957
step 1000: mean loss = 0.00046287978
step 1100: mean loss = 0.00046565256
step 1200: mean loss = 0.00046460025
epoch 148: mean loss = 0.00046436783  learning rate = 0.00048767496
============================
Start of epoch 149
step 0: mean loss = 0.00032816472
step 100: mean loss = 0.00044570173
step 200: mean loss = 0.00044530444
step 300: mean loss = 0.00043615245
step 400: mean loss = 0.00044279086
step 500: mean loss = 0.00045015634
step 600: mean loss = 0.00045385174
step 700: mean loss = 0.0004576105
step 800: mean loss = 0.0004573348
step 900: mean loss = 0.0004630362
step 1000: mean loss = 0.00046523416
step 1100: mean loss = 0.00046457353
step 1200: mean loss = 0.0004631602
epoch 149: mean loss = 0.0004616468  learning rate = 0.00046329116
============================
Start of epoch 150
step 0: mean loss = 0.0004596286
step 100: mean loss = 0.00042156666
step 200: mean loss = 0.00043327743
step 300: mean loss = 0.00042359837
step 400: mean loss = 0.0004255738
step 500: mean loss = 0.0004252365
step 600: mean loss = 0.00042679266
step 700: mean loss = 0.00042840812
step 800: mean loss = 0.00042412223
step 900: mean loss = 0.00042971192
step 1000: mean loss = 0.0004373463
step 1100: mean loss = 0.00043833462
step 1200: mean loss = 0.0004399316
epoch 150: mean loss = 0.00043967695  learning rate = 0.00046329116
============================
Start of epoch 151
step 0: mean loss = 0.00045669172
step 100: mean loss = 0.0004127613
step 200: mean loss = 0.00042114663
step 300: mean loss = 0.0004221869
step 400: mean loss = 0.0004215321
step 500: mean loss = 0.00042546442
step 600: mean loss = 0.0004277731
step 700: mean loss = 0.0004241648
step 800: mean loss = 0.0004253255
step 900: mean loss = 0.0004313102
step 1000: mean loss = 0.00043462057
step 1100: mean loss = 0.00044103604
step 1200: mean loss = 0.000439043
epoch 151: mean loss = 0.00043957878  learning rate = 0.00046329116
============================
Start of epoch 152
step 0: mean loss = 0.0004908298
step 100: mean loss = 0.00045555187
step 200: mean loss = 0.00044445915
step 300: mean loss = 0.00042804985
step 400: mean loss = 0.00043333837
step 500: mean loss = 0.00043658464
step 600: mean loss = 0.00043572934
step 700: mean loss = 0.00043754702
step 800: mean loss = 0.00043983173
step 900: mean loss = 0.00044095848
step 1000: mean loss = 0.00043655242
step 1100: mean loss = 0.00043999674
step 1200: mean loss = 0.0004382134
epoch 152: mean loss = 0.00043850875  learning rate = 0.00046329116
============================
Start of epoch 153
step 0: mean loss = 0.00045729004
step 100: mean loss = 0.00046370458
step 200: mean loss = 0.00045005203
step 300: mean loss = 0.00043234683
step 400: mean loss = 0.0004273632
step 500: mean loss = 0.00043356913
step 600: mean loss = 0.00043456978
step 700: mean loss = 0.00043378325
step 800: mean loss = 0.0004323553
step 900: mean loss = 0.00043639666
step 1000: mean loss = 0.000441924
step 1100: mean loss = 0.00044322733
step 1200: mean loss = 0.00044309968
epoch 153: mean loss = 0.00044287447  learning rate = 0.00046329116
============================
Start of epoch 154
step 0: mean loss = 0.0002935537
step 100: mean loss = 0.00044197385
step 200: mean loss = 0.00043573213
step 300: mean loss = 0.00041850135
step 400: mean loss = 0.00041616653
step 500: mean loss = 0.00041626554
step 600: mean loss = 0.0004147972
step 700: mean loss = 0.00041609036
step 800: mean loss = 0.00042269862
step 900: mean loss = 0.00042725817
step 1000: mean loss = 0.00042991483
step 1100: mean loss = 0.00042841295
step 1200: mean loss = 0.00042871517
epoch 154: mean loss = 0.00043212643  learning rate = 0.00046329116
============================
Start of epoch 155
step 0: mean loss = 0.00044208832
step 100: mean loss = 0.00045144738
step 200: mean loss = 0.0004379701
step 300: mean loss = 0.00044294033
step 400: mean loss = 0.00044556792
step 500: mean loss = 0.00044417343
step 600: mean loss = 0.0004425044
step 700: mean loss = 0.00043706875
step 800: mean loss = 0.0004384582
step 900: mean loss = 0.00043893838
step 1000: mean loss = 0.00043643423
step 1100: mean loss = 0.00043620818
step 1200: mean loss = 0.0004364131
epoch 155: mean loss = 0.00043544912  learning rate = 0.00046329116
============================
Start of epoch 156
step 0: mean loss = 0.0005896089
step 100: mean loss = 0.000403275
step 200: mean loss = 0.00044557118
step 300: mean loss = 0.0004325422
step 400: mean loss = 0.00043718424
step 500: mean loss = 0.00043804222
step 600: mean loss = 0.0004326409
step 700: mean loss = 0.00042407803
step 800: mean loss = 0.00042867204
step 900: mean loss = 0.00042419456
step 1000: mean loss = 0.00042638354
step 1100: mean loss = 0.00042900714
step 1200: mean loss = 0.000430629
epoch 156: mean loss = 0.0004302507  learning rate = 0.00046329116
============================
Start of epoch 157
step 0: mean loss = 0.00032596217
step 100: mean loss = 0.000439158
step 200: mean loss = 0.0004199268
step 300: mean loss = 0.00042361804
step 400: mean loss = 0.00042802427
step 500: mean loss = 0.0004288258
step 600: mean loss = 0.00042297415
step 700: mean loss = 0.00042497696
step 800: mean loss = 0.0004273776
step 900: mean loss = 0.00043601287
step 1000: mean loss = 0.00043922273
step 1100: mean loss = 0.00043810924
step 1200: mean loss = 0.000438022
epoch 157: mean loss = 0.00043594465  learning rate = 0.00046329116
============================
Start of epoch 158
step 0: mean loss = 0.00045906068
step 100: mean loss = 0.0004288704
step 200: mean loss = 0.00041321627
step 300: mean loss = 0.0004241708
step 400: mean loss = 0.00042395951
step 500: mean loss = 0.00041519603
step 600: mean loss = 0.00042192545
step 700: mean loss = 0.00043079167
step 800: mean loss = 0.00043482726
step 900: mean loss = 0.00042967938
step 1000: mean loss = 0.0004304287
step 1100: mean loss = 0.0004303837
step 1200: mean loss = 0.00042775454
epoch 158: mean loss = 0.0004261948  learning rate = 0.00046329116
============================
Start of epoch 159
step 0: mean loss = 0.00035072234
step 100: mean loss = 0.00040335595
step 200: mean loss = 0.00042358384
step 300: mean loss = 0.0004420182
step 400: mean loss = 0.0004479308
step 500: mean loss = 0.0004519473
step 600: mean loss = 0.00044531215
step 700: mean loss = 0.0004395264
step 800: mean loss = 0.00043297146
step 900: mean loss = 0.000427751
step 1000: mean loss = 0.00042569693
step 1100: mean loss = 0.00041943725
step 1200: mean loss = 0.00041867315
epoch 159: mean loss = 0.00042014214  learning rate = 0.00044012658
============================
Start of epoch 160
step 0: mean loss = 0.0003039068
step 100: mean loss = 0.00039231486
step 200: mean loss = 0.0004142772
step 300: mean loss = 0.00041773738
step 400: mean loss = 0.0004136393
step 500: mean loss = 0.00041795505
step 600: mean loss = 0.00041886113
step 700: mean loss = 0.0004177478
step 800: mean loss = 0.0004117059
step 900: mean loss = 0.00040603487
step 1000: mean loss = 0.0004116345
step 1100: mean loss = 0.00041262162
step 1200: mean loss = 0.0004124533
epoch 160: mean loss = 0.0004112943  learning rate = 0.00044012658
============================
Start of epoch 161
step 0: mean loss = 0.00039710745
step 100: mean loss = 0.00038250635
step 200: mean loss = 0.00039959725
step 300: mean loss = 0.00040306192
step 400: mean loss = 0.00040758413
step 500: mean loss = 0.00040856062
step 600: mean loss = 0.00041300594
step 700: mean loss = 0.00040602
step 800: mean loss = 0.00040451504
step 900: mean loss = 0.00040446594
step 1000: mean loss = 0.00040085352
step 1100: mean loss = 0.00040235094
step 1200: mean loss = 0.00040316934
epoch 161: mean loss = 0.00040320927  learning rate = 0.00044012658
============================
Start of epoch 162
step 0: mean loss = 0.00022937212
step 100: mean loss = 0.0003898467
step 200: mean loss = 0.00040040002
step 300: mean loss = 0.00040596057
step 400: mean loss = 0.00041168233
step 500: mean loss = 0.0004094648
step 600: mean loss = 0.00040417718
step 700: mean loss = 0.00039665526
step 800: mean loss = 0.00039506744
step 900: mean loss = 0.00039838994
step 1000: mean loss = 0.00039959585
step 1100: mean loss = 0.00040576936
step 1200: mean loss = 0.00040585978
epoch 162: mean loss = 0.00040782246  learning rate = 0.00044012658
============================
Start of epoch 163
step 0: mean loss = 0.00041767108
step 100: mean loss = 0.00042393696
step 200: mean loss = 0.00041281976
step 300: mean loss = 0.0004102662
step 400: mean loss = 0.00041189868
step 500: mean loss = 0.00040173554
step 600: mean loss = 0.0003978106
step 700: mean loss = 0.00038916012
step 800: mean loss = 0.0003884564
step 900: mean loss = 0.00039308777
step 1000: mean loss = 0.0003928207
step 1100: mean loss = 0.0003955632
step 1200: mean loss = 0.00040212445
epoch 163: mean loss = 0.00040469374  learning rate = 0.00044012658
============================
Start of epoch 164
step 0: mean loss = 0.00038738825
step 100: mean loss = 0.00038214098
step 200: mean loss = 0.00040138484
step 300: mean loss = 0.00038255716
step 400: mean loss = 0.0003899022
step 500: mean loss = 0.00039149588
step 600: mean loss = 0.0003955878
step 700: mean loss = 0.00039548197
step 800: mean loss = 0.00039553965
step 900: mean loss = 0.0003959461
step 1000: mean loss = 0.00039626725
step 1100: mean loss = 0.00039497126
step 1200: mean loss = 0.00039787305
epoch 164: mean loss = 0.00039809832  learning rate = 0.00044012658
============================
Start of epoch 165
step 0: mean loss = 0.00043230713
step 100: mean loss = 0.0004229486
step 200: mean loss = 0.0004107349
step 300: mean loss = 0.00040780456
step 400: mean loss = 0.00040872645
step 500: mean loss = 0.00041343935
step 600: mean loss = 0.00042434674
step 700: mean loss = 0.0004214324
step 800: mean loss = 0.0004241203
step 900: mean loss = 0.000421695
step 1000: mean loss = 0.00041991338
step 1100: mean loss = 0.00041729497
step 1200: mean loss = 0.00041421148
epoch 165: mean loss = 0.00041225358  learning rate = 0.00044012658
============================
Start of epoch 166
step 0: mean loss = 0.00046420307
step 100: mean loss = 0.00036453654
step 200: mean loss = 0.00038864726
step 300: mean loss = 0.00039518296
step 400: mean loss = 0.0003934801
step 500: mean loss = 0.00039921154
step 600: mean loss = 0.00040413026
step 700: mean loss = 0.00040596965
step 800: mean loss = 0.00040692626
step 900: mean loss = 0.0004063363
step 1000: mean loss = 0.00040717545
step 1100: mean loss = 0.0004041313
step 1200: mean loss = 0.00040333733
epoch 166: mean loss = 0.00040243272  learning rate = 0.00044012658
============================
Start of epoch 167
step 0: mean loss = 0.0003049004
step 100: mean loss = 0.00037826336
step 200: mean loss = 0.000383779
step 300: mean loss = 0.0003897587
step 400: mean loss = 0.0003879215
step 500: mean loss = 0.0003816802
step 600: mean loss = 0.0003838017
step 700: mean loss = 0.00038871315
step 800: mean loss = 0.00039560936
step 900: mean loss = 0.00039641187
step 1000: mean loss = 0.00040075873
step 1100: mean loss = 0.0003999202
step 1200: mean loss = 0.0003994608
epoch 167: mean loss = 0.0003995156  learning rate = 0.00044012658
============================
Start of epoch 168
step 0: mean loss = 0.00056061486
step 100: mean loss = 0.00037120347
step 200: mean loss = 0.0003683335
step 300: mean loss = 0.00038275067
step 400: mean loss = 0.00039371784
step 500: mean loss = 0.00040217783
step 600: mean loss = 0.00040001495
step 700: mean loss = 0.00039969676
step 800: mean loss = 0.00039772433
step 900: mean loss = 0.0003971249
step 1000: mean loss = 0.000399225
step 1100: mean loss = 0.00039839148
step 1200: mean loss = 0.00040130215
epoch 168: mean loss = 0.0004002177  learning rate = 0.00044012658
============================
Start of epoch 169
step 0: mean loss = 0.00031575857
step 100: mean loss = 0.00038750743
step 200: mean loss = 0.0003876178
step 300: mean loss = 0.00039890816
step 400: mean loss = 0.0003981921
step 500: mean loss = 0.00039851875
step 600: mean loss = 0.0003955886
step 700: mean loss = 0.00039395137
step 800: mean loss = 0.0003950715
step 900: mean loss = 0.00039351548
step 1000: mean loss = 0.00039465752
step 1100: mean loss = 0.00039915237
step 1200: mean loss = 0.00040052252
epoch 169: mean loss = 0.00040143967  learning rate = 0.00041812027
============================
Start of epoch 170
step 0: mean loss = 0.00026815315
step 100: mean loss = 0.00037099374
step 200: mean loss = 0.00036759963
step 300: mean loss = 0.00036199734
step 400: mean loss = 0.00036781305
step 500: mean loss = 0.0003701273
step 600: mean loss = 0.000367443
step 700: mean loss = 0.0003677196
step 800: mean loss = 0.00037086772
step 900: mean loss = 0.00037135519
step 1000: mean loss = 0.00037251366
step 1100: mean loss = 0.00037385538
step 1200: mean loss = 0.00037728163
epoch 170: mean loss = 0.00037809933  learning rate = 0.00041812027
============================
Start of epoch 171
step 0: mean loss = 0.00035121033
step 100: mean loss = 0.0003685915
step 200: mean loss = 0.00037000384
step 300: mean loss = 0.0003765436
step 400: mean loss = 0.00037934378
step 500: mean loss = 0.0003839947
step 600: mean loss = 0.00038004018
step 700: mean loss = 0.00037744662
step 800: mean loss = 0.00037542617
step 900: mean loss = 0.0003812431
step 1000: mean loss = 0.00038335196
step 1100: mean loss = 0.00038394856
step 1200: mean loss = 0.000382948
epoch 171: mean loss = 0.0003840182  learning rate = 0.00041812027
============================
Start of epoch 172
step 0: mean loss = 0.00032890262
step 100: mean loss = 0.0003741166
step 200: mean loss = 0.0003746984
step 300: mean loss = 0.00038707381
step 400: mean loss = 0.0003849167
step 500: mean loss = 0.00038447045
step 600: mean loss = 0.0003783244
step 700: mean loss = 0.0003733424
step 800: mean loss = 0.00037176636
step 900: mean loss = 0.0003754793
step 1000: mean loss = 0.00037521022
step 1100: mean loss = 0.00037751335
step 1200: mean loss = 0.0003774795
epoch 172: mean loss = 0.00037915775  learning rate = 0.00041812027
============================
Start of epoch 173
step 0: mean loss = 0.00038521644
step 100: mean loss = 0.0003508469
step 200: mean loss = 0.00037461007
step 300: mean loss = 0.0003756614
step 400: mean loss = 0.0003788391
step 500: mean loss = 0.00037987993
step 600: mean loss = 0.00037880597
step 700: mean loss = 0.00037571104
step 800: mean loss = 0.00037885772
step 900: mean loss = 0.00038286697
step 1000: mean loss = 0.00038150162
step 1100: mean loss = 0.0003814643
step 1200: mean loss = 0.0003789708
epoch 173: mean loss = 0.00037904127  learning rate = 0.00041812027
============================
Start of epoch 174
step 0: mean loss = 0.0006089427
step 100: mean loss = 0.00034694397
step 200: mean loss = 0.00036519917
step 300: mean loss = 0.00036737922
step 400: mean loss = 0.00037559422
step 500: mean loss = 0.00037693293
step 600: mean loss = 0.00038691127
step 700: mean loss = 0.0003862382
step 800: mean loss = 0.00038402888
step 900: mean loss = 0.00038012821
step 1000: mean loss = 0.00037743643
step 1100: mean loss = 0.0003748538
step 1200: mean loss = 0.00037605633
epoch 174: mean loss = 0.0003755953  learning rate = 0.00041812027
============================
Start of epoch 175
step 0: mean loss = 0.0003300425
step 100: mean loss = 0.00035422816
step 200: mean loss = 0.00036882286
step 300: mean loss = 0.00038116865
step 400: mean loss = 0.00037469759
step 500: mean loss = 0.00037018783
step 600: mean loss = 0.00037527032
step 700: mean loss = 0.00037538962
step 800: mean loss = 0.00038057446
step 900: mean loss = 0.0003788318
step 1000: mean loss = 0.00037955563
step 1100: mean loss = 0.00037880687
step 1200: mean loss = 0.00037694362
epoch 175: mean loss = 0.00037519218  learning rate = 0.00041812027
============================
Start of epoch 176
step 0: mean loss = 0.00029061094
step 100: mean loss = 0.000382399
step 200: mean loss = 0.00038538367
step 300: mean loss = 0.0003917626
step 400: mean loss = 0.00039231847
step 500: mean loss = 0.00038920983
step 600: mean loss = 0.00038716942
step 700: mean loss = 0.00038929132
step 800: mean loss = 0.00038752286
step 900: mean loss = 0.00038288737
step 1000: mean loss = 0.00038412938
step 1100: mean loss = 0.00038533064
step 1200: mean loss = 0.0003829148
epoch 176: mean loss = 0.00038325385  learning rate = 0.00041812027
============================
Start of epoch 177
step 0: mean loss = 0.00045451082
step 100: mean loss = 0.00037697935
step 200: mean loss = 0.00038506216
step 300: mean loss = 0.00037782665
step 400: mean loss = 0.0003687868
step 500: mean loss = 0.0003626114
step 600: mean loss = 0.0003663621
step 700: mean loss = 0.00036733501
step 800: mean loss = 0.00036839195
step 900: mean loss = 0.00037377203
step 1000: mean loss = 0.00037538062
step 1100: mean loss = 0.0003786203
step 1200: mean loss = 0.00037901403
epoch 177: mean loss = 0.00037904418  learning rate = 0.00041812027
============================
Start of epoch 178
step 0: mean loss = 0.0003689641
step 100: mean loss = 0.0003495708
step 200: mean loss = 0.00035002138
step 300: mean loss = 0.00036121547
step 400: mean loss = 0.00036883284
step 500: mean loss = 0.00037252632
step 600: mean loss = 0.00037757464
step 700: mean loss = 0.00037437375
step 800: mean loss = 0.0003763063
step 900: mean loss = 0.00037526348
step 1000: mean loss = 0.00037438935
step 1100: mean loss = 0.00037649448
step 1200: mean loss = 0.00037575414
epoch 178: mean loss = 0.00037512783  learning rate = 0.00041812027
============================
Start of epoch 179
step 0: mean loss = 0.00031770725
step 100: mean loss = 0.00038002428
step 200: mean loss = 0.00037016397
step 300: mean loss = 0.00036497504
step 400: mean loss = 0.0003657012
step 500: mean loss = 0.00036418482
step 600: mean loss = 0.00036493252
step 700: mean loss = 0.00036747876
step 800: mean loss = 0.00036648623
step 900: mean loss = 0.0003666621
step 1000: mean loss = 0.00036917094
step 1100: mean loss = 0.00036844506
step 1200: mean loss = 0.00037137812
epoch 179: mean loss = 0.0003705167  learning rate = 0.00039721426
============================
Start of epoch 180
step 0: mean loss = 0.00041563762
step 100: mean loss = 0.0003707195
step 200: mean loss = 0.00035295944
step 300: mean loss = 0.0003635353
step 400: mean loss = 0.00037055783
step 500: mean loss = 0.00036727858
step 600: mean loss = 0.00036296534
step 700: mean loss = 0.00036009683
step 800: mean loss = 0.0003587089
step 900: mean loss = 0.000356108
step 1000: mean loss = 0.00035617058
step 1100: mean loss = 0.0003578382
step 1200: mean loss = 0.00035824202
epoch 180: mean loss = 0.0003564316  learning rate = 0.00039721426
============================
Start of epoch 181
step 0: mean loss = 0.0002892533
step 100: mean loss = 0.00031854687
step 200: mean loss = 0.00034379907
step 300: mean loss = 0.0003419799
step 400: mean loss = 0.00034029447
step 500: mean loss = 0.00033420412
step 600: mean loss = 0.0003382481
step 700: mean loss = 0.00034266335
step 800: mean loss = 0.00034507998
step 900: mean loss = 0.00035289538
step 1000: mean loss = 0.00035546103
step 1100: mean loss = 0.00035852034
step 1200: mean loss = 0.00035980705
epoch 181: mean loss = 0.0003604538  learning rate = 0.00039721426
============================
Start of epoch 182
step 0: mean loss = 0.0003673218
step 100: mean loss = 0.00033832234
step 200: mean loss = 0.00034283262
step 300: mean loss = 0.00034553235
step 400: mean loss = 0.00035131097
step 500: mean loss = 0.0003514152
step 600: mean loss = 0.0003475052
step 700: mean loss = 0.00035050564
step 800: mean loss = 0.0003562587
step 900: mean loss = 0.00035555533
step 1000: mean loss = 0.00035322475
step 1100: mean loss = 0.00035742018
step 1200: mean loss = 0.00035779766
epoch 182: mean loss = 0.0003581993  learning rate = 0.00039721426
============================
Start of epoch 183
step 0: mean loss = 0.00035238615
step 100: mean loss = 0.00033959476
step 200: mean loss = 0.0003577804
step 300: mean loss = 0.0003539956
step 400: mean loss = 0.00034840242
step 500: mean loss = 0.00035034074
step 600: mean loss = 0.00035323287
step 700: mean loss = 0.00035708025
step 800: mean loss = 0.00035792
step 900: mean loss = 0.00035839344
step 1000: mean loss = 0.00035704166
step 1100: mean loss = 0.00036118136
step 1200: mean loss = 0.00035819068
epoch 183: mean loss = 0.00035783334  learning rate = 0.00039721426
============================
Start of epoch 184
step 0: mean loss = 0.00034848863
step 100: mean loss = 0.00034877262
step 200: mean loss = 0.00035596624
step 300: mean loss = 0.00035544377
step 400: mean loss = 0.00035246968
step 500: mean loss = 0.0003551441
step 600: mean loss = 0.0003556632
step 700: mean loss = 0.0003502299
step 800: mean loss = 0.00034552216
step 900: mean loss = 0.00034456784
step 1000: mean loss = 0.00034438676
step 1100: mean loss = 0.0003460415
step 1200: mean loss = 0.00034650753
epoch 184: mean loss = 0.0003480784  learning rate = 0.00039721426
============================
Start of epoch 185
step 0: mean loss = 0.00032274102
step 100: mean loss = 0.0003583165
step 200: mean loss = 0.00034944343
step 300: mean loss = 0.00035340703
step 400: mean loss = 0.00034521133
step 500: mean loss = 0.00034750733
step 600: mean loss = 0.0003498065
step 700: mean loss = 0.00035108495
step 800: mean loss = 0.0003495617
step 900: mean loss = 0.00034501342
step 1000: mean loss = 0.00034608322
step 1100: mean loss = 0.0003499148
step 1200: mean loss = 0.00035402103
epoch 185: mean loss = 0.00035254154  learning rate = 0.00039721426
============================
Start of epoch 186
step 0: mean loss = 0.00033293758
step 100: mean loss = 0.0003329038
step 200: mean loss = 0.00033896606
step 300: mean loss = 0.00034698402
step 400: mean loss = 0.00034504093
step 500: mean loss = 0.000340919
step 600: mean loss = 0.00034560243
step 700: mean loss = 0.00034720896
step 800: mean loss = 0.00034690328
step 900: mean loss = 0.0003441814
step 1000: mean loss = 0.00034283512
step 1100: mean loss = 0.00034332403
step 1200: mean loss = 0.00034558968
epoch 186: mean loss = 0.0003460929  learning rate = 0.00039721426
============================
Start of epoch 187
step 0: mean loss = 0.00035373023
step 100: mean loss = 0.00031979373
step 200: mean loss = 0.00031773653
step 300: mean loss = 0.00033637218
step 400: mean loss = 0.00034393102
step 500: mean loss = 0.00034633552
step 600: mean loss = 0.00034914003
step 700: mean loss = 0.00035183557
step 800: mean loss = 0.00035638543
step 900: mean loss = 0.00036007553
step 1000: mean loss = 0.00036093206
step 1100: mean loss = 0.00036014276
step 1200: mean loss = 0.00035899543
epoch 187: mean loss = 0.00035873536  learning rate = 0.00039721426
============================
Start of epoch 188
step 0: mean loss = 0.00036496893
step 100: mean loss = 0.00036688222
step 200: mean loss = 0.00037697895
step 300: mean loss = 0.00036806866
step 400: mean loss = 0.00036142918
step 500: mean loss = 0.0003605578
step 600: mean loss = 0.00035354018
step 700: mean loss = 0.0003527763
step 800: mean loss = 0.00034511354
step 900: mean loss = 0.0003459859
step 1000: mean loss = 0.00034841953
step 1100: mean loss = 0.0003491642
step 1200: mean loss = 0.00035125422
epoch 188: mean loss = 0.00035171883  learning rate = 0.00039721426
============================
Start of epoch 189
step 0: mean loss = 0.0003453149
step 100: mean loss = 0.00030768942
step 200: mean loss = 0.00032016172
step 300: mean loss = 0.00033640745
step 400: mean loss = 0.00033715647
step 500: mean loss = 0.0003392881
step 600: mean loss = 0.000342909
step 700: mean loss = 0.0003425707
step 800: mean loss = 0.00034321105
step 900: mean loss = 0.00034415897
step 1000: mean loss = 0.00034940007
step 1100: mean loss = 0.0003475923
step 1200: mean loss = 0.00034911858
epoch 189: mean loss = 0.00035068256  learning rate = 0.00037735354
============================
Start of epoch 190
step 0: mean loss = 0.00031899902
step 100: mean loss = 0.00031408705
step 200: mean loss = 0.00032103132
step 300: mean loss = 0.00032304277
step 400: mean loss = 0.00032303328
step 500: mean loss = 0.00032271483
step 600: mean loss = 0.00032687563
step 700: mean loss = 0.00032309617
step 800: mean loss = 0.0003216078
step 900: mean loss = 0.00032788978
step 1000: mean loss = 0.00033155686
step 1100: mean loss = 0.0003301639
step 1200: mean loss = 0.00032895443
epoch 190: mean loss = 0.00032994265  learning rate = 0.00037735354
============================
Start of epoch 191
step 0: mean loss = 0.0003743958
step 100: mean loss = 0.00031298265
step 200: mean loss = 0.0003175501
step 300: mean loss = 0.0003263765
step 400: mean loss = 0.0003274479
step 500: mean loss = 0.0003269816
step 600: mean loss = 0.00032631663
step 700: mean loss = 0.00033177834
step 800: mean loss = 0.000329143
step 900: mean loss = 0.00032986735
step 1000: mean loss = 0.0003334425
step 1100: mean loss = 0.00033273324
step 1200: mean loss = 0.00033147796
epoch 191: mean loss = 0.00033127065  learning rate = 0.00037735354
============================
Start of epoch 192
step 0: mean loss = 0.0005539459
step 100: mean loss = 0.00035377638
step 200: mean loss = 0.0003409845
step 300: mean loss = 0.00033859655
step 400: mean loss = 0.00034093545
step 500: mean loss = 0.00033584915
step 600: mean loss = 0.00033339285
step 700: mean loss = 0.0003344018
step 800: mean loss = 0.00033378543
step 900: mean loss = 0.00033582308
step 1000: mean loss = 0.00033730853
step 1100: mean loss = 0.000341662
step 1200: mean loss = 0.00034005442
epoch 192: mean loss = 0.00033992037  learning rate = 0.00037735354
============================
Start of epoch 193
step 0: mean loss = 0.00033047525
step 100: mean loss = 0.00036892347
step 200: mean loss = 0.0003450212
step 300: mean loss = 0.00035739434
step 400: mean loss = 0.00035576432
step 500: mean loss = 0.00034270607
step 600: mean loss = 0.0003361788
step 700: mean loss = 0.00033400467
step 800: mean loss = 0.00033782376
step 900: mean loss = 0.0003367369
step 1000: mean loss = 0.00033508166
step 1100: mean loss = 0.0003339551
step 1200: mean loss = 0.00033373493
epoch 193: mean loss = 0.00033394748  learning rate = 0.00037735354
============================
Start of epoch 194
step 0: mean loss = 0.0004831283
step 100: mean loss = 0.00033926853
step 200: mean loss = 0.00034217336
step 300: mean loss = 0.00034170854
step 400: mean loss = 0.00033125927
step 500: mean loss = 0.0003307641
step 600: mean loss = 0.0003323095
step 700: mean loss = 0.00032949346
step 800: mean loss = 0.0003304363
step 900: mean loss = 0.0003291793
step 1000: mean loss = 0.0003338453
step 1100: mean loss = 0.00033370376
step 1200: mean loss = 0.0003322147
epoch 194: mean loss = 0.00033396075  learning rate = 0.00037735354
============================
Start of epoch 195
step 0: mean loss = 0.0002697767
step 100: mean loss = 0.00037235487
step 200: mean loss = 0.0003686967
step 300: mean loss = 0.00035230513
step 400: mean loss = 0.0003407685
step 500: mean loss = 0.00033455165
step 600: mean loss = 0.00032839554
step 700: mean loss = 0.00032452802
step 800: mean loss = 0.00032395578
step 900: mean loss = 0.00032444161
step 1000: mean loss = 0.0003251558
step 1100: mean loss = 0.00032806332
step 1200: mean loss = 0.00032800075
epoch 195: mean loss = 0.00032832424  learning rate = 0.00037735354
============================
Start of epoch 196
step 0: mean loss = 0.00028347835
step 100: mean loss = 0.0003457713
step 200: mean loss = 0.0003450785
step 300: mean loss = 0.00033040473
step 400: mean loss = 0.00032730776
step 500: mean loss = 0.00032370217
step 600: mean loss = 0.00032796126
step 700: mean loss = 0.00033236615
step 800: mean loss = 0.00033432993
step 900: mean loss = 0.00033257887
step 1000: mean loss = 0.0003306793
step 1100: mean loss = 0.00032782898
step 1200: mean loss = 0.00033039565
epoch 196: mean loss = 0.00033120398  learning rate = 0.00037735354
============================
Start of epoch 197
step 0: mean loss = 0.0005615407
step 100: mean loss = 0.0003645609
step 200: mean loss = 0.00034929207
step 300: mean loss = 0.00035036626
step 400: mean loss = 0.00033749343
step 500: mean loss = 0.0003337888
step 600: mean loss = 0.00032918106
step 700: mean loss = 0.0003327037
step 800: mean loss = 0.0003324565
step 900: mean loss = 0.00033388424
step 1000: mean loss = 0.0003345478
step 1100: mean loss = 0.00033475854
step 1200: mean loss = 0.0003338191
epoch 197: mean loss = 0.00033340053  learning rate = 0.00037735354
============================
Start of epoch 198
step 0: mean loss = 0.0003084347
step 100: mean loss = 0.000350464
step 200: mean loss = 0.00034600424
step 300: mean loss = 0.00033677262
step 400: mean loss = 0.00032839828
step 500: mean loss = 0.00032693133
step 600: mean loss = 0.00033145575
step 700: mean loss = 0.0003328965
step 800: mean loss = 0.0003288708
step 900: mean loss = 0.00032802965
step 1000: mean loss = 0.00033064195
step 1100: mean loss = 0.00032711553
step 1200: mean loss = 0.00032631328
epoch 198: mean loss = 0.00032562888  learning rate = 0.00037735354
============================
Start of epoch 199
step 0: mean loss = 0.00031746703
step 100: mean loss = 0.00033111096
step 200: mean loss = 0.00032546045
step 300: mean loss = 0.00032831458
step 400: mean loss = 0.00032577734
step 500: mean loss = 0.00032010674
step 600: mean loss = 0.00032276032
step 700: mean loss = 0.00032699507
step 800: mean loss = 0.00032690947
step 900: mean loss = 0.00032598063
step 1000: mean loss = 0.00032804653
step 1100: mean loss = 0.0003334917
step 1200: mean loss = 0.000331136
epoch 199: mean loss = 0.00033157924  learning rate = 0.00035848588
saving the weights
++++++++++++++++++++++++++++++
Start of cycle 1
Total number of epochs in this cycle: 400
Batch size in this cycle: 16
============================
Start of epoch 0
computing the FFT
applying the multipliers
(16, 1, 1001)
inverse fft
step 0: mean loss = 0.00028709884
step 100: mean loss = 0.0002579643
step 200: mean loss = 0.0002398513
step 300: mean loss = 0.00022906301
step 400: mean loss = 0.00023133517
step 500: mean loss = 0.00023019376
step 600: mean loss = 0.00023072933
epoch 0: mean loss = 0.00023060376  learning rate = 0.00035848588
============================
Start of epoch 1
step 0: mean loss = 0.00021033607
step 100: mean loss = 0.00024260706
step 200: mean loss = 0.00022827768
step 300: mean loss = 0.00022756241
step 400: mean loss = 0.00022770846
step 500: mean loss = 0.00023080468
step 600: mean loss = 0.00023381737
epoch 1: mean loss = 0.0002330633  learning rate = 0.00035848588
============================
Start of epoch 2
step 0: mean loss = 0.00021864696
step 100: mean loss = 0.00022234142
step 200: mean loss = 0.00022889409
step 300: mean loss = 0.00023163382
step 400: mean loss = 0.00023564101
step 500: mean loss = 0.00024147118
step 600: mean loss = 0.00024090408
epoch 2: mean loss = 0.00024212759  learning rate = 0.00035848588
============================
Start of epoch 3
step 0: mean loss = 0.00017606691
step 100: mean loss = 0.00023137614
step 200: mean loss = 0.00023512142
step 300: mean loss = 0.00023436999
step 400: mean loss = 0.00024110785
step 500: mean loss = 0.00024105098
step 600: mean loss = 0.00024164618
epoch 3: mean loss = 0.00024136512  learning rate = 0.00035848588
============================
Start of epoch 4
step 0: mean loss = 0.00025904988
step 100: mean loss = 0.00025222142
step 200: mean loss = 0.000250402
step 300: mean loss = 0.0002470485
step 400: mean loss = 0.0002477919
step 500: mean loss = 0.0002498568
step 600: mean loss = 0.0002478071
epoch 4: mean loss = 0.00024781667  learning rate = 0.00035848588
============================
Start of epoch 5
step 0: mean loss = 0.00024473947
step 100: mean loss = 0.00024043112
step 200: mean loss = 0.00024733046
step 300: mean loss = 0.00025000967
step 400: mean loss = 0.00024770742
step 500: mean loss = 0.00024953322
step 600: mean loss = 0.00025025135
epoch 5: mean loss = 0.00025089126  learning rate = 0.00035848588
============================
Start of epoch 6
step 0: mean loss = 0.00020683237
step 100: mean loss = 0.00024880457
step 200: mean loss = 0.00024266331
step 300: mean loss = 0.00024241219
step 400: mean loss = 0.00024190068
step 500: mean loss = 0.00024308258
step 600: mean loss = 0.00024430515
epoch 6: mean loss = 0.00024439118  learning rate = 0.00035848588
============================
Start of epoch 7
step 0: mean loss = 0.00017066493
step 100: mean loss = 0.00022839957
step 200: mean loss = 0.00023431075
step 300: mean loss = 0.00024115216
step 400: mean loss = 0.00024148451
step 500: mean loss = 0.00023993247
step 600: mean loss = 0.00024100712
epoch 7: mean loss = 0.00024144661  learning rate = 0.00035848588
============================
Start of epoch 8
step 0: mean loss = 0.00022006634
step 100: mean loss = 0.0002410371
step 200: mean loss = 0.00023739718
step 300: mean loss = 0.00023837766
step 400: mean loss = 0.00024089457
step 500: mean loss = 0.00024192131
step 600: mean loss = 0.00024551255
epoch 8: mean loss = 0.00024780014  learning rate = 0.00035848588
============================
Start of epoch 9
step 0: mean loss = 0.00022185635
step 100: mean loss = 0.00024871572
step 200: mean loss = 0.00024297961
step 300: mean loss = 0.00024580004
step 400: mean loss = 0.0002455321
step 500: mean loss = 0.0002452767
step 600: mean loss = 0.00024687426
epoch 9: mean loss = 0.00024647635  learning rate = 0.00035848588
============================
Start of epoch 10
step 0: mean loss = 0.00029583627
step 100: mean loss = 0.00024322812
step 200: mean loss = 0.0002403066
step 300: mean loss = 0.0002433824
step 400: mean loss = 0.00024546104
step 500: mean loss = 0.0002454059
step 600: mean loss = 0.00024268299
epoch 10: mean loss = 0.00024273731  learning rate = 0.00035848588
============================
Start of epoch 11
step 0: mean loss = 0.00019231171
step 100: mean loss = 0.00023741498
step 200: mean loss = 0.00023421564
step 300: mean loss = 0.00023997328
step 400: mean loss = 0.00024074288
step 500: mean loss = 0.00024051698
step 600: mean loss = 0.00024339162
epoch 11: mean loss = 0.00024300235  learning rate = 0.00035848588
============================
Start of epoch 12
step 0: mean loss = 0.0002135476
step 100: mean loss = 0.00025636438
step 200: mean loss = 0.00024951098
step 300: mean loss = 0.00024576348
step 400: mean loss = 0.0002441999
step 500: mean loss = 0.00024478592
step 600: mean loss = 0.00024347455
epoch 12: mean loss = 0.0002434335  learning rate = 0.00035848588
============================
Start of epoch 13
step 0: mean loss = 0.0002656016
step 100: mean loss = 0.0002290519
step 200: mean loss = 0.00023428263
step 300: mean loss = 0.0002381593
step 400: mean loss = 0.00024286653
step 500: mean loss = 0.00024219287
step 600: mean loss = 0.00024208258
epoch 13: mean loss = 0.00024211896  learning rate = 0.00035848588
============================
Start of epoch 14
step 0: mean loss = 0.00025366535
step 100: mean loss = 0.00026260086
step 200: mean loss = 0.0002503034
step 300: mean loss = 0.00024793347
step 400: mean loss = 0.00024812753
step 500: mean loss = 0.0002481251
step 600: mean loss = 0.00024723794
epoch 14: mean loss = 0.0002470039  learning rate = 0.00035848588
============================
Start of epoch 15
step 0: mean loss = 0.00031789113
step 100: mean loss = 0.0002286779
step 200: mean loss = 0.00023434604
step 300: mean loss = 0.00024314327
step 400: mean loss = 0.00024582096
step 500: mean loss = 0.00024180392
step 600: mean loss = 0.00024245789
epoch 15: mean loss = 0.00024127505  learning rate = 0.00035848588
============================
Start of epoch 16
step 0: mean loss = 0.00020790662
step 100: mean loss = 0.00023934226
step 200: mean loss = 0.00023726084
step 300: mean loss = 0.00023770929
step 400: mean loss = 0.00024018402
step 500: mean loss = 0.0002374848
step 600: mean loss = 0.00023948093
epoch 16: mean loss = 0.00023878073  learning rate = 0.00035848588
============================
Start of epoch 17
step 0: mean loss = 0.00026748434
step 100: mean loss = 0.00023232601
step 200: mean loss = 0.00023610394
step 300: mean loss = 0.0002369941
step 400: mean loss = 0.00023686081
step 500: mean loss = 0.00023629422
step 600: mean loss = 0.000235065
epoch 17: mean loss = 0.00023496913  learning rate = 0.00035848588
============================
Start of epoch 18
step 0: mean loss = 0.00026162155
step 100: mean loss = 0.00023296814
step 200: mean loss = 0.00023927799
step 300: mean loss = 0.00023783292
step 400: mean loss = 0.0002346116
step 500: mean loss = 0.00023355513
step 600: mean loss = 0.00023402931
epoch 18: mean loss = 0.00023430541  learning rate = 0.00035848588
============================
Start of epoch 19
step 0: mean loss = 0.0002378888
step 100: mean loss = 0.00023232297
step 200: mean loss = 0.00024271195
step 300: mean loss = 0.00024157624
step 400: mean loss = 0.00024105492
step 500: mean loss = 0.00024141547
step 600: mean loss = 0.0002416406
epoch 19: mean loss = 0.00024262872  learning rate = 0.00034056156
============================
Start of epoch 20
step 0: mean loss = 0.00020432545
step 100: mean loss = 0.00024044525
step 200: mean loss = 0.00023037942
step 300: mean loss = 0.00022880889
step 400: mean loss = 0.00022990453
step 500: mean loss = 0.00022856139
step 600: mean loss = 0.00022941091
epoch 20: mean loss = 0.00022941633  learning rate = 0.00034056156
============================
Start of epoch 21
step 0: mean loss = 0.00026652237
step 100: mean loss = 0.00023642051
step 200: mean loss = 0.0002347121
step 300: mean loss = 0.00023519824
step 400: mean loss = 0.0002308196
step 500: mean loss = 0.00023405536
step 600: mean loss = 0.00023332436
epoch 21: mean loss = 0.00023305426  learning rate = 0.00034056156
============================
Start of epoch 22
step 0: mean loss = 0.00023029462
step 100: mean loss = 0.00022583884
step 200: mean loss = 0.0002322356
step 300: mean loss = 0.00022731096
step 400: mean loss = 0.00023140576
step 500: mean loss = 0.00023012295
step 600: mean loss = 0.0002288444
epoch 22: mean loss = 0.00022810943  learning rate = 0.00034056156
============================
Start of epoch 23
step 0: mean loss = 0.0002128198
step 100: mean loss = 0.00022029616
step 200: mean loss = 0.00021726145
step 300: mean loss = 0.00021912328
step 400: mean loss = 0.00022052998
step 500: mean loss = 0.00022356615
step 600: mean loss = 0.00022577411
epoch 23: mean loss = 0.000225948  learning rate = 0.00034056156
============================
Start of epoch 24
step 0: mean loss = 0.00019964032
step 100: mean loss = 0.00022501245
step 200: mean loss = 0.00022572724
step 300: mean loss = 0.00022622211
step 400: mean loss = 0.00022543933
step 500: mean loss = 0.0002221575
step 600: mean loss = 0.00022478204
epoch 24: mean loss = 0.00022629669  learning rate = 0.00034056156
============================
Start of epoch 25
step 0: mean loss = 0.00024511933
step 100: mean loss = 0.00021171106
step 200: mean loss = 0.00022344787
step 300: mean loss = 0.0002254092
step 400: mean loss = 0.00022471984
step 500: mean loss = 0.00022431849
step 600: mean loss = 0.00022619333
epoch 25: mean loss = 0.00022642594  learning rate = 0.00034056156
============================
Start of epoch 26
step 0: mean loss = 0.00023475519
step 100: mean loss = 0.00023662498
step 200: mean loss = 0.0002368547
step 300: mean loss = 0.00023513754
step 400: mean loss = 0.00023141944
step 500: mean loss = 0.00022717557
step 600: mean loss = 0.00022712823
epoch 26: mean loss = 0.00022827604  learning rate = 0.00034056156
============================
Start of epoch 27
step 0: mean loss = 0.00027043853
step 100: mean loss = 0.00021873771
step 200: mean loss = 0.00022405942
step 300: mean loss = 0.0002229207
step 400: mean loss = 0.0002239237
step 500: mean loss = 0.00022286881
step 600: mean loss = 0.00022256421
epoch 27: mean loss = 0.00022217668  learning rate = 0.00034056156
============================
Start of epoch 28
step 0: mean loss = 0.00019332903
step 100: mean loss = 0.00021763993
step 200: mean loss = 0.00022594475
step 300: mean loss = 0.00022658113
step 400: mean loss = 0.00022510621
step 500: mean loss = 0.00022472978
step 600: mean loss = 0.00022463074
epoch 28: mean loss = 0.0002239377  learning rate = 0.00034056156
============================
Start of epoch 29
step 0: mean loss = 0.00020225167
step 100: mean loss = 0.000219849
step 200: mean loss = 0.00022536442
step 300: mean loss = 0.00022114083
step 400: mean loss = 0.00021870027
step 500: mean loss = 0.0002210319
step 600: mean loss = 0.00022345257
epoch 29: mean loss = 0.00022371793  learning rate = 0.00034056156
============================
Start of epoch 30
step 0: mean loss = 0.00020802736
step 100: mean loss = 0.00022356256
step 200: mean loss = 0.00022459762
step 300: mean loss = 0.00022268617
step 400: mean loss = 0.0002234937
step 500: mean loss = 0.00022303432
step 600: mean loss = 0.00022246024
epoch 30: mean loss = 0.00022241058  learning rate = 0.00034056156
============================
Start of epoch 31
step 0: mean loss = 0.00023021159
step 100: mean loss = 0.00021001184
step 200: mean loss = 0.00022125963
step 300: mean loss = 0.00022322126
step 400: mean loss = 0.00022564117
step 500: mean loss = 0.00022290698
step 600: mean loss = 0.00022305189
epoch 31: mean loss = 0.00022370457  learning rate = 0.00034056156
============================
Start of epoch 32
step 0: mean loss = 0.00022517933
step 100: mean loss = 0.00021430924
step 200: mean loss = 0.00021559185
step 300: mean loss = 0.00021892687
step 400: mean loss = 0.00021965192
step 500: mean loss = 0.00022091162
step 600: mean loss = 0.00022026068
epoch 32: mean loss = 0.00022048733  learning rate = 0.00034056156
============================
Start of epoch 33
step 0: mean loss = 0.00021951938
step 100: mean loss = 0.00021961919
step 200: mean loss = 0.00021886807
step 300: mean loss = 0.00021634594
step 400: mean loss = 0.00021488461
step 500: mean loss = 0.00021515871
step 600: mean loss = 0.00021802097
epoch 33: mean loss = 0.00021762826  learning rate = 0.00034056156
============================
Start of epoch 34
step 0: mean loss = 0.00019123201
step 100: mean loss = 0.00021408132
step 200: mean loss = 0.00021104375
step 300: mean loss = 0.00021344419
step 400: mean loss = 0.00021618349
step 500: mean loss = 0.00021584904
step 600: mean loss = 0.00021802737
epoch 34: mean loss = 0.00021763505  learning rate = 0.00034056156
============================
Start of epoch 35
step 0: mean loss = 0.00018689466
step 100: mean loss = 0.0002187113
step 200: mean loss = 0.00021976871
step 300: mean loss = 0.00021442608
step 400: mean loss = 0.00021510999
step 500: mean loss = 0.00021716414
step 600: mean loss = 0.00021862997
epoch 35: mean loss = 0.00021821616  learning rate = 0.00034056156
============================
Start of epoch 36
step 0: mean loss = 0.00015896681
step 100: mean loss = 0.00022143751
step 200: mean loss = 0.00022097002
step 300: mean loss = 0.00022080365
step 400: mean loss = 0.00022400124
step 500: mean loss = 0.0002213566
step 600: mean loss = 0.00022269729
epoch 36: mean loss = 0.00022296036  learning rate = 0.00034056156
============================
Start of epoch 37
step 0: mean loss = 0.00017889349
step 100: mean loss = 0.0002177122
step 200: mean loss = 0.00021813615
step 300: mean loss = 0.00021624686
step 400: mean loss = 0.00022042771
step 500: mean loss = 0.00022013499
step 600: mean loss = 0.00022031603
epoch 37: mean loss = 0.00022062162  learning rate = 0.00034056156
============================
Start of epoch 38
step 0: mean loss = 0.00022913847
step 100: mean loss = 0.00021674806
step 200: mean loss = 0.00021694237
step 300: mean loss = 0.00021270472
step 400: mean loss = 0.00021565966
step 500: mean loss = 0.00021587498
step 600: mean loss = 0.0002171189
epoch 38: mean loss = 0.00021778914  learning rate = 0.00034056156
============================
Start of epoch 39
step 0: mean loss = 0.0002440543
step 100: mean loss = 0.00021472732
step 200: mean loss = 0.00022217949
step 300: mean loss = 0.00021440738
step 400: mean loss = 0.00021830383
step 500: mean loss = 0.00021895734
step 600: mean loss = 0.00021782059
epoch 39: mean loss = 0.00021935113  learning rate = 0.00032353346
============================
Start of epoch 40
step 0: mean loss = 0.00020840754
step 100: mean loss = 0.00021428168
step 200: mean loss = 0.000202913
step 300: mean loss = 0.00020924317
step 400: mean loss = 0.00020980707
step 500: mean loss = 0.00021227245
step 600: mean loss = 0.000213567
epoch 40: mean loss = 0.0002140389  learning rate = 0.00032353346
============================
Start of epoch 41
step 0: mean loss = 0.00022254584
step 100: mean loss = 0.00020441881
step 200: mean loss = 0.00020867464
step 300: mean loss = 0.00021336199
step 400: mean loss = 0.00021259862
step 500: mean loss = 0.00020880811
step 600: mean loss = 0.00020796317
epoch 41: mean loss = 0.00020890577  learning rate = 0.00032353346
============================
Start of epoch 42
step 0: mean loss = 0.00020322354
step 100: mean loss = 0.00021236196
step 200: mean loss = 0.00021444974
step 300: mean loss = 0.00021430929
step 400: mean loss = 0.00021141392
step 500: mean loss = 0.00021264055
step 600: mean loss = 0.00021225718
epoch 42: mean loss = 0.00021321778  learning rate = 0.00032353346
============================
Start of epoch 43
step 0: mean loss = 0.00023107996
step 100: mean loss = 0.00021040006
step 200: mean loss = 0.00021656988
step 300: mean loss = 0.00021679523
step 400: mean loss = 0.00021679177
step 500: mean loss = 0.00021415866
step 600: mean loss = 0.00021047017
epoch 43: mean loss = 0.00020970662  learning rate = 0.00032353346
============================
Start of epoch 44
step 0: mean loss = 0.00024258145
step 100: mean loss = 0.00020059469
step 200: mean loss = 0.00020715968
step 300: mean loss = 0.00021378651
step 400: mean loss = 0.00021395973
step 500: mean loss = 0.00021159352
step 600: mean loss = 0.00021168526
epoch 44: mean loss = 0.00021090393  learning rate = 0.00032353346
============================
Start of epoch 45
step 0: mean loss = 0.00015399783
step 100: mean loss = 0.00021970925
step 200: mean loss = 0.00021030178
step 300: mean loss = 0.0002057929
step 400: mean loss = 0.00020571932
step 500: mean loss = 0.00021042199
step 600: mean loss = 0.00021119705
epoch 45: mean loss = 0.00021185698  learning rate = 0.00032353346
============================
Start of epoch 46
step 0: mean loss = 0.0003102168
step 100: mean loss = 0.0002011918
step 200: mean loss = 0.00020577162
step 300: mean loss = 0.00020743006
step 400: mean loss = 0.00020661925
step 500: mean loss = 0.00021064561
step 600: mean loss = 0.00021063894
epoch 46: mean loss = 0.00021076054  learning rate = 0.00032353346
============================
Start of epoch 47
step 0: mean loss = 0.0001988993
step 100: mean loss = 0.0001930488
step 200: mean loss = 0.00020453408
step 300: mean loss = 0.00020484079
step 400: mean loss = 0.00020776677
step 500: mean loss = 0.00020481383
step 600: mean loss = 0.00020286132
epoch 47: mean loss = 0.0002027082  learning rate = 0.00032353346
============================
Start of epoch 48
step 0: mean loss = 0.0001359351
step 100: mean loss = 0.00019137174
step 200: mean loss = 0.00020297764
step 300: mean loss = 0.0002089855
step 400: mean loss = 0.00020845918
step 500: mean loss = 0.0002091485
step 600: mean loss = 0.00020946171
epoch 48: mean loss = 0.00021042737  learning rate = 0.00032353346
============================
Start of epoch 49
step 0: mean loss = 0.00021266361
step 100: mean loss = 0.00019255155
step 200: mean loss = 0.00020563061
step 300: mean loss = 0.0002037576
step 400: mean loss = 0.00020680924
step 500: mean loss = 0.00020833101
step 600: mean loss = 0.00020664501
epoch 49: mean loss = 0.00020693635  learning rate = 0.00032353346
============================
Start of epoch 50
step 0: mean loss = 0.00017286956
step 100: mean loss = 0.00019636845
step 200: mean loss = 0.00019774954
step 300: mean loss = 0.00020064169
step 400: mean loss = 0.00020264936
step 500: mean loss = 0.00020383649
step 600: mean loss = 0.00020403118
epoch 50: mean loss = 0.00020381398  learning rate = 0.00032353346
============================
Start of epoch 51
step 0: mean loss = 0.00019878405
step 100: mean loss = 0.00019521858
step 200: mean loss = 0.00020376105
step 300: mean loss = 0.0002032949
step 400: mean loss = 0.00020165583
step 500: mean loss = 0.00020418956
step 600: mean loss = 0.00020763082
epoch 51: mean loss = 0.00020690642  learning rate = 0.00032353346
============================
Start of epoch 52
step 0: mean loss = 0.00016970205
step 100: mean loss = 0.00019123321
step 200: mean loss = 0.00019982395
step 300: mean loss = 0.00020248856
step 400: mean loss = 0.00020370183
step 500: mean loss = 0.00020464421
step 600: mean loss = 0.00020393809
epoch 52: mean loss = 0.00020404131  learning rate = 0.00032353346
============================
Start of epoch 53
step 0: mean loss = 0.00019372397
step 100: mean loss = 0.00019850253
step 200: mean loss = 0.00020311541
step 300: mean loss = 0.00020951778
step 400: mean loss = 0.00020541497
step 500: mean loss = 0.00020480555
step 600: mean loss = 0.00020472752
epoch 53: mean loss = 0.00020546434  learning rate = 0.00032353346
============================
Start of epoch 54
step 0: mean loss = 0.00017614414
step 100: mean loss = 0.00020419066
step 200: mean loss = 0.0002146754
step 300: mean loss = 0.00021457669
step 400: mean loss = 0.00021170363
step 500: mean loss = 0.00021181653
step 600: mean loss = 0.00021138981
epoch 54: mean loss = 0.00021165797  learning rate = 0.00032353346
============================
Start of epoch 55
step 0: mean loss = 0.00016311117
step 100: mean loss = 0.00020440345
step 200: mean loss = 0.00020437683
step 300: mean loss = 0.00020391108
step 400: mean loss = 0.00020484405
step 500: mean loss = 0.0002036972
step 600: mean loss = 0.00020393016
epoch 55: mean loss = 0.00020401803  learning rate = 0.00032353346
============================
Start of epoch 56
step 0: mean loss = 0.0002872831
step 100: mean loss = 0.00019814329
step 200: mean loss = 0.0001952455
step 300: mean loss = 0.0001968676
step 400: mean loss = 0.00019405267
step 500: mean loss = 0.00019569928
step 600: mean loss = 0.000198578
epoch 56: mean loss = 0.00019888223  learning rate = 0.00032353346
============================
Start of epoch 57
step 0: mean loss = 0.00018679857
step 100: mean loss = 0.0002047605
step 200: mean loss = 0.00020298923
step 300: mean loss = 0.00020175203
step 400: mean loss = 0.00020545008
step 500: mean loss = 0.00020375324
step 600: mean loss = 0.00020454651
epoch 57: mean loss = 0.00020476198  learning rate = 0.00032353346
============================
Start of epoch 58
step 0: mean loss = 0.00024850102
step 100: mean loss = 0.00020767898
step 200: mean loss = 0.00019633675
step 300: mean loss = 0.00020191711
step 400: mean loss = 0.00020315526
step 500: mean loss = 0.0002023212
step 600: mean loss = 0.0002014886
epoch 58: mean loss = 0.00020146096  learning rate = 0.00032353346
============================
Start of epoch 59
step 0: mean loss = 0.00027505978
step 100: mean loss = 0.0002085159
step 200: mean loss = 0.00020085684
step 300: mean loss = 0.00020426798
step 400: mean loss = 0.00020192015
step 500: mean loss = 0.00020088804
step 600: mean loss = 0.00020095064
epoch 59: mean loss = 0.0002006112  learning rate = 0.0003073568
============================
Start of epoch 60
step 0: mean loss = 0.00016428097
step 100: mean loss = 0.0001935687
step 200: mean loss = 0.00019131791
step 300: mean loss = 0.00019395826
step 400: mean loss = 0.00019593466
step 500: mean loss = 0.00019595695
step 600: mean loss = 0.00019579596
epoch 60: mean loss = 0.00019571981  learning rate = 0.0003073568
============================
Start of epoch 61
step 0: mean loss = 0.00014525212
step 100: mean loss = 0.00019799883
step 200: mean loss = 0.0001967947
step 300: mean loss = 0.00020215928
step 400: mean loss = 0.00020041586
step 500: mean loss = 0.00019763358
step 600: mean loss = 0.00019695831
epoch 61: mean loss = 0.00019741921  learning rate = 0.0003073568
============================
Start of epoch 62
step 0: mean loss = 0.00019281372
step 100: mean loss = 0.00018878246
step 200: mean loss = 0.00019400378
step 300: mean loss = 0.00019467738
step 400: mean loss = 0.00019688209
step 500: mean loss = 0.00019350233
step 600: mean loss = 0.00019134034
epoch 62: mean loss = 0.00019183486  learning rate = 0.0003073568
============================
Start of epoch 63
step 0: mean loss = 0.00015540005
step 100: mean loss = 0.00019085142
step 200: mean loss = 0.00019599489
step 300: mean loss = 0.00019553922
step 400: mean loss = 0.00019618667
step 500: mean loss = 0.00019738909
step 600: mean loss = 0.00019784228
epoch 63: mean loss = 0.00019833515  learning rate = 0.0003073568
============================
Start of epoch 64
step 0: mean loss = 0.00021064833
step 100: mean loss = 0.00020316703
step 200: mean loss = 0.00020640314
step 300: mean loss = 0.00020319321
step 400: mean loss = 0.0001981183
step 500: mean loss = 0.0001954556
step 600: mean loss = 0.00019551265
epoch 64: mean loss = 0.00019501997  learning rate = 0.0003073568
============================
Start of epoch 65
step 0: mean loss = 0.00018119981
step 100: mean loss = 0.00019305908
step 200: mean loss = 0.00019356844
step 300: mean loss = 0.00019455896
step 400: mean loss = 0.00019361179
step 500: mean loss = 0.00019393499
step 600: mean loss = 0.00019440654
epoch 65: mean loss = 0.00019418623  learning rate = 0.0003073568
============================
Start of epoch 66
step 0: mean loss = 0.00017682338
step 100: mean loss = 0.00018361252
step 200: mean loss = 0.00019094071
step 300: mean loss = 0.00019001708
step 400: mean loss = 0.00018980732
step 500: mean loss = 0.00019062989
step 600: mean loss = 0.00018951723
epoch 66: mean loss = 0.00018981617  learning rate = 0.0003073568
============================
Start of epoch 67
step 0: mean loss = 0.00015734347
step 100: mean loss = 0.00019486822
step 200: mean loss = 0.00019533165
step 300: mean loss = 0.00019348707
step 400: mean loss = 0.00019250177
step 500: mean loss = 0.00019155379
step 600: mean loss = 0.00019225353
epoch 67: mean loss = 0.00019369833  learning rate = 0.0003073568
============================
Start of epoch 68
step 0: mean loss = 0.00023824495
step 100: mean loss = 0.00020743732
step 200: mean loss = 0.00019488645
step 300: mean loss = 0.00019089076
step 400: mean loss = 0.00019172383
step 500: mean loss = 0.00019146317
step 600: mean loss = 0.00019149252
epoch 68: mean loss = 0.00019129345  learning rate = 0.0003073568
============================
Start of epoch 69
step 0: mean loss = 0.0002035625
step 100: mean loss = 0.00018267363
step 200: mean loss = 0.00018966741
step 300: mean loss = 0.00019551927
step 400: mean loss = 0.00019500479
step 500: mean loss = 0.00019490217
step 600: mean loss = 0.00019340812
epoch 69: mean loss = 0.0001935288  learning rate = 0.0003073568
============================
Start of epoch 70
step 0: mean loss = 0.00014681912
step 100: mean loss = 0.00018798055
step 200: mean loss = 0.0001828672
step 300: mean loss = 0.00018639163
step 400: mean loss = 0.00018810798
step 500: mean loss = 0.00018703974
step 600: mean loss = 0.00018857172
epoch 70: mean loss = 0.00018892005  learning rate = 0.0003073568
============================
Start of epoch 71
step 0: mean loss = 0.00016878975
step 100: mean loss = 0.00019802028
step 200: mean loss = 0.00019168631
step 300: mean loss = 0.00019338107
step 400: mean loss = 0.00019176044
step 500: mean loss = 0.00019339383
step 600: mean loss = 0.00019211335
epoch 71: mean loss = 0.00019297449  learning rate = 0.0003073568
============================
Start of epoch 72
step 0: mean loss = 0.00021841971
step 100: mean loss = 0.00019238249
step 200: mean loss = 0.00018293162
step 300: mean loss = 0.00018625242
step 400: mean loss = 0.00018813128
step 500: mean loss = 0.0001886719
step 600: mean loss = 0.00019034906
epoch 72: mean loss = 0.00019057158  learning rate = 0.0003073568
============================
Start of epoch 73
step 0: mean loss = 0.00014946307
step 100: mean loss = 0.0001908584
step 200: mean loss = 0.00019091112
step 300: mean loss = 0.0001872991
step 400: mean loss = 0.00018569094
step 500: mean loss = 0.00018903794
step 600: mean loss = 0.00018840659
epoch 73: mean loss = 0.00018812814  learning rate = 0.0003073568
============================
Start of epoch 74
step 0: mean loss = 0.00011932226
step 100: mean loss = 0.00018236223
step 200: mean loss = 0.00018774724
step 300: mean loss = 0.00018960044
step 400: mean loss = 0.00019197144
step 500: mean loss = 0.00019359632
step 600: mean loss = 0.00019395782
epoch 74: mean loss = 0.00019358358  learning rate = 0.0003073568
============================
Start of epoch 75
step 0: mean loss = 0.00019331166
step 100: mean loss = 0.00018907207
step 200: mean loss = 0.00018467272
step 300: mean loss = 0.0001835701
step 400: mean loss = 0.00018326892
step 500: mean loss = 0.00018815447
step 600: mean loss = 0.00018885605
epoch 75: mean loss = 0.00018856268  learning rate = 0.0003073568
============================
Start of epoch 76
step 0: mean loss = 0.00017964907
step 100: mean loss = 0.0001811286
step 200: mean loss = 0.00017952289
step 300: mean loss = 0.00018482811
step 400: mean loss = 0.00018642076
step 500: mean loss = 0.00018829046
step 600: mean loss = 0.00018879442
epoch 76: mean loss = 0.00018863802  learning rate = 0.0003073568
============================
Start of epoch 77
step 0: mean loss = 0.00022319573
step 100: mean loss = 0.0001784721
step 200: mean loss = 0.00018826575
step 300: mean loss = 0.00018758717
step 400: mean loss = 0.00018616865
step 500: mean loss = 0.00018787473
step 600: mean loss = 0.00019044906
epoch 77: mean loss = 0.0001906864  learning rate = 0.0003073568
============================
Start of epoch 78
step 0: mean loss = 0.00012155263
step 100: mean loss = 0.00018267702
step 200: mean loss = 0.0001775529
step 300: mean loss = 0.00018345582
step 400: mean loss = 0.0001849512
step 500: mean loss = 0.0001844528
step 600: mean loss = 0.00018618857
epoch 78: mean loss = 0.0001865898  learning rate = 0.0003073568
============================
Start of epoch 79
step 0: mean loss = 0.0001722601
step 100: mean loss = 0.00018661779
step 200: mean loss = 0.0001846267
step 300: mean loss = 0.00018478018
step 400: mean loss = 0.00018647588
step 500: mean loss = 0.00018496934
step 600: mean loss = 0.00018666848
epoch 79: mean loss = 0.00018638621  learning rate = 0.00029198892
============================
Start of epoch 80
step 0: mean loss = 0.00022479646
step 100: mean loss = 0.0001797489
step 200: mean loss = 0.0001799978
step 300: mean loss = 0.00017829935
step 400: mean loss = 0.0001784443
step 500: mean loss = 0.00018020715
step 600: mean loss = 0.00017975042
epoch 80: mean loss = 0.00018048518  learning rate = 0.00029198892
============================
Start of epoch 81
step 0: mean loss = 0.00017126858
step 100: mean loss = 0.00018709837
step 200: mean loss = 0.00018166583
step 300: mean loss = 0.00017858863
step 400: mean loss = 0.00018048087
step 500: mean loss = 0.00018230696
step 600: mean loss = 0.00018295148
epoch 81: mean loss = 0.00018284169  learning rate = 0.00029198892
============================
Start of epoch 82
step 0: mean loss = 0.00017242221
step 100: mean loss = 0.00017766433
step 200: mean loss = 0.0001808032
step 300: mean loss = 0.00017972139
step 400: mean loss = 0.00017812662
step 500: mean loss = 0.00017612727
step 600: mean loss = 0.0001753811
epoch 82: mean loss = 0.00017702072  learning rate = 0.00029198892
============================
Start of epoch 83
step 0: mean loss = 0.00017608164
step 100: mean loss = 0.00018642463
step 200: mean loss = 0.00018130465
step 300: mean loss = 0.00018107863
step 400: mean loss = 0.00018120682
step 500: mean loss = 0.0001804423
step 600: mean loss = 0.0001829902
epoch 83: mean loss = 0.0001830631  learning rate = 0.00029198892
============================
Start of epoch 84
step 0: mean loss = 0.00016231326
step 100: mean loss = 0.00017609134
step 200: mean loss = 0.00018259295
step 300: mean loss = 0.00018057688
step 400: mean loss = 0.00018030957
step 500: mean loss = 0.00017993929
step 600: mean loss = 0.00017867198
epoch 84: mean loss = 0.00017841096  learning rate = 0.00029198892
============================
Start of epoch 85
step 0: mean loss = 0.00017676516
step 100: mean loss = 0.00018790086
step 200: mean loss = 0.00018258514
step 300: mean loss = 0.0001833949
step 400: mean loss = 0.00018496181
step 500: mean loss = 0.00018572166
step 600: mean loss = 0.00018379069
epoch 85: mean loss = 0.00018334782  learning rate = 0.00029198892
============================
Start of epoch 86
step 0: mean loss = 0.00017078142
step 100: mean loss = 0.00017925863
step 200: mean loss = 0.0001800398
step 300: mean loss = 0.00017548568
step 400: mean loss = 0.00017619776
step 500: mean loss = 0.00017918702
step 600: mean loss = 0.00018001898
epoch 86: mean loss = 0.00017981551  learning rate = 0.00029198892
============================
Start of epoch 87
step 0: mean loss = 0.00015636501
step 100: mean loss = 0.00016404256
step 200: mean loss = 0.00017463931
step 300: mean loss = 0.00017693873
step 400: mean loss = 0.00018045295
step 500: mean loss = 0.00018094953
step 600: mean loss = 0.00018096184
epoch 87: mean loss = 0.00018054494  learning rate = 0.00029198892
============================
Start of epoch 88
step 0: mean loss = 0.00010734823
step 100: mean loss = 0.00016711133
step 200: mean loss = 0.00017249123
step 300: mean loss = 0.00017149062
step 400: mean loss = 0.00017585275
step 500: mean loss = 0.00017699141
step 600: mean loss = 0.00017595378
epoch 88: mean loss = 0.00017609287  learning rate = 0.00029198892
============================
Start of epoch 89
step 0: mean loss = 0.00015626039
step 100: mean loss = 0.00017354226
step 200: mean loss = 0.00017656144
step 300: mean loss = 0.00017914905
step 400: mean loss = 0.00017935835
step 500: mean loss = 0.00017684337
step 600: mean loss = 0.00017731317
epoch 89: mean loss = 0.0001767521  learning rate = 0.00029198892
============================
Start of epoch 90
step 0: mean loss = 0.0001301113
step 100: mean loss = 0.00017867422
step 200: mean loss = 0.00017525973
step 300: mean loss = 0.00017461873
step 400: mean loss = 0.0001737535
step 500: mean loss = 0.00017387964
step 600: mean loss = 0.00017360173
epoch 90: mean loss = 0.00017374915  learning rate = 0.00029198892
============================
Start of epoch 91
step 0: mean loss = 0.00014428834
step 100: mean loss = 0.00017542546
step 200: mean loss = 0.00018344427
step 300: mean loss = 0.00018349252
step 400: mean loss = 0.00018010673
step 500: mean loss = 0.00017991931
step 600: mean loss = 0.00018062822
epoch 91: mean loss = 0.00018039705  learning rate = 0.00029198892
============================
Start of epoch 92
step 0: mean loss = 0.00019992443
step 100: mean loss = 0.00017892964
step 200: mean loss = 0.00017797963
step 300: mean loss = 0.00017231939
step 400: mean loss = 0.00017981978
step 500: mean loss = 0.00018037701
step 600: mean loss = 0.0001794088
epoch 92: mean loss = 0.0001792806  learning rate = 0.00029198892
============================
Start of epoch 93
step 0: mean loss = 0.00015090966
step 100: mean loss = 0.00018356029
step 200: mean loss = 0.00018078543
step 300: mean loss = 0.00017745086
step 400: mean loss = 0.00017925541
step 500: mean loss = 0.00017806228
step 600: mean loss = 0.0001782736
epoch 93: mean loss = 0.00017867264  learning rate = 0.00029198892
============================
Start of epoch 94
step 0: mean loss = 0.00019055395
step 100: mean loss = 0.0001740955
step 200: mean loss = 0.00017069058
step 300: mean loss = 0.0001749661
step 400: mean loss = 0.00017758454
step 500: mean loss = 0.00017577437
step 600: mean loss = 0.00017628055
epoch 94: mean loss = 0.00017637233  learning rate = 0.00029198892
============================
Start of epoch 95
step 0: mean loss = 0.00019749792
step 100: mean loss = 0.00016949754
step 200: mean loss = 0.00016950676
step 300: mean loss = 0.00017570745
step 400: mean loss = 0.0001752421
step 500: mean loss = 0.00017965036
step 600: mean loss = 0.00017913747
epoch 95: mean loss = 0.0001787264  learning rate = 0.00029198892
============================
Start of epoch 96
step 0: mean loss = 0.00017079967
step 100: mean loss = 0.00017387242
step 200: mean loss = 0.00018028326
step 300: mean loss = 0.00017681063
step 400: mean loss = 0.00017531197
step 500: mean loss = 0.00017608675
step 600: mean loss = 0.0001747739
epoch 96: mean loss = 0.00017451959  learning rate = 0.00029198892
============================
Start of epoch 97
step 0: mean loss = 0.00012940065
step 100: mean loss = 0.00016330244
step 200: mean loss = 0.00017221
step 300: mean loss = 0.00017942859
step 400: mean loss = 0.00017670766
step 500: mean loss = 0.00017694301
step 600: mean loss = 0.00017565793
epoch 97: mean loss = 0.00017551189  learning rate = 0.00029198892
============================
Start of epoch 98
step 0: mean loss = 0.00013473582
step 100: mean loss = 0.00016910168
step 200: mean loss = 0.00017005841
step 300: mean loss = 0.00017714074
step 400: mean loss = 0.00017591278
step 500: mean loss = 0.00017262163
step 600: mean loss = 0.00017374536
epoch 98: mean loss = 0.00017349167  learning rate = 0.00029198892
============================
Start of epoch 99
step 0: mean loss = 0.00014189605
step 100: mean loss = 0.00016439678
step 200: mean loss = 0.00017391192
step 300: mean loss = 0.00017500234
step 400: mean loss = 0.00017577164
step 500: mean loss = 0.00017559412
step 600: mean loss = 0.00017760096
epoch 99: mean loss = 0.00017754038  learning rate = 0.0002773895
============================
Start of epoch 100
step 0: mean loss = 0.00020089865
step 100: mean loss = 0.00017133555
step 200: mean loss = 0.00017220763
step 300: mean loss = 0.00017180262
step 400: mean loss = 0.0001742824
step 500: mean loss = 0.0001708975
step 600: mean loss = 0.00017027372
epoch 100: mean loss = 0.00016977132  learning rate = 0.0002773895
============================
Start of epoch 101
step 0: mean loss = 0.00016578048
step 100: mean loss = 0.00016736543
step 200: mean loss = 0.00016485603
step 300: mean loss = 0.00016556261
step 400: mean loss = 0.00016734637
step 500: mean loss = 0.0001664258
step 600: mean loss = 0.00016936321
epoch 101: mean loss = 0.00016988795  learning rate = 0.0002773895
============================
Start of epoch 102
step 0: mean loss = 0.0002616567
step 100: mean loss = 0.00018169747
step 200: mean loss = 0.00017191126
step 300: mean loss = 0.00017312393
step 400: mean loss = 0.00017180872
step 500: mean loss = 0.0001707912
step 600: mean loss = 0.00016964368
epoch 102: mean loss = 0.0001693629  learning rate = 0.0002773895
============================
Start of epoch 103
step 0: mean loss = 0.00015582246
step 100: mean loss = 0.00016469699
step 200: mean loss = 0.0001634902
step 300: mean loss = 0.00016510127
step 400: mean loss = 0.00016809677
step 500: mean loss = 0.00016979335
step 600: mean loss = 0.00016799594
epoch 103: mean loss = 0.00016739631  learning rate = 0.0002773895
============================
Start of epoch 104
step 0: mean loss = 0.00019552455
step 100: mean loss = 0.00016659207
step 200: mean loss = 0.0001673886
step 300: mean loss = 0.00016729129
step 400: mean loss = 0.00016646061
step 500: mean loss = 0.00016757981
step 600: mean loss = 0.0001684691
epoch 104: mean loss = 0.00016854086  learning rate = 0.0002773895
============================
Start of epoch 105
step 0: mean loss = 0.00017020249
step 100: mean loss = 0.00016540983
step 200: mean loss = 0.00016104415
step 300: mean loss = 0.000162654
step 400: mean loss = 0.00016279162
step 500: mean loss = 0.00016314267
step 600: mean loss = 0.00016378649
epoch 105: mean loss = 0.0001651271  learning rate = 0.0002773895
============================
Start of epoch 106
step 0: mean loss = 0.00017848902
step 100: mean loss = 0.00016028513
step 200: mean loss = 0.0001613329
step 300: mean loss = 0.00016283874
step 400: mean loss = 0.00016574582
step 500: mean loss = 0.00016824166
step 600: mean loss = 0.00016702212
epoch 106: mean loss = 0.00016706143  learning rate = 0.0002773895
============================
Start of epoch 107
step 0: mean loss = 0.00018463947
step 100: mean loss = 0.00016472
step 200: mean loss = 0.00016165666
step 300: mean loss = 0.00016037414
step 400: mean loss = 0.00016316777
step 500: mean loss = 0.00016536102
step 600: mean loss = 0.0001648212
epoch 107: mean loss = 0.00016500025  learning rate = 0.0002773895
============================
Start of epoch 108
step 0: mean loss = 0.0001591311
step 100: mean loss = 0.00018538606
step 200: mean loss = 0.00017455895
step 300: mean loss = 0.00017156266
step 400: mean loss = 0.00016667956
step 500: mean loss = 0.00016623345
step 600: mean loss = 0.00016573543
epoch 108: mean loss = 0.00016606832  learning rate = 0.0002773895
============================
Start of epoch 109
step 0: mean loss = 0.0001198773
step 100: mean loss = 0.00016756928
step 200: mean loss = 0.00016891632
step 300: mean loss = 0.00017080546
step 400: mean loss = 0.0001703278
step 500: mean loss = 0.00017045057
step 600: mean loss = 0.00016944697
epoch 109: mean loss = 0.00016954687  learning rate = 0.0002773895
============================
Start of epoch 110
step 0: mean loss = 0.00016467739
step 100: mean loss = 0.00015991749
step 200: mean loss = 0.000159907
step 300: mean loss = 0.00016326108
step 400: mean loss = 0.00016733055
step 500: mean loss = 0.00016722296
step 600: mean loss = 0.00016651639
epoch 110: mean loss = 0.0001664801  learning rate = 0.0002773895
============================
Start of epoch 111
step 0: mean loss = 0.00013848921
step 100: mean loss = 0.0001612337
step 200: mean loss = 0.00016003249
step 300: mean loss = 0.00015951264
step 400: mean loss = 0.00016161196
step 500: mean loss = 0.00016186318
step 600: mean loss = 0.0001624643
epoch 111: mean loss = 0.00016298723  learning rate = 0.0002773895
============================
Start of epoch 112
step 0: mean loss = 0.00013614187
step 100: mean loss = 0.00016831995
step 200: mean loss = 0.00016890297
step 300: mean loss = 0.00016830608
step 400: mean loss = 0.00016926911
step 500: mean loss = 0.00016990946
step 600: mean loss = 0.0001705718
epoch 112: mean loss = 0.00017109055  learning rate = 0.0002773895
============================
Start of epoch 113
step 0: mean loss = 0.00016242292
step 100: mean loss = 0.00017035227
step 200: mean loss = 0.0001684112
step 300: mean loss = 0.00016650927
step 400: mean loss = 0.00016540535
step 500: mean loss = 0.00016479677
step 600: mean loss = 0.00016366156
epoch 113: mean loss = 0.00016423667  learning rate = 0.0002773895
============================
Start of epoch 114
step 0: mean loss = 0.0001285439
step 100: mean loss = 0.00016329064
step 200: mean loss = 0.00016641598
step 300: mean loss = 0.00016799851
step 400: mean loss = 0.00016821567
step 500: mean loss = 0.00016651055
step 600: mean loss = 0.00016682535
epoch 114: mean loss = 0.00016687925  learning rate = 0.0002773895
============================
Start of epoch 115
step 0: mean loss = 0.00014750124
step 100: mean loss = 0.00015704356
step 200: mean loss = 0.00015611011
step 300: mean loss = 0.00015951069
step 400: mean loss = 0.00016436516
step 500: mean loss = 0.00016349451
step 600: mean loss = 0.00016291896
epoch 115: mean loss = 0.00016253341  learning rate = 0.0002773895
============================
Start of epoch 116
step 0: mean loss = 0.00018470605
step 100: mean loss = 0.00016772644
step 200: mean loss = 0.00016656781
step 300: mean loss = 0.00016640128
step 400: mean loss = 0.00016582517
step 500: mean loss = 0.00016664987
step 600: mean loss = 0.00016714825
epoch 116: mean loss = 0.00016701195  learning rate = 0.0002773895
============================
Start of epoch 117
step 0: mean loss = 0.00016520795
step 100: mean loss = 0.00016503969
step 200: mean loss = 0.0001638506
step 300: mean loss = 0.00016482592
step 400: mean loss = 0.00016565506
step 500: mean loss = 0.0001645561
step 600: mean loss = 0.0001627017
epoch 117: mean loss = 0.00016337392  learning rate = 0.0002773895
============================
Start of epoch 118
step 0: mean loss = 0.0002071269
step 100: mean loss = 0.00017321209
step 200: mean loss = 0.00017989059
step 300: mean loss = 0.00017501626
step 400: mean loss = 0.0001712052
step 500: mean loss = 0.0001698124
step 600: mean loss = 0.00016918879
epoch 118: mean loss = 0.00016885382  learning rate = 0.0002773895
============================
Start of epoch 119
step 0: mean loss = 0.00015091892
step 100: mean loss = 0.00015633089
step 200: mean loss = 0.00015951728
step 300: mean loss = 0.00016024042
step 400: mean loss = 0.00016410882
step 500: mean loss = 0.0001639729
step 600: mean loss = 0.00016537355
epoch 119: mean loss = 0.00016491393  learning rate = 0.00026352002
============================
Start of epoch 120
step 0: mean loss = 0.000102032645
step 100: mean loss = 0.00015522864
step 200: mean loss = 0.00016157723
step 300: mean loss = 0.00015835458
step 400: mean loss = 0.00015811843
step 500: mean loss = 0.00016014458
step 600: mean loss = 0.00016000982
epoch 120: mean loss = 0.0001595159  learning rate = 0.00026352002
============================
Start of epoch 121
step 0: mean loss = 0.00012687352
step 100: mean loss = 0.00016853139
step 200: mean loss = 0.00016110828
step 300: mean loss = 0.00015710878
step 400: mean loss = 0.00015957592
step 500: mean loss = 0.00016010577
step 600: mean loss = 0.00015841839
epoch 121: mean loss = 0.00015813175  learning rate = 0.00026352002
============================
Start of epoch 122
step 0: mean loss = 0.00014908392
step 100: mean loss = 0.00015925328
step 200: mean loss = 0.00015983477
step 300: mean loss = 0.00016157482
step 400: mean loss = 0.00015757694
step 500: mean loss = 0.00015633638
step 600: mean loss = 0.0001564095
epoch 122: mean loss = 0.00015618972  learning rate = 0.00026352002
============================
Start of epoch 123
step 0: mean loss = 0.00015263731
step 100: mean loss = 0.00015679497
step 200: mean loss = 0.00015955229
step 300: mean loss = 0.00015998361
step 400: mean loss = 0.00016070552
step 500: mean loss = 0.00015773808
step 600: mean loss = 0.00015715344
epoch 123: mean loss = 0.00015718405  learning rate = 0.00026352002
============================
Start of epoch 124
step 0: mean loss = 0.0001789257
step 100: mean loss = 0.0001580411
step 200: mean loss = 0.0001619825
step 300: mean loss = 0.00016156041
step 400: mean loss = 0.00016059457
step 500: mean loss = 0.00015952592
step 600: mean loss = 0.00015882481
epoch 124: mean loss = 0.00015885911  learning rate = 0.00026352002
============================
Start of epoch 125
step 0: mean loss = 0.00011190839
step 100: mean loss = 0.00015411111
step 200: mean loss = 0.00015081231
step 300: mean loss = 0.00015388099
step 400: mean loss = 0.00015717381
step 500: mean loss = 0.00015814592
step 600: mean loss = 0.00015700808
epoch 125: mean loss = 0.00015800254  learning rate = 0.00026352002
============================
Start of epoch 126
step 0: mean loss = 0.00022075968
step 100: mean loss = 0.0001628946
step 200: mean loss = 0.00016118865
step 300: mean loss = 0.00016143778
step 400: mean loss = 0.00015890777
step 500: mean loss = 0.0001569038
step 600: mean loss = 0.00015518344
epoch 126: mean loss = 0.00015505057  learning rate = 0.00026352002
============================
Start of epoch 127
step 0: mean loss = 0.00016799847
step 100: mean loss = 0.0001527819
step 200: mean loss = 0.00015538083
step 300: mean loss = 0.00015820473
step 400: mean loss = 0.00015989918
step 500: mean loss = 0.00016012992
step 600: mean loss = 0.00015990621
epoch 127: mean loss = 0.00015921604  learning rate = 0.00026352002
============================
Start of epoch 128
step 0: mean loss = 0.00018853944
step 100: mean loss = 0.00015617238
step 200: mean loss = 0.00015737489
step 300: mean loss = 0.00015736533
step 400: mean loss = 0.00015678343
step 500: mean loss = 0.00015513407
step 600: mean loss = 0.0001556081
epoch 128: mean loss = 0.00015563745  learning rate = 0.00026352002
============================
Start of epoch 129
step 0: mean loss = 0.00014350499
step 100: mean loss = 0.00015872394
step 200: mean loss = 0.00015558102
step 300: mean loss = 0.00015749116
step 400: mean loss = 0.00015776261
step 500: mean loss = 0.00015841692
step 600: mean loss = 0.00015657094
epoch 129: mean loss = 0.00015626464  learning rate = 0.00026352002
============================
Start of epoch 130
step 0: mean loss = 0.00013439136
step 100: mean loss = 0.00014615181
step 200: mean loss = 0.00015314358
step 300: mean loss = 0.00015309066
step 400: mean loss = 0.00015540868
step 500: mean loss = 0.00015766307
step 600: mean loss = 0.00015795887
epoch 130: mean loss = 0.00015879673  learning rate = 0.00026352002
============================
Start of epoch 131
step 0: mean loss = 0.00017334825
step 100: mean loss = 0.00016196811
step 200: mean loss = 0.00015548224
step 300: mean loss = 0.00015476647
step 400: mean loss = 0.00015391193
step 500: mean loss = 0.00015620209
step 600: mean loss = 0.00015694574
epoch 131: mean loss = 0.0001570936  learning rate = 0.00026352002
============================
Start of epoch 132
step 0: mean loss = 0.00013514751
step 100: mean loss = 0.00016000206
step 200: mean loss = 0.00015953793
step 300: mean loss = 0.00015733924
step 400: mean loss = 0.00015503273
step 500: mean loss = 0.00015530625
step 600: mean loss = 0.00015430553
epoch 132: mean loss = 0.0001543668  learning rate = 0.00026352002
============================
Start of epoch 133
step 0: mean loss = 0.00015554522
step 100: mean loss = 0.00015047842
step 200: mean loss = 0.00015404857
step 300: mean loss = 0.0001566882
step 400: mean loss = 0.00015437546
step 500: mean loss = 0.00015546886
step 600: mean loss = 0.00015633246
epoch 133: mean loss = 0.00015649381  learning rate = 0.00026352002
============================
Start of epoch 134
step 0: mean loss = 0.0001577046
step 100: mean loss = 0.00016151625
step 200: mean loss = 0.00016424376
step 300: mean loss = 0.0001566416
step 400: mean loss = 0.00015441095
step 500: mean loss = 0.00015505927
step 600: mean loss = 0.00015723919
epoch 134: mean loss = 0.00015724941  learning rate = 0.00026352002
============================
Start of epoch 135
step 0: mean loss = 0.00015683388
step 100: mean loss = 0.00015283634
step 200: mean loss = 0.0001482673
step 300: mean loss = 0.00014880512
step 400: mean loss = 0.00014914617
step 500: mean loss = 0.00014914233
step 600: mean loss = 0.00014972908
epoch 135: mean loss = 0.00015056126  learning rate = 0.00026352002
============================
Start of epoch 136
step 0: mean loss = 0.000189003
step 100: mean loss = 0.00015454344
step 200: mean loss = 0.00015368819
step 300: mean loss = 0.0001535817
step 400: mean loss = 0.00015463131
step 500: mean loss = 0.00015252383
step 600: mean loss = 0.00015292756
epoch 136: mean loss = 0.0001533486  learning rate = 0.00026352002
============================
Start of epoch 137
step 0: mean loss = 0.00018540304
step 100: mean loss = 0.00016332115
step 200: mean loss = 0.00016434077
step 300: mean loss = 0.00016286207
step 400: mean loss = 0.00016094508
step 500: mean loss = 0.00015995243
step 600: mean loss = 0.0001578962
epoch 137: mean loss = 0.00015706623  learning rate = 0.00026352002
============================
Start of epoch 138
step 0: mean loss = 0.00011357918
step 100: mean loss = 0.00015331342
step 200: mean loss = 0.00014820103
step 300: mean loss = 0.00015016593
step 400: mean loss = 0.00015413175
step 500: mean loss = 0.00015353503
step 600: mean loss = 0.00015466462
epoch 138: mean loss = 0.00015529389  learning rate = 0.00026352002
============================
Start of epoch 139
step 0: mean loss = 0.000145887
step 100: mean loss = 0.00013859826
step 200: mean loss = 0.00014526934
step 300: mean loss = 0.00014599343
step 400: mean loss = 0.000149866
step 500: mean loss = 0.00015187716
step 600: mean loss = 0.00015255442
epoch 139: mean loss = 0.00015266454  learning rate = 0.00025034402
============================
Start of epoch 140
step 0: mean loss = 0.00018104933
step 100: mean loss = 0.00014661888
step 200: mean loss = 0.00014393292
step 300: mean loss = 0.0001450629
step 400: mean loss = 0.00014992224
step 500: mean loss = 0.00015048674
step 600: mean loss = 0.00015045713
epoch 140: mean loss = 0.00015017818  learning rate = 0.00025034402
============================
Start of epoch 141
step 0: mean loss = 0.00014560454
step 100: mean loss = 0.0001434652
step 200: mean loss = 0.00014315503
step 300: mean loss = 0.0001435581
step 400: mean loss = 0.00014492882
step 500: mean loss = 0.00014622294
step 600: mean loss = 0.00014552443
epoch 141: mean loss = 0.00014597319  learning rate = 0.00025034402
============================
Start of epoch 142
step 0: mean loss = 0.00012927217
step 100: mean loss = 0.00014495658
step 200: mean loss = 0.00014463236
step 300: mean loss = 0.0001489166
step 400: mean loss = 0.00015033316
step 500: mean loss = 0.00014989042
step 600: mean loss = 0.00014904111
epoch 142: mean loss = 0.00014894966  learning rate = 0.00025034402
============================
Start of epoch 143
step 0: mean loss = 0.000113540635
step 100: mean loss = 0.00015264751
step 200: mean loss = 0.00015120488
step 300: mean loss = 0.00015005973
step 400: mean loss = 0.00014692065
step 500: mean loss = 0.00014723578
step 600: mean loss = 0.00014834866
epoch 143: mean loss = 0.00014819323  learning rate = 0.00025034402
============================
Start of epoch 144
step 0: mean loss = 0.000114566414
step 100: mean loss = 0.00014183586
step 200: mean loss = 0.00014379424
step 300: mean loss = 0.00014920415
step 400: mean loss = 0.00014640726
step 500: mean loss = 0.00014673042
step 600: mean loss = 0.00014671993
epoch 144: mean loss = 0.00014679275  learning rate = 0.00025034402
============================
Start of epoch 145
step 0: mean loss = 0.00010035297
step 100: mean loss = 0.00014191886
step 200: mean loss = 0.00014261763
step 300: mean loss = 0.00014713826
step 400: mean loss = 0.00014695368
step 500: mean loss = 0.00014636143
step 600: mean loss = 0.00014761073
epoch 145: mean loss = 0.00014733858  learning rate = 0.00025034402
============================
Start of epoch 146
step 0: mean loss = 0.00014532829
step 100: mean loss = 0.00014329227
step 200: mean loss = 0.00014611526
step 300: mean loss = 0.0001448988
step 400: mean loss = 0.00014600424
step 500: mean loss = 0.00014766636
step 600: mean loss = 0.00014938938
epoch 146: mean loss = 0.00014928864  learning rate = 0.00025034402
============================
Start of epoch 147
step 0: mean loss = 0.00012951043
step 100: mean loss = 0.00014675697
step 200: mean loss = 0.00014265944
step 300: mean loss = 0.00014159858
step 400: mean loss = 0.0001401156
step 500: mean loss = 0.00014188321
step 600: mean loss = 0.0001433702
epoch 147: mean loss = 0.00014389497  learning rate = 0.00025034402
============================
Start of epoch 148
step 0: mean loss = 0.00014857156
step 100: mean loss = 0.00014141697
step 200: mean loss = 0.00014335125
step 300: mean loss = 0.0001410697
step 400: mean loss = 0.0001467288
step 500: mean loss = 0.00014756338
step 600: mean loss = 0.00014703846
epoch 148: mean loss = 0.00014742605  learning rate = 0.00025034402
============================
Start of epoch 149
step 0: mean loss = 0.00011628562
step 100: mean loss = 0.00014312718
step 200: mean loss = 0.00014236172
step 300: mean loss = 0.00014006413
step 400: mean loss = 0.00014091101
step 500: mean loss = 0.00014180485
step 600: mean loss = 0.00014434851
epoch 149: mean loss = 0.00014487962  learning rate = 0.00025034402
============================
Start of epoch 150
step 0: mean loss = 0.00014757137
step 100: mean loss = 0.00013988285
step 200: mean loss = 0.0001373571
step 300: mean loss = 0.00014000532
step 400: mean loss = 0.00014066914
step 500: mean loss = 0.00014223992
step 600: mean loss = 0.0001434148
epoch 150: mean loss = 0.00014361415  learning rate = 0.00025034402
============================
Start of epoch 151
step 0: mean loss = 0.0001892434
step 100: mean loss = 0.00014923076
step 200: mean loss = 0.00014762204
step 300: mean loss = 0.00015066343
step 400: mean loss = 0.00014710322
step 500: mean loss = 0.00014575207
step 600: mean loss = 0.00014764989
epoch 151: mean loss = 0.000147735  learning rate = 0.00025034402
============================
Start of epoch 152
step 0: mean loss = 0.0001663921
step 100: mean loss = 0.00014256121
step 200: mean loss = 0.00014631847
step 300: mean loss = 0.00014625219
step 400: mean loss = 0.00014506078
step 500: mean loss = 0.00014511828
step 600: mean loss = 0.0001447731
epoch 152: mean loss = 0.000144614  learning rate = 0.00025034402
============================
Start of epoch 153
step 0: mean loss = 0.00011206382
step 100: mean loss = 0.00013996063
step 200: mean loss = 0.00014041514
step 300: mean loss = 0.00014304825
step 400: mean loss = 0.00014452758
step 500: mean loss = 0.000143537
step 600: mean loss = 0.00014491001
epoch 153: mean loss = 0.00014518666  learning rate = 0.00025034402
============================
Start of epoch 154
step 0: mean loss = 0.00012366427
step 100: mean loss = 0.00014616802
step 200: mean loss = 0.00014873299
step 300: mean loss = 0.00014940806
step 400: mean loss = 0.00014714513
step 500: mean loss = 0.00014673333
step 600: mean loss = 0.00014556387
epoch 154: mean loss = 0.0001450816  learning rate = 0.00025034402
============================
Start of epoch 155
step 0: mean loss = 0.00010559285
step 100: mean loss = 0.0001368108
step 200: mean loss = 0.00013856564
step 300: mean loss = 0.00014281405
step 400: mean loss = 0.00014251801
step 500: mean loss = 0.00014183935
step 600: mean loss = 0.00014264902
epoch 155: mean loss = 0.00014282858  learning rate = 0.00025034402
============================
Start of epoch 156
step 0: mean loss = 0.0001282211
step 100: mean loss = 0.00013994014
step 200: mean loss = 0.00014004651
step 300: mean loss = 0.00014126912
step 400: mean loss = 0.00014057824
step 500: mean loss = 0.00014307017
step 600: mean loss = 0.00014381576
epoch 156: mean loss = 0.0001436705  learning rate = 0.00025034402
============================
Start of epoch 157
step 0: mean loss = 0.0001850151
step 100: mean loss = 0.00013179614
step 200: mean loss = 0.00013929053
step 300: mean loss = 0.00014034423
step 400: mean loss = 0.00014193516
step 500: mean loss = 0.00014470425
step 600: mean loss = 0.00014589635
epoch 157: mean loss = 0.00014587234  learning rate = 0.00025034402
============================
Start of epoch 158
step 0: mean loss = 0.00015160476
step 100: mean loss = 0.00014582802
step 200: mean loss = 0.00014304323
step 300: mean loss = 0.00014514454
step 400: mean loss = 0.00014757806
step 500: mean loss = 0.00014663149
step 600: mean loss = 0.00014546506
epoch 158: mean loss = 0.00014517545  learning rate = 0.00025034402
============================
Start of epoch 159
step 0: mean loss = 0.0001158627
step 100: mean loss = 0.0001369758
step 200: mean loss = 0.00013984278
step 300: mean loss = 0.00014100445
step 400: mean loss = 0.0001441294
step 500: mean loss = 0.00014384341
step 600: mean loss = 0.00014374593
epoch 159: mean loss = 0.00014354002  learning rate = 0.00023782681
============================
Start of epoch 160
step 0: mean loss = 0.00012974624
step 100: mean loss = 0.00013258806
step 200: mean loss = 0.00013466706
step 300: mean loss = 0.00013619279
step 400: mean loss = 0.00013681628
step 500: mean loss = 0.00013612148
step 600: mean loss = 0.00013712847
epoch 160: mean loss = 0.00013746363  learning rate = 0.00023782681
============================
Start of epoch 161
step 0: mean loss = 0.000114978444
step 100: mean loss = 0.00013284181
step 200: mean loss = 0.00014143862
step 300: mean loss = 0.0001383605
step 400: mean loss = 0.00013891485
step 500: mean loss = 0.0001385907
step 600: mean loss = 0.00013861795
epoch 161: mean loss = 0.00013834985  learning rate = 0.00023782681
============================
Start of epoch 162
step 0: mean loss = 0.00013518542
step 100: mean loss = 0.00013605104
step 200: mean loss = 0.00014178145
step 300: mean loss = 0.00014254679
step 400: mean loss = 0.000142061
step 500: mean loss = 0.00014202883
step 600: mean loss = 0.00014124767
epoch 162: mean loss = 0.0001409677  learning rate = 0.00023782681
============================
Start of epoch 163
step 0: mean loss = 0.00012492613
step 100: mean loss = 0.00012814553
step 200: mean loss = 0.00013493648
step 300: mean loss = 0.00013790341
step 400: mean loss = 0.00013693058
step 500: mean loss = 0.00013658407
step 600: mean loss = 0.0001368772
epoch 163: mean loss = 0.00013739047  learning rate = 0.00023782681
============================
Start of epoch 164
step 0: mean loss = 0.00013850487
step 100: mean loss = 0.00013431118
step 200: mean loss = 0.00013871385
step 300: mean loss = 0.00013821162
step 400: mean loss = 0.00013820537
step 500: mean loss = 0.0001385704
step 600: mean loss = 0.00013984654
epoch 164: mean loss = 0.0001396276  learning rate = 0.00023782681
============================
Start of epoch 165
step 0: mean loss = 0.000120601166
step 100: mean loss = 0.0001299796
step 200: mean loss = 0.00013323723
step 300: mean loss = 0.00013473193
step 400: mean loss = 0.00013491284
step 500: mean loss = 0.00013420066
step 600: mean loss = 0.0001349858
epoch 165: mean loss = 0.00013474483  learning rate = 0.00023782681
============================
Start of epoch 166
step 0: mean loss = 0.000106194384
step 100: mean loss = 0.0001381696
step 200: mean loss = 0.0001377341
step 300: mean loss = 0.00013832579
step 400: mean loss = 0.00013594961
step 500: mean loss = 0.00013760901
step 600: mean loss = 0.00013755533
epoch 166: mean loss = 0.00013727848  learning rate = 0.00023782681
============================
Start of epoch 167
step 0: mean loss = 0.00011426953
step 100: mean loss = 0.0001306656
step 200: mean loss = 0.00013098077
step 300: mean loss = 0.00013340882
step 400: mean loss = 0.00013300945
step 500: mean loss = 0.00013297205
step 600: mean loss = 0.00013532737
epoch 167: mean loss = 0.00013495787  learning rate = 0.00023782681
============================
Start of epoch 168
step 0: mean loss = 0.00014118884
step 100: mean loss = 0.00013052723
step 200: mean loss = 0.0001301329
step 300: mean loss = 0.00013150022
step 400: mean loss = 0.00013493685
step 500: mean loss = 0.0001374511
step 600: mean loss = 0.00013820807
epoch 168: mean loss = 0.00013802464  learning rate = 0.00023782681
============================
Start of epoch 169
step 0: mean loss = 0.00013560787
step 100: mean loss = 0.00015161333
step 200: mean loss = 0.00014338276
step 300: mean loss = 0.00013723552
step 400: mean loss = 0.00013546932
step 500: mean loss = 0.00013472518
step 600: mean loss = 0.00013637492
epoch 169: mean loss = 0.0001371527  learning rate = 0.00023782681
============================
Start of epoch 170
step 0: mean loss = 0.00014979942
step 100: mean loss = 0.0001326687
step 200: mean loss = 0.000133834
step 300: mean loss = 0.00013609025
step 400: mean loss = 0.0001380181
step 500: mean loss = 0.00013705416
step 600: mean loss = 0.00013598881
epoch 170: mean loss = 0.00013558503  learning rate = 0.00023782681
============================
Start of epoch 171
step 0: mean loss = 0.00010207089
step 100: mean loss = 0.00013143587
step 200: mean loss = 0.00013812388
step 300: mean loss = 0.00013573666
step 400: mean loss = 0.00013565189
step 500: mean loss = 0.00013836652
step 600: mean loss = 0.00013632738
epoch 171: mean loss = 0.00013613279  learning rate = 0.00023782681
============================
Start of epoch 172
step 0: mean loss = 0.00014488997
step 100: mean loss = 0.00012388568
step 200: mean loss = 0.00012802116
step 300: mean loss = 0.0001307257
step 400: mean loss = 0.00013289806
step 500: mean loss = 0.00013394539
step 600: mean loss = 0.0001347635
epoch 172: mean loss = 0.00013496084  learning rate = 0.00023782681
============================
Start of epoch 173
step 0: mean loss = 9.636739e-05
step 100: mean loss = 0.00012699148
step 200: mean loss = 0.00012835531
step 300: mean loss = 0.0001312325
step 400: mean loss = 0.0001345289
step 500: mean loss = 0.00013558842
step 600: mean loss = 0.00013409957
epoch 173: mean loss = 0.00013397262  learning rate = 0.00023782681
============================
Start of epoch 174
step 0: mean loss = 0.00011798268
step 100: mean loss = 0.00013391898
step 200: mean loss = 0.00013164994
step 300: mean loss = 0.00013101866
step 400: mean loss = 0.00013191196
step 500: mean loss = 0.00013276625
step 600: mean loss = 0.00013382385
epoch 174: mean loss = 0.00013374772  learning rate = 0.00023782681
============================
Start of epoch 175
step 0: mean loss = 0.0001569678
step 100: mean loss = 0.0001330999
step 200: mean loss = 0.00013996639
step 300: mean loss = 0.00013810056
step 400: mean loss = 0.0001362472
step 500: mean loss = 0.00013524144
step 600: mean loss = 0.00013528785
epoch 175: mean loss = 0.0001350573  learning rate = 0.00023782681
============================
Start of epoch 176
step 0: mean loss = 0.00014710015
step 100: mean loss = 0.00014157408
step 200: mean loss = 0.00014264572
step 300: mean loss = 0.00014196298
step 400: mean loss = 0.00013717466
step 500: mean loss = 0.00013543853
step 600: mean loss = 0.00013545537
epoch 176: mean loss = 0.00013568896  learning rate = 0.00023782681
============================
Start of epoch 177
step 0: mean loss = 0.00016451109
step 100: mean loss = 0.00013652458
step 200: mean loss = 0.00013945888
step 300: mean loss = 0.00013548303
step 400: mean loss = 0.00013437362
step 500: mean loss = 0.00013445447
step 600: mean loss = 0.00013500331
epoch 177: mean loss = 0.00013521852  learning rate = 0.00023782681
============================
Start of epoch 178
step 0: mean loss = 0.00015141147
step 100: mean loss = 0.00013559114
step 200: mean loss = 0.00013396659
step 300: mean loss = 0.00013474056
step 400: mean loss = 0.00013367926
step 500: mean loss = 0.00013327935
step 600: mean loss = 0.00013393101
epoch 178: mean loss = 0.00013401144  learning rate = 0.00023782681
============================
Start of epoch 179
step 0: mean loss = 0.0001059161
step 100: mean loss = 0.00012663752
step 200: mean loss = 0.0001284009
step 300: mean loss = 0.000129356
step 400: mean loss = 0.00012979783
step 500: mean loss = 0.00013118875
step 600: mean loss = 0.0001335186
epoch 179: mean loss = 0.00013458304  learning rate = 0.00022593547
============================
Start of epoch 180
step 0: mean loss = 0.00016659005
step 100: mean loss = 0.0001303261
step 200: mean loss = 0.00012969828
step 300: mean loss = 0.00012723506
step 400: mean loss = 0.00012726396
step 500: mean loss = 0.00012652794
step 600: mean loss = 0.00012656917
epoch 180: mean loss = 0.00012669885  learning rate = 0.00022593547
============================
Start of epoch 181
step 0: mean loss = 0.000107895845
step 100: mean loss = 0.00013678391
step 200: mean loss = 0.00013041796
step 300: mean loss = 0.00013085711
step 400: mean loss = 0.00012973504
step 500: mean loss = 0.000129076
step 600: mean loss = 0.00012798862
epoch 181: mean loss = 0.00012806714  learning rate = 0.00022593547
============================
Start of epoch 182
step 0: mean loss = 9.185032e-05
step 100: mean loss = 0.0001333919
step 200: mean loss = 0.00013160091
step 300: mean loss = 0.00012999438
step 400: mean loss = 0.00012922351
step 500: mean loss = 0.0001280136
step 600: mean loss = 0.00012807769
epoch 182: mean loss = 0.00012784751  learning rate = 0.00022593547
============================
Start of epoch 183
step 0: mean loss = 0.0001303082
step 100: mean loss = 0.00013246371
step 200: mean loss = 0.00013232413
step 300: mean loss = 0.00013099333
step 400: mean loss = 0.0001289695
step 500: mean loss = 0.00013039928
step 600: mean loss = 0.00013012426
epoch 183: mean loss = 0.00012943486  learning rate = 0.00022593547
============================
Start of epoch 184
step 0: mean loss = 0.00013774051
step 100: mean loss = 0.00011562488
step 200: mean loss = 0.00011848044
step 300: mean loss = 0.00012089529
step 400: mean loss = 0.00012279823
step 500: mean loss = 0.00012373773
step 600: mean loss = 0.00012477084
epoch 184: mean loss = 0.0001257333  learning rate = 0.00022593547
============================
Start of epoch 185
step 0: mean loss = 0.00011679336
step 100: mean loss = 0.00013687817
step 200: mean loss = 0.00013419619
step 300: mean loss = 0.00013045823
step 400: mean loss = 0.00013064446
step 500: mean loss = 0.00012793856
step 600: mean loss = 0.00012943981
epoch 185: mean loss = 0.00012952698  learning rate = 0.00022593547
============================
Start of epoch 186
step 0: mean loss = 0.00014606933
step 100: mean loss = 0.00012936696
step 200: mean loss = 0.0001252495
step 300: mean loss = 0.00012633787
step 400: mean loss = 0.00012646179
step 500: mean loss = 0.0001246943
step 600: mean loss = 0.00012750323
epoch 186: mean loss = 0.00012746437  learning rate = 0.00022593547
============================
Start of epoch 187
step 0: mean loss = 0.00010233657
step 100: mean loss = 0.00011617132
step 200: mean loss = 0.00012632675
step 300: mean loss = 0.0001292325
step 400: mean loss = 0.000128981
step 500: mean loss = 0.00012742789
step 600: mean loss = 0.00012663053
epoch 187: mean loss = 0.00012729595  learning rate = 0.00022593547
============================
Start of epoch 188
step 0: mean loss = 0.00012517683
step 100: mean loss = 0.00012361024
step 200: mean loss = 0.00012317412
step 300: mean loss = 0.0001242318
step 400: mean loss = 0.0001284778
step 500: mean loss = 0.00012979256
step 600: mean loss = 0.00013028893
epoch 188: mean loss = 0.00013004913  learning rate = 0.00022593547
============================
Start of epoch 189
step 0: mean loss = 0.00011127164
step 100: mean loss = 0.00012965768
step 200: mean loss = 0.0001289297
step 300: mean loss = 0.00012631332
step 400: mean loss = 0.00012605153
step 500: mean loss = 0.00012553761
step 600: mean loss = 0.00012505907
epoch 189: mean loss = 0.00012491428  learning rate = 0.00022593547
============================
Start of epoch 190
step 0: mean loss = 8.713038e-05
step 100: mean loss = 0.00011883096
step 200: mean loss = 0.00011859248
step 300: mean loss = 0.000121663164
step 400: mean loss = 0.00012445857
step 500: mean loss = 0.00012482396
step 600: mean loss = 0.00012485716
epoch 190: mean loss = 0.00012492557  learning rate = 0.00022593547
============================
Start of epoch 191
step 0: mean loss = 0.000106869295
step 100: mean loss = 0.00012173891
step 200: mean loss = 0.00012292329
step 300: mean loss = 0.00012302329
step 400: mean loss = 0.00012474786
step 500: mean loss = 0.0001243254
step 600: mean loss = 0.0001249083
epoch 191: mean loss = 0.00012465016  learning rate = 0.00022593547
============================
Start of epoch 192
step 0: mean loss = 0.000101960024
step 100: mean loss = 0.00012094906
step 200: mean loss = 0.00012734623
step 300: mean loss = 0.00012556226
step 400: mean loss = 0.0001244472
step 500: mean loss = 0.00012586132
step 600: mean loss = 0.00012560302
epoch 192: mean loss = 0.00012593783  learning rate = 0.00022593547
============================
Start of epoch 193
step 0: mean loss = 0.00020651304
step 100: mean loss = 0.00012948077
step 200: mean loss = 0.00012994399
step 300: mean loss = 0.00012877485
step 400: mean loss = 0.00012623661
step 500: mean loss = 0.00012530404
step 600: mean loss = 0.00012605611
epoch 193: mean loss = 0.00012574797  learning rate = 0.00022593547
============================
Start of epoch 194
step 0: mean loss = 0.00013217315
step 100: mean loss = 0.00013555285
step 200: mean loss = 0.00013009475
step 300: mean loss = 0.00013126388
step 400: mean loss = 0.0001283391
step 500: mean loss = 0.00012627663
step 600: mean loss = 0.00012776165
epoch 194: mean loss = 0.00012796925  learning rate = 0.00022593547
============================
Start of epoch 195
step 0: mean loss = 7.469693e-05
step 100: mean loss = 0.00012064367
step 200: mean loss = 0.000121026955
step 300: mean loss = 0.00012274153
step 400: mean loss = 0.00012431205
step 500: mean loss = 0.00012584805
step 600: mean loss = 0.000125403
epoch 195: mean loss = 0.00012533585  learning rate = 0.00022593547
============================
Start of epoch 196
step 0: mean loss = 0.0001246325
step 100: mean loss = 0.00012764709
step 200: mean loss = 0.00012360854
step 300: mean loss = 0.00012474503
step 400: mean loss = 0.00012450399
step 500: mean loss = 0.00012476019
step 600: mean loss = 0.00012488925
epoch 196: mean loss = 0.00012491475  learning rate = 0.00022593547
============================
Start of epoch 197
step 0: mean loss = 0.000109466564
step 100: mean loss = 0.00012310295
step 200: mean loss = 0.00012711441
step 300: mean loss = 0.00012752603
step 400: mean loss = 0.00012611208
step 500: mean loss = 0.00012515108
step 600: mean loss = 0.00012755743
epoch 197: mean loss = 0.00012735155  learning rate = 0.00022593547
============================
Start of epoch 198
step 0: mean loss = 9.8668366e-05
step 100: mean loss = 0.00012906201
step 200: mean loss = 0.0001267246
step 300: mean loss = 0.00012273055
step 400: mean loss = 0.00012128717
step 500: mean loss = 0.00012071313
step 600: mean loss = 0.00012357984
epoch 198: mean loss = 0.00012433481  learning rate = 0.00022593547
============================
Start of epoch 199
step 0: mean loss = 0.00010470708
step 100: mean loss = 0.00013295906
step 200: mean loss = 0.00012911668
step 300: mean loss = 0.0001268757
step 400: mean loss = 0.00012673486
step 500: mean loss = 0.00012685826
step 600: mean loss = 0.00012593997
epoch 199: mean loss = 0.00012581395  learning rate = 0.00021463867
============================
Start of epoch 200
step 0: mean loss = 0.00015169368
step 100: mean loss = 0.00012348019
step 200: mean loss = 0.00011938265
step 300: mean loss = 0.00011915064
step 400: mean loss = 0.00011942584
step 500: mean loss = 0.00011892227
step 600: mean loss = 0.0001195207
epoch 200: mean loss = 0.000120294026  learning rate = 0.00021463867
============================
Start of epoch 201
step 0: mean loss = 0.00010787793
step 100: mean loss = 0.000119892706
step 200: mean loss = 0.00011948395
step 300: mean loss = 0.00011534871
step 400: mean loss = 0.00011585965
step 500: mean loss = 0.000117496216
step 600: mean loss = 0.00011897345
epoch 201: mean loss = 0.00011872386  learning rate = 0.00021463867
============================
Start of epoch 202
step 0: mean loss = 0.00013031746
step 100: mean loss = 0.00011334004
step 200: mean loss = 0.0001168376
step 300: mean loss = 0.000116856354
step 400: mean loss = 0.00011773522
step 500: mean loss = 0.000118963144
step 600: mean loss = 0.00011935768
epoch 202: mean loss = 0.0001193699  learning rate = 0.00021463867
============================
Start of epoch 203
step 0: mean loss = 8.882947e-05
step 100: mean loss = 0.00012184542
step 200: mean loss = 0.00011779219
step 300: mean loss = 0.000121007615
step 400: mean loss = 0.00012077492
step 500: mean loss = 0.0001233774
step 600: mean loss = 0.00012320452
epoch 203: mean loss = 0.00012344972  learning rate = 0.00021463867
============================
Start of epoch 204
step 0: mean loss = 0.00020105128
step 100: mean loss = 0.00011810404
step 200: mean loss = 0.00011711147
step 300: mean loss = 0.00011645032
step 400: mean loss = 0.000116308394
step 500: mean loss = 0.00011841975
step 600: mean loss = 0.00011926777
epoch 204: mean loss = 0.00011876821  learning rate = 0.00021463867
============================
Start of epoch 205
step 0: mean loss = 9.42858e-05
step 100: mean loss = 0.00011506569
step 200: mean loss = 0.000115512245
step 300: mean loss = 0.000116033334
step 400: mean loss = 0.00011920839
step 500: mean loss = 0.00011765011
step 600: mean loss = 0.00011811264
epoch 205: mean loss = 0.00011827666  learning rate = 0.00021463867
============================
Start of epoch 206
step 0: mean loss = 0.000102595244
step 100: mean loss = 0.000121369
step 200: mean loss = 0.00012082902
step 300: mean loss = 0.00012059776
step 400: mean loss = 0.000119504904
step 500: mean loss = 0.00011940003
step 600: mean loss = 0.000119026816
epoch 206: mean loss = 0.00011927831  learning rate = 0.00021463867
============================
Start of epoch 207
step 0: mean loss = 9.395046e-05
step 100: mean loss = 0.00011236307
step 200: mean loss = 0.00011666285
step 300: mean loss = 0.00011841591
step 400: mean loss = 0.00011682698
step 500: mean loss = 0.00011734416
step 600: mean loss = 0.0001170318
epoch 207: mean loss = 0.000117045405  learning rate = 0.00021463867
============================
Start of epoch 208
step 0: mean loss = 9.3565e-05
step 100: mean loss = 0.00011172831
step 200: mean loss = 0.0001181616
step 300: mean loss = 0.00011850244
step 400: mean loss = 0.000120215955
step 500: mean loss = 0.00011807284
step 600: mean loss = 0.00011818581
epoch 208: mean loss = 0.000118159056  learning rate = 0.00021463867
============================
Start of epoch 209
step 0: mean loss = 0.00014609622
step 100: mean loss = 0.000112989605
step 200: mean loss = 0.000113247515
step 300: mean loss = 0.000115245755
step 400: mean loss = 0.0001187984
step 500: mean loss = 0.000119782395
step 600: mean loss = 0.00011955209
epoch 209: mean loss = 0.000119517244  learning rate = 0.00021463867
============================
Start of epoch 210
step 0: mean loss = 0.00012400688
step 100: mean loss = 0.00011980171
step 200: mean loss = 0.000120715704
step 300: mean loss = 0.00011805046
step 400: mean loss = 0.00011669086
step 500: mean loss = 0.000116988325
step 600: mean loss = 0.000118371536
epoch 210: mean loss = 0.00011816257  learning rate = 0.00021463867
============================
Start of epoch 211
step 0: mean loss = 0.00012276827
step 100: mean loss = 0.00011719411
step 200: mean loss = 0.00011313291
step 300: mean loss = 0.00011201755
step 400: mean loss = 0.000114009614
step 500: mean loss = 0.000114795745
step 600: mean loss = 0.00011606828
epoch 211: mean loss = 0.0001165116  learning rate = 0.00021463867
============================
Start of epoch 212
step 0: mean loss = 0.000110841574
step 100: mean loss = 0.00011625281
step 200: mean loss = 0.000114206116
step 300: mean loss = 0.00011427814
step 400: mean loss = 0.00011735704
step 500: mean loss = 0.00011795157
step 600: mean loss = 0.0001199048
epoch 212: mean loss = 0.00012029739  learning rate = 0.00021463867
============================
Start of epoch 213
step 0: mean loss = 0.00013388952
step 100: mean loss = 0.000115674164
step 200: mean loss = 0.00012056187
step 300: mean loss = 0.00011922419
step 400: mean loss = 0.000117907446
step 500: mean loss = 0.00011713058
step 600: mean loss = 0.00011737967
epoch 213: mean loss = 0.00011734986  learning rate = 0.00021463867
============================
Start of epoch 214
step 0: mean loss = 7.9243124e-05
step 100: mean loss = 0.00011525506
step 200: mean loss = 0.00011638986
step 300: mean loss = 0.00011726518
step 400: mean loss = 0.00011532097
step 500: mean loss = 0.00011653116
step 600: mean loss = 0.0001168424
epoch 214: mean loss = 0.000116860116  learning rate = 0.00021463867
============================
Start of epoch 215
step 0: mean loss = 0.00012330308
step 100: mean loss = 0.000112864305
step 200: mean loss = 0.000110265464
step 300: mean loss = 0.00011372386
step 400: mean loss = 0.00011468439
step 500: mean loss = 0.00011573183
step 600: mean loss = 0.00011626164
epoch 215: mean loss = 0.0001164407  learning rate = 0.00021463867
============================
Start of epoch 216
step 0: mean loss = 0.00016453101
step 100: mean loss = 0.000114292365
step 200: mean loss = 0.000113581875
step 300: mean loss = 0.000115345756
step 400: mean loss = 0.00011537509
step 500: mean loss = 0.00011624399
step 600: mean loss = 0.00011502849
epoch 216: mean loss = 0.0001148727  learning rate = 0.00021463867
============================
Start of epoch 217
step 0: mean loss = 0.00011752723
step 100: mean loss = 0.00011725375
step 200: mean loss = 0.00011827432
step 300: mean loss = 0.00011727528
step 400: mean loss = 0.00011868202
step 500: mean loss = 0.000119981276
step 600: mean loss = 0.00011927482
epoch 217: mean loss = 0.00011936299  learning rate = 0.00021463867
============================
Start of epoch 218
step 0: mean loss = 0.00010146247
step 100: mean loss = 0.000112895854
step 200: mean loss = 0.000114994946
step 300: mean loss = 0.00011427176
step 400: mean loss = 0.000114589966
step 500: mean loss = 0.000114709546
step 600: mean loss = 0.00011452594
epoch 218: mean loss = 0.00011473837  learning rate = 0.00021463867
============================
Start of epoch 219
step 0: mean loss = 9.1305905e-05
step 100: mean loss = 0.00012045717
step 200: mean loss = 0.000119711185
step 300: mean loss = 0.00011935279
step 400: mean loss = 0.00011776456
step 500: mean loss = 0.00011831583
step 600: mean loss = 0.00011844169
epoch 219: mean loss = 0.000117887095  learning rate = 0.00020390673
============================
Start of epoch 220
step 0: mean loss = 9.336569e-05
step 100: mean loss = 0.000101717786
step 200: mean loss = 0.000109731474
step 300: mean loss = 0.00010835494
step 400: mean loss = 0.00011042935
step 500: mean loss = 0.000110079905
step 600: mean loss = 0.00011173094
epoch 220: mean loss = 0.00011187869  learning rate = 0.00020390673
============================
Start of epoch 221
step 0: mean loss = 9.459737e-05
step 100: mean loss = 0.00010611012
step 200: mean loss = 0.000105293744
step 300: mean loss = 0.00010996948
step 400: mean loss = 0.0001111697
step 500: mean loss = 0.00011267368
step 600: mean loss = 0.00011255214
epoch 221: mean loss = 0.0001121664  learning rate = 0.00020390673
============================
Start of epoch 222
step 0: mean loss = 0.00014221936
step 100: mean loss = 0.000114803224
step 200: mean loss = 0.00011219139
step 300: mean loss = 0.00011484572
step 400: mean loss = 0.00011404027
step 500: mean loss = 0.00011303166
step 600: mean loss = 0.00011351832
epoch 222: mean loss = 0.000113390735  learning rate = 0.00020390673
============================
Start of epoch 223
step 0: mean loss = 0.00013305877
step 100: mean loss = 0.00011252259
step 200: mean loss = 0.00011137353
step 300: mean loss = 0.000113805945
step 400: mean loss = 0.00011268509
step 500: mean loss = 0.00011184463
step 600: mean loss = 0.000111329675
epoch 223: mean loss = 0.000111698064  learning rate = 0.00020390673
============================
Start of epoch 224
step 0: mean loss = 0.0001068643
step 100: mean loss = 0.00011244502
step 200: mean loss = 0.00011180457
step 300: mean loss = 0.00011375993
step 400: mean loss = 0.00011425208
step 500: mean loss = 0.000111391506
step 600: mean loss = 0.00011074662
epoch 224: mean loss = 0.00011080003  learning rate = 0.00020390673
============================
Start of epoch 225
step 0: mean loss = 0.00010202287
step 100: mean loss = 0.000115425435
step 200: mean loss = 0.000113008
step 300: mean loss = 0.00011227227
step 400: mean loss = 0.00011310546
step 500: mean loss = 0.00011331143
step 600: mean loss = 0.000112995185
epoch 225: mean loss = 0.000112449874  learning rate = 0.00020390673
============================
Start of epoch 226
step 0: mean loss = 0.00010368366
step 100: mean loss = 0.00010869501
step 200: mean loss = 0.0001096624
step 300: mean loss = 0.00011415762
step 400: mean loss = 0.000115363015
step 500: mean loss = 0.00011454422
step 600: mean loss = 0.00011343348
epoch 226: mean loss = 0.00011316873  learning rate = 0.00020390673
============================
Start of epoch 227
step 0: mean loss = 0.00010637725
step 100: mean loss = 0.00010254485
step 200: mean loss = 0.00010445837
step 300: mean loss = 0.00010772729
step 400: mean loss = 0.00010961062
step 500: mean loss = 0.000110981164
step 600: mean loss = 0.00011132911
epoch 227: mean loss = 0.00011114466  learning rate = 0.00020390673
============================
Start of epoch 228
step 0: mean loss = 9.116298e-05
step 100: mean loss = 0.00010930653
step 200: mean loss = 0.00011165251
step 300: mean loss = 0.00011054003
step 400: mean loss = 0.00011137234
step 500: mean loss = 0.00011202475
step 600: mean loss = 0.00011146428
epoch 228: mean loss = 0.00011127323  learning rate = 0.00020390673
============================
Start of epoch 229
step 0: mean loss = 9.181517e-05
step 100: mean loss = 0.00010418258
step 200: mean loss = 0.00010713501
step 300: mean loss = 0.000110160945
step 400: mean loss = 0.000112674046
step 500: mean loss = 0.000111350164
step 600: mean loss = 0.000112211506
epoch 229: mean loss = 0.0001126435  learning rate = 0.00020390673
============================
Start of epoch 230
step 0: mean loss = 0.00011587409
step 100: mean loss = 0.00010270908
step 200: mean loss = 0.00010499493
step 300: mean loss = 0.00010650427
step 400: mean loss = 0.00010692375
step 500: mean loss = 0.00010851691
step 600: mean loss = 0.000108453256
epoch 230: mean loss = 0.00010868393  learning rate = 0.00020390673
============================
Start of epoch 231
step 0: mean loss = 9.215268e-05
step 100: mean loss = 0.000116571544
step 200: mean loss = 0.00011126091
step 300: mean loss = 0.00011091828
step 400: mean loss = 0.0001099715
step 500: mean loss = 0.00011091806
step 600: mean loss = 0.00011110135
epoch 231: mean loss = 0.0001111785  learning rate = 0.00020390673
============================
Start of epoch 232
step 0: mean loss = 9.521005e-05
step 100: mean loss = 0.0001144127
step 200: mean loss = 0.00011339177
step 300: mean loss = 0.00011584502
step 400: mean loss = 0.00011369389
step 500: mean loss = 0.00011248508
step 600: mean loss = 0.000111411806
epoch 232: mean loss = 0.00011131568  learning rate = 0.00020390673
============================
Start of epoch 233
step 0: mean loss = 9.062523e-05
step 100: mean loss = 0.00010905576
step 200: mean loss = 0.00010682022
step 300: mean loss = 0.000106284126
step 400: mean loss = 0.00010858705
step 500: mean loss = 0.00010979173
step 600: mean loss = 0.00010998496
epoch 233: mean loss = 0.00010966599  learning rate = 0.00020390673
============================
Start of epoch 234
step 0: mean loss = 0.00011416481
step 100: mean loss = 0.000111318135
step 200: mean loss = 0.00011168847
step 300: mean loss = 0.00010868552
step 400: mean loss = 0.00010925398
step 500: mean loss = 0.0001086289
step 600: mean loss = 0.000109853914
epoch 234: mean loss = 0.00010983977  learning rate = 0.00020390673
============================
Start of epoch 235
step 0: mean loss = 0.00012355583
step 100: mean loss = 0.0001065718
step 200: mean loss = 0.000109047454
step 300: mean loss = 0.00011020653
step 400: mean loss = 0.00011100257
step 500: mean loss = 0.00011124649
step 600: mean loss = 0.000109812245
epoch 235: mean loss = 0.000109756875  learning rate = 0.00020390673
============================
Start of epoch 236
step 0: mean loss = 0.00012007977
step 100: mean loss = 0.000106441265
step 200: mean loss = 0.00010998257
step 300: mean loss = 0.00011134866
step 400: mean loss = 0.0001102237
step 500: mean loss = 0.00011109551
step 600: mean loss = 0.000110541325
epoch 236: mean loss = 0.00011038676  learning rate = 0.00020390673
============================
Start of epoch 237
step 0: mean loss = 9.2227914e-05
step 100: mean loss = 0.00010231351
step 200: mean loss = 0.000107214124
step 300: mean loss = 0.00010842489
step 400: mean loss = 0.0001106634
step 500: mean loss = 0.0001096847
step 600: mean loss = 0.000109839755
epoch 237: mean loss = 0.000109451554  learning rate = 0.00020390673
============================
Start of epoch 238
step 0: mean loss = 7.9924735e-05
step 100: mean loss = 0.0001060537
step 200: mean loss = 0.00010970144
step 300: mean loss = 0.0001082497
step 400: mean loss = 0.000110451336
step 500: mean loss = 0.00011027635
step 600: mean loss = 0.00010892629
epoch 238: mean loss = 0.0001087299  learning rate = 0.00020390673
============================
Start of epoch 239
step 0: mean loss = 9.832533e-05
step 100: mean loss = 0.00011150152
step 200: mean loss = 0.000109295346
step 300: mean loss = 0.00010806163
step 400: mean loss = 0.00010889856
step 500: mean loss = 0.00010972057
step 600: mean loss = 0.00010889133
epoch 239: mean loss = 0.000108549415  learning rate = 0.00019371141
============================
Start of epoch 240
step 0: mean loss = 7.06825e-05
step 100: mean loss = 0.00010239803
step 200: mean loss = 0.00010292504
step 300: mean loss = 0.00010451281
step 400: mean loss = 0.000105804655
step 500: mean loss = 0.000104622566
step 600: mean loss = 0.00010442889
epoch 240: mean loss = 0.00010478892  learning rate = 0.00019371141
============================
Start of epoch 241
step 0: mean loss = 0.00010934709
step 100: mean loss = 0.000108163586
step 200: mean loss = 0.000104013365
step 300: mean loss = 0.000104587845
step 400: mean loss = 0.000103189464
step 500: mean loss = 0.000104385384
step 600: mean loss = 0.00010435681
epoch 241: mean loss = 0.000104645886  learning rate = 0.00019371141
============================
Start of epoch 242
step 0: mean loss = 9.0695205e-05
step 100: mean loss = 0.000101773214
step 200: mean loss = 0.0001042441
step 300: mean loss = 0.00010497448
step 400: mean loss = 0.00010583637
step 500: mean loss = 0.00010413937
step 600: mean loss = 0.00010388523
epoch 242: mean loss = 0.000103757215  learning rate = 0.00019371141
============================
Start of epoch 243
step 0: mean loss = 0.00011724096
step 100: mean loss = 0.00010540516
step 200: mean loss = 0.000106488165
step 300: mean loss = 0.00010523712
step 400: mean loss = 0.00010592992
step 500: mean loss = 0.00010473384
step 600: mean loss = 0.000105436215
epoch 243: mean loss = 0.00010537424  learning rate = 0.00019371141
============================
Start of epoch 244
step 0: mean loss = 9.285968e-05
step 100: mean loss = 0.00010281464
step 200: mean loss = 0.0001049681
step 300: mean loss = 0.00010376187
step 400: mean loss = 0.000104828236
step 500: mean loss = 0.00010442173
step 600: mean loss = 0.00010443588
epoch 244: mean loss = 0.00010462557  learning rate = 0.00019371141
============================
Start of epoch 245
step 0: mean loss = 0.0001246444
step 100: mean loss = 9.976803e-05
step 200: mean loss = 0.00010115326
step 300: mean loss = 0.00010503425
step 400: mean loss = 0.00010575246
step 500: mean loss = 0.00010437178
step 600: mean loss = 0.00010486312
epoch 245: mean loss = 0.00010447477  learning rate = 0.00019371141
============================
Start of epoch 246
step 0: mean loss = 0.000107855616
step 100: mean loss = 9.955962e-05
step 200: mean loss = 0.000102177946
step 300: mean loss = 0.0001033889
step 400: mean loss = 0.00010668432
step 500: mean loss = 0.00010467039
step 600: mean loss = 0.00010442616
epoch 246: mean loss = 0.0001047184  learning rate = 0.00019371141
============================
Start of epoch 247
step 0: mean loss = 9.8813514e-05
step 100: mean loss = 9.807385e-05
step 200: mean loss = 9.980988e-05
step 300: mean loss = 0.00010214455
step 400: mean loss = 0.00010342096
step 500: mean loss = 0.000103530016
step 600: mean loss = 0.00010381024
epoch 247: mean loss = 0.00010368347  learning rate = 0.00019371141
============================
Start of epoch 248
step 0: mean loss = 0.000109167646
step 100: mean loss = 0.0001012199
step 200: mean loss = 0.00010192052
step 300: mean loss = 0.00010428673
step 400: mean loss = 0.00010427949
step 500: mean loss = 0.0001026981
step 600: mean loss = 0.00010274977
epoch 248: mean loss = 0.00010293759  learning rate = 0.00019371141
============================
Start of epoch 249
step 0: mean loss = 0.00012966993
step 100: mean loss = 0.00010797104
step 200: mean loss = 0.00010595728
step 300: mean loss = 0.000102854
step 400: mean loss = 0.00010421371
step 500: mean loss = 0.00010367414
step 600: mean loss = 0.0001029832
epoch 249: mean loss = 0.00010286066  learning rate = 0.00019371141
============================
Start of epoch 250
step 0: mean loss = 0.0001420234
step 100: mean loss = 0.00010653075
step 200: mean loss = 0.00010220467
step 300: mean loss = 0.0001053709
step 400: mean loss = 0.00010394538
step 500: mean loss = 0.0001029715
step 600: mean loss = 0.000103039296
epoch 250: mean loss = 0.00010297847  learning rate = 0.00019371141
============================
Start of epoch 251
step 0: mean loss = 6.780014e-05
step 100: mean loss = 0.0001034248
step 200: mean loss = 0.00010132946
step 300: mean loss = 0.00010748788
step 400: mean loss = 0.0001061679
step 500: mean loss = 0.00010605168
step 600: mean loss = 0.00010622691
epoch 251: mean loss = 0.000106015825  learning rate = 0.00019371141
============================
Start of epoch 252
step 0: mean loss = 7.851622e-05
step 100: mean loss = 9.774538e-05
step 200: mean loss = 9.817342e-05
step 300: mean loss = 0.00010065611
step 400: mean loss = 0.000101870515
step 500: mean loss = 0.00010256899
step 600: mean loss = 0.00010253964
epoch 252: mean loss = 0.00010249685  learning rate = 0.00019371141
============================
Start of epoch 253
step 0: mean loss = 7.281727e-05
step 100: mean loss = 9.9683624e-05
step 200: mean loss = 0.000107158245
step 300: mean loss = 0.000106338215
step 400: mean loss = 0.00010612426
step 500: mean loss = 0.00010512743
step 600: mean loss = 0.000104747356
epoch 253: mean loss = 0.000104439045  learning rate = 0.00019371141
============================
Start of epoch 254
step 0: mean loss = 7.791567e-05
step 100: mean loss = 0.00010156044
step 200: mean loss = 0.000101551086
step 300: mean loss = 0.00010122398
step 400: mean loss = 0.000102293445
step 500: mean loss = 0.000101957055
step 600: mean loss = 0.00010271536
epoch 254: mean loss = 0.00010283661  learning rate = 0.00019371141
============================
Start of epoch 255
step 0: mean loss = 0.0001188282
step 100: mean loss = 0.00010234307
step 200: mean loss = 0.00010222813
step 300: mean loss = 0.0001022573
step 400: mean loss = 0.00010197754
step 500: mean loss = 0.0001021499
step 600: mean loss = 0.000102051585
epoch 255: mean loss = 0.000102086844  learning rate = 0.00019371141
============================
Start of epoch 256
step 0: mean loss = 0.000102624756
step 100: mean loss = 9.386636e-05
step 200: mean loss = 0.00010094161
step 300: mean loss = 0.00010204967
step 400: mean loss = 0.00010128235
step 500: mean loss = 0.00010179176
step 600: mean loss = 0.00010032916
epoch 256: mean loss = 0.00010029464  learning rate = 0.00019371141
============================
Start of epoch 257
step 0: mean loss = 9.96117e-05
step 100: mean loss = 9.8607066e-05
step 200: mean loss = 0.000105398954
step 300: mean loss = 0.00010689786
step 400: mean loss = 0.00010639797
step 500: mean loss = 0.00010599865
step 600: mean loss = 0.0001045466
epoch 257: mean loss = 0.00010419172  learning rate = 0.00019371141
============================
Start of epoch 258
step 0: mean loss = 8.031778e-05
step 100: mean loss = 0.00010086866
step 200: mean loss = 9.9264864e-05
step 300: mean loss = 9.960105e-05
step 400: mean loss = 9.851718e-05
step 500: mean loss = 9.986296e-05
step 600: mean loss = 0.00010068443
epoch 258: mean loss = 0.00010085059  learning rate = 0.00019371141
============================
Start of epoch 259
step 0: mean loss = 0.00011900217
step 100: mean loss = 0.00010370052
step 200: mean loss = 0.000107425665
step 300: mean loss = 0.000105018815
step 400: mean loss = 0.00010273948
step 500: mean loss = 0.00010156858
step 600: mean loss = 0.000102399536
epoch 259: mean loss = 0.00010236648  learning rate = 0.00018402583
============================
Start of epoch 260
step 0: mean loss = 0.00010028811
step 100: mean loss = 9.407041e-05
step 200: mean loss = 9.7764685e-05
step 300: mean loss = 9.709223e-05
step 400: mean loss = 9.675605e-05
step 500: mean loss = 9.755462e-05
step 600: mean loss = 9.830277e-05
epoch 260: mean loss = 9.790534e-05  learning rate = 0.00018402583
============================
Start of epoch 261
step 0: mean loss = 0.00011687305
step 100: mean loss = 9.763341e-05
step 200: mean loss = 9.545952e-05
step 300: mean loss = 9.64394e-05
step 400: mean loss = 9.8725104e-05
step 500: mean loss = 9.953375e-05
step 600: mean loss = 9.9457255e-05
epoch 261: mean loss = 9.942331e-05  learning rate = 0.00018402583
============================
Start of epoch 262
step 0: mean loss = 0.00010772393
step 100: mean loss = 9.7643795e-05
step 200: mean loss = 9.3949086e-05
step 300: mean loss = 9.6176205e-05
step 400: mean loss = 9.7554715e-05
step 500: mean loss = 9.816023e-05
step 600: mean loss = 9.928638e-05
epoch 262: mean loss = 9.937146e-05  learning rate = 0.00018402583
============================
Start of epoch 263
step 0: mean loss = 0.00011108621
step 100: mean loss = 9.95306e-05
step 200: mean loss = 9.936156e-05
step 300: mean loss = 9.825688e-05
step 400: mean loss = 9.6990894e-05
step 500: mean loss = 9.7098025e-05
step 600: mean loss = 9.670138e-05
epoch 263: mean loss = 9.689921e-05  learning rate = 0.00018402583
============================
Start of epoch 264
step 0: mean loss = 9.32522e-05
step 100: mean loss = 9.857533e-05
step 200: mean loss = 9.745996e-05
step 300: mean loss = 9.753412e-05
step 400: mean loss = 9.854913e-05
step 500: mean loss = 9.777226e-05
step 600: mean loss = 9.831855e-05
epoch 264: mean loss = 9.8493096e-05  learning rate = 0.00018402583
============================
Start of epoch 265
step 0: mean loss = 0.00014875563
step 100: mean loss = 9.812169e-05
step 200: mean loss = 9.7173695e-05
step 300: mean loss = 9.711945e-05
step 400: mean loss = 9.724253e-05
step 500: mean loss = 9.6075375e-05
step 600: mean loss = 9.673027e-05
epoch 265: mean loss = 9.678923e-05  learning rate = 0.00018402583
============================
Start of epoch 266
step 0: mean loss = 0.00011240782
step 100: mean loss = 8.931162e-05
step 200: mean loss = 9.318683e-05
step 300: mean loss = 9.5460346e-05
step 400: mean loss = 9.586554e-05
step 500: mean loss = 9.601132e-05
step 600: mean loss = 9.647675e-05
epoch 266: mean loss = 9.6386895e-05  learning rate = 0.00018402583
============================
Start of epoch 267
step 0: mean loss = 9.219568e-05
step 100: mean loss = 9.55385e-05
step 200: mean loss = 9.863804e-05
step 300: mean loss = 9.8383694e-05
step 400: mean loss = 9.84127e-05
step 500: mean loss = 9.8635464e-05
step 600: mean loss = 9.873407e-05
epoch 267: mean loss = 9.854345e-05  learning rate = 0.00018402583
============================
Start of epoch 268
step 0: mean loss = 9.233211e-05
step 100: mean loss = 9.8393044e-05
step 200: mean loss = 9.5271615e-05
step 300: mean loss = 9.641826e-05
step 400: mean loss = 9.639293e-05
step 500: mean loss = 9.5610645e-05
step 600: mean loss = 9.662446e-05
epoch 268: mean loss = 9.699024e-05  learning rate = 0.00018402583
============================
Start of epoch 269
step 0: mean loss = 0.00012317563
step 100: mean loss = 9.466093e-05
step 200: mean loss = 9.427434e-05
step 300: mean loss = 9.4227005e-05
step 400: mean loss = 9.506376e-05
step 500: mean loss = 9.477601e-05
step 600: mean loss = 9.5768366e-05
epoch 269: mean loss = 9.574705e-05  learning rate = 0.00018402583
============================
Start of epoch 270
step 0: mean loss = 7.591863e-05
step 100: mean loss = 9.468654e-05
step 200: mean loss = 9.5060255e-05
step 300: mean loss = 9.4370196e-05
step 400: mean loss = 9.4457275e-05
step 500: mean loss = 9.564505e-05
step 600: mean loss = 9.624783e-05
epoch 270: mean loss = 9.635217e-05  learning rate = 0.00018402583
============================
Start of epoch 271
step 0: mean loss = 0.00015284194
step 100: mean loss = 0.00010041516
step 200: mean loss = 9.8033495e-05
step 300: mean loss = 9.777613e-05
step 400: mean loss = 9.673579e-05
step 500: mean loss = 9.65544e-05
step 600: mean loss = 9.7257835e-05
epoch 271: mean loss = 9.690344e-05  learning rate = 0.00018402583
============================
Start of epoch 272
step 0: mean loss = 8.879088e-05
step 100: mean loss = 9.089984e-05
step 200: mean loss = 9.3760464e-05
step 300: mean loss = 9.396138e-05
step 400: mean loss = 9.444739e-05
step 500: mean loss = 9.5139614e-05
step 600: mean loss = 9.4828356e-05
epoch 272: mean loss = 9.4961855e-05  learning rate = 0.00018402583
============================
Start of epoch 273
step 0: mean loss = 8.924777e-05
step 100: mean loss = 9.253756e-05
step 200: mean loss = 9.565742e-05
step 300: mean loss = 9.447093e-05
step 400: mean loss = 9.5591226e-05
step 500: mean loss = 9.539574e-05
step 600: mean loss = 9.540358e-05
epoch 273: mean loss = 9.536687e-05  learning rate = 0.00018402583
============================
Start of epoch 274
step 0: mean loss = 7.638415e-05
step 100: mean loss = 9.250381e-05
step 200: mean loss = 9.441556e-05
step 300: mean loss = 9.333226e-05
step 400: mean loss = 9.426627e-05
step 500: mean loss = 9.4450996e-05
step 600: mean loss = 9.5816016e-05
epoch 274: mean loss = 9.631825e-05  learning rate = 0.00018402583
============================
Start of epoch 275
step 0: mean loss = 9.331999e-05
step 100: mean loss = 9.3135095e-05
step 200: mean loss = 9.681858e-05
step 300: mean loss = 9.59902e-05
step 400: mean loss = 9.599119e-05
step 500: mean loss = 9.4711795e-05
step 600: mean loss = 9.546593e-05
epoch 275: mean loss = 9.574479e-05  learning rate = 0.00018402583
============================
Start of epoch 276
step 0: mean loss = 9.780952e-05
step 100: mean loss = 9.689692e-05
step 200: mean loss = 9.902398e-05
step 300: mean loss = 9.730011e-05
step 400: mean loss = 9.8386095e-05
step 500: mean loss = 9.736249e-05
step 600: mean loss = 9.739715e-05
epoch 276: mean loss = 9.7806704e-05  learning rate = 0.00018402583
============================
Start of epoch 277
step 0: mean loss = 6.930623e-05
step 100: mean loss = 8.957895e-05
step 200: mean loss = 9.587156e-05
step 300: mean loss = 9.553084e-05
step 400: mean loss = 9.529586e-05
step 500: mean loss = 9.5042415e-05
step 600: mean loss = 9.5314324e-05
epoch 277: mean loss = 9.529945e-05  learning rate = 0.00018402583
============================
Start of epoch 278
step 0: mean loss = 0.00012617411
step 100: mean loss = 9.4551586e-05
step 200: mean loss = 9.364289e-05
step 300: mean loss = 9.50111e-05
step 400: mean loss = 9.469143e-05
step 500: mean loss = 9.6555785e-05
step 600: mean loss = 9.5709474e-05
epoch 278: mean loss = 9.5502866e-05  learning rate = 0.00018402583
============================
Start of epoch 279
step 0: mean loss = 7.864927e-05
step 100: mean loss = 9.052952e-05
step 200: mean loss = 9.422464e-05
step 300: mean loss = 9.4375035e-05
step 400: mean loss = 9.5497795e-05
step 500: mean loss = 9.451118e-05
step 600: mean loss = 9.475274e-05
epoch 279: mean loss = 9.562974e-05  learning rate = 0.00017482454
============================
Start of epoch 280
step 0: mean loss = 0.000117468604
step 100: mean loss = 9.291215e-05
step 200: mean loss = 9.086403e-05
step 300: mean loss = 9.2676106e-05
step 400: mean loss = 9.215218e-05
step 500: mean loss = 9.065729e-05
step 600: mean loss = 9.105683e-05
epoch 280: mean loss = 9.103949e-05  learning rate = 0.00017482454
============================
Start of epoch 281
step 0: mean loss = 8.461755e-05
step 100: mean loss = 9.106518e-05
step 200: mean loss = 9.2407325e-05
step 300: mean loss = 9.42415e-05
step 400: mean loss = 9.259528e-05
step 500: mean loss = 9.187616e-05
step 600: mean loss = 9.143935e-05
epoch 281: mean loss = 9.140518e-05  learning rate = 0.00017482454
============================
Start of epoch 282
step 0: mean loss = 7.874606e-05
step 100: mean loss = 9.293905e-05
step 200: mean loss = 9.2593895e-05
step 300: mean loss = 9.2187984e-05
step 400: mean loss = 9.239357e-05
step 500: mean loss = 9.384602e-05
step 600: mean loss = 9.269496e-05
epoch 282: mean loss = 9.226364e-05  learning rate = 0.00017482454
============================
Start of epoch 283
step 0: mean loss = 8.66218e-05
step 100: mean loss = 8.654201e-05
step 200: mean loss = 8.762869e-05
step 300: mean loss = 9.010746e-05
step 400: mean loss = 9.196194e-05
step 500: mean loss = 9.167225e-05
step 600: mean loss = 9.157671e-05
epoch 283: mean loss = 9.193741e-05  learning rate = 0.00017482454
============================
Start of epoch 284
step 0: mean loss = 8.8356566e-05
step 100: mean loss = 9.4880284e-05
step 200: mean loss = 9.272034e-05
step 300: mean loss = 9.21434e-05
step 400: mean loss = 9.065822e-05
step 500: mean loss = 9.177498e-05
step 600: mean loss = 9.1729315e-05
epoch 284: mean loss = 9.170927e-05  learning rate = 0.00017482454
============================
Start of epoch 285
step 0: mean loss = 6.0502418e-05
step 100: mean loss = 9.0321526e-05
step 200: mean loss = 8.8231434e-05
step 300: mean loss = 8.9479836e-05
step 400: mean loss = 8.980894e-05
step 500: mean loss = 9.117939e-05
step 600: mean loss = 9.1981834e-05
epoch 285: mean loss = 9.208006e-05  learning rate = 0.00017482454
============================
Start of epoch 286
step 0: mean loss = 9.157018e-05
step 100: mean loss = 8.785384e-05
step 200: mean loss = 9.078653e-05
step 300: mean loss = 8.91328e-05
step 400: mean loss = 8.9803296e-05
step 500: mean loss = 9.0938294e-05
step 600: mean loss = 9.248839e-05
epoch 286: mean loss = 9.26554e-05  learning rate = 0.00017482454
============================
Start of epoch 287
step 0: mean loss = 0.00012435639
step 100: mean loss = 9.305736e-05
step 200: mean loss = 8.9595334e-05
step 300: mean loss = 9.0316185e-05
step 400: mean loss = 9.169937e-05
step 500: mean loss = 9.2111e-05
step 600: mean loss = 9.230685e-05
epoch 287: mean loss = 9.2254915e-05  learning rate = 0.00017482454
============================
Start of epoch 288
step 0: mean loss = 8.069821e-05
step 100: mean loss = 8.976315e-05
step 200: mean loss = 9.1724614e-05
step 300: mean loss = 9.1447095e-05
step 400: mean loss = 9.048055e-05
step 500: mean loss = 9.035702e-05
step 600: mean loss = 9.0645815e-05
epoch 288: mean loss = 9.091005e-05  learning rate = 0.00017482454
============================
Start of epoch 289
step 0: mean loss = 8.385886e-05
step 100: mean loss = 8.604987e-05
step 200: mean loss = 8.647883e-05
step 300: mean loss = 8.808481e-05
step 400: mean loss = 9.022568e-05
step 500: mean loss = 8.968347e-05
step 600: mean loss = 8.9495516e-05
epoch 289: mean loss = 8.986357e-05  learning rate = 0.00017482454
============================
Start of epoch 290
step 0: mean loss = 0.00010115061
step 100: mean loss = 9.239579e-05
step 200: mean loss = 9.343232e-05
step 300: mean loss = 9.302284e-05
step 400: mean loss = 9.476025e-05
step 500: mean loss = 9.353284e-05
step 600: mean loss = 9.2402e-05
epoch 290: mean loss = 9.22038e-05  learning rate = 0.00017482454
============================
Start of epoch 291
step 0: mean loss = 8.46355e-05
step 100: mean loss = 9.069848e-05
step 200: mean loss = 9.470959e-05
step 300: mean loss = 9.280075e-05
step 400: mean loss = 9.151655e-05
step 500: mean loss = 9.1499875e-05
step 600: mean loss = 9.1085305e-05
epoch 291: mean loss = 9.089463e-05  learning rate = 0.00017482454
============================
Start of epoch 292
step 0: mean loss = 7.358754e-05
step 100: mean loss = 8.882021e-05
step 200: mean loss = 9.17054e-05
step 300: mean loss = 9.1282665e-05
step 400: mean loss = 8.9835936e-05
step 500: mean loss = 8.901142e-05
step 600: mean loss = 8.882628e-05
epoch 292: mean loss = 8.8759014e-05  learning rate = 0.00017482454
============================
Start of epoch 293
step 0: mean loss = 6.621344e-05
step 100: mean loss = 9.1374655e-05
step 200: mean loss = 9.102582e-05
step 300: mean loss = 8.9153546e-05
step 400: mean loss = 8.983216e-05
step 500: mean loss = 9.0609174e-05
step 600: mean loss = 9.101602e-05
epoch 293: mean loss = 9.139029e-05  learning rate = 0.00017482454
============================
Start of epoch 294
step 0: mean loss = 0.00010227098
step 100: mean loss = 9.4924915e-05
step 200: mean loss = 9.322582e-05
step 300: mean loss = 9.29759e-05
step 400: mean loss = 9.26243e-05
step 500: mean loss = 9.302457e-05
step 600: mean loss = 9.223562e-05
epoch 294: mean loss = 9.236318e-05  learning rate = 0.00017482454
============================
Start of epoch 295
step 0: mean loss = 9.052268e-05
step 100: mean loss = 8.614289e-05
step 200: mean loss = 8.569578e-05
step 300: mean loss = 8.5932974e-05
step 400: mean loss = 8.7195986e-05
step 500: mean loss = 8.819275e-05
step 600: mean loss = 8.881587e-05
epoch 295: mean loss = 8.881728e-05  learning rate = 0.00017482454
============================
Start of epoch 296
step 0: mean loss = 0.000113916394
step 100: mean loss = 8.6948516e-05
step 200: mean loss = 8.620258e-05
step 300: mean loss = 8.510617e-05
step 400: mean loss = 8.794551e-05
step 500: mean loss = 8.879999e-05
step 600: mean loss = 8.9713634e-05
epoch 296: mean loss = 8.970275e-05  learning rate = 0.00017482454
============================
Start of epoch 297
step 0: mean loss = 7.476703e-05
step 100: mean loss = 9.024395e-05
step 200: mean loss = 8.808829e-05
step 300: mean loss = 9.0362024e-05
step 400: mean loss = 8.955866e-05
step 500: mean loss = 8.8561304e-05
step 600: mean loss = 8.881423e-05
epoch 297: mean loss = 8.873374e-05  learning rate = 0.00017482454
============================
Start of epoch 298
step 0: mean loss = 0.000100868005
step 100: mean loss = 8.678733e-05
step 200: mean loss = 9.08986e-05
step 300: mean loss = 8.95764e-05
step 400: mean loss = 8.897471e-05
step 500: mean loss = 8.990597e-05
step 600: mean loss = 8.9719826e-05
epoch 298: mean loss = 8.950394e-05  learning rate = 0.00017482454
============================
Start of epoch 299
step 0: mean loss = 9.4059644e-05
step 100: mean loss = 8.622296e-05
step 200: mean loss = 8.672604e-05
step 300: mean loss = 8.876645e-05
step 400: mean loss = 9.1279246e-05
step 500: mean loss = 9.175356e-05
step 600: mean loss = 9.217622e-05
epoch 299: mean loss = 9.200297e-05  learning rate = 0.00016608331
============================
Start of epoch 300
step 0: mean loss = 7.204071e-05
step 100: mean loss = 8.234074e-05
step 200: mean loss = 8.28079e-05
step 300: mean loss = 8.490898e-05
step 400: mean loss = 8.4872205e-05
step 500: mean loss = 8.492291e-05
step 600: mean loss = 8.507789e-05
epoch 300: mean loss = 8.493789e-05  learning rate = 0.00016608331
============================
Start of epoch 301
step 0: mean loss = 6.656376e-05
step 100: mean loss = 7.8778634e-05
step 200: mean loss = 7.9473706e-05
step 300: mean loss = 8.079631e-05
step 400: mean loss = 8.090774e-05
step 500: mean loss = 8.239242e-05
step 600: mean loss = 8.343635e-05
epoch 301: mean loss = 8.3340274e-05  learning rate = 0.00016608331
============================
Start of epoch 302
step 0: mean loss = 7.688285e-05
step 100: mean loss = 8.716551e-05
step 200: mean loss = 8.8641704e-05
step 300: mean loss = 8.753909e-05
step 400: mean loss = 8.728022e-05
step 500: mean loss = 8.613707e-05
step 600: mean loss = 8.586061e-05
epoch 302: mean loss = 8.5556334e-05  learning rate = 0.00016608331
============================
Start of epoch 303
step 0: mean loss = 7.657548e-05
step 100: mean loss = 7.881945e-05
step 200: mean loss = 8.451758e-05
step 300: mean loss = 8.50559e-05
step 400: mean loss = 8.5451975e-05
step 500: mean loss = 8.620701e-05
step 600: mean loss = 8.6539636e-05
epoch 303: mean loss = 8.627807e-05  learning rate = 0.00016608331
============================
Start of epoch 304
step 0: mean loss = 6.7275556e-05
step 100: mean loss = 8.634926e-05
step 200: mean loss = 8.562496e-05
step 300: mean loss = 8.72475e-05
step 400: mean loss = 8.76896e-05
step 500: mean loss = 8.610037e-05
step 600: mean loss = 8.566688e-05
epoch 304: mean loss = 8.641535e-05  learning rate = 0.00016608331
============================
Start of epoch 305
step 0: mean loss = 9.6661825e-05
step 100: mean loss = 8.767028e-05
step 200: mean loss = 8.8818604e-05
step 300: mean loss = 8.5202424e-05
step 400: mean loss = 8.5242355e-05
step 500: mean loss = 8.4819374e-05
step 600: mean loss = 8.606094e-05
epoch 305: mean loss = 8.587745e-05  learning rate = 0.00016608331
============================
Start of epoch 306
step 0: mean loss = 8.042682e-05
step 100: mean loss = 8.3514926e-05
step 200: mean loss = 8.172829e-05
step 300: mean loss = 8.32739e-05
step 400: mean loss = 8.428579e-05
step 500: mean loss = 8.4380925e-05
step 600: mean loss = 8.432668e-05
epoch 306: mean loss = 8.478108e-05  learning rate = 0.00016608331
============================
Start of epoch 307
step 0: mean loss = 9.879197e-05
step 100: mean loss = 8.726392e-05
step 200: mean loss = 8.528432e-05
step 300: mean loss = 8.496255e-05
step 400: mean loss = 8.5852356e-05
step 500: mean loss = 8.620842e-05
step 600: mean loss = 8.578115e-05
epoch 307: mean loss = 8.5608524e-05  learning rate = 0.00016608331
============================
Start of epoch 308
step 0: mean loss = 7.0144015e-05
step 100: mean loss = 8.023265e-05
step 200: mean loss = 8.152159e-05
step 300: mean loss = 8.359325e-05
step 400: mean loss = 8.3459054e-05
step 500: mean loss = 8.3403436e-05
step 600: mean loss = 8.464887e-05
epoch 308: mean loss = 8.480704e-05  learning rate = 0.00016608331
============================
Start of epoch 309
step 0: mean loss = 6.1264436e-05
step 100: mean loss = 8.3368825e-05
step 200: mean loss = 8.195082e-05
step 300: mean loss = 8.390717e-05
step 400: mean loss = 8.599631e-05
step 500: mean loss = 8.6254855e-05
step 600: mean loss = 8.5577754e-05
epoch 309: mean loss = 8.573576e-05  learning rate = 0.00016608331
============================
Start of epoch 310
step 0: mean loss = 7.27124e-05
step 100: mean loss = 8.524003e-05
step 200: mean loss = 8.753083e-05
step 300: mean loss = 8.4725296e-05
step 400: mean loss = 8.417407e-05
step 500: mean loss = 8.472105e-05
step 600: mean loss = 8.487851e-05
epoch 310: mean loss = 8.480075e-05  learning rate = 0.00016608331
============================
Start of epoch 311
step 0: mean loss = 8.5181775e-05
step 100: mean loss = 7.9735946e-05
step 200: mean loss = 8.148518e-05
step 300: mean loss = 8.029854e-05
step 400: mean loss = 8.0937774e-05
step 500: mean loss = 8.2371385e-05
step 600: mean loss = 8.325952e-05
epoch 311: mean loss = 8.32444e-05  learning rate = 0.00016608331
============================
Start of epoch 312
step 0: mean loss = 0.000106664695
step 100: mean loss = 8.9042085e-05
step 200: mean loss = 8.703758e-05
step 300: mean loss = 8.6665335e-05
step 400: mean loss = 8.620892e-05
step 500: mean loss = 8.554044e-05
step 600: mean loss = 8.4763116e-05
epoch 312: mean loss = 8.4583065e-05  learning rate = 0.00016608331
============================
Start of epoch 313
step 0: mean loss = 7.519964e-05
step 100: mean loss = 8.6673695e-05
step 200: mean loss = 8.423321e-05
step 300: mean loss = 8.362683e-05
step 400: mean loss = 8.255318e-05
step 500: mean loss = 8.2847364e-05
step 600: mean loss = 8.309973e-05
epoch 313: mean loss = 8.345972e-05  learning rate = 0.00016608331
============================
Start of epoch 314
step 0: mean loss = 7.311728e-05
step 100: mean loss = 8.582528e-05
step 200: mean loss = 8.416651e-05
step 300: mean loss = 8.3181236e-05
step 400: mean loss = 8.40361e-05
step 500: mean loss = 8.56997e-05
step 600: mean loss = 8.6447515e-05
epoch 314: mean loss = 8.633286e-05  learning rate = 0.00016608331
============================
Start of epoch 315
step 0: mean loss = 8.415745e-05
step 100: mean loss = 8.7583576e-05
step 200: mean loss = 8.917769e-05
step 300: mean loss = 8.818606e-05
step 400: mean loss = 8.609155e-05
step 500: mean loss = 8.492237e-05
step 600: mean loss = 8.424836e-05
epoch 315: mean loss = 8.4224346e-05  learning rate = 0.00016608331
============================
Start of epoch 316
step 0: mean loss = 8.1324266e-05
step 100: mean loss = 8.1196384e-05
step 200: mean loss = 8.23148e-05
step 300: mean loss = 8.2510865e-05
step 400: mean loss = 8.421041e-05
step 500: mean loss = 8.381361e-05
step 600: mean loss = 8.415696e-05
epoch 316: mean loss = 8.421093e-05  learning rate = 0.00016608331
============================
Start of epoch 317
step 0: mean loss = 8.576574e-05
step 100: mean loss = 8.220327e-05
step 200: mean loss = 8.4300926e-05
step 300: mean loss = 8.3144296e-05
step 400: mean loss = 8.48204e-05
step 500: mean loss = 8.4657615e-05
step 600: mean loss = 8.425818e-05
epoch 317: mean loss = 8.3910825e-05  learning rate = 0.00016608331
============================
Start of epoch 318
step 0: mean loss = 7.39042e-05
step 100: mean loss = 9.158602e-05
step 200: mean loss = 8.665449e-05
step 300: mean loss = 8.5869215e-05
step 400: mean loss = 8.504425e-05
step 500: mean loss = 8.4686704e-05
step 600: mean loss = 8.451848e-05
epoch 318: mean loss = 8.405302e-05  learning rate = 0.00016608331
============================
Start of epoch 319
step 0: mean loss = 7.315466e-05
step 100: mean loss = 8.090864e-05
step 200: mean loss = 8.170103e-05
step 300: mean loss = 8.17926e-05
step 400: mean loss = 8.187507e-05
step 500: mean loss = 8.174444e-05
step 600: mean loss = 8.221899e-05
epoch 319: mean loss = 8.264184e-05  learning rate = 0.00015777916
============================
Start of epoch 320
step 0: mean loss = 8.322553e-05
step 100: mean loss = 7.942172e-05
step 200: mean loss = 7.936274e-05
step 300: mean loss = 8.039949e-05
step 400: mean loss = 7.970705e-05
step 500: mean loss = 8.01205e-05
step 600: mean loss = 8.127413e-05
epoch 320: mean loss = 8.120342e-05  learning rate = 0.00015777916
============================
Start of epoch 321
step 0: mean loss = 0.00012943178
step 100: mean loss = 8.198567e-05
step 200: mean loss = 8.3189836e-05
step 300: mean loss = 8.336002e-05
step 400: mean loss = 8.231639e-05
step 500: mean loss = 7.9962665e-05
step 600: mean loss = 8.011096e-05
epoch 321: mean loss = 8.042981e-05  learning rate = 0.00015777916
============================
Start of epoch 322
step 0: mean loss = 8.828599e-05
step 100: mean loss = 7.90288e-05
step 200: mean loss = 8.018402e-05
step 300: mean loss = 8.0513295e-05
step 400: mean loss = 8.05151e-05
step 500: mean loss = 8.09385e-05
step 600: mean loss = 8.0493366e-05
epoch 322: mean loss = 8.0570564e-05  learning rate = 0.00015777916
============================
Start of epoch 323
step 0: mean loss = 7.000554e-05
step 100: mean loss = 8.544613e-05
step 200: mean loss = 8.184256e-05
step 300: mean loss = 8.1039034e-05
step 400: mean loss = 8.248816e-05
step 500: mean loss = 8.1451806e-05
step 600: mean loss = 8.0761674e-05
epoch 323: mean loss = 8.049011e-05  learning rate = 0.00015777916
============================
Start of epoch 324
step 0: mean loss = 6.624454e-05
step 100: mean loss = 7.351798e-05
step 200: mean loss = 7.6599645e-05
step 300: mean loss = 7.850738e-05
step 400: mean loss = 7.967557e-05
step 500: mean loss = 8.0557664e-05
step 600: mean loss = 8.033963e-05
epoch 324: mean loss = 8.049258e-05  learning rate = 0.00015777916
============================
Start of epoch 325
step 0: mean loss = 9.219366e-05
step 100: mean loss = 8.3002284e-05
step 200: mean loss = 8.204611e-05
step 300: mean loss = 8.0632664e-05
step 400: mean loss = 8.005841e-05
step 500: mean loss = 8.0288504e-05
step 600: mean loss = 8.003599e-05
epoch 325: mean loss = 8.020377e-05  learning rate = 0.00015777916
============================
Start of epoch 326
step 0: mean loss = 0.00010341265
step 100: mean loss = 8.056189e-05
step 200: mean loss = 7.949581e-05
step 300: mean loss = 7.893705e-05
step 400: mean loss = 7.956834e-05
step 500: mean loss = 7.950552e-05
step 600: mean loss = 7.957424e-05
epoch 326: mean loss = 7.978637e-05  learning rate = 0.00015777916
============================
Start of epoch 327
step 0: mean loss = 0.00010612225
step 100: mean loss = 8.43703e-05
step 200: mean loss = 8.507705e-05
step 300: mean loss = 8.306675e-05
step 400: mean loss = 8.1893624e-05
step 500: mean loss = 8.102447e-05
step 600: mean loss = 8.071462e-05
epoch 327: mean loss = 8.0707e-05  learning rate = 0.00015777916
============================
Start of epoch 328
step 0: mean loss = 9.2266244e-05
step 100: mean loss = 7.820087e-05
step 200: mean loss = 8.0076235e-05
step 300: mean loss = 8.0970574e-05
step 400: mean loss = 8.040396e-05
step 500: mean loss = 8.225576e-05
step 600: mean loss = 8.229817e-05
epoch 328: mean loss = 8.198876e-05  learning rate = 0.00015777916
============================
Start of epoch 329
step 0: mean loss = 7.7110395e-05
step 100: mean loss = 7.661522e-05
step 200: mean loss = 7.660999e-05
step 300: mean loss = 7.67996e-05
step 400: mean loss = 7.683362e-05
step 500: mean loss = 7.8009034e-05
step 600: mean loss = 7.864296e-05
epoch 329: mean loss = 7.857692e-05  learning rate = 0.00015777916
============================
Start of epoch 330
step 0: mean loss = 6.996546e-05
step 100: mean loss = 7.536933e-05
step 200: mean loss = 7.9707286e-05
step 300: mean loss = 7.742843e-05
step 400: mean loss = 7.814891e-05
step 500: mean loss = 7.833063e-05
step 600: mean loss = 7.831707e-05
epoch 330: mean loss = 7.850418e-05  learning rate = 0.00015777916
============================
Start of epoch 331
step 0: mean loss = 0.00012614392
step 100: mean loss = 8.2636056e-05
step 200: mean loss = 8.377301e-05
step 300: mean loss = 8.263826e-05
step 400: mean loss = 8.234458e-05
step 500: mean loss = 8.290369e-05
step 600: mean loss = 8.2093145e-05
epoch 331: mean loss = 8.189311e-05  learning rate = 0.00015777916
============================
Start of epoch 332
step 0: mean loss = 0.00010477363
step 100: mean loss = 7.485376e-05
step 200: mean loss = 7.459106e-05
step 300: mean loss = 7.711693e-05
step 400: mean loss = 7.779411e-05
step 500: mean loss = 7.828707e-05
step 600: mean loss = 7.868478e-05
epoch 332: mean loss = 7.868984e-05  learning rate = 0.00015777916
============================
Start of epoch 333
step 0: mean loss = 8.886057e-05
step 100: mean loss = 7.894267e-05
step 200: mean loss = 7.83515e-05
step 300: mean loss = 7.93092e-05
step 400: mean loss = 7.922522e-05
step 500: mean loss = 8.069367e-05
step 600: mean loss = 8.0500206e-05
epoch 333: mean loss = 8.045993e-05  learning rate = 0.00015777916
============================
Start of epoch 334
step 0: mean loss = 7.541303e-05
step 100: mean loss = 7.688733e-05
step 200: mean loss = 7.7859215e-05
step 300: mean loss = 7.919077e-05
step 400: mean loss = 7.960623e-05
step 500: mean loss = 7.881555e-05
step 600: mean loss = 7.863479e-05
epoch 334: mean loss = 7.8668134e-05  learning rate = 0.00015777916
============================
Start of epoch 335
step 0: mean loss = 6.125793e-05
step 100: mean loss = 7.6951284e-05
step 200: mean loss = 7.721305e-05
step 300: mean loss = 7.728148e-05
step 400: mean loss = 7.8049256e-05
step 500: mean loss = 7.8322606e-05
step 600: mean loss = 7.92034e-05
epoch 335: mean loss = 7.9450845e-05  learning rate = 0.00015777916
============================
Start of epoch 336
step 0: mean loss = 5.8490776e-05
step 100: mean loss = 7.4334595e-05
step 200: mean loss = 7.5783915e-05
step 300: mean loss = 7.759622e-05
step 400: mean loss = 7.779112e-05
step 500: mean loss = 7.9091515e-05
step 600: mean loss = 7.924805e-05
epoch 336: mean loss = 7.909752e-05  learning rate = 0.00015777916
============================
Start of epoch 337
step 0: mean loss = 6.18943e-05
step 100: mean loss = 8.426941e-05
step 200: mean loss = 8.184472e-05
step 300: mean loss = 8.054578e-05
step 400: mean loss = 8.035213e-05
step 500: mean loss = 7.8703844e-05
step 600: mean loss = 7.794741e-05
epoch 337: mean loss = 7.8395395e-05  learning rate = 0.00015777916
============================
Start of epoch 338
step 0: mean loss = 8.440166e-05
step 100: mean loss = 8.1080834e-05
step 200: mean loss = 7.858616e-05
step 300: mean loss = 7.910996e-05
step 400: mean loss = 8.037864e-05
step 500: mean loss = 7.9630176e-05
step 600: mean loss = 7.958061e-05
epoch 338: mean loss = 7.957485e-05  learning rate = 0.00015777916
============================
Start of epoch 339
step 0: mean loss = 7.9633624e-05
step 100: mean loss = 8.362976e-05
step 200: mean loss = 7.944099e-05
step 300: mean loss = 7.98517e-05
step 400: mean loss = 7.956259e-05
step 500: mean loss = 7.8191886e-05
step 600: mean loss = 7.8172256e-05
epoch 339: mean loss = 7.839947e-05  learning rate = 0.00014989018
============================
Start of epoch 340
step 0: mean loss = 8.973307e-05
step 100: mean loss = 7.884466e-05
step 200: mean loss = 7.766346e-05
step 300: mean loss = 7.5424e-05
step 400: mean loss = 7.520244e-05
step 500: mean loss = 7.547545e-05
step 600: mean loss = 7.5402844e-05
epoch 340: mean loss = 7.543627e-05  learning rate = 0.00014989018
============================
Start of epoch 341
step 0: mean loss = 6.653041e-05
step 100: mean loss = 7.2120805e-05
step 200: mean loss = 7.322279e-05
step 300: mean loss = 7.6223405e-05
step 400: mean loss = 7.577051e-05
step 500: mean loss = 7.4533324e-05
step 600: mean loss = 7.531524e-05
epoch 341: mean loss = 7.5316246e-05  learning rate = 0.00014989018
============================
Start of epoch 342
step 0: mean loss = 7.669635e-05
step 100: mean loss = 7.359289e-05
step 200: mean loss = 7.3465315e-05
step 300: mean loss = 7.395248e-05
step 400: mean loss = 7.601009e-05
step 500: mean loss = 7.5646116e-05
step 600: mean loss = 7.514992e-05
epoch 342: mean loss = 7.494684e-05  learning rate = 0.00014989018
============================
Start of epoch 343
step 0: mean loss = 6.892199e-05
step 100: mean loss = 7.451808e-05
step 200: mean loss = 7.5138145e-05
step 300: mean loss = 7.572608e-05
step 400: mean loss = 7.544741e-05
step 500: mean loss = 7.575134e-05
step 600: mean loss = 7.593238e-05
epoch 343: mean loss = 7.597918e-05  learning rate = 0.00014989018
============================
Start of epoch 344
step 0: mean loss = 8.661992e-05
step 100: mean loss = 7.506833e-05
step 200: mean loss = 7.740576e-05
step 300: mean loss = 7.6442535e-05
step 400: mean loss = 7.565532e-05
step 500: mean loss = 7.569413e-05
step 600: mean loss = 7.543667e-05
epoch 344: mean loss = 7.541657e-05  learning rate = 0.00014989018
============================
Start of epoch 345
step 0: mean loss = 6.203058e-05
step 100: mean loss = 7.4265175e-05
step 200: mean loss = 7.339663e-05
step 300: mean loss = 7.311059e-05
step 400: mean loss = 7.35118e-05
step 500: mean loss = 7.551102e-05
step 600: mean loss = 7.552088e-05
epoch 345: mean loss = 7.5394884e-05  learning rate = 0.00014989018
============================
Start of epoch 346
step 0: mean loss = 5.9145146e-05
step 100: mean loss = 7.31347e-05
step 200: mean loss = 7.365354e-05
step 300: mean loss = 7.382366e-05
step 400: mean loss = 7.4011856e-05
step 500: mean loss = 7.4469914e-05
step 600: mean loss = 7.506672e-05
epoch 346: mean loss = 7.490566e-05  learning rate = 0.00014989018
============================
Start of epoch 347
step 0: mean loss = 8.367149e-05
step 100: mean loss = 7.146745e-05
step 200: mean loss = 7.475774e-05
step 300: mean loss = 7.390865e-05
step 400: mean loss = 7.5081254e-05
step 500: mean loss = 7.455042e-05
step 600: mean loss = 7.427131e-05
epoch 347: mean loss = 7.451216e-05  learning rate = 0.00014989018
============================
Start of epoch 348
step 0: mean loss = 5.7619116e-05
step 100: mean loss = 7.3714036e-05
step 200: mean loss = 7.295125e-05
step 300: mean loss = 7.393965e-05
step 400: mean loss = 7.5258395e-05
step 500: mean loss = 7.520546e-05
step 600: mean loss = 7.476288e-05
epoch 348: mean loss = 7.49394e-05  learning rate = 0.00014989018
============================
Start of epoch 349
step 0: mean loss = 0.00011053288
step 100: mean loss = 7.654439e-05
step 200: mean loss = 7.636744e-05
step 300: mean loss = 7.501296e-05
step 400: mean loss = 7.4933785e-05
step 500: mean loss = 7.393709e-05
step 600: mean loss = 7.429965e-05
epoch 349: mean loss = 7.498273e-05  learning rate = 0.00014989018
============================
Start of epoch 350
step 0: mean loss = 7.1151924e-05
step 100: mean loss = 7.39295e-05
step 200: mean loss = 7.786005e-05
step 300: mean loss = 7.5225515e-05
step 400: mean loss = 7.4964046e-05
step 500: mean loss = 7.459304e-05
step 600: mean loss = 7.4236545e-05
epoch 350: mean loss = 7.447915e-05  learning rate = 0.00014989018
============================
Start of epoch 351
step 0: mean loss = 8.1222344e-05
step 100: mean loss = 7.5190976e-05
step 200: mean loss = 7.6942306e-05
step 300: mean loss = 7.6530785e-05
step 400: mean loss = 7.692645e-05
step 500: mean loss = 7.610947e-05
step 600: mean loss = 7.70204e-05
epoch 351: mean loss = 7.681612e-05  learning rate = 0.00014989018
============================
Start of epoch 352
step 0: mean loss = 9.065432e-05
step 100: mean loss = 7.2448456e-05
step 200: mean loss = 7.24802e-05
step 300: mean loss = 7.208333e-05
step 400: mean loss = 7.180971e-05
step 500: mean loss = 7.215525e-05
step 600: mean loss = 7.3439835e-05
epoch 352: mean loss = 7.346736e-05  learning rate = 0.00014989018
============================
Start of epoch 353
step 0: mean loss = 7.1597475e-05
step 100: mean loss = 7.5761425e-05
step 200: mean loss = 7.6427015e-05
step 300: mean loss = 7.446452e-05
step 400: mean loss = 7.389673e-05
step 500: mean loss = 7.3715455e-05
step 600: mean loss = 7.405778e-05
epoch 353: mean loss = 7.409805e-05  learning rate = 0.00014989018
============================
Start of epoch 354
step 0: mean loss = 6.394916e-05
step 100: mean loss = 7.0505776e-05
step 200: mean loss = 7.123597e-05
step 300: mean loss = 7.143932e-05
step 400: mean loss = 7.371724e-05
step 500: mean loss = 7.3095616e-05
step 600: mean loss = 7.373156e-05
epoch 354: mean loss = 7.3785224e-05  learning rate = 0.00014989018
============================
Start of epoch 355
step 0: mean loss = 9.049621e-05
step 100: mean loss = 7.0717666e-05
step 200: mean loss = 7.2901435e-05
step 300: mean loss = 7.2258255e-05
step 400: mean loss = 7.397728e-05
step 500: mean loss = 7.433723e-05
step 600: mean loss = 7.467868e-05
epoch 355: mean loss = 7.438837e-05  learning rate = 0.00014989018
============================
Start of epoch 356
step 0: mean loss = 7.2088114e-05
step 100: mean loss = 6.944532e-05
step 200: mean loss = 6.907712e-05
step 300: mean loss = 7.025224e-05
step 400: mean loss = 7.1806004e-05
step 500: mean loss = 7.2658084e-05
step 600: mean loss = 7.2575735e-05
epoch 356: mean loss = 7.281528e-05  learning rate = 0.00014989018
============================
Start of epoch 357
step 0: mean loss = 8.150165e-05
step 100: mean loss = 7.595305e-05
step 200: mean loss = 7.133911e-05
step 300: mean loss = 7.335197e-05
step 400: mean loss = 7.39093e-05
step 500: mean loss = 7.357199e-05
step 600: mean loss = 7.3734205e-05
epoch 357: mean loss = 7.358253e-05  learning rate = 0.00014989018
============================
Start of epoch 358
step 0: mean loss = 6.8657726e-05
step 100: mean loss = 7.316476e-05
step 200: mean loss = 7.231594e-05
step 300: mean loss = 7.396292e-05
step 400: mean loss = 7.358902e-05
step 500: mean loss = 7.380939e-05
step 600: mean loss = 7.295338e-05
epoch 358: mean loss = 7.388492e-05  learning rate = 0.00014989018
============================
Start of epoch 359
step 0: mean loss = 6.602537e-05
step 100: mean loss = 7.626057e-05
step 200: mean loss = 7.637967e-05
step 300: mean loss = 7.621115e-05
step 400: mean loss = 7.432517e-05
step 500: mean loss = 7.415957e-05
step 600: mean loss = 7.372998e-05
epoch 359: mean loss = 7.370917e-05  learning rate = 0.00014239567
============================
Start of epoch 360
step 0: mean loss = 6.583668e-05
step 100: mean loss = 7.1193484e-05
step 200: mean loss = 7.025351e-05
step 300: mean loss = 7.041614e-05
step 400: mean loss = 7.0461436e-05
step 500: mean loss = 7.130712e-05
step 600: mean loss = 7.078524e-05
epoch 360: mean loss = 7.056371e-05  learning rate = 0.00014239567
============================
Start of epoch 361
step 0: mean loss = 5.348271e-05
step 100: mean loss = 7.0876755e-05
step 200: mean loss = 6.839417e-05
step 300: mean loss = 6.851712e-05
step 400: mean loss = 6.889479e-05
step 500: mean loss = 6.9169204e-05
step 600: mean loss = 6.98853e-05
epoch 361: mean loss = 6.987181e-05  learning rate = 0.00014239567
============================
Start of epoch 362
step 0: mean loss = 7.013176e-05
step 100: mean loss = 7.2088515e-05
step 200: mean loss = 7.1762435e-05
step 300: mean loss = 7.247154e-05
step 400: mean loss = 7.1286006e-05
step 500: mean loss = 7.039464e-05
step 600: mean loss = 7.040981e-05
epoch 362: mean loss = 7.0319235e-05  learning rate = 0.00014239567
============================
Start of epoch 363
step 0: mean loss = 8.965678e-05
step 100: mean loss = 6.962669e-05
step 200: mean loss = 7.1146904e-05
step 300: mean loss = 6.986426e-05
step 400: mean loss = 7.095114e-05
step 500: mean loss = 7.0157585e-05
step 600: mean loss = 7.06611e-05
epoch 363: mean loss = 7.0687754e-05  learning rate = 0.00014239567
============================
Start of epoch 364
step 0: mean loss = 5.4465418e-05
step 100: mean loss = 7.308908e-05
step 200: mean loss = 7.4669144e-05
step 300: mean loss = 7.2500436e-05
step 400: mean loss = 7.145594e-05
step 500: mean loss = 7.114381e-05
step 600: mean loss = 7.027942e-05
epoch 364: mean loss = 7.038149e-05  learning rate = 0.00014239567
============================
Start of epoch 365
step 0: mean loss = 5.9868744e-05
step 100: mean loss = 6.992459e-05
step 200: mean loss = 7.0246744e-05
step 300: mean loss = 7.0308044e-05
step 400: mean loss = 7.006518e-05
step 500: mean loss = 7.0128066e-05
step 600: mean loss = 7.03202e-05
epoch 365: mean loss = 7.004141e-05  learning rate = 0.00014239567
============================
Start of epoch 366
step 0: mean loss = 5.8989408e-05
step 100: mean loss = 6.430159e-05
step 200: mean loss = 6.597634e-05
step 300: mean loss = 6.697277e-05
step 400: mean loss = 6.850526e-05
step 500: mean loss = 6.916912e-05
step 600: mean loss = 6.985696e-05
epoch 366: mean loss = 6.9721e-05  learning rate = 0.00014239567
============================
Start of epoch 367
step 0: mean loss = 6.321104e-05
step 100: mean loss = 6.463257e-05
step 200: mean loss = 6.694654e-05
step 300: mean loss = 6.9156864e-05
step 400: mean loss = 6.892834e-05
step 500: mean loss = 7.072976e-05
step 600: mean loss = 7.1409726e-05
epoch 367: mean loss = 7.121994e-05  learning rate = 0.00014239567
============================
Start of epoch 368
step 0: mean loss = 5.401891e-05
step 100: mean loss = 6.915197e-05
step 200: mean loss = 6.862629e-05
step 300: mean loss = 7.050986e-05
step 400: mean loss = 7.042437e-05
step 500: mean loss = 7.006988e-05
step 600: mean loss = 7.00252e-05
epoch 368: mean loss = 7.012755e-05  learning rate = 0.00014239567
============================
Start of epoch 369
step 0: mean loss = 8.289103e-05
step 100: mean loss = 6.9791015e-05
step 200: mean loss = 7.049198e-05
step 300: mean loss = 7.094077e-05
step 400: mean loss = 7.019971e-05
step 500: mean loss = 6.9722155e-05
step 600: mean loss = 6.930543e-05
epoch 369: mean loss = 6.931623e-05  learning rate = 0.00014239567
============================
Start of epoch 370
step 0: mean loss = 6.778657e-05
step 100: mean loss = 6.931475e-05
step 200: mean loss = 6.886767e-05
step 300: mean loss = 6.9757196e-05
step 400: mean loss = 6.900244e-05
step 500: mean loss = 6.9431546e-05
step 600: mean loss = 6.966099e-05
epoch 370: mean loss = 6.9513175e-05  learning rate = 0.00014239567
============================
Start of epoch 371
step 0: mean loss = 6.668534e-05
step 100: mean loss = 6.699398e-05
step 200: mean loss = 7.0836104e-05
step 300: mean loss = 7.013085e-05
step 400: mean loss = 7.003489e-05
step 500: mean loss = 7.022743e-05
step 600: mean loss = 7.056244e-05
epoch 371: mean loss = 7.05806e-05  learning rate = 0.00014239567
============================
Start of epoch 372
step 0: mean loss = 5.135364e-05
step 100: mean loss = 6.7015266e-05
step 200: mean loss = 6.825998e-05
step 300: mean loss = 6.815953e-05
step 400: mean loss = 7.042912e-05
step 500: mean loss = 7.1701834e-05
step 600: mean loss = 7.128587e-05
epoch 372: mean loss = 7.119991e-05  learning rate = 0.00014239567
============================
Start of epoch 373
step 0: mean loss = 5.7814068e-05
step 100: mean loss = 6.910561e-05
step 200: mean loss = 6.7408386e-05
step 300: mean loss = 6.76355e-05
step 400: mean loss = 6.809768e-05
step 500: mean loss = 6.85171e-05
step 600: mean loss = 6.922784e-05
epoch 373: mean loss = 6.90675e-05  learning rate = 0.00014239567
============================
Start of epoch 374
step 0: mean loss = 4.736518e-05
step 100: mean loss = 6.8968264e-05
step 200: mean loss = 6.6118475e-05
step 300: mean loss = 6.656385e-05
step 400: mean loss = 6.555935e-05
step 500: mean loss = 6.675413e-05
step 600: mean loss = 6.763703e-05
epoch 374: mean loss = 6.756125e-05  learning rate = 0.00014239567
============================
Start of epoch 375
step 0: mean loss = 6.393307e-05
step 100: mean loss = 7.31446e-05
step 200: mean loss = 7.034326e-05
step 300: mean loss = 7.291108e-05
step 400: mean loss = 7.155624e-05
step 500: mean loss = 7.128158e-05
step 600: mean loss = 7.059503e-05
epoch 375: mean loss = 7.037388e-05  learning rate = 0.00014239567
============================
Start of epoch 376
step 0: mean loss = 6.396312e-05
step 100: mean loss = 6.557926e-05
step 200: mean loss = 6.6216926e-05
step 300: mean loss = 6.5759246e-05
step 400: mean loss = 6.6395136e-05
step 500: mean loss = 6.746676e-05
step 600: mean loss = 6.712246e-05
epoch 376: mean loss = 6.7208755e-05  learning rate = 0.00014239567
============================
Start of epoch 377
step 0: mean loss = 5.9238748e-05
step 100: mean loss = 6.7190056e-05
step 200: mean loss = 6.7565394e-05
step 300: mean loss = 6.888509e-05
step 400: mean loss = 6.9238384e-05
step 500: mean loss = 7.02167e-05
step 600: mean loss = 6.9210175e-05
epoch 377: mean loss = 6.894617e-05  learning rate = 0.00014239567
============================
Start of epoch 378
step 0: mean loss = 5.108778e-05
step 100: mean loss = 6.704884e-05
step 200: mean loss = 6.641317e-05
step 300: mean loss = 6.812305e-05
step 400: mean loss = 6.833809e-05
step 500: mean loss = 6.928984e-05
step 600: mean loss = 6.936186e-05
epoch 378: mean loss = 6.901458e-05  learning rate = 0.00014239567
============================
Start of epoch 379
step 0: mean loss = 5.058421e-05
step 100: mean loss = 6.68176e-05
step 200: mean loss = 6.657849e-05
step 300: mean loss = 6.693366e-05
step 400: mean loss = 6.7723755e-05
step 500: mean loss = 6.7464294e-05
step 600: mean loss = 6.808407e-05
epoch 379: mean loss = 6.8236586e-05  learning rate = 0.00013527591
============================
Start of epoch 380
step 0: mean loss = 6.0344726e-05
step 100: mean loss = 6.50168e-05
step 200: mean loss = 6.392927e-05
step 300: mean loss = 6.552634e-05
step 400: mean loss = 6.6795015e-05
step 500: mean loss = 6.6261004e-05
step 600: mean loss = 6.642045e-05
epoch 380: mean loss = 6.651266e-05  learning rate = 0.00013527591
============================
Start of epoch 381
step 0: mean loss = 5.4516608e-05
step 100: mean loss = 6.3108164e-05
step 200: mean loss = 6.683491e-05
step 300: mean loss = 6.7227644e-05
step 400: mean loss = 6.708998e-05
step 500: mean loss = 6.673937e-05
step 600: mean loss = 6.645402e-05
epoch 381: mean loss = 6.6617584e-05  learning rate = 0.00013527591
============================
Start of epoch 382
step 0: mean loss = 6.261401e-05
step 100: mean loss = 6.399251e-05
step 200: mean loss = 6.5539985e-05
step 300: mean loss = 6.5628374e-05
step 400: mean loss = 6.572405e-05
step 500: mean loss = 6.59059e-05
step 600: mean loss = 6.610599e-05
epoch 382: mean loss = 6.628677e-05  learning rate = 0.00013527591
============================
Start of epoch 383
step 0: mean loss = 7.280254e-05
step 100: mean loss = 6.30134e-05
step 200: mean loss = 6.4069565e-05
step 300: mean loss = 6.431833e-05
step 400: mean loss = 6.654126e-05
step 500: mean loss = 6.646891e-05
step 600: mean loss = 6.626125e-05
epoch 383: mean loss = 6.617764e-05  learning rate = 0.00013527591
============================
Start of epoch 384
step 0: mean loss = 4.5779332e-05
step 100: mean loss = 6.672351e-05
step 200: mean loss = 6.595675e-05
step 300: mean loss = 6.5064894e-05
step 400: mean loss = 6.5237946e-05
step 500: mean loss = 6.5403394e-05
step 600: mean loss = 6.610191e-05
epoch 384: mean loss = 6.6197696e-05  learning rate = 0.00013527591
============================
Start of epoch 385
step 0: mean loss = 5.242554e-05
step 100: mean loss = 6.336645e-05
step 200: mean loss = 6.4340806e-05
step 300: mean loss = 6.492463e-05
step 400: mean loss = 6.5512664e-05
step 500: mean loss = 6.5310385e-05
step 600: mean loss = 6.595691e-05
epoch 385: mean loss = 6.598608e-05  learning rate = 0.00013527591
============================
Start of epoch 386
step 0: mean loss = 4.9983344e-05
step 100: mean loss = 6.333815e-05
step 200: mean loss = 6.453816e-05
step 300: mean loss = 6.526714e-05
step 400: mean loss = 6.6530985e-05
step 500: mean loss = 6.6195964e-05
step 600: mean loss = 6.562424e-05
epoch 386: mean loss = 6.5877844e-05  learning rate = 0.00013527591
============================
Start of epoch 387
step 0: mean loss = 9.198256e-05
step 100: mean loss = 6.6189445e-05
step 200: mean loss = 6.5528555e-05
step 300: mean loss = 6.54897e-05
step 400: mean loss = 6.6043955e-05
step 500: mean loss = 6.650249e-05
step 600: mean loss = 6.6516666e-05
epoch 387: mean loss = 6.636679e-05  learning rate = 0.00013527591
============================
Start of epoch 388
step 0: mean loss = 5.6870875e-05
step 100: mean loss = 6.263884e-05
step 200: mean loss = 6.6934954e-05
step 300: mean loss = 6.578335e-05
step 400: mean loss = 6.568183e-05
step 500: mean loss = 6.523017e-05
step 600: mean loss = 6.498705e-05
epoch 388: mean loss = 6.476369e-05  learning rate = 0.00013527591
============================
Start of epoch 389
step 0: mean loss = 6.0094175e-05
step 100: mean loss = 6.3120046e-05
step 200: mean loss = 6.6441e-05
step 300: mean loss = 6.663118e-05
step 400: mean loss = 6.607126e-05
step 500: mean loss = 6.604351e-05
step 600: mean loss = 6.604252e-05
epoch 389: mean loss = 6.610276e-05  learning rate = 0.00013527591
============================
Start of epoch 390
step 0: mean loss = 0.00010510235
step 100: mean loss = 6.547576e-05
step 200: mean loss = 6.580948e-05
step 300: mean loss = 6.5669505e-05
step 400: mean loss = 6.587452e-05
step 500: mean loss = 6.503299e-05
step 600: mean loss = 6.567499e-05
epoch 390: mean loss = 6.580374e-05  learning rate = 0.00013527591
============================
Start of epoch 391
step 0: mean loss = 5.435236e-05
step 100: mean loss = 6.596886e-05
step 200: mean loss = 6.5888395e-05
step 300: mean loss = 6.508769e-05
step 400: mean loss = 6.4213746e-05
step 500: mean loss = 6.4314336e-05
step 600: mean loss = 6.4605316e-05
epoch 391: mean loss = 6.462932e-05  learning rate = 0.00013527591
============================
Start of epoch 392
step 0: mean loss = 8.113728e-05
step 100: mean loss = 6.526113e-05
step 200: mean loss = 6.551019e-05
step 300: mean loss = 6.5862376e-05
step 400: mean loss = 6.558077e-05
step 500: mean loss = 6.5914406e-05
step 600: mean loss = 6.601835e-05
epoch 392: mean loss = 6.6292356e-05  learning rate = 0.00013527591
============================
Start of epoch 393
step 0: mean loss = 8.580752e-05
step 100: mean loss = 6.379048e-05
step 200: mean loss = 6.473789e-05
step 300: mean loss = 6.621515e-05
step 400: mean loss = 6.549212e-05
step 500: mean loss = 6.496889e-05
step 600: mean loss = 6.4637476e-05
epoch 393: mean loss = 6.466411e-05  learning rate = 0.00013527591
============================
Start of epoch 394
step 0: mean loss = 7.144787e-05
step 100: mean loss = 6.8617526e-05
step 200: mean loss = 6.717944e-05
step 300: mean loss = 6.5561755e-05
step 400: mean loss = 6.5131695e-05
step 500: mean loss = 6.543793e-05
step 600: mean loss = 6.5373955e-05
epoch 394: mean loss = 6.5456086e-05  learning rate = 0.00013527591
============================
Start of epoch 395
step 0: mean loss = 6.0160386e-05
step 100: mean loss = 6.352866e-05
step 200: mean loss = 6.348355e-05
step 300: mean loss = 6.4675034e-05
step 400: mean loss = 6.388912e-05
step 500: mean loss = 6.4735665e-05
step 600: mean loss = 6.474617e-05
epoch 395: mean loss = 6.453223e-05  learning rate = 0.00013527591
============================
Start of epoch 396
step 0: mean loss = 8.511299e-05
step 100: mean loss = 6.179104e-05
step 200: mean loss = 6.201186e-05
step 300: mean loss = 6.253115e-05
step 400: mean loss = 6.309275e-05
step 500: mean loss = 6.453083e-05
step 600: mean loss = 6.5669185e-05
epoch 396: mean loss = 6.572237e-05  learning rate = 0.00013527591
============================
Start of epoch 397
step 0: mean loss = 5.383786e-05
step 100: mean loss = 6.423428e-05
step 200: mean loss = 6.288325e-05
step 300: mean loss = 6.500066e-05
step 400: mean loss = 6.4997235e-05
step 500: mean loss = 6.496645e-05
step 600: mean loss = 6.452728e-05
epoch 397: mean loss = 6.4501255e-05  learning rate = 0.00013527591
============================
Start of epoch 398
step 0: mean loss = 4.6794175e-05
step 100: mean loss = 6.181636e-05
step 200: mean loss = 6.29045e-05
step 300: mean loss = 6.4030624e-05
step 400: mean loss = 6.450378e-05
step 500: mean loss = 6.377725e-05
step 600: mean loss = 6.368849e-05
epoch 398: mean loss = 6.3731466e-05  learning rate = 0.00013527591
============================
Start of epoch 399
step 0: mean loss = 5.288371e-05
step 100: mean loss = 6.248458e-05
step 200: mean loss = 6.247916e-05
step 300: mean loss = 6.228665e-05
step 400: mean loss = 6.312845e-05
step 500: mean loss = 6.399e-05
step 600: mean loss = 6.455947e-05
epoch 399: mean loss = 6.478415e-05  learning rate = 0.0001285121
saving the weights
++++++++++++++++++++++++++++++
Start of cycle 2
Total number of epochs in this cycle: 800
Batch size in this cycle: 32
============================
WARNING:tensorflow:5 out of the last 6 calls to <function genDistInvPer at 0x7f4ef0a2e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Start of epoch 0
computing the FFT
applying the multipliers
(32, 1, 1001)
inverse fft
step 0: mean loss = 6.301451e-05
step 100: mean loss = 4.790692e-05
step 200: mean loss = 4.565906e-05
step 300: mean loss = 4.4982145e-05
epoch 0: mean loss = 4.4885648e-05  learning rate = 0.0001285121
============================
Start of epoch 1
step 0: mean loss = 3.2931286e-05
step 100: mean loss = 4.400929e-05
step 200: mean loss = 4.571232e-05
step 300: mean loss = 4.520285e-05
epoch 1: mean loss = 4.517427e-05  learning rate = 0.0001285121
============================
Start of epoch 2
step 0: mean loss = 5.2267475e-05
step 100: mean loss = 4.5108078e-05
step 200: mean loss = 4.4598193e-05
step 300: mean loss = 4.5197543e-05
epoch 2: mean loss = 4.5312696e-05  learning rate = 0.0001285121
============================
Start of epoch 3
step 0: mean loss = 3.967934e-05
step 100: mean loss = 4.662815e-05
step 200: mean loss = 4.7906822e-05
step 300: mean loss = 4.7591195e-05
epoch 3: mean loss = 4.753256e-05  learning rate = 0.0001285121
============================
Start of epoch 4
step 0: mean loss = 4.4731067e-05
step 100: mean loss = 4.8993006e-05
step 200: mean loss = 4.7514608e-05
step 300: mean loss = 4.776526e-05
epoch 4: mean loss = 4.7670746e-05  learning rate = 0.0001285121
============================
Start of epoch 5
step 0: mean loss = 4.0130886e-05
step 100: mean loss = 4.8266178e-05
step 200: mean loss = 4.760277e-05
step 300: mean loss = 4.7561884e-05
epoch 5: mean loss = 4.7736663e-05  learning rate = 0.0001285121
============================
Start of epoch 6
step 0: mean loss = 7.1426504e-05
step 100: mean loss = 4.6821657e-05
step 200: mean loss = 4.748159e-05
step 300: mean loss = 4.808219e-05
epoch 6: mean loss = 4.8306574e-05  learning rate = 0.0001285121
============================
Start of epoch 7
step 0: mean loss = 4.7164925e-05
step 100: mean loss = 4.9170165e-05
step 200: mean loss = 4.8636226e-05
step 300: mean loss = 4.9233797e-05
epoch 7: mean loss = 4.9165326e-05  learning rate = 0.0001285121
============================
Start of epoch 8
step 0: mean loss = 4.220368e-05
step 100: mean loss = 5.013684e-05
step 200: mean loss = 4.9246795e-05
step 300: mean loss = 4.848742e-05
epoch 8: mean loss = 4.840174e-05  learning rate = 0.0001285121
============================
Start of epoch 9
step 0: mean loss = 6.258364e-05
step 100: mean loss = 4.9606515e-05
step 200: mean loss = 4.8906204e-05
step 300: mean loss = 4.902759e-05
epoch 9: mean loss = 4.907128e-05  learning rate = 0.0001285121
============================
Start of epoch 10
step 0: mean loss = 5.3929638e-05
step 100: mean loss = 4.973823e-05
step 200: mean loss = 4.928921e-05
step 300: mean loss = 4.9278566e-05
epoch 10: mean loss = 4.9170278e-05  learning rate = 0.0001285121
============================
Start of epoch 11
step 0: mean loss = 3.5470403e-05
step 100: mean loss = 4.8144615e-05
step 200: mean loss = 4.8454596e-05
step 300: mean loss = 4.8909344e-05
epoch 11: mean loss = 4.893875e-05  learning rate = 0.0001285121
============================
Start of epoch 12
step 0: mean loss = 5.467783e-05
step 100: mean loss = 4.995356e-05
step 200: mean loss = 4.8466118e-05
step 300: mean loss = 4.8524205e-05
epoch 12: mean loss = 4.8351696e-05  learning rate = 0.0001285121
============================
Start of epoch 13
step 0: mean loss = 4.1843792e-05
step 100: mean loss = 4.785957e-05
step 200: mean loss = 4.8833575e-05
step 300: mean loss = 4.909255e-05
epoch 13: mean loss = 4.914941e-05  learning rate = 0.0001285121
============================
Start of epoch 14
step 0: mean loss = 4.7424805e-05
step 100: mean loss = 4.8123027e-05
step 200: mean loss = 4.9028797e-05
step 300: mean loss = 4.885651e-05
epoch 14: mean loss = 4.8859045e-05  learning rate = 0.0001285121
============================
Start of epoch 15
step 0: mean loss = 4.9227878e-05
step 100: mean loss = 4.759555e-05
step 200: mean loss = 4.7045236e-05
step 300: mean loss = 4.7858382e-05
epoch 15: mean loss = 4.7908507e-05  learning rate = 0.0001285121
============================
Start of epoch 16
step 0: mean loss = 5.5572207e-05
step 100: mean loss = 4.7858215e-05
step 200: mean loss = 4.8404596e-05
step 300: mean loss = 4.8122925e-05
epoch 16: mean loss = 4.818177e-05  learning rate = 0.0001285121
============================
Start of epoch 17
step 0: mean loss = 7.029969e-05
step 100: mean loss = 4.8686245e-05
step 200: mean loss = 4.8255984e-05
step 300: mean loss = 4.759071e-05
epoch 17: mean loss = 4.7611255e-05  learning rate = 0.0001285121
============================
Start of epoch 18
step 0: mean loss = 5.0356884e-05
step 100: mean loss = 4.837992e-05
step 200: mean loss = 4.8438003e-05
step 300: mean loss = 4.922569e-05
epoch 18: mean loss = 4.907497e-05  learning rate = 0.0001285121
============================
Start of epoch 19
step 0: mean loss = 4.247944e-05
step 100: mean loss = 4.7398717e-05
step 200: mean loss = 4.721222e-05
step 300: mean loss = 4.7865247e-05
epoch 19: mean loss = 4.780273e-05  learning rate = 0.0001285121
============================
Start of epoch 20
step 0: mean loss = 4.921769e-05
step 100: mean loss = 4.896735e-05
step 200: mean loss = 4.737155e-05
step 300: mean loss = 4.8316684e-05
epoch 20: mean loss = 4.8308662e-05  learning rate = 0.0001285121
============================
Start of epoch 21
step 0: mean loss = 6.101351e-05
step 100: mean loss = 4.7717178e-05
step 200: mean loss = 4.795014e-05
step 300: mean loss = 4.873682e-05
epoch 21: mean loss = 4.8518457e-05  learning rate = 0.0001285121
============================
Start of epoch 22
step 0: mean loss = 3.266605e-05
step 100: mean loss = 4.7178506e-05
step 200: mean loss = 4.6326993e-05
step 300: mean loss = 4.698246e-05
epoch 22: mean loss = 4.7078658e-05  learning rate = 0.0001285121
============================
Start of epoch 23
step 0: mean loss = 5.095053e-05
step 100: mean loss = 4.7807414e-05
step 200: mean loss = 4.6571018e-05
step 300: mean loss = 4.723204e-05
epoch 23: mean loss = 4.734846e-05  learning rate = 0.0001285121
============================
Start of epoch 24
step 0: mean loss = 4.0644736e-05
step 100: mean loss = 4.7817597e-05
step 200: mean loss = 4.7603895e-05
step 300: mean loss = 4.711624e-05
epoch 24: mean loss = 4.7171627e-05  learning rate = 0.0001285121
============================
Start of epoch 25
step 0: mean loss = 4.5060944e-05
step 100: mean loss = 4.7352234e-05
step 200: mean loss = 4.6460184e-05
step 300: mean loss = 4.7224163e-05
epoch 25: mean loss = 4.7162877e-05  learning rate = 0.0001285121
============================
Start of epoch 26
step 0: mean loss = 3.2661217e-05
step 100: mean loss = 4.8372138e-05
step 200: mean loss = 4.8275455e-05
step 300: mean loss = 4.83046e-05
epoch 26: mean loss = 4.8235688e-05  learning rate = 0.0001285121
============================
Start of epoch 27
step 0: mean loss = 3.5598725e-05
step 100: mean loss = 4.7009886e-05
step 200: mean loss = 4.733467e-05
step 300: mean loss = 4.649517e-05
epoch 27: mean loss = 4.65684e-05  learning rate = 0.0001285121
============================
Start of epoch 28
step 0: mean loss = 5.7591933e-05
step 100: mean loss = 4.6441088e-05
step 200: mean loss = 4.7715952e-05
step 300: mean loss = 4.726609e-05
epoch 28: mean loss = 4.7324364e-05  learning rate = 0.0001285121
============================
Start of epoch 29
step 0: mean loss = 4.1180312e-05
step 100: mean loss = 4.663872e-05
step 200: mean loss = 4.6094927e-05
step 300: mean loss = 4.6814523e-05
epoch 29: mean loss = 4.6963538e-05  learning rate = 0.0001285121
============================
Start of epoch 30
step 0: mean loss = 3.726931e-05
step 100: mean loss = 4.5976292e-05
step 200: mean loss = 4.6538087e-05
step 300: mean loss = 4.6945046e-05
epoch 30: mean loss = 4.6913596e-05  learning rate = 0.0001285121
============================
Start of epoch 31
step 0: mean loss = 3.9333776e-05
step 100: mean loss = 4.6258516e-05
step 200: mean loss = 4.6596637e-05
step 300: mean loss = 4.781753e-05
epoch 31: mean loss = 4.7780257e-05  learning rate = 0.0001285121
============================
Start of epoch 32
step 0: mean loss = 5.5973112e-05
step 100: mean loss = 4.846798e-05
step 200: mean loss = 4.7752175e-05
step 300: mean loss = 4.7485166e-05
epoch 32: mean loss = 4.773241e-05  learning rate = 0.0001285121
============================
Start of epoch 33
step 0: mean loss = 4.853136e-05
step 100: mean loss = 4.6827292e-05
step 200: mean loss = 4.6466776e-05
step 300: mean loss = 4.642058e-05
epoch 33: mean loss = 4.628787e-05  learning rate = 0.0001285121
============================
Start of epoch 34
step 0: mean loss = 4.3121243e-05
step 100: mean loss = 4.673461e-05
step 200: mean loss = 4.7099773e-05
step 300: mean loss = 4.7088e-05
epoch 34: mean loss = 4.7048958e-05  learning rate = 0.0001285121
============================
Start of epoch 35
step 0: mean loss = 3.8035203e-05
step 100: mean loss = 4.736013e-05
step 200: mean loss = 4.6239977e-05
step 300: mean loss = 4.5971115e-05
epoch 35: mean loss = 4.6031968e-05  learning rate = 0.0001285121
============================
Start of epoch 36
step 0: mean loss = 4.376112e-05
step 100: mean loss = 4.7536345e-05
step 200: mean loss = 4.6384535e-05
step 300: mean loss = 4.6323694e-05
epoch 36: mean loss = 4.6509747e-05  learning rate = 0.0001285121
============================
Start of epoch 37
step 0: mean loss = 4.487278e-05
step 100: mean loss = 4.6180492e-05
step 200: mean loss = 4.614288e-05
step 300: mean loss = 4.7414513e-05
epoch 37: mean loss = 4.7394788e-05  learning rate = 0.0001285121
============================
Start of epoch 38
step 0: mean loss = 6.039638e-05
step 100: mean loss = 4.446219e-05
step 200: mean loss = 4.5735138e-05
step 300: mean loss = 4.549083e-05
epoch 38: mean loss = 4.5471555e-05  learning rate = 0.0001285121
============================
Start of epoch 39
step 0: mean loss = 5.8757167e-05
step 100: mean loss = 4.5681598e-05
step 200: mean loss = 4.62551e-05
step 300: mean loss = 4.57845e-05
epoch 39: mean loss = 4.575961e-05  learning rate = 0.0001220865
============================
Start of epoch 40
step 0: mean loss = 3.960094e-05
step 100: mean loss = 4.5305915e-05
step 200: mean loss = 4.4413864e-05
step 300: mean loss = 4.4699977e-05
epoch 40: mean loss = 4.47423e-05  learning rate = 0.0001220865
============================
Start of epoch 41
step 0: mean loss = 4.4445238e-05
step 100: mean loss = 4.436079e-05
step 200: mean loss = 4.435807e-05
step 300: mean loss = 4.4366065e-05
epoch 41: mean loss = 4.450317e-05  learning rate = 0.0001220865
============================
Start of epoch 42
step 0: mean loss = 4.491846e-05
step 100: mean loss = 4.563151e-05
step 200: mean loss = 4.6235396e-05
step 300: mean loss = 4.5763467e-05
epoch 42: mean loss = 4.5633435e-05  learning rate = 0.0001220865
============================
Start of epoch 43
step 0: mean loss = 3.7571263e-05
step 100: mean loss = 4.387081e-05
step 200: mean loss = 4.456914e-05
step 300: mean loss = 4.4362754e-05
epoch 43: mean loss = 4.430025e-05  learning rate = 0.0001220865
============================
Start of epoch 44
step 0: mean loss = 4.1739644e-05
step 100: mean loss = 4.6685098e-05
step 200: mean loss = 4.6431916e-05
step 300: mean loss = 4.5976536e-05
epoch 44: mean loss = 4.5782093e-05  learning rate = 0.0001220865
============================
Start of epoch 45
step 0: mean loss = 3.7437738e-05
step 100: mean loss = 4.4115077e-05
step 200: mean loss = 4.4925615e-05
step 300: mean loss = 4.501221e-05
epoch 45: mean loss = 4.494192e-05  learning rate = 0.0001220865
============================
Start of epoch 46
step 0: mean loss = 3.7660593e-05
step 100: mean loss = 4.4156757e-05
step 200: mean loss = 4.3801316e-05
step 300: mean loss = 4.384815e-05
epoch 46: mean loss = 4.397416e-05  learning rate = 0.0001220865
============================
Start of epoch 47
step 0: mean loss = 5.0511022e-05
step 100: mean loss = 4.6339745e-05
step 200: mean loss = 4.6082314e-05
step 300: mean loss = 4.528921e-05
epoch 47: mean loss = 4.5368903e-05  learning rate = 0.0001220865
============================
Start of epoch 48
step 0: mean loss = 3.643317e-05
step 100: mean loss = 4.6372097e-05
step 200: mean loss = 4.5155368e-05
step 300: mean loss = 4.476303e-05
epoch 48: mean loss = 4.455208e-05  learning rate = 0.0001220865
============================
Start of epoch 49
step 0: mean loss = 5.0730137e-05
step 100: mean loss = 4.3614928e-05
step 200: mean loss = 4.4199092e-05
step 300: mean loss = 4.406957e-05
epoch 49: mean loss = 4.4255823e-05  learning rate = 0.0001220865
============================
Start of epoch 50
step 0: mean loss = 4.2015025e-05
step 100: mean loss = 4.4850975e-05
step 200: mean loss = 4.5826237e-05
step 300: mean loss = 4.4519184e-05
epoch 50: mean loss = 4.4612534e-05  learning rate = 0.0001220865
============================
Start of epoch 51
step 0: mean loss = 4.4090033e-05
step 100: mean loss = 4.4863642e-05
step 200: mean loss = 4.593478e-05
step 300: mean loss = 4.5457302e-05
epoch 51: mean loss = 4.5273515e-05  learning rate = 0.0001220865
============================
Start of epoch 52
step 0: mean loss = 4.9465525e-05
step 100: mean loss = 4.4156302e-05
step 200: mean loss = 4.4875982e-05
step 300: mean loss = 4.4581946e-05
epoch 52: mean loss = 4.4635537e-05  learning rate = 0.0001220865
============================
Start of epoch 53
step 0: mean loss = 4.710713e-05
step 100: mean loss = 4.5399735e-05
step 200: mean loss = 4.4245364e-05
step 300: mean loss = 4.375671e-05
epoch 53: mean loss = 4.356222e-05  learning rate = 0.0001220865
============================
Start of epoch 54
step 0: mean loss = 6.960575e-05
step 100: mean loss = 4.3364522e-05
step 200: mean loss = 4.3949225e-05
step 300: mean loss = 4.4390195e-05
epoch 54: mean loss = 4.4279517e-05  learning rate = 0.0001220865
============================
Start of epoch 55
step 0: mean loss = 4.798155e-05
step 100: mean loss = 4.3383076e-05
step 200: mean loss = 4.4101296e-05
step 300: mean loss = 4.3773725e-05
epoch 55: mean loss = 4.385596e-05  learning rate = 0.0001220865
============================
Start of epoch 56
step 0: mean loss = 3.538953e-05
step 100: mean loss = 4.424631e-05
step 200: mean loss = 4.400039e-05
step 300: mean loss = 4.3901255e-05
epoch 56: mean loss = 4.3918695e-05  learning rate = 0.0001220865
============================
Start of epoch 57
step 0: mean loss = 4.462076e-05
step 100: mean loss = 4.33056e-05
step 200: mean loss = 4.4077446e-05
step 300: mean loss = 4.3777283e-05
epoch 57: mean loss = 4.3881282e-05  learning rate = 0.0001220865
============================
Start of epoch 58
step 0: mean loss = 5.1280105e-05
step 100: mean loss = 4.2615367e-05
step 200: mean loss = 4.3181713e-05
step 300: mean loss = 4.3557993e-05
epoch 58: mean loss = 4.3556003e-05  learning rate = 0.0001220865
============================
Start of epoch 59
step 0: mean loss = 3.820045e-05
step 100: mean loss = 4.3575554e-05
step 200: mean loss = 4.3093885e-05
step 300: mean loss = 4.368815e-05
epoch 59: mean loss = 4.3674852e-05  learning rate = 0.0001220865
============================
Start of epoch 60
step 0: mean loss = 3.531658e-05
step 100: mean loss = 4.3115786e-05
step 200: mean loss = 4.295447e-05
step 300: mean loss = 4.3269913e-05
epoch 60: mean loss = 4.3422257e-05  learning rate = 0.0001220865
============================
Start of epoch 61
step 0: mean loss = 4.1435174e-05
step 100: mean loss = 4.2610885e-05
step 200: mean loss = 4.2955453e-05
step 300: mean loss = 4.288939e-05
epoch 61: mean loss = 4.2798605e-05  learning rate = 0.0001220865
============================
Start of epoch 62
step 0: mean loss = 4.1825126e-05
step 100: mean loss = 4.3802687e-05
step 200: mean loss = 4.4142384e-05
step 300: mean loss = 4.4258457e-05
epoch 62: mean loss = 4.4355587e-05  learning rate = 0.0001220865
============================
Start of epoch 63
step 0: mean loss = 4.5330235e-05
step 100: mean loss = 4.4116325e-05
step 200: mean loss = 4.4630327e-05
step 300: mean loss = 4.4039647e-05
epoch 63: mean loss = 4.3970846e-05  learning rate = 0.0001220865
============================
Start of epoch 64
step 0: mean loss = 5.7284076e-05
step 100: mean loss = 4.351258e-05
step 200: mean loss = 4.308537e-05
step 300: mean loss = 4.2627827e-05
epoch 64: mean loss = 4.268761e-05  learning rate = 0.0001220865
============================
Start of epoch 65
step 0: mean loss = 4.015296e-05
step 100: mean loss = 4.2433883e-05
step 200: mean loss = 4.262872e-05
step 300: mean loss = 4.289616e-05
epoch 65: mean loss = 4.2961638e-05  learning rate = 0.0001220865
============================
Start of epoch 66
step 0: mean loss = 3.8350532e-05
step 100: mean loss = 4.2827218e-05
step 200: mean loss = 4.261676e-05
step 300: mean loss = 4.309587e-05
epoch 66: mean loss = 4.3361804e-05  learning rate = 0.0001220865
============================
Start of epoch 67
step 0: mean loss = 6.0430848e-05
step 100: mean loss = 4.380555e-05
step 200: mean loss = 4.309797e-05
step 300: mean loss = 4.3428103e-05
epoch 67: mean loss = 4.3312044e-05  learning rate = 0.0001220865
============================
Start of epoch 68
step 0: mean loss = 4.2263688e-05
step 100: mean loss = 4.5736335e-05
step 200: mean loss = 4.3822485e-05
step 300: mean loss = 4.2845106e-05
epoch 68: mean loss = 4.2792057e-05  learning rate = 0.0001220865
============================
Start of epoch 69
step 0: mean loss = 4.491175e-05
step 100: mean loss = 4.3392738e-05
step 200: mean loss = 4.2999192e-05
step 300: mean loss = 4.3372358e-05
epoch 69: mean loss = 4.330493e-05  learning rate = 0.0001220865
============================
Start of epoch 70
step 0: mean loss = 7.2001065e-05
step 100: mean loss = 4.4892106e-05
step 200: mean loss = 4.337401e-05
step 300: mean loss = 4.3110434e-05
epoch 70: mean loss = 4.3095435e-05  learning rate = 0.0001220865
============================
Start of epoch 71
step 0: mean loss = 3.83332e-05
step 100: mean loss = 4.1224754e-05
step 200: mean loss = 4.149203e-05
step 300: mean loss = 4.2209576e-05
epoch 71: mean loss = 4.2300555e-05  learning rate = 0.0001220865
============================
Start of epoch 72
step 0: mean loss = 4.1457686e-05
step 100: mean loss = 4.4270695e-05
step 200: mean loss = 4.2993463e-05
step 300: mean loss = 4.3059554e-05
epoch 72: mean loss = 4.3048407e-05  learning rate = 0.0001220865
============================
Start of epoch 73
step 0: mean loss = 3.3234253e-05
step 100: mean loss = 4.165419e-05
step 200: mean loss = 4.046517e-05
step 300: mean loss = 4.2949192e-05
epoch 73: mean loss = 4.2688698e-05  learning rate = 0.0001220865
============================
Start of epoch 74
step 0: mean loss = 5.335071e-05
step 100: mean loss = 4.151501e-05
step 200: mean loss = 4.285648e-05
step 300: mean loss = 4.283188e-05
epoch 74: mean loss = 4.283539e-05  learning rate = 0.0001220865
============================
Start of epoch 75
step 0: mean loss = 4.4364177e-05
step 100: mean loss = 4.1268802e-05
step 200: mean loss = 4.156626e-05
step 300: mean loss = 4.1544095e-05
epoch 75: mean loss = 4.166857e-05  learning rate = 0.0001220865
============================
Start of epoch 76
step 0: mean loss = 4.5675893e-05
step 100: mean loss = 4.3276003e-05
step 200: mean loss = 4.245029e-05
step 300: mean loss = 4.2609394e-05
epoch 76: mean loss = 4.2638967e-05  learning rate = 0.0001220865
============================
Start of epoch 77
step 0: mean loss = 4.534497e-05
step 100: mean loss = 4.2456013e-05
step 200: mean loss = 4.2182703e-05
step 300: mean loss = 4.278624e-05
epoch 77: mean loss = 4.279492e-05  learning rate = 0.0001220865
============================
Start of epoch 78
step 0: mean loss = 4.5682107e-05
step 100: mean loss = 4.4580975e-05
step 200: mean loss = 4.2373278e-05
step 300: mean loss = 4.2150932e-05
epoch 78: mean loss = 4.2176263e-05  learning rate = 0.0001220865
============================
Start of epoch 79
step 0: mean loss = 3.8133017e-05
step 100: mean loss = 4.2830437e-05
step 200: mean loss = 4.1299318e-05
step 300: mean loss = 4.150332e-05
epoch 79: mean loss = 4.146612e-05  learning rate = 0.00011598217
============================
Start of epoch 80
step 0: mean loss = 3.797016e-05
step 100: mean loss = 4.238016e-05
step 200: mean loss = 4.159422e-05
step 300: mean loss = 4.137723e-05
epoch 80: mean loss = 4.150775e-05  learning rate = 0.00011598217
============================
Start of epoch 81
step 0: mean loss = 5.1254385e-05
step 100: mean loss = 4.0044473e-05
step 200: mean loss = 4.0125436e-05
step 300: mean loss = 4.0484705e-05
epoch 81: mean loss = 4.05575e-05  learning rate = 0.00011598217
============================
Start of epoch 82
step 0: mean loss = 5.9392973e-05
step 100: mean loss = 3.856148e-05
step 200: mean loss = 4.030103e-05
step 300: mean loss = 4.0892362e-05
epoch 82: mean loss = 4.0998835e-05  learning rate = 0.00011598217
============================
Start of epoch 83
step 0: mean loss = 3.6388425e-05
step 100: mean loss = 4.2298394e-05
step 200: mean loss = 4.1179144e-05
step 300: mean loss = 4.0893297e-05
epoch 83: mean loss = 4.0854058e-05  learning rate = 0.00011598217
============================
Start of epoch 84
step 0: mean loss = 3.4592835e-05
step 100: mean loss = 3.963543e-05
step 200: mean loss = 4.0504383e-05
step 300: mean loss = 4.0881398e-05
epoch 84: mean loss = 4.0832678e-05  learning rate = 0.00011598217
============================
Start of epoch 85
step 0: mean loss = 8.070385e-05
step 100: mean loss = 4.000213e-05
step 200: mean loss = 4.074362e-05
step 300: mean loss = 4.1007777e-05
epoch 85: mean loss = 4.1139778e-05  learning rate = 0.00011598217
============================
Start of epoch 86
step 0: mean loss = 4.2033676e-05
step 100: mean loss = 3.9117043e-05
step 200: mean loss = 4.0133345e-05
step 300: mean loss = 4.018515e-05
epoch 86: mean loss = 4.0269202e-05  learning rate = 0.00011598217
============================
Start of epoch 87
step 0: mean loss = 4.4139622e-05
step 100: mean loss = 4.2162097e-05
step 200: mean loss = 4.2450567e-05
step 300: mean loss = 4.1239968e-05
epoch 87: mean loss = 4.1185343e-05  learning rate = 0.00011598217
============================
Start of epoch 88
step 0: mean loss = 3.9246785e-05
step 100: mean loss = 4.0471223e-05
step 200: mean loss = 4.179476e-05
step 300: mean loss = 4.0652707e-05
epoch 88: mean loss = 4.0491577e-05  learning rate = 0.00011598217
============================
Start of epoch 89
step 0: mean loss = 4.38145e-05
step 100: mean loss = 4.0165753e-05
step 200: mean loss = 4.119604e-05
step 300: mean loss = 4.0625786e-05
epoch 89: mean loss = 4.0493247e-05  learning rate = 0.00011598217
============================
Start of epoch 90
step 0: mean loss = 2.718842e-05
step 100: mean loss = 3.9974486e-05
step 200: mean loss = 4.0508483e-05
step 300: mean loss = 4.0402323e-05
epoch 90: mean loss = 4.0455485e-05  learning rate = 0.00011598217
============================
Start of epoch 91
step 0: mean loss = 4.4903165e-05
step 100: mean loss = 4.167693e-05
step 200: mean loss = 4.168124e-05
step 300: mean loss = 4.0521754e-05
epoch 91: mean loss = 4.0593928e-05  learning rate = 0.00011598217
============================
Start of epoch 92
step 0: mean loss = 4.6585632e-05
step 100: mean loss = 4.400229e-05
step 200: mean loss = 4.1937154e-05
step 300: mean loss = 4.1017443e-05
epoch 92: mean loss = 4.123495e-05  learning rate = 0.00011598217
============================
Start of epoch 93
step 0: mean loss = 3.8572376e-05
step 100: mean loss = 3.9266113e-05
step 200: mean loss = 4.069047e-05
step 300: mean loss = 4.0546092e-05
epoch 93: mean loss = 4.0583192e-05  learning rate = 0.00011598217
============================
Start of epoch 94
step 0: mean loss = 3.7095404e-05
step 100: mean loss = 3.829821e-05
step 200: mean loss = 3.945543e-05
step 300: mean loss = 4.0045503e-05
epoch 94: mean loss = 4.0029427e-05  learning rate = 0.00011598217
============================
Start of epoch 95
step 0: mean loss = 3.5068762e-05
step 100: mean loss = 3.9256414e-05
step 200: mean loss = 4.0142244e-05
step 300: mean loss = 3.9948867e-05
epoch 95: mean loss = 3.9970568e-05  learning rate = 0.00011598217
============================
Start of epoch 96
step 0: mean loss = 3.2967117e-05
step 100: mean loss = 3.9492956e-05
step 200: mean loss = 3.9788218e-05
step 300: mean loss = 4.05559e-05
epoch 96: mean loss = 4.0502957e-05  learning rate = 0.00011598217
============================
Start of epoch 97
step 0: mean loss = 3.848445e-05
step 100: mean loss = 4.0968822e-05
step 200: mean loss = 3.9976752e-05
step 300: mean loss = 3.998988e-05
epoch 97: mean loss = 4.027127e-05  learning rate = 0.00011598217
============================
Start of epoch 98
step 0: mean loss = 4.436091e-05
step 100: mean loss = 4.2161115e-05
step 200: mean loss = 4.08016e-05
step 300: mean loss = 4.0545754e-05
epoch 98: mean loss = 4.051295e-05  learning rate = 0.00011598217
============================
Start of epoch 99
step 0: mean loss = 3.9490023e-05
step 100: mean loss = 4.0104194e-05
step 200: mean loss = 4.1471405e-05
step 300: mean loss = 4.0518942e-05
epoch 99: mean loss = 4.0608204e-05  learning rate = 0.00011598217
============================
Start of epoch 100
step 0: mean loss = 3.191628e-05
step 100: mean loss = 3.9144696e-05
step 200: mean loss = 3.9211936e-05
step 300: mean loss = 3.936205e-05
epoch 100: mean loss = 3.9233033e-05  learning rate = 0.00011598217
============================
Start of epoch 101
step 0: mean loss = 3.2276486e-05
step 100: mean loss = 4.103849e-05
step 200: mean loss = 3.9833332e-05
step 300: mean loss = 4.023744e-05
epoch 101: mean loss = 4.027338e-05  learning rate = 0.00011598217
============================
Start of epoch 102
step 0: mean loss = 4.0836898e-05
step 100: mean loss = 4.075338e-05
step 200: mean loss = 3.994184e-05
step 300: mean loss = 3.98875e-05
epoch 102: mean loss = 3.98372e-05  learning rate = 0.00011598217
============================
Start of epoch 103
step 0: mean loss = 2.8483097e-05
step 100: mean loss = 3.7688547e-05
step 200: mean loss = 3.887052e-05
step 300: mean loss = 3.999604e-05
epoch 103: mean loss = 4.0050905e-05  learning rate = 0.00011598217
============================
Start of epoch 104
step 0: mean loss = 3.1454707e-05
step 100: mean loss = 4.0266703e-05
step 200: mean loss = 4.0920397e-05
step 300: mean loss = 4.0286362e-05
epoch 104: mean loss = 4.0263607e-05  learning rate = 0.00011598217
============================
Start of epoch 105
step 0: mean loss = 4.2038788e-05
step 100: mean loss = 4.0971434e-05
step 200: mean loss = 3.9243238e-05
step 300: mean loss = 3.9249862e-05
epoch 105: mean loss = 3.916267e-05  learning rate = 0.00011598217
============================
Start of epoch 106
step 0: mean loss = 3.708429e-05
step 100: mean loss = 4.0098013e-05
step 200: mean loss = 4.0743165e-05
step 300: mean loss = 3.9818377e-05
epoch 106: mean loss = 3.9741943e-05  learning rate = 0.00011598217
============================
Start of epoch 107
step 0: mean loss = 3.640532e-05
step 100: mean loss = 4.0300296e-05
step 200: mean loss = 3.9516057e-05
step 300: mean loss = 3.950854e-05
epoch 107: mean loss = 3.9533992e-05  learning rate = 0.00011598217
============================
Start of epoch 108
step 0: mean loss = 3.4165223e-05
step 100: mean loss = 3.9508952e-05
step 200: mean loss = 3.927382e-05
step 300: mean loss = 3.9831193e-05
epoch 108: mean loss = 3.9798848e-05  learning rate = 0.00011598217
============================
Start of epoch 109
step 0: mean loss = 3.2510237e-05
step 100: mean loss = 3.842764e-05
step 200: mean loss = 3.921529e-05
step 300: mean loss = 3.9818675e-05
epoch 109: mean loss = 3.968799e-05  learning rate = 0.00011598217
============================
Start of epoch 110
step 0: mean loss = 3.124828e-05
step 100: mean loss = 4.0250587e-05
step 200: mean loss = 3.951661e-05
step 300: mean loss = 3.9088034e-05
epoch 110: mean loss = 3.9126186e-05  learning rate = 0.00011598217
============================
Start of epoch 111
step 0: mean loss = 4.008652e-05
step 100: mean loss = 3.961737e-05
step 200: mean loss = 4.0288687e-05
step 300: mean loss = 3.970138e-05
epoch 111: mean loss = 3.957818e-05  learning rate = 0.00011598217
============================
Start of epoch 112
step 0: mean loss = 4.0368337e-05
step 100: mean loss = 3.8633698e-05
step 200: mean loss = 3.8698574e-05
step 300: mean loss = 3.9257116e-05
epoch 112: mean loss = 3.9208793e-05  learning rate = 0.00011598217
============================
Start of epoch 113
step 0: mean loss = 3.2834752e-05
step 100: mean loss = 3.836279e-05
step 200: mean loss = 3.8959228e-05
step 300: mean loss = 4.0843235e-05
epoch 113: mean loss = 4.082648e-05  learning rate = 0.00011598217
============================
Start of epoch 114
step 0: mean loss = 3.701577e-05
step 100: mean loss = 3.955686e-05
step 200: mean loss = 3.8689734e-05
step 300: mean loss = 3.8802882e-05
epoch 114: mean loss = 3.8796352e-05  learning rate = 0.00011598217
============================
Start of epoch 115
step 0: mean loss = 3.7492195e-05
step 100: mean loss = 3.954041e-05
step 200: mean loss = 3.8730155e-05
step 300: mean loss = 3.893309e-05
epoch 115: mean loss = 3.914603e-05  learning rate = 0.00011598217
============================
Start of epoch 116
step 0: mean loss = 3.4292996e-05
step 100: mean loss = 3.743391e-05
step 200: mean loss = 3.7968137e-05
step 300: mean loss = 3.8850998e-05
epoch 116: mean loss = 3.897559e-05  learning rate = 0.00011598217
============================
Start of epoch 117
step 0: mean loss = 3.8094688e-05
step 100: mean loss = 3.97133e-05
step 200: mean loss = 3.9698723e-05
step 300: mean loss = 3.963749e-05
epoch 117: mean loss = 3.9458446e-05  learning rate = 0.00011598217
============================
Start of epoch 118
step 0: mean loss = 3.2728858e-05
step 100: mean loss = 3.894138e-05
step 200: mean loss = 3.849785e-05
step 300: mean loss = 3.8932034e-05
epoch 118: mean loss = 3.9078335e-05  learning rate = 0.00011598217
============================
Start of epoch 119
step 0: mean loss = 4.1447875e-05
step 100: mean loss = 3.8745988e-05
step 200: mean loss = 3.953258e-05
step 300: mean loss = 3.9133516e-05
epoch 119: mean loss = 3.9018225e-05  learning rate = 0.00011018306
============================
Start of epoch 120
step 0: mean loss = 4.6113673e-05
step 100: mean loss = 3.6593196e-05
step 200: mean loss = 3.798925e-05
step 300: mean loss = 3.7547372e-05
epoch 120: mean loss = 3.7701873e-05  learning rate = 0.00011018306
============================
Start of epoch 121
step 0: mean loss = 3.5875433e-05
step 100: mean loss = 3.5538385e-05
step 200: mean loss = 3.694938e-05
step 300: mean loss = 3.728209e-05
epoch 121: mean loss = 3.7329854e-05  learning rate = 0.00011018306
============================
Start of epoch 122
step 0: mean loss = 3.716056e-05
step 100: mean loss = 3.7969254e-05
step 200: mean loss = 3.7718914e-05
step 300: mean loss = 3.7465456e-05
epoch 122: mean loss = 3.747813e-05  learning rate = 0.00011018306
============================
Start of epoch 123
step 0: mean loss = 3.0945062e-05
step 100: mean loss = 3.9350816e-05
step 200: mean loss = 3.902688e-05
step 300: mean loss = 3.775139e-05
epoch 123: mean loss = 3.761539e-05  learning rate = 0.00011018306
============================
Start of epoch 124
step 0: mean loss = 3.0993157e-05
step 100: mean loss = 3.612014e-05
step 200: mean loss = 3.695276e-05
step 300: mean loss = 3.6845086e-05
epoch 124: mean loss = 3.686707e-05  learning rate = 0.00011018306
============================
Start of epoch 125
step 0: mean loss = 4.8101898e-05
step 100: mean loss = 3.7612543e-05
step 200: mean loss = 3.7188027e-05
step 300: mean loss = 3.7823742e-05
epoch 125: mean loss = 3.7860213e-05  learning rate = 0.00011018306
============================
Start of epoch 126
step 0: mean loss = 3.2408694e-05
step 100: mean loss = 3.9503393e-05
step 200: mean loss = 3.8125057e-05
step 300: mean loss = 3.838608e-05
epoch 126: mean loss = 3.8179594e-05  learning rate = 0.00011018306
============================
Start of epoch 127
step 0: mean loss = 3.0319705e-05
step 100: mean loss = 3.771995e-05
step 200: mean loss = 3.7197646e-05
step 300: mean loss = 3.7231024e-05
epoch 127: mean loss = 3.7121405e-05  learning rate = 0.00011018306
============================
Start of epoch 128
step 0: mean loss = 3.2607586e-05
step 100: mean loss = 3.779467e-05
step 200: mean loss = 3.846272e-05
step 300: mean loss = 3.7937483e-05
epoch 128: mean loss = 3.7876613e-05  learning rate = 0.00011018306
============================
Start of epoch 129
step 0: mean loss = 3.619611e-05
step 100: mean loss = 3.6981804e-05
step 200: mean loss = 3.6269423e-05
step 300: mean loss = 3.6994847e-05
epoch 129: mean loss = 3.73013e-05  learning rate = 0.00011018306
============================
Start of epoch 130
step 0: mean loss = 4.190434e-05
step 100: mean loss = 3.85405e-05
step 200: mean loss = 3.7894006e-05
step 300: mean loss = 3.8345413e-05
epoch 130: mean loss = 3.8255665e-05  learning rate = 0.00011018306
============================
Start of epoch 131
step 0: mean loss = 3.1434716e-05
step 100: mean loss = 3.7576647e-05
step 200: mean loss = 3.8833667e-05
step 300: mean loss = 3.8198603e-05
epoch 131: mean loss = 3.7974325e-05  learning rate = 0.00011018306
============================
Start of epoch 132
step 0: mean loss = 2.6597678e-05
step 100: mean loss = 3.6244193e-05
step 200: mean loss = 3.6524958e-05
step 300: mean loss = 3.742153e-05
epoch 132: mean loss = 3.7571823e-05  learning rate = 0.00011018306
============================
Start of epoch 133
step 0: mean loss = 3.494106e-05
step 100: mean loss = 3.828632e-05
step 200: mean loss = 3.752129e-05
step 300: mean loss = 3.7559596e-05
epoch 133: mean loss = 3.757629e-05  learning rate = 0.00011018306
============================
Start of epoch 134
step 0: mean loss = 3.215992e-05
step 100: mean loss = 3.7235855e-05
step 200: mean loss = 3.7599046e-05
step 300: mean loss = 3.7092883e-05
epoch 134: mean loss = 3.7087186e-05  learning rate = 0.00011018306
============================
Start of epoch 135
step 0: mean loss = 4.2778545e-05
step 100: mean loss = 3.7321624e-05
step 200: mean loss = 3.7545586e-05
step 300: mean loss = 3.678167e-05
epoch 135: mean loss = 3.6770678e-05  learning rate = 0.00011018306
============================
Start of epoch 136
step 0: mean loss = 3.0517982e-05
step 100: mean loss = 3.740849e-05
step 200: mean loss = 3.700221e-05
step 300: mean loss = 3.6849102e-05
epoch 136: mean loss = 3.6983874e-05  learning rate = 0.00011018306
============================
Start of epoch 137
step 0: mean loss = 4.0841318e-05
step 100: mean loss = 3.7163107e-05
step 200: mean loss = 3.6289257e-05
step 300: mean loss = 3.7626374e-05
epoch 137: mean loss = 3.772994e-05  learning rate = 0.00011018306
============================
Start of epoch 138
step 0: mean loss = 4.5510275e-05
step 100: mean loss = 3.8131755e-05
step 200: mean loss = 3.683266e-05
step 300: mean loss = 3.70225e-05
epoch 138: mean loss = 3.6996073e-05  learning rate = 0.00011018306
============================
Start of epoch 139
step 0: mean loss = 3.2926422e-05
step 100: mean loss = 3.674795e-05
step 200: mean loss = 3.7069673e-05
step 300: mean loss = 3.6453963e-05
epoch 139: mean loss = 3.6517085e-05  learning rate = 0.00011018306
============================
Start of epoch 140
step 0: mean loss = 2.7124086e-05
step 100: mean loss = 3.5533147e-05
step 200: mean loss = 3.700369e-05
step 300: mean loss = 3.704079e-05
epoch 140: mean loss = 3.703318e-05  learning rate = 0.00011018306
============================
Start of epoch 141
step 0: mean loss = 2.9820187e-05
step 100: mean loss = 3.7474416e-05
step 200: mean loss = 5.2343446e-05
step 300: mean loss = 9.338379e-05
epoch 141: mean loss = 9.554116e-05  learning rate = 0.00011018306
============================
Start of epoch 142
step 0: mean loss = 0.00013042637
step 100: mean loss = 0.00011850059
step 200: mean loss = 9.879218e-05
step 300: mean loss = 8.678348e-05
epoch 142: mean loss = 8.5929925e-05  learning rate = 0.00011018306
============================
Start of epoch 143
step 0: mean loss = 6.341938e-05
step 100: mean loss = 5.3196807e-05
step 200: mean loss = 5.0547347e-05
step 300: mean loss = 4.7755417e-05
epoch 143: mean loss = 4.797731e-05  learning rate = 0.00011018306
============================
Start of epoch 144
step 0: mean loss = 3.6702608e-05
step 100: mean loss = 3.9585222e-05
step 200: mean loss = 3.96472e-05
step 300: mean loss = 3.917914e-05
epoch 144: mean loss = 3.9134164e-05  learning rate = 0.00011018306
============================
Start of epoch 145
step 0: mean loss = 3.9291066e-05
step 100: mean loss = 3.800772e-05
step 200: mean loss = 3.8386428e-05
step 300: mean loss = 3.8442435e-05
epoch 145: mean loss = 3.829792e-05  learning rate = 0.00011018306
============================
Start of epoch 146
step 0: mean loss = 2.8745038e-05
step 100: mean loss = 3.5024408e-05
step 200: mean loss = 3.4666802e-05
step 300: mean loss = 3.5513887e-05
epoch 146: mean loss = 3.5661575e-05  learning rate = 0.00011018306
============================
Start of epoch 147
step 0: mean loss = 3.7183207e-05
step 100: mean loss = 3.7395228e-05
step 200: mean loss = 3.755187e-05
step 300: mean loss = 3.7090133e-05
epoch 147: mean loss = 3.700028e-05  learning rate = 0.00011018306
============================
Start of epoch 148
step 0: mean loss = 3.7714086e-05
step 100: mean loss = 3.6839872e-05
step 200: mean loss = 3.65596e-05
step 300: mean loss = 3.7095164e-05
epoch 148: mean loss = 3.7177546e-05  learning rate = 0.00011018306
============================
Start of epoch 149
step 0: mean loss = 3.7924012e-05
step 100: mean loss = 3.73028e-05
step 200: mean loss = 3.7811275e-05
step 300: mean loss = 3.762002e-05
epoch 149: mean loss = 3.7430145e-05  learning rate = 0.00011018306
============================
Start of epoch 150
step 0: mean loss = 9.555151e-05
step 100: mean loss = 3.7974038e-05
step 200: mean loss = 3.758274e-05
step 300: mean loss = 3.707027e-05
epoch 150: mean loss = 3.7034082e-05  learning rate = 0.00011018306
============================
Start of epoch 151
step 0: mean loss = 5.031051e-05
step 100: mean loss = 3.6600333e-05
step 200: mean loss = 3.7811446e-05
step 300: mean loss = 3.685261e-05
epoch 151: mean loss = 3.678733e-05  learning rate = 0.00011018306
============================
Start of epoch 152
step 0: mean loss = 2.9006156e-05
step 100: mean loss = 3.4893925e-05
step 200: mean loss = 3.6119156e-05
step 300: mean loss = 3.603487e-05
epoch 152: mean loss = 3.622321e-05  learning rate = 0.00011018306
============================
Start of epoch 153
step 0: mean loss = 3.6949277e-05
step 100: mean loss = 3.6597583e-05
step 200: mean loss = 3.661677e-05
step 300: mean loss = 3.6907186e-05
epoch 153: mean loss = 3.684961e-05  learning rate = 0.00011018306
============================
Start of epoch 154
step 0: mean loss = 2.3497934e-05
step 100: mean loss = 3.705067e-05
step 200: mean loss = 3.726583e-05
step 300: mean loss = 3.709562e-05
epoch 154: mean loss = 3.6946694e-05  learning rate = 0.00011018306
============================
Start of epoch 155
step 0: mean loss = 4.1306925e-05
step 100: mean loss = 3.657807e-05
step 200: mean loss = 3.651746e-05
step 300: mean loss = 3.7061654e-05
epoch 155: mean loss = 3.7092952e-05  learning rate = 0.00011018306
============================
Start of epoch 156
step 0: mean loss = 3.549355e-05
step 100: mean loss = 3.5994683e-05
step 200: mean loss = 3.587016e-05
step 300: mean loss = 3.6149497e-05
epoch 156: mean loss = 3.6103622e-05  learning rate = 0.00011018306
============================
Start of epoch 157
step 0: mean loss = 3.1824904e-05
step 100: mean loss = 3.4261524e-05
step 200: mean loss = 3.5718105e-05
step 300: mean loss = 3.5920355e-05
epoch 157: mean loss = 3.5929505e-05  learning rate = 0.00011018306
============================
Start of epoch 158
step 0: mean loss = 3.8118218e-05
step 100: mean loss = 3.683697e-05
step 200: mean loss = 3.616e-05
step 300: mean loss = 3.6901234e-05
epoch 158: mean loss = 3.6869085e-05  learning rate = 0.00011018306
============================
Start of epoch 159
step 0: mean loss = 2.9797891e-05
step 100: mean loss = 3.5425608e-05
step 200: mean loss = 3.5566223e-05
step 300: mean loss = 3.576272e-05
epoch 159: mean loss = 3.5800553e-05  learning rate = 0.000104673905
============================
Start of epoch 160
step 0: mean loss = 3.0640367e-05
step 100: mean loss = 3.453741e-05
step 200: mean loss = 3.5007317e-05
step 300: mean loss = 3.5396726e-05
epoch 160: mean loss = 3.536864e-05  learning rate = 0.000104673905
============================
Start of epoch 161
step 0: mean loss = 2.815459e-05
step 100: mean loss = 3.6262816e-05
step 200: mean loss = 3.549259e-05
step 300: mean loss = 3.4830904e-05
epoch 161: mean loss = 3.471139e-05  learning rate = 0.000104673905
============================
Start of epoch 162
step 0: mean loss = 4.325243e-05
step 100: mean loss = 3.637112e-05
step 200: mean loss = 3.5731857e-05
step 300: mean loss = 3.549233e-05
epoch 162: mean loss = 3.539991e-05  learning rate = 0.000104673905
============================
Start of epoch 163
step 0: mean loss = 2.7484406e-05
step 100: mean loss = 3.3681266e-05
step 200: mean loss = 3.507352e-05
step 300: mean loss = 3.541751e-05
epoch 163: mean loss = 3.531428e-05  learning rate = 0.000104673905
============================
Start of epoch 164
step 0: mean loss = 2.5368807e-05
step 100: mean loss = 3.5168843e-05
step 200: mean loss = 3.6774753e-05
step 300: mean loss = 3.624543e-05
epoch 164: mean loss = 3.611654e-05  learning rate = 0.000104673905
============================
Start of epoch 165
step 0: mean loss = 3.625954e-05
step 100: mean loss = 3.418068e-05
step 200: mean loss = 3.453056e-05
step 300: mean loss = 3.4179735e-05
epoch 165: mean loss = 3.428506e-05  learning rate = 0.000104673905
============================
Start of epoch 166
step 0: mean loss = 3.2122054e-05
step 100: mean loss = 3.5195535e-05
step 200: mean loss = 3.415342e-05
step 300: mean loss = 3.468844e-05
epoch 166: mean loss = 3.4646513e-05  learning rate = 0.000104673905
============================
Start of epoch 167
step 0: mean loss = 3.791101e-05
step 100: mean loss = 3.437001e-05
step 200: mean loss = 3.4299366e-05
step 300: mean loss = 3.4926034e-05
epoch 167: mean loss = 3.5205096e-05  learning rate = 0.000104673905
============================
Start of epoch 168
step 0: mean loss = 3.4567165e-05
step 100: mean loss = 3.5900764e-05
step 200: mean loss = 3.5911253e-05
step 300: mean loss = 3.5450492e-05
epoch 168: mean loss = 3.5367408e-05  learning rate = 0.000104673905
============================
Start of epoch 169
step 0: mean loss = 4.8399233e-05
step 100: mean loss = 3.605507e-05
step 200: mean loss = 3.5083885e-05
step 300: mean loss = 3.4899538e-05
epoch 169: mean loss = 3.4859626e-05  learning rate = 0.000104673905
============================
Start of epoch 170
step 0: mean loss = 3.0689203e-05
step 100: mean loss = 3.405336e-05
step 200: mean loss = 3.407374e-05
step 300: mean loss = 3.435783e-05
epoch 170: mean loss = 3.4349006e-05  learning rate = 0.000104673905
============================
Start of epoch 171
step 0: mean loss = 3.3783625e-05
step 100: mean loss = 3.4534223e-05
step 200: mean loss = 3.4525085e-05
step 300: mean loss = 3.459705e-05
epoch 171: mean loss = 3.4568e-05  learning rate = 0.000104673905
============================
Start of epoch 172
step 0: mean loss = 3.0423564e-05
step 100: mean loss = 3.3690554e-05
step 200: mean loss = 3.4376033e-05
step 300: mean loss = 3.4490917e-05
epoch 172: mean loss = 3.438128e-05  learning rate = 0.000104673905
============================
Start of epoch 173
step 0: mean loss = 2.7298394e-05
step 100: mean loss = 3.494745e-05
step 200: mean loss = 3.44002e-05
step 300: mean loss = 3.4510253e-05
epoch 173: mean loss = 3.4522705e-05  learning rate = 0.000104673905
============================
Start of epoch 174
step 0: mean loss = 3.3536795e-05
step 100: mean loss = 3.4837423e-05
step 200: mean loss = 3.4218847e-05
step 300: mean loss = 3.4295972e-05
epoch 174: mean loss = 3.4212422e-05  learning rate = 0.000104673905
============================
Start of epoch 175
step 0: mean loss = 2.8947092e-05
step 100: mean loss = 3.302282e-05
step 200: mean loss = 3.386386e-05
step 300: mean loss = 3.4354944e-05
epoch 175: mean loss = 3.428314e-05  learning rate = 0.000104673905
============================
Start of epoch 176
step 0: mean loss = 3.4813213e-05
step 100: mean loss = 3.4231027e-05
step 200: mean loss = 3.4716933e-05
step 300: mean loss = 3.483073e-05
epoch 176: mean loss = 3.477747e-05  learning rate = 0.000104673905
============================
Start of epoch 177
step 0: mean loss = 4.0983807e-05
step 100: mean loss = 3.461522e-05
step 200: mean loss = 3.4909794e-05
step 300: mean loss = 3.488516e-05
epoch 177: mean loss = 3.4792596e-05  learning rate = 0.000104673905
============================
Start of epoch 178
step 0: mean loss = 3.0302399e-05
step 100: mean loss = 3.397705e-05
step 200: mean loss = 3.5261568e-05
step 300: mean loss = 3.5078698e-05
epoch 178: mean loss = 3.498349e-05  learning rate = 0.000104673905
============================
Start of epoch 179
step 0: mean loss = 3.4238255e-05
step 100: mean loss = 3.2910906e-05
step 200: mean loss = 3.3193493e-05
step 300: mean loss = 3.427142e-05
epoch 179: mean loss = 3.4333167e-05  learning rate = 0.000104673905
============================
Start of epoch 180
step 0: mean loss = 4.0582083e-05
step 100: mean loss = 3.319892e-05
step 200: mean loss = 3.4475866e-05
step 300: mean loss = 3.4339853e-05
epoch 180: mean loss = 3.4390843e-05  learning rate = 0.000104673905
============================
Start of epoch 181
step 0: mean loss = 2.8967548e-05
step 100: mean loss = 3.3961776e-05
step 200: mean loss = 3.4963934e-05
step 300: mean loss = 3.4992183e-05
epoch 181: mean loss = 3.4937948e-05  learning rate = 0.000104673905
============================
Start of epoch 182
step 0: mean loss = 3.1619784e-05
step 100: mean loss = 3.4187942e-05
step 200: mean loss = 3.378156e-05
step 300: mean loss = 3.3685814e-05
epoch 182: mean loss = 3.3668308e-05  learning rate = 0.000104673905
============================
Start of epoch 183
step 0: mean loss = 4.0113184e-05
step 100: mean loss = 3.3388354e-05
step 200: mean loss = 3.3837056e-05
step 300: mean loss = 3.384529e-05
epoch 183: mean loss = 3.3889024e-05  learning rate = 0.000104673905
============================
Start of epoch 184
step 0: mean loss = 3.062435e-05
step 100: mean loss = 3.443414e-05
step 200: mean loss = 3.443842e-05
step 300: mean loss = 3.4177367e-05
epoch 184: mean loss = 3.4246794e-05  learning rate = 0.000104673905
============================
Start of epoch 185
step 0: mean loss = 7.486833e-05
step 100: mean loss = 3.342637e-05
step 200: mean loss = 3.389232e-05
step 300: mean loss = 3.4169927e-05
epoch 185: mean loss = 3.4212495e-05  learning rate = 0.000104673905
============================
Start of epoch 186
step 0: mean loss = 3.3014658e-05
step 100: mean loss = 3.4689725e-05
step 200: mean loss = 3.4081535e-05
step 300: mean loss = 3.331702e-05
epoch 186: mean loss = 3.3287455e-05  learning rate = 0.000104673905
============================
Start of epoch 187
step 0: mean loss = 2.9982126e-05
step 100: mean loss = 3.4800003e-05
step 200: mean loss = 3.3917953e-05
step 300: mean loss = 3.3698794e-05
epoch 187: mean loss = 3.3765544e-05  learning rate = 0.000104673905
============================
Start of epoch 188
step 0: mean loss = 2.7835973e-05
step 100: mean loss = 3.5658068e-05
step 200: mean loss = 3.5830722e-05
step 300: mean loss = 3.4918958e-05
epoch 188: mean loss = 3.4813747e-05  learning rate = 0.000104673905
============================
Start of epoch 189
step 0: mean loss = 2.6253883e-05
step 100: mean loss = 3.493773e-05
step 200: mean loss = 3.4491106e-05
step 300: mean loss = 3.418968e-05
epoch 189: mean loss = 3.4075725e-05  learning rate = 0.000104673905
============================
Start of epoch 190
step 0: mean loss = 2.971039e-05
step 100: mean loss = 3.3472104e-05
step 200: mean loss = 3.450634e-05
step 300: mean loss = 3.4689958e-05
epoch 190: mean loss = 3.4582175e-05  learning rate = 0.000104673905
============================
Start of epoch 191
step 0: mean loss = 2.6347054e-05
step 100: mean loss = 3.374057e-05
step 200: mean loss = 3.4587807e-05
step 300: mean loss = 3.3590168e-05
epoch 191: mean loss = 3.3453456e-05  learning rate = 0.000104673905
============================
Start of epoch 192
step 0: mean loss = 2.8904302e-05
step 100: mean loss = 3.282869e-05
step 200: mean loss = 3.247756e-05
step 300: mean loss = 3.3683602e-05
epoch 192: mean loss = 3.376127e-05  learning rate = 0.000104673905
============================
Start of epoch 193
step 0: mean loss = 2.9609675e-05
step 100: mean loss = 3.353191e-05
step 200: mean loss = 3.336524e-05
step 300: mean loss = 3.363861e-05
epoch 193: mean loss = 3.3902634e-05  learning rate = 0.000104673905
============================
Start of epoch 194
step 0: mean loss = 3.7833983e-05
step 100: mean loss = 3.5147626e-05
step 200: mean loss = 3.5462566e-05
step 300: mean loss = 3.453552e-05
epoch 194: mean loss = 3.441896e-05  learning rate = 0.000104673905
============================
Start of epoch 195
step 0: mean loss = 3.084383e-05
step 100: mean loss = 3.587809e-05
step 200: mean loss = 3.4261586e-05
step 300: mean loss = 3.3960165e-05
epoch 195: mean loss = 3.3992994e-05  learning rate = 0.000104673905
============================
Start of epoch 196
step 0: mean loss = 2.5262114e-05
step 100: mean loss = 3.428509e-05
step 200: mean loss = 3.328757e-05
step 300: mean loss = 3.41775e-05
epoch 196: mean loss = 3.399906e-05  learning rate = 0.000104673905
============================
Start of epoch 197
step 0: mean loss = 2.7911337e-05
step 100: mean loss = 3.3663968e-05
step 200: mean loss = 3.2843065e-05
step 300: mean loss = 3.3048836e-05
epoch 197: mean loss = 3.301829e-05  learning rate = 0.000104673905
============================
Start of epoch 198
step 0: mean loss = 3.2928656e-05
step 100: mean loss = 3.4062043e-05
step 200: mean loss = 3.3963726e-05
step 300: mean loss = 3.3781384e-05
epoch 198: mean loss = 3.364273e-05  learning rate = 0.000104673905
============================
Start of epoch 199
step 0: mean loss = 3.4334815e-05
step 100: mean loss = 3.388172e-05
step 200: mean loss = 3.369888e-05
step 300: mean loss = 3.3434462e-05
epoch 199: mean loss = 3.3304026e-05  learning rate = 9.944021e-05
============================
Start of epoch 200
step 0: mean loss = 2.6197553e-05
step 100: mean loss = 3.1188043e-05
step 200: mean loss = 3.2844222e-05
step 300: mean loss = 3.218234e-05
epoch 200: mean loss = 3.210425e-05  learning rate = 9.944021e-05
============================
Start of epoch 201
step 0: mean loss = 3.5197685e-05
step 100: mean loss = 3.0863277e-05
step 200: mean loss = 3.1251966e-05
step 300: mean loss = 3.2133314e-05
epoch 201: mean loss = 3.2143216e-05  learning rate = 9.944021e-05
============================
Start of epoch 202
step 0: mean loss = 3.091732e-05
step 100: mean loss = 3.1714946e-05
step 200: mean loss = 3.20707e-05
step 300: mean loss = 3.2047505e-05
epoch 202: mean loss = 3.230644e-05  learning rate = 9.944021e-05
============================
Start of epoch 203
step 0: mean loss = 2.471462e-05
step 100: mean loss = 3.3251996e-05
step 200: mean loss = 3.2026997e-05
step 300: mean loss = 3.278093e-05
epoch 203: mean loss = 3.2698063e-05  learning rate = 9.944021e-05
============================
Start of epoch 204
step 0: mean loss = 3.618279e-05
step 100: mean loss = 3.3178734e-05
step 200: mean loss = 3.2682176e-05
step 300: mean loss = 3.226472e-05
epoch 204: mean loss = 3.2193926e-05  learning rate = 9.944021e-05
============================
Start of epoch 205
step 0: mean loss = 3.021451e-05
step 100: mean loss = 3.1690684e-05
step 200: mean loss = 3.2691663e-05
step 300: mean loss = 3.257986e-05
epoch 205: mean loss = 3.2532218e-05  learning rate = 9.944021e-05
============================
Start of epoch 206
step 0: mean loss = 2.9992898e-05
step 100: mean loss = 3.2235075e-05
step 200: mean loss = 3.1620555e-05
step 300: mean loss = 3.267264e-05
epoch 206: mean loss = 3.2617565e-05  learning rate = 9.944021e-05
============================
Start of epoch 207
step 0: mean loss = 2.9403709e-05
step 100: mean loss = 3.307796e-05
step 200: mean loss = 3.2762546e-05
step 300: mean loss = 3.2529544e-05
epoch 207: mean loss = 3.2617972e-05  learning rate = 9.944021e-05
============================
Start of epoch 208
step 0: mean loss = 2.723913e-05
step 100: mean loss = 3.060197e-05
step 200: mean loss = 3.2017244e-05
step 300: mean loss = 3.2201257e-05
epoch 208: mean loss = 3.217006e-05  learning rate = 9.944021e-05
============================
Start of epoch 209
step 0: mean loss = 3.338445e-05
step 100: mean loss = 3.2133714e-05
step 200: mean loss = 3.2085423e-05
step 300: mean loss = 3.323291e-05
epoch 209: mean loss = 3.3084598e-05  learning rate = 9.944021e-05
============================
Start of epoch 210
step 0: mean loss = 2.8965636e-05
step 100: mean loss = 3.1858708e-05
step 200: mean loss = 3.2061336e-05
step 300: mean loss = 3.3040193e-05
epoch 210: mean loss = 3.2998934e-05  learning rate = 9.944021e-05
============================
Start of epoch 211
step 0: mean loss = 3.33893e-05
step 100: mean loss = 3.322692e-05
step 200: mean loss = 3.208961e-05
step 300: mean loss = 3.321933e-05
epoch 211: mean loss = 3.3279623e-05  learning rate = 9.944021e-05
============================
Start of epoch 212
step 0: mean loss = 3.122708e-05
step 100: mean loss = 3.238311e-05
step 200: mean loss = 3.2027e-05
step 300: mean loss = 3.1877174e-05
epoch 212: mean loss = 3.1689633e-05  learning rate = 9.944021e-05
============================
Start of epoch 213
step 0: mean loss = 6.918726e-05
step 100: mean loss = 3.2535034e-05
step 200: mean loss = 3.2376087e-05
step 300: mean loss = 3.317855e-05
epoch 213: mean loss = 3.304884e-05  learning rate = 9.944021e-05
============================
Start of epoch 214
step 0: mean loss = 3.340119e-05
step 100: mean loss = 3.3617274e-05
step 200: mean loss = 3.3261334e-05
step 300: mean loss = 3.2693006e-05
epoch 214: mean loss = 3.269383e-05  learning rate = 9.944021e-05
============================
Start of epoch 215
step 0: mean loss = 3.2674805e-05
step 100: mean loss = 3.3633005e-05
step 200: mean loss = 3.3729666e-05
step 300: mean loss = 3.3144952e-05
epoch 215: mean loss = 3.3094642e-05  learning rate = 9.944021e-05
============================
Start of epoch 216
step 0: mean loss = 3.0611725e-05
step 100: mean loss = 3.234287e-05
step 200: mean loss = 3.228353e-05
step 300: mean loss = 3.21671e-05
epoch 216: mean loss = 3.2102544e-05  learning rate = 9.944021e-05
============================
Start of epoch 217
step 0: mean loss = 3.9576047e-05
step 100: mean loss = 3.3868673e-05
step 200: mean loss = 3.3856366e-05
step 300: mean loss = 3.284101e-05
epoch 217: mean loss = 3.2795164e-05  learning rate = 9.944021e-05
============================
Start of epoch 218
step 0: mean loss = 3.206102e-05
step 100: mean loss = 3.2687454e-05
step 200: mean loss = 3.3358905e-05
step 300: mean loss = 3.260156e-05
epoch 218: mean loss = 3.245706e-05  learning rate = 9.944021e-05
============================
Start of epoch 219
step 0: mean loss = 3.0905903e-05
step 100: mean loss = 3.1490843e-05
step 200: mean loss = 3.2393207e-05
step 300: mean loss = 3.253578e-05
epoch 219: mean loss = 3.2433647e-05  learning rate = 9.944021e-05
============================
Start of epoch 220
step 0: mean loss = 2.8841718e-05
step 100: mean loss = 3.106429e-05
step 200: mean loss = 3.0941686e-05
step 300: mean loss = 3.2270356e-05
epoch 220: mean loss = 3.2308966e-05  learning rate = 9.944021e-05
============================
Start of epoch 221
step 0: mean loss = 3.2510594e-05
step 100: mean loss = 3.1161642e-05
step 200: mean loss = 3.0487723e-05
step 300: mean loss = 3.2124535e-05
epoch 221: mean loss = 3.2281678e-05  learning rate = 9.944021e-05
============================
Start of epoch 222
step 0: mean loss = 3.581317e-05
step 100: mean loss = 3.3095435e-05
step 200: mean loss = 3.218201e-05
step 300: mean loss = 3.1993393e-05
epoch 222: mean loss = 3.2190273e-05  learning rate = 9.944021e-05
============================
Start of epoch 223
step 0: mean loss = 3.2264263e-05
step 100: mean loss = 3.2719498e-05
step 200: mean loss = 3.288525e-05
step 300: mean loss = 3.2151696e-05
epoch 223: mean loss = 3.2261112e-05  learning rate = 9.944021e-05
============================
Start of epoch 224
step 0: mean loss = 3.725731e-05
step 100: mean loss = 3.09242e-05
step 200: mean loss = 3.1921754e-05
step 300: mean loss = 3.2495635e-05
epoch 224: mean loss = 3.241565e-05  learning rate = 9.944021e-05
============================
Start of epoch 225
step 0: mean loss = 3.0173145e-05
step 100: mean loss = 3.0342591e-05
step 200: mean loss = 3.232586e-05
step 300: mean loss = 3.196921e-05
epoch 225: mean loss = 3.212942e-05  learning rate = 9.944021e-05
============================
Start of epoch 226
step 0: mean loss = 3.2799504e-05
step 100: mean loss = 3.17119e-05
step 200: mean loss = 3.066602e-05
step 300: mean loss = 3.2065112e-05
epoch 226: mean loss = 3.214347e-05  learning rate = 9.944021e-05
============================
Start of epoch 227
step 0: mean loss = 2.9065022e-05
step 100: mean loss = 3.365023e-05
step 200: mean loss = 3.3001357e-05
step 300: mean loss = 3.265038e-05
epoch 227: mean loss = 3.2654454e-05  learning rate = 9.944021e-05
============================
Start of epoch 228
step 0: mean loss = 3.6859215e-05
step 100: mean loss = 3.4529876e-05
step 200: mean loss = 3.3253124e-05
step 300: mean loss = 3.1724783e-05
epoch 228: mean loss = 3.1638752e-05  learning rate = 9.944021e-05
============================
Start of epoch 229
step 0: mean loss = 2.5284868e-05
step 100: mean loss = 3.2637952e-05
step 200: mean loss = 3.1098814e-05
step 300: mean loss = 3.217478e-05
epoch 229: mean loss = 3.2162145e-05  learning rate = 9.944021e-05
============================
Start of epoch 230
step 0: mean loss = 2.8558583e-05
step 100: mean loss = 3.0549145e-05
step 200: mean loss = 3.2437536e-05
step 300: mean loss = 3.2182816e-05
epoch 230: mean loss = 3.2263637e-05  learning rate = 9.944021e-05
============================
Start of epoch 231
step 0: mean loss = 2.7742628e-05
step 100: mean loss = 3.249104e-05
step 200: mean loss = 3.1639094e-05
step 300: mean loss = 3.149944e-05
epoch 231: mean loss = 3.1570216e-05  learning rate = 9.944021e-05
============================
Start of epoch 232
step 0: mean loss = 3.1384086e-05
step 100: mean loss = 3.223609e-05
step 200: mean loss = 3.254418e-05
step 300: mean loss = 3.195092e-05
epoch 232: mean loss = 3.190797e-05  learning rate = 9.944021e-05
============================
Start of epoch 233
step 0: mean loss = 3.392693e-05
step 100: mean loss = 3.0249901e-05
step 200: mean loss = 3.2626427e-05
step 300: mean loss = 3.147479e-05
epoch 233: mean loss = 3.147763e-05  learning rate = 9.944021e-05
============================
Start of epoch 234
step 0: mean loss = 2.9021201e-05
step 100: mean loss = 3.5085664e-05
step 200: mean loss = 3.3512315e-05
step 300: mean loss = 3.3054086e-05
epoch 234: mean loss = 3.292505e-05  learning rate = 9.944021e-05
============================
Start of epoch 235
step 0: mean loss = 3.8661885e-05
step 100: mean loss = 3.175181e-05
step 200: mean loss = 3.1657066e-05
step 300: mean loss = 3.1871095e-05
epoch 235: mean loss = 3.1823187e-05  learning rate = 9.944021e-05
============================
Start of epoch 236
step 0: mean loss = 2.7965092e-05
step 100: mean loss = 3.1488733e-05
step 200: mean loss = 3.122177e-05
step 300: mean loss = 3.208231e-05
epoch 236: mean loss = 3.2020875e-05  learning rate = 9.944021e-05
============================
Start of epoch 237
step 0: mean loss = 3.8081926e-05
step 100: mean loss = 3.2024775e-05
step 200: mean loss = 3.195452e-05
step 300: mean loss = 3.1422034e-05
epoch 237: mean loss = 3.142883e-05  learning rate = 9.944021e-05
============================
Start of epoch 238
step 0: mean loss = 3.2230717e-05
step 100: mean loss = 3.28053e-05
step 200: mean loss = 3.101037e-05
step 300: mean loss = 3.1446765e-05
epoch 238: mean loss = 3.137061e-05  learning rate = 9.944021e-05
============================
Start of epoch 239
step 0: mean loss = 3.7343438e-05
step 100: mean loss = 3.0523377e-05
step 200: mean loss = 3.1312557e-05
step 300: mean loss = 3.106402e-05
epoch 239: mean loss = 3.1076514e-05  learning rate = 9.446819e-05
============================
Start of epoch 240
step 0: mean loss = 2.7625196e-05
step 100: mean loss = 3.0934963e-05
step 200: mean loss = 3.0934847e-05
step 300: mean loss = 3.0903706e-05
epoch 240: mean loss = 3.1006075e-05  learning rate = 9.446819e-05
============================
Start of epoch 241
step 0: mean loss = 2.6419431e-05
step 100: mean loss = 2.9632036e-05
step 200: mean loss = 3.091915e-05
step 300: mean loss = 3.0197578e-05
epoch 241: mean loss = 3.030792e-05  learning rate = 9.446819e-05
============================
Start of epoch 242
step 0: mean loss = 2.968084e-05
step 100: mean loss = 2.9519324e-05
step 200: mean loss = 2.9669134e-05
step 300: mean loss = 3.0555075e-05
epoch 242: mean loss = 3.0394998e-05  learning rate = 9.446819e-05
============================
Start of epoch 243
step 0: mean loss = 2.537045e-05
step 100: mean loss = 3.0918938e-05
step 200: mean loss = 3.126123e-05
step 300: mean loss = 3.131577e-05
epoch 243: mean loss = 3.139515e-05  learning rate = 9.446819e-05
============================
Start of epoch 244
step 0: mean loss = 2.9786075e-05
step 100: mean loss = 3.076952e-05
step 200: mean loss = 3.1065243e-05
step 300: mean loss = 3.0979794e-05
epoch 244: mean loss = 3.0929466e-05  learning rate = 9.446819e-05
============================
Start of epoch 245
step 0: mean loss = 3.412278e-05
step 100: mean loss = 2.976122e-05
step 200: mean loss = 2.9564206e-05
step 300: mean loss = 3.0792326e-05
epoch 245: mean loss = 3.0724103e-05  learning rate = 9.446819e-05
============================
Start of epoch 246
step 0: mean loss = 2.4849594e-05
step 100: mean loss = 3.1872787e-05
step 200: mean loss = 3.0933996e-05
step 300: mean loss = 3.040992e-05
epoch 246: mean loss = 3.0393952e-05  learning rate = 9.446819e-05
============================
Start of epoch 247
step 0: mean loss = 3.0429253e-05
step 100: mean loss = 3.142074e-05
step 200: mean loss = 3.0399266e-05
step 300: mean loss = 3.0167004e-05
epoch 247: mean loss = 3.0159543e-05  learning rate = 9.446819e-05
============================
Start of epoch 248
step 0: mean loss = 3.427318e-05
step 100: mean loss = 2.974397e-05
step 200: mean loss = 3.0255029e-05
step 300: mean loss = 3.0280074e-05
epoch 248: mean loss = 3.0313922e-05  learning rate = 9.446819e-05
============================
Start of epoch 249
step 0: mean loss = 3.1045107e-05
step 100: mean loss = 3.1919e-05
step 200: mean loss = 3.1577867e-05
step 300: mean loss = 3.0824438e-05
epoch 249: mean loss = 3.0782296e-05  learning rate = 9.446819e-05
============================
Start of epoch 250
step 0: mean loss = 2.4181256e-05
step 100: mean loss = 3.160667e-05
step 200: mean loss = 3.0340727e-05
step 300: mean loss = 2.9893376e-05
epoch 250: mean loss = 2.9824201e-05  learning rate = 9.446819e-05
============================
Start of epoch 251
step 0: mean loss = 2.3344499e-05
step 100: mean loss = 2.9250281e-05
step 200: mean loss = 2.9666564e-05
step 300: mean loss = 3.0237068e-05
epoch 251: mean loss = 3.0149542e-05  learning rate = 9.446819e-05
============================
Start of epoch 252
step 0: mean loss = 2.8749117e-05
step 100: mean loss = 2.9980552e-05
step 200: mean loss = 2.934284e-05
step 300: mean loss = 2.95363e-05
epoch 252: mean loss = 2.9746363e-05  learning rate = 9.446819e-05
============================
Start of epoch 253
step 0: mean loss = 5.3073563e-05
step 100: mean loss = 3.0236324e-05
step 200: mean loss = 2.985295e-05
step 300: mean loss = 3.0802752e-05
epoch 253: mean loss = 3.0787818e-05  learning rate = 9.446819e-05
============================
Start of epoch 254
step 0: mean loss = 3.370667e-05
step 100: mean loss = 3.023956e-05
step 200: mean loss = 3.0765823e-05
step 300: mean loss = 3.0358204e-05
epoch 254: mean loss = 3.0316498e-05  learning rate = 9.446819e-05
============================
Start of epoch 255
step 0: mean loss = 2.9517316e-05
step 100: mean loss = 2.9312489e-05
step 200: mean loss = 3.0047944e-05
step 300: mean loss = 3.050103e-05
epoch 255: mean loss = 3.065661e-05  learning rate = 9.446819e-05
============================
Start of epoch 256
step 0: mean loss = 3.069732e-05
step 100: mean loss = 3.182913e-05
step 200: mean loss = 3.165593e-05
step 300: mean loss = 3.0543728e-05
epoch 256: mean loss = 3.0392008e-05  learning rate = 9.446819e-05
============================
Start of epoch 257
step 0: mean loss = 2.5629128e-05
step 100: mean loss = 3.0526455e-05
step 200: mean loss = 2.998281e-05
step 300: mean loss = 3.0014478e-05
epoch 257: mean loss = 2.992844e-05  learning rate = 9.446819e-05
============================
Start of epoch 258
step 0: mean loss = 2.3389946e-05
step 100: mean loss = 3.0973748e-05
step 200: mean loss = 3.061611e-05
step 300: mean loss = 2.9760131e-05
epoch 258: mean loss = 2.9640538e-05  learning rate = 9.446819e-05
============================
Start of epoch 259
step 0: mean loss = 3.2081356e-05
step 100: mean loss = 3.1579784e-05
step 200: mean loss = 3.123243e-05
step 300: mean loss = 3.0678355e-05
epoch 259: mean loss = 3.045701e-05  learning rate = 9.446819e-05
============================
Start of epoch 260
step 0: mean loss = 2.5337125e-05
step 100: mean loss = 3.144462e-05
step 200: mean loss = 3.052326e-05
step 300: mean loss = 3.0029374e-05
epoch 260: mean loss = 2.9960293e-05  learning rate = 9.446819e-05
============================
Start of epoch 261
step 0: mean loss = 2.7540607e-05
step 100: mean loss = 3.0721603e-05
step 200: mean loss = 3.0187417e-05
step 300: mean loss = 3.001375e-05
epoch 261: mean loss = 3.0103463e-05  learning rate = 9.446819e-05
============================
Start of epoch 262
step 0: mean loss = 2.5296438e-05
step 100: mean loss = 3.2373424e-05
step 200: mean loss = 3.0161002e-05
step 300: mean loss = 2.9944242e-05
epoch 262: mean loss = 3.00763e-05  learning rate = 9.446819e-05
============================
Start of epoch 263
step 0: mean loss = 3.5085683e-05
step 100: mean loss = 3.0596715e-05
step 200: mean loss = 3.1050964e-05
step 300: mean loss = 3.115407e-05
epoch 263: mean loss = 3.114201e-05  learning rate = 9.446819e-05
============================
Start of epoch 264
step 0: mean loss = 2.9824545e-05
step 100: mean loss = 3.125185e-05
step 200: mean loss = 2.9697854e-05
step 300: mean loss = 2.9709186e-05
epoch 264: mean loss = 2.9658375e-05  learning rate = 9.446819e-05
============================
Start of epoch 265
step 0: mean loss = 2.544454e-05
step 100: mean loss = 2.8852053e-05
step 200: mean loss = 2.8346512e-05
step 300: mean loss = 3.0442707e-05
epoch 265: mean loss = 3.0441533e-05  learning rate = 9.446819e-05
============================
Start of epoch 266
step 0: mean loss = 2.8430335e-05
step 100: mean loss = 2.979602e-05
step 200: mean loss = 2.9121285e-05
step 300: mean loss = 2.9733139e-05
epoch 266: mean loss = 2.9616805e-05  learning rate = 9.446819e-05
============================
Start of epoch 267
step 0: mean loss = 2.8815248e-05
step 100: mean loss = 3.158389e-05
step 200: mean loss = 2.9991314e-05
step 300: mean loss = 3.0857573e-05
epoch 267: mean loss = 3.0741747e-05  learning rate = 9.446819e-05
============================
Start of epoch 268
step 0: mean loss = 2.6361979e-05
step 100: mean loss = 2.7330318e-05
step 200: mean loss = 2.7405513e-05
step 300: mean loss = 2.89561e-05
epoch 268: mean loss = 2.930451e-05  learning rate = 9.446819e-05
============================
Start of epoch 269
step 0: mean loss = 3.269483e-05
step 100: mean loss = 3.084585e-05
step 200: mean loss = 2.9900179e-05
step 300: mean loss = 2.9514831e-05
epoch 269: mean loss = 2.9453568e-05  learning rate = 9.446819e-05
============================
Start of epoch 270
step 0: mean loss = 3.0605173e-05
step 100: mean loss = 2.9137243e-05
step 200: mean loss = 3.0402964e-05
step 300: mean loss = 3.0273352e-05
epoch 270: mean loss = 3.0100018e-05  learning rate = 9.446819e-05
============================
Start of epoch 271
step 0: mean loss = 2.7358928e-05
step 100: mean loss = 2.699027e-05
step 200: mean loss = 2.854714e-05
step 300: mean loss = 2.977769e-05
epoch 271: mean loss = 2.9797671e-05  learning rate = 9.446819e-05
============================
Start of epoch 272
step 0: mean loss = 3.430146e-05
step 100: mean loss = 3.211363e-05
step 200: mean loss = 3.0656192e-05
step 300: mean loss = 2.982511e-05
epoch 272: mean loss = 2.9773226e-05  learning rate = 9.446819e-05
============================
Start of epoch 273
step 0: mean loss = 2.966333e-05
step 100: mean loss = 2.916831e-05
step 200: mean loss = 2.991766e-05
step 300: mean loss = 3.0104888e-05
epoch 273: mean loss = 3.0221627e-05  learning rate = 9.446819e-05
============================
Start of epoch 274
step 0: mean loss = 3.0926756e-05
step 100: mean loss = 2.9269113e-05
step 200: mean loss = 2.9463756e-05
step 300: mean loss = 3.0155219e-05
epoch 274: mean loss = 3.0322357e-05  learning rate = 9.446819e-05
============================
Start of epoch 275
step 0: mean loss = 2.8154507e-05
step 100: mean loss = 3.1174146e-05
step 200: mean loss = 2.9689456e-05
step 300: mean loss = 2.9931956e-05
epoch 275: mean loss = 2.9930694e-05  learning rate = 9.446819e-05
============================
Start of epoch 276
step 0: mean loss = 2.5514299e-05
step 100: mean loss = 2.9443952e-05
step 200: mean loss = 3.0059895e-05
step 300: mean loss = 2.9500632e-05
epoch 276: mean loss = 2.9555376e-05  learning rate = 9.446819e-05
============================
Start of epoch 277
step 0: mean loss = 2.9924046e-05
step 100: mean loss = 2.9393716e-05
step 200: mean loss = 2.9124438e-05
step 300: mean loss = 2.9862054e-05
epoch 277: mean loss = 3.0056588e-05  learning rate = 9.446819e-05
============================
Start of epoch 278
step 0: mean loss = 3.040761e-05
step 100: mean loss = 2.8409004e-05
step 200: mean loss = 2.8787765e-05
step 300: mean loss = 2.9827688e-05
epoch 278: mean loss = 3.0109552e-05  learning rate = 9.446819e-05
============================
Start of epoch 279
step 0: mean loss = 3.357925e-05
step 100: mean loss = 3.1696152e-05
step 200: mean loss = 3.0370345e-05
step 300: mean loss = 2.9674156e-05
epoch 279: mean loss = 2.9499053e-05  learning rate = 8.974478e-05
============================
Start of epoch 280
step 0: mean loss = 2.3214652e-05
step 100: mean loss = 2.654474e-05
step 200: mean loss = 2.7121168e-05
step 300: mean loss = 2.8076038e-05
epoch 280: mean loss = 2.8113835e-05  learning rate = 8.974478e-05
============================
Start of epoch 281
step 0: mean loss = 2.4458925e-05
step 100: mean loss = 2.846102e-05
step 200: mean loss = 2.8960138e-05
step 300: mean loss = 2.8543673e-05
epoch 281: mean loss = 2.8574066e-05  learning rate = 8.974478e-05
============================
Start of epoch 282
step 0: mean loss = 2.7486527e-05
step 100: mean loss = 2.8145128e-05
step 200: mean loss = 2.9084824e-05
step 300: mean loss = 2.9532654e-05
epoch 282: mean loss = 2.9409772e-05  learning rate = 8.974478e-05
============================
Start of epoch 283
step 0: mean loss = 2.974875e-05
step 100: mean loss = 2.927119e-05
step 200: mean loss = 2.868831e-05
step 300: mean loss = 2.930124e-05
epoch 283: mean loss = 2.9231913e-05  learning rate = 8.974478e-05
============================
Start of epoch 284
step 0: mean loss = 2.937013e-05
step 100: mean loss = 2.8811983e-05
step 200: mean loss = 2.8640241e-05
step 300: mean loss = 2.889551e-05
epoch 284: mean loss = 2.8833949e-05  learning rate = 8.974478e-05
============================
Start of epoch 285
step 0: mean loss = 2.6604725e-05
step 100: mean loss = 2.843572e-05
step 200: mean loss = 2.8662484e-05
step 300: mean loss = 2.8935487e-05
epoch 285: mean loss = 2.8810413e-05  learning rate = 8.974478e-05
============================
Start of epoch 286
step 0: mean loss = 2.2858716e-05
step 100: mean loss = 2.6466376e-05
step 200: mean loss = 2.8107606e-05
step 300: mean loss = 2.8009486e-05
epoch 286: mean loss = 2.859568e-05  learning rate = 8.974478e-05
============================
Start of epoch 287
step 0: mean loss = 3.45522e-05
step 100: mean loss = 3.0460307e-05
step 200: mean loss = 2.8972343e-05
step 300: mean loss = 2.9030261e-05
epoch 287: mean loss = 2.8952774e-05  learning rate = 8.974478e-05
============================
Start of epoch 288
step 0: mean loss = 2.862886e-05
step 100: mean loss = 2.848035e-05
step 200: mean loss = 2.8581711e-05
step 300: mean loss = 2.8551769e-05
epoch 288: mean loss = 2.8486449e-05  learning rate = 8.974478e-05
============================
Start of epoch 289
step 0: mean loss = 2.90662e-05
step 100: mean loss = 2.9353234e-05
step 200: mean loss = 2.8155642e-05
step 300: mean loss = 2.8364515e-05
epoch 289: mean loss = 2.8424354e-05  learning rate = 8.974478e-05
============================
Start of epoch 290
step 0: mean loss = 2.4999206e-05
step 100: mean loss = 2.7633852e-05
step 200: mean loss = 2.9045494e-05
step 300: mean loss = 2.88338e-05
epoch 290: mean loss = 2.8734637e-05  learning rate = 8.974478e-05
============================
Start of epoch 291
step 0: mean loss = 2.195972e-05
step 100: mean loss = 2.5938167e-05
step 200: mean loss = 2.776675e-05
step 300: mean loss = 2.8409017e-05
epoch 291: mean loss = 2.8453871e-05  learning rate = 8.974478e-05
============================
Start of epoch 292
step 0: mean loss = 2.8323784e-05
step 100: mean loss = 2.8471775e-05
step 200: mean loss = 2.8411796e-05
step 300: mean loss = 2.8242994e-05
epoch 292: mean loss = 2.819573e-05  learning rate = 8.974478e-05
============================
Start of epoch 293
step 0: mean loss = 2.164803e-05
step 100: mean loss = 2.759457e-05
step 200: mean loss = 2.9606406e-05
step 300: mean loss = 2.9074903e-05
epoch 293: mean loss = 2.9048026e-05  learning rate = 8.974478e-05
============================
Start of epoch 294
step 0: mean loss = 2.5931922e-05
step 100: mean loss = 2.9774423e-05
step 200: mean loss = 2.8964363e-05
step 300: mean loss = 2.8577339e-05
epoch 294: mean loss = 2.8471772e-05  learning rate = 8.974478e-05
============================
Start of epoch 295
step 0: mean loss = 2.3484648e-05
step 100: mean loss = 2.6013018e-05
step 200: mean loss = 2.7160051e-05
step 300: mean loss = 2.8093309e-05
epoch 295: mean loss = 2.8073764e-05  learning rate = 8.974478e-05
============================
Start of epoch 296
step 0: mean loss = 2.3938082e-05
step 100: mean loss = 2.9073835e-05
step 200: mean loss = 2.7846285e-05
step 300: mean loss = 2.7640073e-05
epoch 296: mean loss = 2.7876751e-05  learning rate = 8.974478e-05
============================
Start of epoch 297
step 0: mean loss = 2.4908724e-05
step 100: mean loss = 2.847837e-05
step 200: mean loss = 2.8658116e-05
step 300: mean loss = 2.8383934e-05
epoch 297: mean loss = 2.8257538e-05  learning rate = 8.974478e-05
============================
Start of epoch 298
step 0: mean loss = 2.859789e-05
step 100: mean loss = 2.8350043e-05
step 200: mean loss = 2.7705486e-05
step 300: mean loss = 2.7727852e-05
epoch 298: mean loss = 2.777871e-05  learning rate = 8.974478e-05
============================
Start of epoch 299
step 0: mean loss = 2.8825201e-05
step 100: mean loss = 2.696201e-05
step 200: mean loss = 2.7237867e-05
step 300: mean loss = 2.7325883e-05
epoch 299: mean loss = 2.7740502e-05  learning rate = 8.974478e-05
============================
Start of epoch 300
step 0: mean loss = 3.6387613e-05
step 100: mean loss = 2.948659e-05
step 200: mean loss = 2.8912113e-05
step 300: mean loss = 2.8546538e-05
epoch 300: mean loss = 2.8479315e-05  learning rate = 8.974478e-05
============================
Start of epoch 301
step 0: mean loss = 2.4547491e-05
step 100: mean loss = 2.8620638e-05
step 200: mean loss = 2.827286e-05
step 300: mean loss = 2.8044895e-05
epoch 301: mean loss = 2.7976846e-05  learning rate = 8.974478e-05
============================
Start of epoch 302
step 0: mean loss = 2.660517e-05
step 100: mean loss = 2.710663e-05
step 200: mean loss = 2.6489017e-05
step 300: mean loss = 2.7825836e-05
epoch 302: mean loss = 2.787045e-05  learning rate = 8.974478e-05
============================
Start of epoch 303
step 0: mean loss = 3.6585083e-05
step 100: mean loss = 2.8301616e-05
step 200: mean loss = 2.8323833e-05
step 300: mean loss = 2.8785036e-05
epoch 303: mean loss = 2.8995484e-05  learning rate = 8.974478e-05
============================
Start of epoch 304
step 0: mean loss = 3.6319958e-05
step 100: mean loss = 2.7988488e-05
step 200: mean loss = 2.820888e-05
step 300: mean loss = 2.836268e-05
epoch 304: mean loss = 2.828969e-05  learning rate = 8.974478e-05
============================
Start of epoch 305
step 0: mean loss = 3.832535e-05
step 100: mean loss = 2.7824182e-05
step 200: mean loss = 2.758778e-05
step 300: mean loss = 2.8028437e-05
epoch 305: mean loss = 2.7948892e-05  learning rate = 8.974478e-05
============================
Start of epoch 306
step 0: mean loss = 2.925799e-05
step 100: mean loss = 2.734056e-05
step 200: mean loss = 2.7084387e-05
step 300: mean loss = 2.7508351e-05
epoch 306: mean loss = 2.74486e-05  learning rate = 8.974478e-05
============================
Start of epoch 307
step 0: mean loss = 2.3216138e-05
step 100: mean loss = 2.874464e-05
step 200: mean loss = 2.8023063e-05
step 300: mean loss = 2.8284236e-05
epoch 307: mean loss = 2.823235e-05  learning rate = 8.974478e-05
============================
Start of epoch 308
step 0: mean loss = 2.4305338e-05
step 100: mean loss = 2.8591381e-05
step 200: mean loss = 2.7220536e-05
step 300: mean loss = 2.716577e-05
epoch 308: mean loss = 2.7108475e-05  learning rate = 8.974478e-05
============================
Start of epoch 309
step 0: mean loss = 2.5619851e-05
step 100: mean loss = 2.6679805e-05
step 200: mean loss = 2.696883e-05
step 300: mean loss = 2.6918568e-05
epoch 309: mean loss = 2.738671e-05  learning rate = 8.974478e-05
============================
Start of epoch 310
step 0: mean loss = 3.159888e-05
step 100: mean loss = 2.6781281e-05
step 200: mean loss = 2.7021002e-05
step 300: mean loss = 2.7654782e-05
epoch 310: mean loss = 2.7563712e-05  learning rate = 8.974478e-05
============================
Start of epoch 311
step 0: mean loss = 4.3196116e-05
step 100: mean loss = 3.0029514e-05
step 200: mean loss = 2.7887001e-05
step 300: mean loss = 2.7895809e-05
epoch 311: mean loss = 2.7864615e-05  learning rate = 8.974478e-05
============================
Start of epoch 312
step 0: mean loss = 2.5577043e-05
step 100: mean loss = 2.9880639e-05
step 200: mean loss = 2.8119162e-05
step 300: mean loss = 2.7792801e-05
epoch 312: mean loss = 2.8138802e-05  learning rate = 8.974478e-05
============================
Start of epoch 313
step 0: mean loss = 3.5466175e-05
step 100: mean loss = 3.0577092e-05
step 200: mean loss = 2.8525084e-05
step 300: mean loss = 2.7775832e-05
epoch 313: mean loss = 2.761552e-05  learning rate = 8.974478e-05
============================
Start of epoch 314
step 0: mean loss = 3.2939126e-05
step 100: mean loss = 2.6776966e-05
step 200: mean loss = 2.6679403e-05
step 300: mean loss = 2.7497908e-05
epoch 314: mean loss = 2.7560242e-05  learning rate = 8.974478e-05
============================
Start of epoch 315
step 0: mean loss = 3.0220666e-05
step 100: mean loss = 2.991729e-05
step 200: mean loss = 2.832224e-05
step 300: mean loss = 2.7583135e-05
epoch 315: mean loss = 2.7487986e-05  learning rate = 8.974478e-05
============================
Start of epoch 316
step 0: mean loss = 2.3348406e-05
step 100: mean loss = 2.653818e-05
step 200: mean loss = 2.793988e-05
step 300: mean loss = 2.7832932e-05
epoch 316: mean loss = 2.7685024e-05  learning rate = 8.974478e-05
============================
Start of epoch 317
step 0: mean loss = 2.2284961e-05
step 100: mean loss = 2.6140407e-05
step 200: mean loss = 2.7537786e-05
step 300: mean loss = 2.7844444e-05
epoch 317: mean loss = 2.7726479e-05  learning rate = 8.974478e-05
============================
Start of epoch 318
step 0: mean loss = 2.8104227e-05
step 100: mean loss = 2.7044971e-05
step 200: mean loss = 2.844626e-05
step 300: mean loss = 2.7410479e-05
epoch 318: mean loss = 2.7372489e-05  learning rate = 8.974478e-05
============================
Start of epoch 319
step 0: mean loss = 2.6762405e-05
step 100: mean loss = 2.81896e-05
step 200: mean loss = 2.7884642e-05
step 300: mean loss = 2.7245907e-05
epoch 319: mean loss = 2.7110777e-05  learning rate = 8.525754e-05
============================
Start of epoch 320
step 0: mean loss = 2.0749878e-05
step 100: mean loss = 2.5960378e-05
step 200: mean loss = 2.7015038e-05
step 300: mean loss = 2.6615724e-05
epoch 320: mean loss = 2.6642683e-05  learning rate = 8.525754e-05
============================
Start of epoch 321
step 0: mean loss = 2.1504728e-05
step 100: mean loss = 2.529412e-05
step 200: mean loss = 2.6349264e-05
step 300: mean loss = 2.6234797e-05
epoch 321: mean loss = 2.6250666e-05  learning rate = 8.525754e-05
============================
Start of epoch 322
step 0: mean loss = 2.5618348e-05
step 100: mean loss = 2.8488434e-05
step 200: mean loss = 2.735075e-05
step 300: mean loss = 2.6481624e-05
epoch 322: mean loss = 2.6406544e-05  learning rate = 8.525754e-05
============================
Start of epoch 323
step 0: mean loss = 3.1568994e-05
step 100: mean loss = 2.7988894e-05
step 200: mean loss = 2.7886272e-05
step 300: mean loss = 2.7355107e-05
epoch 323: mean loss = 2.7240478e-05  learning rate = 8.525754e-05
============================
Start of epoch 324
step 0: mean loss = 2.7544873e-05
step 100: mean loss = 2.6042037e-05
step 200: mean loss = 2.6312047e-05
step 300: mean loss = 2.6500815e-05
epoch 324: mean loss = 2.6658492e-05  learning rate = 8.525754e-05
============================
Start of epoch 325
step 0: mean loss = 2.6628863e-05
step 100: mean loss = 2.7874827e-05
step 200: mean loss = 2.8158633e-05
step 300: mean loss = 2.700207e-05
epoch 325: mean loss = 2.6894533e-05  learning rate = 8.525754e-05
============================
Start of epoch 326
step 0: mean loss = 2.5184516e-05
step 100: mean loss = 2.570113e-05
step 200: mean loss = 2.6304551e-05
step 300: mean loss = 2.667966e-05
epoch 326: mean loss = 2.6703476e-05  learning rate = 8.525754e-05
============================
Start of epoch 327
step 0: mean loss = 3.405527e-05
step 100: mean loss = 2.5191042e-05
step 200: mean loss = 2.6027774e-05
step 300: mean loss = 2.625902e-05
epoch 327: mean loss = 2.6694635e-05  learning rate = 8.525754e-05
============================
Start of epoch 328
step 0: mean loss = 3.3962475e-05
step 100: mean loss = 2.6175097e-05
step 200: mean loss = 2.6616191e-05
step 300: mean loss = 2.699793e-05
epoch 328: mean loss = 2.7243666e-05  learning rate = 8.525754e-05
============================
Start of epoch 329
step 0: mean loss = 3.2976495e-05
step 100: mean loss = 2.606059e-05
step 200: mean loss = 2.631086e-05
step 300: mean loss = 2.6238155e-05
epoch 329: mean loss = 2.6114776e-05  learning rate = 8.525754e-05
============================
Start of epoch 330
step 0: mean loss = 3.015688e-05
step 100: mean loss = 2.6118061e-05
step 200: mean loss = 2.6482887e-05
step 300: mean loss = 2.665871e-05
epoch 330: mean loss = 2.6725098e-05  learning rate = 8.525754e-05
============================
Start of epoch 331
step 0: mean loss = 2.7278867e-05
step 100: mean loss = 2.8002705e-05
step 200: mean loss = 2.6743963e-05
step 300: mean loss = 2.6602407e-05
epoch 331: mean loss = 2.6547485e-05  learning rate = 8.525754e-05
============================
Start of epoch 332
step 0: mean loss = 2.591062e-05
step 100: mean loss = 2.515235e-05
step 200: mean loss = 2.6282758e-05
step 300: mean loss = 2.6338805e-05
epoch 332: mean loss = 2.6369547e-05  learning rate = 8.525754e-05
============================
Start of epoch 333
step 0: mean loss = 2.1822441e-05
step 100: mean loss = 2.79855e-05
step 200: mean loss = 2.6737409e-05
step 300: mean loss = 2.626683e-05
epoch 333: mean loss = 2.6280775e-05  learning rate = 8.525754e-05
============================
Start of epoch 334
step 0: mean loss = 2.7517239e-05
step 100: mean loss = 2.8107213e-05
step 200: mean loss = 2.6429176e-05
step 300: mean loss = 2.624369e-05
epoch 334: mean loss = 2.6242516e-05  learning rate = 8.525754e-05
============================
Start of epoch 335
step 0: mean loss = 2.5482714e-05
step 100: mean loss = 2.474304e-05
step 200: mean loss = 2.6175912e-05
step 300: mean loss = 2.6865651e-05
epoch 335: mean loss = 2.675621e-05  learning rate = 8.525754e-05
============================
Start of epoch 336
step 0: mean loss = 3.0992094e-05
step 100: mean loss = 2.4177813e-05
step 200: mean loss = 2.558253e-05
step 300: mean loss = 2.6257052e-05
epoch 336: mean loss = 2.6280482e-05  learning rate = 8.525754e-05
============================
Start of epoch 337
step 0: mean loss = 2.852906e-05
step 100: mean loss = 2.5697334e-05
step 200: mean loss = 2.6839936e-05
step 300: mean loss = 2.652722e-05
epoch 337: mean loss = 2.6523874e-05  learning rate = 8.525754e-05
============================
Start of epoch 338
step 0: mean loss = 2.435888e-05
step 100: mean loss = 2.559516e-05
step 200: mean loss = 2.643867e-05
step 300: mean loss = 2.5847025e-05
epoch 338: mean loss = 2.6072506e-05  learning rate = 8.525754e-05
============================
Start of epoch 339
step 0: mean loss = 2.9220533e-05
step 100: mean loss = 2.7835198e-05
step 200: mean loss = 2.7722355e-05
step 300: mean loss = 2.7092341e-05
epoch 339: mean loss = 2.694687e-05  learning rate = 8.525754e-05
============================
Start of epoch 340
step 0: mean loss = 2.1555265e-05
step 100: mean loss = 2.5948344e-05
step 200: mean loss = 2.6002901e-05
step 300: mean loss = 2.6076052e-05
epoch 340: mean loss = 2.6383326e-05  learning rate = 8.525754e-05
============================
Start of epoch 341
step 0: mean loss = 2.3952738e-05
step 100: mean loss = 2.7289703e-05
step 200: mean loss = 2.6078798e-05
step 300: mean loss = 2.6396458e-05
epoch 341: mean loss = 2.6410184e-05  learning rate = 8.525754e-05
============================
Start of epoch 342
step 0: mean loss = 2.405715e-05
step 100: mean loss = 2.7500648e-05
step 200: mean loss = 2.6077594e-05
step 300: mean loss = 2.6424606e-05
epoch 342: mean loss = 2.6427784e-05  learning rate = 8.525754e-05
============================
Start of epoch 343
step 0: mean loss = 2.5596702e-05
step 100: mean loss = 2.8210685e-05
step 200: mean loss = 2.7185442e-05
step 300: mean loss = 2.6950069e-05
epoch 343: mean loss = 2.6830448e-05  learning rate = 8.525754e-05
============================
Start of epoch 344
step 0: mean loss = 2.5835127e-05
step 100: mean loss = 2.6708518e-05
step 200: mean loss = 2.6771544e-05
step 300: mean loss = 2.6683036e-05
epoch 344: mean loss = 2.6587775e-05  learning rate = 8.525754e-05
============================
Start of epoch 345
step 0: mean loss = 2.0842683e-05
step 100: mean loss = 2.8793962e-05
step 200: mean loss = 2.6760006e-05
step 300: mean loss = 2.6053232e-05
epoch 345: mean loss = 2.5913156e-05  learning rate = 8.525754e-05
============================
Start of epoch 346
step 0: mean loss = 2.0820386e-05
step 100: mean loss = 2.4970463e-05
step 200: mean loss = 2.5126448e-05
step 300: mean loss = 2.588951e-05
epoch 346: mean loss = 2.5942014e-05  learning rate = 8.525754e-05
============================
Start of epoch 347
step 0: mean loss = 2.7271813e-05
step 100: mean loss = 2.7853843e-05
step 200: mean loss = 2.7011072e-05
step 300: mean loss = 2.6543734e-05
epoch 347: mean loss = 2.6468486e-05  learning rate = 8.525754e-05
============================
Start of epoch 348
step 0: mean loss = 2.0857413e-05
step 100: mean loss = 2.644438e-05
step 200: mean loss = 2.7038473e-05
step 300: mean loss = 2.6507609e-05
epoch 348: mean loss = 2.6589729e-05  learning rate = 8.525754e-05
============================
Start of epoch 349
step 0: mean loss = 2.6159254e-05
step 100: mean loss = 2.6393482e-05
step 200: mean loss = 2.5681815e-05
step 300: mean loss = 2.6375938e-05
epoch 349: mean loss = 2.6335101e-05  learning rate = 8.525754e-05
============================
Start of epoch 350
step 0: mean loss = 2.2222e-05
step 100: mean loss = 2.5595367e-05
step 200: mean loss = 2.5465575e-05
step 300: mean loss = 2.5971873e-05
epoch 350: mean loss = 2.5926247e-05  learning rate = 8.525754e-05
============================
Start of epoch 351
step 0: mean loss = 3.041901e-05
step 100: mean loss = 2.5807689e-05
step 200: mean loss = 2.5557369e-05
step 300: mean loss = 2.5606223e-05
epoch 351: mean loss = 2.5665337e-05  learning rate = 8.525754e-05
============================
Start of epoch 352
step 0: mean loss = 2.8751725e-05
step 100: mean loss = 2.7066784e-05
step 200: mean loss = 2.5925076e-05
step 300: mean loss = 2.5829617e-05
epoch 352: mean loss = 2.5858302e-05  learning rate = 8.525754e-05
============================
Start of epoch 353
step 0: mean loss = 2.3141634e-05
step 100: mean loss = 2.7746442e-05
step 200: mean loss = 2.5699996e-05
step 300: mean loss = 2.6473834e-05
epoch 353: mean loss = 2.6325555e-05  learning rate = 8.525754e-05
============================
Start of epoch 354
step 0: mean loss = 2.2289247e-05
step 100: mean loss = 2.5783334e-05
step 200: mean loss = 2.6146612e-05
step 300: mean loss = 2.5695093e-05
epoch 354: mean loss = 2.5736987e-05  learning rate = 8.525754e-05
============================
Start of epoch 355
step 0: mean loss = 2.8976852e-05
step 100: mean loss = 2.4674173e-05
step 200: mean loss = 2.5225261e-05
step 300: mean loss = 2.6342437e-05
epoch 355: mean loss = 2.6231683e-05  learning rate = 8.525754e-05
============================
Start of epoch 356
step 0: mean loss = 2.8079588e-05
step 100: mean loss = 2.5661402e-05
step 200: mean loss = 2.4897696e-05
step 300: mean loss = 2.6165848e-05
epoch 356: mean loss = 2.619828e-05  learning rate = 8.525754e-05
============================
Start of epoch 357
step 0: mean loss = 2.1525242e-05
step 100: mean loss = 2.8798822e-05
step 200: mean loss = 2.6737736e-05
step 300: mean loss = 2.5967396e-05
epoch 357: mean loss = 2.5840733e-05  learning rate = 8.525754e-05
============================
Start of epoch 358
step 0: mean loss = 2.0419013e-05
step 100: mean loss = 2.5421694e-05
step 200: mean loss = 2.5439305e-05
step 300: mean loss = 2.537095e-05
epoch 358: mean loss = 2.5695193e-05  learning rate = 8.525754e-05
============================
Start of epoch 359
step 0: mean loss = 2.4034922e-05
step 100: mean loss = 2.6395226e-05
step 200: mean loss = 2.6289103e-05
step 300: mean loss = 2.5686062e-05
epoch 359: mean loss = 2.5597952e-05  learning rate = 8.0994665e-05
============================
Start of epoch 360
step 0: mean loss = 1.9576237e-05
step 100: mean loss = 2.4772862e-05
step 200: mean loss = 2.5091684e-05
step 300: mean loss = 2.5562491e-05
epoch 360: mean loss = 2.5563224e-05  learning rate = 8.0994665e-05
============================
Start of epoch 361
step 0: mean loss = 2.4314082e-05
step 100: mean loss = 2.5690524e-05
step 200: mean loss = 2.6168753e-05
step 300: mean loss = 2.5421768e-05
epoch 361: mean loss = 2.5352589e-05  learning rate = 8.0994665e-05
============================
Start of epoch 362
step 0: mean loss = 2.0878024e-05
step 100: mean loss = 2.4107374e-05
step 200: mean loss = 2.4584815e-05
step 300: mean loss = 2.5191308e-05
epoch 362: mean loss = 2.5155556e-05  learning rate = 8.0994665e-05
============================
Start of epoch 363
step 0: mean loss = 2.275038e-05
step 100: mean loss = 2.5899608e-05
step 200: mean loss = 2.5033867e-05
step 300: mean loss = 2.5080812e-05
epoch 363: mean loss = 2.5124735e-05  learning rate = 8.0994665e-05
============================
Start of epoch 364
step 0: mean loss = 2.7300768e-05
step 100: mean loss = 2.6111265e-05
step 200: mean loss = 2.546828e-05
step 300: mean loss = 2.4989558e-05
epoch 364: mean loss = 2.4981951e-05  learning rate = 8.0994665e-05
============================
Start of epoch 365
step 0: mean loss = 2.528379e-05
step 100: mean loss = 2.5213689e-05
step 200: mean loss = 2.561717e-05
step 300: mean loss = 2.607468e-05
epoch 365: mean loss = 2.5947882e-05  learning rate = 8.0994665e-05
============================
Start of epoch 366
step 0: mean loss = 1.6322505e-05
step 100: mean loss = 2.682486e-05
step 200: mean loss = 2.7095224e-05
step 300: mean loss = 2.6194088e-05
epoch 366: mean loss = 2.6035825e-05  learning rate = 8.0994665e-05
============================
Start of epoch 367
step 0: mean loss = 2.5005447e-05
step 100: mean loss = 2.5035859e-05
step 200: mean loss = 2.5147981e-05
step 300: mean loss = 2.504803e-05
epoch 367: mean loss = 2.5071668e-05  learning rate = 8.0994665e-05
============================
Start of epoch 368
step 0: mean loss = 2.2694097e-05
step 100: mean loss = 2.6556843e-05
step 200: mean loss = 2.6033065e-05
step 300: mean loss = 2.5231844e-05
epoch 368: mean loss = 2.5187426e-05  learning rate = 8.0994665e-05
============================
Start of epoch 369
step 0: mean loss = 2.6784193e-05
step 100: mean loss = 2.3823128e-05
step 200: mean loss = 2.4685989e-05
step 300: mean loss = 2.5154717e-05
epoch 369: mean loss = 2.5170855e-05  learning rate = 8.0994665e-05
============================
Start of epoch 370
step 0: mean loss = 2.7030526e-05
step 100: mean loss = 2.4384968e-05
step 200: mean loss = 2.4800991e-05
step 300: mean loss = 2.4395718e-05
epoch 370: mean loss = 2.4335406e-05  learning rate = 8.0994665e-05
============================
Start of epoch 371
step 0: mean loss = 2.1163323e-05
step 100: mean loss = 2.4837322e-05
step 200: mean loss = 2.4223444e-05
step 300: mean loss = 2.4419594e-05
epoch 371: mean loss = 2.4456143e-05  learning rate = 8.0994665e-05
============================
Start of epoch 372
step 0: mean loss = 2.4444718e-05
step 100: mean loss = 2.4072742e-05
step 200: mean loss = 2.4477158e-05
step 300: mean loss = 2.4356441e-05
epoch 372: mean loss = 2.4319195e-05  learning rate = 8.0994665e-05
============================
Start of epoch 373
step 0: mean loss = 2.7497334e-05
step 100: mean loss = 2.3966786e-05
step 200: mean loss = 2.4793793e-05
step 300: mean loss = 2.4763827e-05
epoch 373: mean loss = 2.4711635e-05  learning rate = 8.0994665e-05
============================
Start of epoch 374
step 0: mean loss = 2.2074371e-05
step 100: mean loss = 2.4237665e-05
step 200: mean loss = 2.5303247e-05
step 300: mean loss = 2.4857844e-05
epoch 374: mean loss = 2.4809377e-05  learning rate = 8.0994665e-05
============================
Start of epoch 375
step 0: mean loss = 2.3084394e-05
step 100: mean loss = 2.4992489e-05
step 200: mean loss = 2.475099e-05
step 300: mean loss = 2.4945919e-05
epoch 375: mean loss = 2.4952282e-05  learning rate = 8.0994665e-05
============================
Start of epoch 376
step 0: mean loss = 2.7828191e-05
step 100: mean loss = 2.418397e-05
step 200: mean loss = 2.4353316e-05
step 300: mean loss = 2.4462683e-05
epoch 376: mean loss = 2.4606643e-05  learning rate = 8.0994665e-05
============================
Start of epoch 377
step 0: mean loss = 2.6192938e-05
step 100: mean loss = 2.501402e-05
step 200: mean loss = 2.3462759e-05
step 300: mean loss = 2.4421413e-05
epoch 377: mean loss = 2.4421193e-05  learning rate = 8.0994665e-05
============================
Start of epoch 378
step 0: mean loss = 2.1147905e-05
step 100: mean loss = 2.5515043e-05
step 200: mean loss = 2.5520822e-05
step 300: mean loss = 2.462286e-05
epoch 378: mean loss = 2.4545658e-05  learning rate = 8.0994665e-05
============================
Start of epoch 379
step 0: mean loss = 1.9844563e-05
step 100: mean loss = 2.5912872e-05
step 200: mean loss = 2.4911295e-05
step 300: mean loss = 2.483013e-05
epoch 379: mean loss = 2.469521e-05  learning rate = 8.0994665e-05
============================
Start of epoch 380
step 0: mean loss = 2.2086228e-05
step 100: mean loss = 2.4986508e-05
step 200: mean loss = 2.3565393e-05
step 300: mean loss = 2.3571796e-05
epoch 380: mean loss = 2.356227e-05  learning rate = 8.0994665e-05
============================
Start of epoch 381
step 0: mean loss = 2.2566175e-05
step 100: mean loss = 2.3136061e-05
step 200: mean loss = 2.3756686e-05
step 300: mean loss = 2.4094055e-05
epoch 381: mean loss = 2.4359326e-05  learning rate = 8.0994665e-05
============================
Start of epoch 382
step 0: mean loss = 2.847875e-05
step 100: mean loss = 2.3479513e-05
step 200: mean loss = 2.4487827e-05
step 300: mean loss = 2.438938e-05
epoch 382: mean loss = 2.4415951e-05  learning rate = 8.0994665e-05
============================
Start of epoch 383
step 0: mean loss = 2.219761e-05
step 100: mean loss = 2.5204316e-05
step 200: mean loss = 2.4311006e-05
step 300: mean loss = 2.441998e-05
epoch 383: mean loss = 2.4366753e-05  learning rate = 8.0994665e-05
============================
Start of epoch 384
step 0: mean loss = 2.4545601e-05
step 100: mean loss = 2.4695035e-05
step 200: mean loss = 2.470747e-05
step 300: mean loss = 2.4322351e-05
epoch 384: mean loss = 2.4356059e-05  learning rate = 8.0994665e-05
============================
Start of epoch 385
step 0: mean loss = 2.4135372e-05
step 100: mean loss = 2.2830043e-05
step 200: mean loss = 2.3410816e-05
step 300: mean loss = 2.3464352e-05
epoch 385: mean loss = 2.3858696e-05  learning rate = 8.0994665e-05
============================
Start of epoch 386
step 0: mean loss = 3.3534816e-05
step 100: mean loss = 2.5104808e-05
step 200: mean loss = 2.4235458e-05
step 300: mean loss = 2.3979595e-05
epoch 386: mean loss = 2.3856388e-05  learning rate = 8.0994665e-05
============================
Start of epoch 387
step 0: mean loss = 2.0596943e-05
step 100: mean loss = 2.4630532e-05
step 200: mean loss = 2.4732703e-05
step 300: mean loss = 2.4678635e-05
epoch 387: mean loss = 2.4596353e-05  learning rate = 8.0994665e-05
============================
Start of epoch 388
step 0: mean loss = 2.4395558e-05
step 100: mean loss = 2.4140578e-05
step 200: mean loss = 2.4831623e-05
step 300: mean loss = 2.4333032e-05
epoch 388: mean loss = 2.4332738e-05  learning rate = 8.0994665e-05
============================
Start of epoch 389
step 0: mean loss = 2.7605462e-05
step 100: mean loss = 2.365848e-05
step 200: mean loss = 2.3866744e-05
step 300: mean loss = 2.3912158e-05
epoch 389: mean loss = 2.3896482e-05  learning rate = 8.0994665e-05
============================
Start of epoch 390
step 0: mean loss = 2.1223663e-05
step 100: mean loss = 2.5415035e-05
step 200: mean loss = 2.4722129e-05
step 300: mean loss = 2.4261626e-05
epoch 390: mean loss = 2.4244291e-05  learning rate = 8.0994665e-05
============================
Start of epoch 391
step 0: mean loss = 1.9363262e-05
step 100: mean loss = 2.4247664e-05
step 200: mean loss = 2.509928e-05
step 300: mean loss = 2.428562e-05
epoch 391: mean loss = 2.422672e-05  learning rate = 8.0994665e-05
============================
Start of epoch 392
step 0: mean loss = 2.7426448e-05
step 100: mean loss = 2.2733202e-05
step 200: mean loss = 2.2813296e-05
step 300: mean loss = 2.4280609e-05
epoch 392: mean loss = 2.4306897e-05  learning rate = 8.0994665e-05
============================
Start of epoch 393
step 0: mean loss = 2.0296122e-05
step 100: mean loss = 2.3898601e-05
step 200: mean loss = 2.353741e-05
step 300: mean loss = 2.4364537e-05
epoch 393: mean loss = 2.4349005e-05  learning rate = 8.0994665e-05
============================
Start of epoch 394
step 0: mean loss = 2.1516113e-05
step 100: mean loss = 2.5665335e-05
step 200: mean loss = 2.5189904e-05
step 300: mean loss = 2.4399289e-05
epoch 394: mean loss = 2.4329403e-05  learning rate = 8.0994665e-05
============================
Start of epoch 395
step 0: mean loss = 3.1690848e-05
step 100: mean loss = 2.3002005e-05
step 200: mean loss = 2.4627245e-05
step 300: mean loss = 2.398405e-05
epoch 395: mean loss = 2.3925166e-05  learning rate = 8.0994665e-05
============================
Start of epoch 396
step 0: mean loss = 1.988917e-05
step 100: mean loss = 2.1855234e-05
step 200: mean loss = 2.411401e-05
step 300: mean loss = 2.3580576e-05
epoch 396: mean loss = 2.3597122e-05  learning rate = 8.0994665e-05
============================
Start of epoch 397
step 0: mean loss = 2.4410956e-05
step 100: mean loss = 2.3707496e-05
step 200: mean loss = 2.353363e-05
step 300: mean loss = 2.4051145e-05
epoch 397: mean loss = 2.4002848e-05  learning rate = 8.0994665e-05
============================
Start of epoch 398
step 0: mean loss = 2.1038291e-05
step 100: mean loss = 2.3683731e-05
step 200: mean loss = 2.3063261e-05
step 300: mean loss = 2.3589982e-05
epoch 398: mean loss = 2.355618e-05  learning rate = 8.0994665e-05
============================
Start of epoch 399
step 0: mean loss = 2.1761061e-05
step 100: mean loss = 2.3563616e-05
step 200: mean loss = 2.3214645e-05
step 300: mean loss = 2.3025363e-05
epoch 399: mean loss = 2.2994636e-05  learning rate = 7.694493e-05
============================
Start of epoch 400
step 0: mean loss = 1.8268296e-05
step 100: mean loss = 2.4666737e-05
step 200: mean loss = 2.312649e-05
step 300: mean loss = 2.338614e-05
epoch 400: mean loss = 2.3296081e-05  learning rate = 7.694493e-05
============================
Start of epoch 401
step 0: mean loss = 2.0015425e-05
step 100: mean loss = 2.1798865e-05
step 200: mean loss = 2.2225347e-05
step 300: mean loss = 2.2734197e-05
epoch 401: mean loss = 2.2761194e-05  learning rate = 7.694493e-05
============================
Start of epoch 402
step 0: mean loss = 2.4414017e-05
step 100: mean loss = 2.2034237e-05
step 200: mean loss = 2.3142207e-05
step 300: mean loss = 2.2694692e-05
epoch 402: mean loss = 2.2923206e-05  learning rate = 7.694493e-05
============================
Start of epoch 403
step 0: mean loss = 2.3679688e-05
step 100: mean loss = 2.1886503e-05
step 200: mean loss = 2.2839688e-05
step 300: mean loss = 2.2575616e-05
epoch 403: mean loss = 2.2750968e-05  learning rate = 7.694493e-05
============================
Start of epoch 404
step 0: mean loss = 2.10051e-05
step 100: mean loss = 2.2750932e-05
step 200: mean loss = 2.2513428e-05
step 300: mean loss = 2.277252e-05
epoch 404: mean loss = 2.281735e-05  learning rate = 7.694493e-05
============================
Start of epoch 405
step 0: mean loss = 2.2510852e-05
step 100: mean loss = 2.2493803e-05
step 200: mean loss = 2.2756438e-05
step 300: mean loss = 2.3161087e-05
epoch 405: mean loss = 2.3121687e-05  learning rate = 7.694493e-05
============================
Start of epoch 406
step 0: mean loss = 2.1663476e-05
step 100: mean loss = 2.3879355e-05
step 200: mean loss = 2.3187044e-05
step 300: mean loss = 2.3249177e-05
epoch 406: mean loss = 2.321441e-05  learning rate = 7.694493e-05
============================
Start of epoch 407
step 0: mean loss = 2.6640582e-05
step 100: mean loss = 2.2167342e-05
step 200: mean loss = 2.3559593e-05
step 300: mean loss = 2.3028259e-05
epoch 407: mean loss = 2.3007136e-05  learning rate = 7.694493e-05
============================
Start of epoch 408
step 0: mean loss = 1.9273393e-05
step 100: mean loss = 2.298029e-05
step 200: mean loss = 2.279064e-05
step 300: mean loss = 2.2741991e-05
epoch 408: mean loss = 2.2685956e-05  learning rate = 7.694493e-05
============================
Start of epoch 409
step 0: mean loss = 2.2052796e-05
step 100: mean loss = 2.1510068e-05
step 200: mean loss = 2.2154427e-05
step 300: mean loss = 2.285965e-05
epoch 409: mean loss = 2.2872504e-05  learning rate = 7.694493e-05
============================
Start of epoch 410
step 0: mean loss = 2.0007094e-05
step 100: mean loss = 2.200603e-05
step 200: mean loss = 2.280614e-05
step 300: mean loss = 2.2864528e-05
epoch 410: mean loss = 2.28259e-05  learning rate = 7.694493e-05
============================
Start of epoch 411
step 0: mean loss = 2.1275875e-05
step 100: mean loss = 2.1436326e-05
step 200: mean loss = 2.1953007e-05
step 300: mean loss = 2.2778779e-05
epoch 411: mean loss = 2.2849119e-05  learning rate = 7.694493e-05
============================
Start of epoch 412
step 0: mean loss = 1.9852236e-05
step 100: mean loss = 2.199565e-05
step 200: mean loss = 2.2396693e-05
step 300: mean loss = 2.2856762e-05
epoch 412: mean loss = 2.281656e-05  learning rate = 7.694493e-05
============================
Start of epoch 413
step 0: mean loss = 2.0303873e-05
step 100: mean loss = 2.394068e-05
step 200: mean loss = 2.329937e-05
step 300: mean loss = 2.2743208e-05
epoch 413: mean loss = 2.2689914e-05  learning rate = 7.694493e-05
============================
Start of epoch 414
step 0: mean loss = 1.8311399e-05
step 100: mean loss = 2.2672228e-05
step 200: mean loss = 2.3243514e-05
step 300: mean loss = 2.347848e-05
epoch 414: mean loss = 2.3411576e-05  learning rate = 7.694493e-05
============================
Start of epoch 415
step 0: mean loss = 8.1189806e-05
step 100: mean loss = 2.1843525e-05
step 200: mean loss = 2.1836311e-05
step 300: mean loss = 2.2127388e-05
epoch 415: mean loss = 2.2373604e-05  learning rate = 7.694493e-05
============================
Start of epoch 416
step 0: mean loss = 1.7603106e-05
step 100: mean loss = 2.4332692e-05
step 200: mean loss = 2.308823e-05
step 300: mean loss = 2.27811e-05
epoch 416: mean loss = 2.2696622e-05  learning rate = 7.694493e-05
============================
Start of epoch 417
step 0: mean loss = 2.2703065e-05
step 100: mean loss = 2.2584001e-05
step 200: mean loss = 2.2844117e-05
step 300: mean loss = 2.2520757e-05
epoch 417: mean loss = 2.2695393e-05  learning rate = 7.694493e-05
============================
Start of epoch 418
step 0: mean loss = 2.0982177e-05
step 100: mean loss = 2.456918e-05
step 200: mean loss = 2.2972721e-05
step 300: mean loss = 2.274929e-05
epoch 418: mean loss = 2.2743743e-05  learning rate = 7.694493e-05
============================
Start of epoch 419
step 0: mean loss = 1.963326e-05
step 100: mean loss = 2.2689916e-05
step 200: mean loss = 2.237767e-05
step 300: mean loss = 2.2966029e-05
epoch 419: mean loss = 2.3018902e-05  learning rate = 7.694493e-05
============================
Start of epoch 420
step 0: mean loss = 2.5854275e-05
step 100: mean loss = 2.4209206e-05
step 200: mean loss = 2.3256087e-05
step 300: mean loss = 2.2856017e-05
epoch 420: mean loss = 2.2791186e-05  learning rate = 7.694493e-05
============================
Start of epoch 421
step 0: mean loss = 2.1989388e-05
step 100: mean loss = 2.3107817e-05
step 200: mean loss = 2.2391552e-05
step 300: mean loss = 2.2112616e-05
epoch 421: mean loss = 2.2331715e-05  learning rate = 7.694493e-05
============================
Start of epoch 422
step 0: mean loss = 2.0682555e-05
step 100: mean loss = 2.4197396e-05
step 200: mean loss = 2.3825909e-05
step 300: mean loss = 2.3114288e-05
epoch 422: mean loss = 2.309804e-05  learning rate = 7.694493e-05
============================
Start of epoch 423
step 0: mean loss = 2.277899e-05
step 100: mean loss = 2.1666885e-05
step 200: mean loss = 2.2060494e-05
step 300: mean loss = 2.2314496e-05
epoch 423: mean loss = 2.2392946e-05  learning rate = 7.694493e-05
============================
Start of epoch 424
step 0: mean loss = 2.028335e-05
step 100: mean loss = 2.2388656e-05
step 200: mean loss = 2.2411143e-05
step 300: mean loss = 2.2865506e-05
epoch 424: mean loss = 2.2933727e-05  learning rate = 7.694493e-05
============================
Start of epoch 425
step 0: mean loss = 2.5104366e-05
step 100: mean loss = 2.4943809e-05
step 200: mean loss = 2.404359e-05
step 300: mean loss = 2.312789e-05
epoch 425: mean loss = 2.306817e-05  learning rate = 7.694493e-05
============================
Start of epoch 426
step 0: mean loss = 2.4052184e-05
step 100: mean loss = 2.2032496e-05
step 200: mean loss = 2.2310309e-05
step 300: mean loss = 2.2195914e-05
epoch 426: mean loss = 2.2154269e-05  learning rate = 7.694493e-05
============================
Start of epoch 427
step 0: mean loss = 1.8129329e-05
step 100: mean loss = 2.2507196e-05
step 200: mean loss = 2.2163968e-05
step 300: mean loss = 2.2660299e-05
epoch 427: mean loss = 2.2537519e-05  learning rate = 7.694493e-05
============================
Start of epoch 428
step 0: mean loss = 1.8923016e-05
step 100: mean loss = 2.1090034e-05
step 200: mean loss = 2.244447e-05
step 300: mean loss = 2.2071223e-05
epoch 428: mean loss = 2.2032378e-05  learning rate = 7.694493e-05
============================
Start of epoch 429
step 0: mean loss = 1.7588929e-05
step 100: mean loss = 2.2807479e-05
step 200: mean loss = 2.2440174e-05
step 300: mean loss = 2.2460328e-05
epoch 429: mean loss = 2.2385146e-05  learning rate = 7.694493e-05
============================
Start of epoch 430
step 0: mean loss = 1.899464e-05
step 100: mean loss = 2.2809445e-05
step 200: mean loss = 2.2368418e-05
step 300: mean loss = 2.2305312e-05
epoch 430: mean loss = 2.2278813e-05  learning rate = 7.694493e-05
============================
Start of epoch 431
step 0: mean loss = 2.1955359e-05
step 100: mean loss = 2.2571567e-05
step 200: mean loss = 2.239398e-05
step 300: mean loss = 2.2426964e-05
epoch 431: mean loss = 2.242119e-05  learning rate = 7.694493e-05
============================
Start of epoch 432
step 0: mean loss = 2.4954657e-05
step 100: mean loss = 2.2869357e-05
step 200: mean loss = 2.2305669e-05
step 300: mean loss = 2.1913187e-05
epoch 432: mean loss = 2.1932014e-05  learning rate = 7.694493e-05
============================
Start of epoch 433
step 0: mean loss = 2.136568e-05
step 100: mean loss = 2.1563661e-05
step 200: mean loss = 2.158655e-05
step 300: mean loss = 2.2041524e-05
epoch 433: mean loss = 2.2031893e-05  learning rate = 7.694493e-05
============================
Start of epoch 434
step 0: mean loss = 2.6086464e-05
step 100: mean loss = 2.2680506e-05
step 200: mean loss = 2.275195e-05
step 300: mean loss = 2.1941565e-05
epoch 434: mean loss = 2.2019747e-05  learning rate = 7.694493e-05
============================
Start of epoch 435
step 0: mean loss = 2.19178e-05
step 100: mean loss = 2.1284264e-05
step 200: mean loss = 2.1963631e-05
step 300: mean loss = 2.2050992e-05
epoch 435: mean loss = 2.205547e-05  learning rate = 7.694493e-05
============================
Start of epoch 436
step 0: mean loss = 2.1779339e-05
step 100: mean loss = 2.2864842e-05
step 200: mean loss = 2.2942062e-05
step 300: mean loss = 2.2456054e-05
epoch 436: mean loss = 2.2333244e-05  learning rate = 7.694493e-05
============================
Start of epoch 437
step 0: mean loss = 1.64564e-05
step 100: mean loss = 2.269448e-05
step 200: mean loss = 2.2418866e-05
step 300: mean loss = 2.2653934e-05
epoch 437: mean loss = 2.2571629e-05  learning rate = 7.694493e-05
============================
Start of epoch 438
step 0: mean loss = 2.1309526e-05
step 100: mean loss = 2.2287e-05
step 200: mean loss = 2.1596434e-05
step 300: mean loss = 2.2040404e-05
epoch 438: mean loss = 2.1999127e-05  learning rate = 7.694493e-05
============================
Start of epoch 439
step 0: mean loss = 1.893821e-05
step 100: mean loss = 2.3596755e-05
step 200: mean loss = 2.1946622e-05
step 300: mean loss = 2.1344744e-05
epoch 439: mean loss = 2.1340427e-05  learning rate = 7.309768e-05
============================
Start of epoch 440
step 0: mean loss = 2.1809685e-05
step 100: mean loss = 2.1549555e-05
step 200: mean loss = 2.2034434e-05
step 300: mean loss = 2.2064676e-05
epoch 440: mean loss = 2.1977561e-05  learning rate = 7.309768e-05
============================
Start of epoch 441
step 0: mean loss = 1.8037144e-05
step 100: mean loss = 2.3102184e-05
step 200: mean loss = 2.175488e-05
step 300: mean loss = 2.1102245e-05
epoch 441: mean loss = 2.1122229e-05  learning rate = 7.309768e-05
============================
Start of epoch 442
step 0: mean loss = 2.099851e-05
step 100: mean loss = 2.0828815e-05
step 200: mean loss = 2.0893844e-05
step 300: mean loss = 2.1498634e-05
epoch 442: mean loss = 2.150313e-05  learning rate = 7.309768e-05
============================
Start of epoch 443
step 0: mean loss = 2.192715e-05
step 100: mean loss = 2.0984438e-05
step 200: mean loss = 2.0814146e-05
step 300: mean loss = 2.1467198e-05
epoch 443: mean loss = 2.1387257e-05  learning rate = 7.309768e-05
============================
Start of epoch 444
step 0: mean loss = 1.6986838e-05
step 100: mean loss = 2.3221928e-05
step 200: mean loss = 2.1498801e-05
step 300: mean loss = 2.1399333e-05
epoch 444: mean loss = 2.1454009e-05  learning rate = 7.309768e-05
============================
Start of epoch 445
step 0: mean loss = 2.101954e-05
step 100: mean loss = 2.1164593e-05
step 200: mean loss = 2.1458327e-05
step 300: mean loss = 2.1575113e-05
epoch 445: mean loss = 2.1473415e-05  learning rate = 7.309768e-05
============================
Start of epoch 446
step 0: mean loss = 1.7712533e-05
step 100: mean loss = 2.1242695e-05
step 200: mean loss = 2.1195892e-05
step 300: mean loss = 2.1343836e-05
epoch 446: mean loss = 2.131914e-05  learning rate = 7.309768e-05
============================
Start of epoch 447
step 0: mean loss = 2.1181351e-05
step 100: mean loss = 2.0542688e-05
step 200: mean loss = 2.1542466e-05
step 300: mean loss = 2.150623e-05
epoch 447: mean loss = 2.1417607e-05  learning rate = 7.309768e-05
============================
Start of epoch 448
step 0: mean loss = 1.8731696e-05
step 100: mean loss = 2.1336316e-05
step 200: mean loss = 2.1504562e-05
step 300: mean loss = 2.1569622e-05
epoch 448: mean loss = 2.1522044e-05  learning rate = 7.309768e-05
============================
Start of epoch 449
step 0: mean loss = 2.0720992e-05
step 100: mean loss = 2.0616073e-05
step 200: mean loss = 2.2043518e-05
step 300: mean loss = 2.1247137e-05
epoch 449: mean loss = 2.120167e-05  learning rate = 7.309768e-05
============================
Start of epoch 450
step 0: mean loss = 1.8583056e-05
step 100: mean loss = 2.110231e-05
step 200: mean loss = 2.0587724e-05
step 300: mean loss = 2.08741e-05
epoch 450: mean loss = 2.1131602e-05  learning rate = 7.309768e-05
============================
Start of epoch 451
step 0: mean loss = 2.1274038e-05
step 100: mean loss = 2.1558928e-05
step 200: mean loss = 2.180744e-05
step 300: mean loss = 2.1683672e-05
epoch 451: mean loss = 2.1686912e-05  learning rate = 7.309768e-05
============================
Start of epoch 452
step 0: mean loss = 1.554079e-05
step 100: mean loss = 2.1874208e-05
step 200: mean loss = 2.2252023e-05
step 300: mean loss = 2.1533959e-05
epoch 452: mean loss = 2.1444488e-05  learning rate = 7.309768e-05
============================
Start of epoch 453
step 0: mean loss = 2.070413e-05
step 100: mean loss = 2.0742125e-05
step 200: mean loss = 2.0998234e-05
step 300: mean loss = 2.1364136e-05
epoch 453: mean loss = 2.142731e-05  learning rate = 7.309768e-05
============================
Start of epoch 454
step 0: mean loss = 2.6304653e-05
step 100: mean loss = 2.2369077e-05
step 200: mean loss = 2.2221635e-05
step 300: mean loss = 2.1269536e-05
epoch 454: mean loss = 2.1249305e-05  learning rate = 7.309768e-05
============================
Start of epoch 455
step 0: mean loss = 2.1797458e-05
step 100: mean loss = 1.987727e-05
step 200: mean loss = 2.0276862e-05
step 300: mean loss = 2.1262396e-05
epoch 455: mean loss = 2.1186306e-05  learning rate = 7.309768e-05
============================
Start of epoch 456
step 0: mean loss = 2.6194728e-05
step 100: mean loss = 2.3627419e-05
step 200: mean loss = 2.177586e-05
step 300: mean loss = 2.1200267e-05
epoch 456: mean loss = 2.1198171e-05  learning rate = 7.309768e-05
============================
Start of epoch 457
step 0: mean loss = 2.050471e-05
step 100: mean loss = 2.017637e-05
step 200: mean loss = 2.1249274e-05
step 300: mean loss = 2.1326678e-05
epoch 457: mean loss = 2.1248457e-05  learning rate = 7.309768e-05
============================
Start of epoch 458
step 0: mean loss = 2.155302e-05
step 100: mean loss = 2.0736312e-05
step 200: mean loss = 2.0194275e-05
step 300: mean loss = 2.0892421e-05
epoch 458: mean loss = 2.0842741e-05  learning rate = 7.309768e-05
============================
Start of epoch 459
step 0: mean loss = 2.1134634e-05
step 100: mean loss = 2.15587e-05
step 200: mean loss = 2.158461e-05
step 300: mean loss = 2.099897e-05
epoch 459: mean loss = 2.0946503e-05  learning rate = 7.309768e-05
============================
Start of epoch 460
step 0: mean loss = 1.6991233e-05
step 100: mean loss = 2.2165674e-05
step 200: mean loss = 2.0996236e-05
step 300: mean loss = 2.117912e-05
epoch 460: mean loss = 2.118301e-05  learning rate = 7.309768e-05
============================
Start of epoch 461
step 0: mean loss = 2.4035333e-05
step 100: mean loss = 2.150005e-05
step 200: mean loss = 2.0831782e-05
step 300: mean loss = 2.1230646e-05
epoch 461: mean loss = 2.1188034e-05  learning rate = 7.309768e-05
============================
Start of epoch 462
step 0: mean loss = 2.0575608e-05
step 100: mean loss = 2.0240526e-05
step 200: mean loss = 2.115425e-05
step 300: mean loss = 2.101257e-05
epoch 462: mean loss = 2.0985872e-05  learning rate = 7.309768e-05
============================
Start of epoch 463
step 0: mean loss = 1.9815285e-05
step 100: mean loss = 2.046576e-05
step 200: mean loss = 2.131505e-05
step 300: mean loss = 2.0857598e-05
epoch 463: mean loss = 2.0842494e-05  learning rate = 7.309768e-05
============================
Start of epoch 464
step 0: mean loss = 2.1012886e-05
step 100: mean loss = 2.23202e-05
step 200: mean loss = 2.1308848e-05
step 300: mean loss = 2.134421e-05
epoch 464: mean loss = 2.1359006e-05  learning rate = 7.309768e-05
============================
Start of epoch 465
step 0: mean loss = 2.188916e-05
step 100: mean loss = 2.0706362e-05
step 200: mean loss = 2.0238214e-05
step 300: mean loss = 2.1130323e-05
epoch 465: mean loss = 2.1086136e-05  learning rate = 7.309768e-05
============================
Start of epoch 466
step 0: mean loss = 1.8020106e-05
step 100: mean loss = 2.191895e-05
step 200: mean loss = 2.1478709e-05
step 300: mean loss = 2.1179689e-05
epoch 466: mean loss = 2.115733e-05  learning rate = 7.309768e-05
============================
Start of epoch 467
step 0: mean loss = 1.9340374e-05
step 100: mean loss = 2.2955299e-05
step 200: mean loss = 2.1898732e-05
step 300: mean loss = 2.13877e-05
epoch 467: mean loss = 2.1266234e-05  learning rate = 7.309768e-05
============================
Start of epoch 468
step 0: mean loss = 2.3849028e-05
step 100: mean loss = 2.0736621e-05
step 200: mean loss = 2.1117816e-05
step 300: mean loss = 2.1147785e-05
epoch 468: mean loss = 2.1048012e-05  learning rate = 7.309768e-05
============================
Start of epoch 469
step 0: mean loss = 1.7466831e-05
step 100: mean loss = 2.1014313e-05
step 200: mean loss = 2.0994003e-05
step 300: mean loss = 2.0685435e-05
epoch 469: mean loss = 2.0667481e-05  learning rate = 7.309768e-05
============================
Start of epoch 470
step 0: mean loss = 1.9145264e-05
step 100: mean loss = 2.1878473e-05
step 200: mean loss = 2.1653123e-05
step 300: mean loss = 2.0965774e-05
epoch 470: mean loss = 2.0900254e-05  learning rate = 7.309768e-05
============================
Start of epoch 471
step 0: mean loss = 1.7253293e-05
step 100: mean loss = 2.0459029e-05
step 200: mean loss = 2.0189496e-05
step 300: mean loss = 2.0420262e-05
epoch 471: mean loss = 2.046932e-05  learning rate = 7.309768e-05
============================
Start of epoch 472
step 0: mean loss = 2.0402695e-05
step 100: mean loss = 2.1488318e-05
step 200: mean loss = 2.1704056e-05
step 300: mean loss = 2.1255213e-05
epoch 472: mean loss = 2.1252814e-05  learning rate = 7.309768e-05
============================
Start of epoch 473
step 0: mean loss = 2.3090444e-05
step 100: mean loss = 2.056896e-05
step 200: mean loss = 2.1446614e-05
step 300: mean loss = 2.081683e-05
epoch 473: mean loss = 2.0755728e-05  learning rate = 7.309768e-05
============================
Start of epoch 474
step 0: mean loss = 1.7032133e-05
step 100: mean loss = 1.9987116e-05
step 200: mean loss = 2.1094991e-05
step 300: mean loss = 2.106555e-05
epoch 474: mean loss = 2.100909e-05  learning rate = 7.309768e-05
============================
Start of epoch 475
step 0: mean loss = 1.8726809e-05
step 100: mean loss = 1.9797268e-05
step 200: mean loss = 1.9840576e-05
step 300: mean loss = 2.0832784e-05
epoch 475: mean loss = 2.0884154e-05  learning rate = 7.309768e-05
============================
Start of epoch 476
step 0: mean loss = 2.1163538e-05
step 100: mean loss = 2.1014188e-05
step 200: mean loss = 2.0555524e-05
step 300: mean loss = 2.0855434e-05
epoch 476: mean loss = 2.0766633e-05  learning rate = 7.309768e-05
============================
Start of epoch 477
step 0: mean loss = 2.195708e-05
step 100: mean loss = 2.1742284e-05
step 200: mean loss = 2.079215e-05
step 300: mean loss = 2.0638943e-05
epoch 477: mean loss = 2.0690934e-05  learning rate = 7.309768e-05
============================
Start of epoch 478
step 0: mean loss = 2.5185707e-05
step 100: mean loss = 2.2957793e-05
step 200: mean loss = 2.1795631e-05
step 300: mean loss = 2.1324095e-05
epoch 478: mean loss = 2.1225123e-05  learning rate = 7.309768e-05
============================
Start of epoch 479
step 0: mean loss = 1.8737363e-05
step 100: mean loss = 2.1246815e-05
step 200: mean loss = 2.037196e-05
step 300: mean loss = 2.0136358e-05
epoch 479: mean loss = 2.0149762e-05  learning rate = 6.9442794e-05
============================
Start of epoch 480
step 0: mean loss = 1.7962358e-05
step 100: mean loss = 1.9215811e-05
step 200: mean loss = 2.0251202e-05
step 300: mean loss = 2.020551e-05
epoch 480: mean loss = 2.0200885e-05  learning rate = 6.9442794e-05
============================
Start of epoch 481
step 0: mean loss = 1.9025501e-05
step 100: mean loss = 2.0835352e-05
step 200: mean loss = 2.0421207e-05
step 300: mean loss = 2.0088095e-05
epoch 481: mean loss = 2.0129995e-05  learning rate = 6.9442794e-05
============================
Start of epoch 482
step 0: mean loss = 2.3895504e-05
step 100: mean loss = 2.016151e-05
step 200: mean loss = 2.0316022e-05
step 300: mean loss = 2.0190662e-05
epoch 482: mean loss = 2.0147401e-05  learning rate = 6.9442794e-05
============================
Start of epoch 483
step 0: mean loss = 1.5394933e-05
step 100: mean loss = 2.207931e-05
step 200: mean loss = 2.1216689e-05
step 300: mean loss = 2.0233112e-05
epoch 483: mean loss = 2.0196876e-05  learning rate = 6.9442794e-05
============================
Start of epoch 484
step 0: mean loss = 2.3829289e-05
step 100: mean loss = 1.9526522e-05
step 200: mean loss = 1.9360137e-05
step 300: mean loss = 1.9755915e-05
epoch 484: mean loss = 1.9917263e-05  learning rate = 6.9442794e-05
============================
Start of epoch 485
step 0: mean loss = 1.9922685e-05
step 100: mean loss = 1.9003413e-05
step 200: mean loss = 1.993191e-05
step 300: mean loss = 2.0157484e-05
epoch 485: mean loss = 2.044033e-05  learning rate = 6.9442794e-05
============================
Start of epoch 486
step 0: mean loss = 2.6823604e-05
step 100: mean loss = 2.1828457e-05
step 200: mean loss = 2.2129703e-05
step 300: mean loss = 2.121746e-05
epoch 486: mean loss = 2.1102414e-05  learning rate = 6.9442794e-05
============================
Start of epoch 487
step 0: mean loss = 1.8438473e-05
step 100: mean loss = 1.8742421e-05
step 200: mean loss = 1.9709316e-05
step 300: mean loss = 1.9449066e-05
epoch 487: mean loss = 1.9796486e-05  learning rate = 6.9442794e-05
============================
Start of epoch 488
step 0: mean loss = 2.3991915e-05
step 100: mean loss = 2.0367119e-05
step 200: mean loss = 2.0385009e-05
step 300: mean loss = 2.0124158e-05
epoch 488: mean loss = 2.034481e-05  learning rate = 6.9442794e-05
============================
Start of epoch 489
step 0: mean loss = 2.0778378e-05
step 100: mean loss = 2.0312309e-05
step 200: mean loss = 1.9518819e-05
step 300: mean loss = 2.0229447e-05
epoch 489: mean loss = 2.0241501e-05  learning rate = 6.9442794e-05
============================
Start of epoch 490
step 0: mean loss = 1.63179e-05
step 100: mean loss = 1.9315685e-05
step 200: mean loss = 1.9243333e-05
step 300: mean loss = 2.025443e-05
epoch 490: mean loss = 2.0216512e-05  learning rate = 6.9442794e-05
============================
Start of epoch 491
step 0: mean loss = 1.7556187e-05
step 100: mean loss = 1.8679366e-05
step 200: mean loss = 1.9489116e-05
step 300: mean loss = 1.970302e-05
epoch 491: mean loss = 1.9674642e-05  learning rate = 6.9442794e-05
============================
Start of epoch 492
step 0: mean loss = 1.6613678e-05
step 100: mean loss = 2.092977e-05
step 200: mean loss = 2.0022142e-05
step 300: mean loss = 1.986823e-05
epoch 492: mean loss = 1.9840598e-05  learning rate = 6.9442794e-05
============================
Start of epoch 493
step 0: mean loss = 1.9431041e-05
step 100: mean loss = 2.1645685e-05
step 200: mean loss = 2.0393554e-05
step 300: mean loss = 1.9925403e-05
epoch 493: mean loss = 1.9901621e-05  learning rate = 6.9442794e-05
============================
Start of epoch 494
step 0: mean loss = 1.63163e-05
step 100: mean loss = 1.877264e-05
step 200: mean loss = 1.9564006e-05
step 300: mean loss = 1.946624e-05
epoch 494: mean loss = 1.9698675e-05  learning rate = 6.9442794e-05
============================
Start of epoch 495
step 0: mean loss = 1.7833521e-05
step 100: mean loss = 1.9974488e-05
step 200: mean loss = 1.9576453e-05
step 300: mean loss = 2.0156547e-05
epoch 495: mean loss = 2.0102692e-05  learning rate = 6.9442794e-05
============================
Start of epoch 496
step 0: mean loss = 1.7991248e-05
step 100: mean loss = 2.0125279e-05
step 200: mean loss = 2.0256675e-05
step 300: mean loss = 2.0045229e-05
epoch 496: mean loss = 2.0062238e-05  learning rate = 6.9442794e-05
============================
Start of epoch 497
step 0: mean loss = 1.8310624e-05
step 100: mean loss = 1.9966048e-05
step 200: mean loss = 2.0090036e-05
step 300: mean loss = 2.0284691e-05
epoch 497: mean loss = 2.0285439e-05  learning rate = 6.9442794e-05
============================
Start of epoch 498
step 0: mean loss = 1.941469e-05
step 100: mean loss = 1.8698976e-05
step 200: mean loss = 1.9631918e-05
step 300: mean loss = 1.9781042e-05
epoch 498: mean loss = 1.981763e-05  learning rate = 6.9442794e-05
============================
Start of epoch 499
step 0: mean loss = 1.5427735e-05
step 100: mean loss = 1.8643697e-05
step 200: mean loss = 2.0465839e-05
step 300: mean loss = 1.9651765e-05
epoch 499: mean loss = 1.9671003e-05  learning rate = 6.9442794e-05
============================
Start of epoch 500
step 0: mean loss = 2.0261068e-05
step 100: mean loss = 2.196057e-05
step 200: mean loss = 2.0589576e-05
step 300: mean loss = 1.9970188e-05
epoch 500: mean loss = 1.9970765e-05  learning rate = 6.9442794e-05
============================
Start of epoch 501
step 0: mean loss = 1.7021459e-05
step 100: mean loss = 1.9579144e-05
step 200: mean loss = 1.9176936e-05
step 300: mean loss = 1.9738185e-05
epoch 501: mean loss = 1.9743207e-05  learning rate = 6.9442794e-05
============================
Start of epoch 502
step 0: mean loss = 1.9568855e-05
step 100: mean loss = 2.1626045e-05
step 200: mean loss = 2.0012236e-05
step 300: mean loss = 2.0054591e-05
epoch 502: mean loss = 2.000404e-05  learning rate = 6.9442794e-05
============================
Start of epoch 503
step 0: mean loss = 1.5078201e-05
step 100: mean loss = 2.3580995e-05
step 200: mean loss = 2.1614753e-05
step 300: mean loss = 2.0380072e-05
epoch 503: mean loss = 2.0279014e-05  learning rate = 6.9442794e-05
============================
Start of epoch 504
step 0: mean loss = 1.6744398e-05
step 100: mean loss = 2.0145077e-05
step 200: mean loss = 1.9732497e-05
step 300: mean loss = 1.9671657e-05
epoch 504: mean loss = 1.9781646e-05  learning rate = 6.9442794e-05
============================
Start of epoch 505
step 0: mean loss = 2.044038e-05
step 100: mean loss = 2.0634372e-05
step 200: mean loss = 2.0121088e-05
step 300: mean loss = 1.9938276e-05
epoch 505: mean loss = 2.007047e-05  learning rate = 6.9442794e-05
============================
Start of epoch 506
step 0: mean loss = 2.131061e-05
step 100: mean loss = 2.0356998e-05
step 200: mean loss = 2.0094336e-05
step 300: mean loss = 2.0417516e-05
epoch 506: mean loss = 2.0380634e-05  learning rate = 6.9442794e-05
============================
Start of epoch 507
step 0: mean loss = 1.69757e-05
step 100: mean loss = 1.8904402e-05
step 200: mean loss = 1.9605184e-05
step 300: mean loss = 1.974924e-05
epoch 507: mean loss = 1.9987274e-05  learning rate = 6.9442794e-05
============================
Start of epoch 508
step 0: mean loss = 2.002804e-05
step 100: mean loss = 2.0634718e-05
step 200: mean loss = 1.9448946e-05
step 300: mean loss = 1.9645515e-05
epoch 508: mean loss = 1.964633e-05  learning rate = 6.9442794e-05
============================
Start of epoch 509
step 0: mean loss = 2.2897524e-05
step 100: mean loss = 2.0852292e-05
step 200: mean loss = 1.9653771e-05
step 300: mean loss = 1.9575247e-05
epoch 509: mean loss = 1.9544468e-05  learning rate = 6.9442794e-05
============================
Start of epoch 510
step 0: mean loss = 2.2559536e-05
step 100: mean loss = 1.985451e-05
step 200: mean loss = 1.9893228e-05
step 300: mean loss = 1.9743597e-05
epoch 510: mean loss = 1.9774254e-05  learning rate = 6.9442794e-05
============================
Start of epoch 511
step 0: mean loss = 2.3409157e-05
step 100: mean loss = 2.043011e-05
step 200: mean loss = 1.9913421e-05
step 300: mean loss = 1.9861513e-05
epoch 511: mean loss = 1.9839948e-05  learning rate = 6.9442794e-05
============================
Start of epoch 512
step 0: mean loss = 1.4998666e-05
step 100: mean loss = 1.9019477e-05
step 200: mean loss = 2.0393032e-05
step 300: mean loss = 1.9619774e-05
epoch 512: mean loss = 1.9549176e-05  learning rate = 6.9442794e-05
============================
Start of epoch 513
step 0: mean loss = 1.4250203e-05
step 100: mean loss = 2.0525924e-05
step 200: mean loss = 1.9930094e-05
step 300: mean loss = 1.99866e-05
epoch 513: mean loss = 1.9907658e-05  learning rate = 6.9442794e-05
============================
Start of epoch 514
step 0: mean loss = 1.9107216e-05
step 100: mean loss = 1.8814218e-05
step 200: mean loss = 1.9107498e-05
step 300: mean loss = 1.9604087e-05
epoch 514: mean loss = 1.9570305e-05  learning rate = 6.9442794e-05
============================
Start of epoch 515
step 0: mean loss = 1.6290309e-05
step 100: mean loss = 2.0922254e-05
step 200: mean loss = 2.0091675e-05
step 300: mean loss = 1.9483032e-05
epoch 515: mean loss = 1.9388366e-05  learning rate = 6.9442794e-05
============================
Start of epoch 516
step 0: mean loss = 2.1290038e-05
step 100: mean loss = 1.9617042e-05
step 200: mean loss = 1.9175617e-05
step 300: mean loss = 1.9927258e-05
epoch 516: mean loss = 1.9931622e-05  learning rate = 6.9442794e-05
============================
Start of epoch 517
step 0: mean loss = 1.6640464e-05
step 100: mean loss = 1.8346214e-05
step 200: mean loss = 1.9079733e-05
step 300: mean loss = 1.9156585e-05
epoch 517: mean loss = 1.9352721e-05  learning rate = 6.9442794e-05
============================
Start of epoch 518
step 0: mean loss = 2.4990128e-05
step 100: mean loss = 1.908463e-05
step 200: mean loss = 1.9070272e-05
step 300: mean loss = 1.9678248e-05
epoch 518: mean loss = 1.9764842e-05  learning rate = 6.9442794e-05
============================
Start of epoch 519
step 0: mean loss = 1.8071947e-05
step 100: mean loss = 2.0757332e-05
step 200: mean loss = 1.8977562e-05
step 300: mean loss = 1.8963641e-05
epoch 519: mean loss = 1.8971294e-05  learning rate = 6.597066e-05
============================
Start of epoch 520
step 0: mean loss = 1.769459e-05
step 100: mean loss = 1.9329911e-05
step 200: mean loss = 1.8810038e-05
step 300: mean loss = 1.8989875e-05
epoch 520: mean loss = 1.9017873e-05  learning rate = 6.597066e-05
============================
Start of epoch 521
step 0: mean loss = 1.7303315e-05
step 100: mean loss = 1.9340803e-05
step 200: mean loss = 1.9189289e-05
step 300: mean loss = 1.9196039e-05
epoch 521: mean loss = 1.9177785e-05  learning rate = 6.597066e-05
============================
Start of epoch 522
step 0: mean loss = 1.6117712e-05
step 100: mean loss = 1.8334138e-05
step 200: mean loss = 1.8076895e-05
step 300: mean loss = 1.9424666e-05
epoch 522: mean loss = 1.9329744e-05  learning rate = 6.597066e-05
============================
Start of epoch 523
step 0: mean loss = 2.1439362e-05
step 100: mean loss = 1.9974601e-05
step 200: mean loss = 1.8973082e-05
step 300: mean loss = 1.8782304e-05
epoch 523: mean loss = 1.8744204e-05  learning rate = 6.597066e-05
============================
Start of epoch 524
step 0: mean loss = 1.6804963e-05
step 100: mean loss = 1.9010999e-05
step 200: mean loss = 1.9007175e-05
step 300: mean loss = 1.8938072e-05
epoch 524: mean loss = 1.890413e-05  learning rate = 6.597066e-05
============================
Start of epoch 525
step 0: mean loss = 1.6982096e-05
step 100: mean loss = 1.91028e-05
step 200: mean loss = 1.9706806e-05
step 300: mean loss = 1.9230327e-05
epoch 525: mean loss = 1.9170462e-05  learning rate = 6.597066e-05
============================
Start of epoch 526
step 0: mean loss = 2.0874284e-05
step 100: mean loss = 1.9585848e-05
step 200: mean loss = 1.9239682e-05
step 300: mean loss = 1.9089744e-05
epoch 526: mean loss = 1.9105744e-05  learning rate = 6.597066e-05
============================
Start of epoch 527
step 0: mean loss = 1.7307793e-05
step 100: mean loss = 1.8971503e-05
step 200: mean loss = 1.906495e-05
step 300: mean loss = 1.8556215e-05
epoch 527: mean loss = 1.8568373e-05  learning rate = 6.597066e-05
============================
Start of epoch 528
step 0: mean loss = 2.068858e-05
step 100: mean loss = 1.8903911e-05
step 200: mean loss = 1.8816685e-05
step 300: mean loss = 1.9409494e-05
epoch 528: mean loss = 1.9403398e-05  learning rate = 6.597066e-05
============================
Start of epoch 529
step 0: mean loss = 1.6093529e-05
step 100: mean loss = 1.934959e-05
step 200: mean loss = 1.9088779e-05
step 300: mean loss = 1.8635328e-05
epoch 529: mean loss = 1.8549401e-05  learning rate = 6.597066e-05
============================
Start of epoch 530
step 0: mean loss = 1.762859e-05
step 100: mean loss = 1.8593677e-05
step 200: mean loss = 1.8486111e-05
step 300: mean loss = 1.8844365e-05
epoch 530: mean loss = 1.8787085e-05  learning rate = 6.597066e-05
============================
Start of epoch 531
step 0: mean loss = 2.0695119e-05
step 100: mean loss = 1.9400615e-05
step 200: mean loss = 1.8909186e-05
step 300: mean loss = 1.906481e-05
epoch 531: mean loss = 1.9087005e-05  learning rate = 6.597066e-05
============================
Start of epoch 532
step 0: mean loss = 1.6819618e-05
step 100: mean loss = 2.0249454e-05
step 200: mean loss = 1.9652092e-05
step 300: mean loss = 1.9003422e-05
epoch 532: mean loss = 1.8979506e-05  learning rate = 6.597066e-05
============================
Start of epoch 533
step 0: mean loss = 2.1523023e-05
step 100: mean loss = 1.8364311e-05
step 200: mean loss = 1.8682797e-05
step 300: mean loss = 1.906828e-05
epoch 533: mean loss = 1.9115127e-05  learning rate = 6.597066e-05
============================
Start of epoch 534
step 0: mean loss = 1.5465132e-05
step 100: mean loss = 1.8890112e-05
step 200: mean loss = 1.8507697e-05
step 300: mean loss = 1.895728e-05
epoch 534: mean loss = 1.9079489e-05  learning rate = 6.597066e-05
============================
Start of epoch 535
step 0: mean loss = 2.0267524e-05
step 100: mean loss = 1.8145938e-05
step 200: mean loss = 1.9851012e-05
step 300: mean loss = 1.9137216e-05
epoch 535: mean loss = 1.9073597e-05  learning rate = 6.597066e-05
============================
Start of epoch 536
step 0: mean loss = 1.7996317e-05
step 100: mean loss = 1.8757946e-05
step 200: mean loss = 1.903717e-05
step 300: mean loss = 1.8960318e-05
epoch 536: mean loss = 1.8891613e-05  learning rate = 6.597066e-05
============================
Start of epoch 537
step 0: mean loss = 1.47507935e-05
step 100: mean loss = 1.9635194e-05
step 200: mean loss = 1.9472769e-05
step 300: mean loss = 1.8763236e-05
epoch 537: mean loss = 1.86934e-05  learning rate = 6.597066e-05
============================
Start of epoch 538
step 0: mean loss = 1.790374e-05
step 100: mean loss = 1.7469803e-05
step 200: mean loss = 1.8358258e-05
step 300: mean loss = 1.8926508e-05
epoch 538: mean loss = 1.8867244e-05  learning rate = 6.597066e-05
============================
Start of epoch 539
step 0: mean loss = 1.402075e-05
step 100: mean loss = 2.0253688e-05
step 200: mean loss = 1.9106523e-05
step 300: mean loss = 1.8588862e-05
epoch 539: mean loss = 1.8628389e-05  learning rate = 6.597066e-05
============================
Start of epoch 540
step 0: mean loss = 1.6899354e-05
step 100: mean loss = 1.8908824e-05
step 200: mean loss = 1.81734e-05
step 300: mean loss = 1.846816e-05
epoch 540: mean loss = 1.8851357e-05  learning rate = 6.597066e-05
============================
Start of epoch 541
step 0: mean loss = 1.7558808e-05
step 100: mean loss = 2.0296075e-05
step 200: mean loss = 1.920809e-05
step 300: mean loss = 1.971367e-05
epoch 541: mean loss = 1.9621792e-05  learning rate = 6.597066e-05
============================
Start of epoch 542
step 0: mean loss = 2.042533e-05
step 100: mean loss = 2.013821e-05
step 200: mean loss = 1.9214674e-05
step 300: mean loss = 1.85248e-05
epoch 542: mean loss = 1.844087e-05  learning rate = 6.597066e-05
============================
Start of epoch 543
step 0: mean loss = 1.4220826e-05
step 100: mean loss = 1.7232438e-05
step 200: mean loss = 1.8688337e-05
step 300: mean loss = 1.8174711e-05
epoch 543: mean loss = 1.8433899e-05  learning rate = 6.597066e-05
============================
Start of epoch 544
step 0: mean loss = 1.7362576e-05
step 100: mean loss = 1.8794504e-05
step 200: mean loss = 1.871387e-05
step 300: mean loss = 1.9046485e-05
epoch 544: mean loss = 1.9050076e-05  learning rate = 6.597066e-05
============================
Start of epoch 545
step 0: mean loss = 2.039298e-05
step 100: mean loss = 1.881851e-05
step 200: mean loss = 1.8629718e-05
step 300: mean loss = 1.8460338e-05
epoch 545: mean loss = 1.8397895e-05  learning rate = 6.597066e-05
============================
Start of epoch 546
step 0: mean loss = 8.592228e-05
step 100: mean loss = 1.8753592e-05
step 200: mean loss = 1.844015e-05
step 300: mean loss = 1.8739274e-05
epoch 546: mean loss = 1.8737794e-05  learning rate = 6.597066e-05
============================
Start of epoch 547
step 0: mean loss = 1.6757747e-05
step 100: mean loss = 1.8006425e-05
step 200: mean loss = 1.819054e-05
step 300: mean loss = 1.8964136e-05
epoch 547: mean loss = 1.8906367e-05  learning rate = 6.597066e-05
============================
Start of epoch 548
step 0: mean loss = 1.6184933e-05
step 100: mean loss = 1.8410552e-05
step 200: mean loss = 1.860268e-05
step 300: mean loss = 1.8833058e-05
epoch 548: mean loss = 1.892655e-05  learning rate = 6.597066e-05
============================
Start of epoch 549
step 0: mean loss = 2.1626263e-05
step 100: mean loss = 1.8764169e-05
step 200: mean loss = 1.83824e-05
step 300: mean loss = 1.838629e-05
epoch 549: mean loss = 1.8359453e-05  learning rate = 6.597066e-05
============================
Start of epoch 550
step 0: mean loss = 1.8873718e-05
step 100: mean loss = 1.9129699e-05
step 200: mean loss = 1.8481529e-05
step 300: mean loss = 1.8755474e-05
epoch 550: mean loss = 1.8760045e-05  learning rate = 6.597066e-05
============================
Start of epoch 551
step 0: mean loss = 1.6434982e-05
step 100: mean loss = 1.842954e-05
step 200: mean loss = 1.8680876e-05
step 300: mean loss = 1.8496288e-05
epoch 551: mean loss = 1.8393617e-05  learning rate = 6.597066e-05
============================
Start of epoch 552
step 0: mean loss = 1.3535211e-05
step 100: mean loss = 1.9360472e-05
step 200: mean loss = 1.9119707e-05
step 300: mean loss = 1.8416267e-05
epoch 552: mean loss = 1.8374758e-05  learning rate = 6.597066e-05
============================
Start of epoch 553
step 0: mean loss = 1.8336737e-05
step 100: mean loss = 2.0619447e-05
step 200: mean loss = 1.9192825e-05
step 300: mean loss = 1.8745417e-05
epoch 553: mean loss = 1.8661478e-05  learning rate = 6.597066e-05
============================
Start of epoch 554
step 0: mean loss = 1.5525362e-05
step 100: mean loss = 1.8650326e-05
step 200: mean loss = 1.908697e-05
step 300: mean loss = 1.8731906e-05
epoch 554: mean loss = 1.8615538e-05  learning rate = 6.597066e-05
============================
Start of epoch 555
step 0: mean loss = 1.7153216e-05
step 100: mean loss = 1.7385131e-05
step 200: mean loss = 1.892042e-05
step 300: mean loss = 1.8583336e-05
epoch 555: mean loss = 1.8545672e-05  learning rate = 6.597066e-05
============================
Start of epoch 556
step 0: mean loss = 1.7013128e-05
step 100: mean loss = 1.7379047e-05
step 200: mean loss = 1.7547685e-05
step 300: mean loss = 1.8499792e-05
epoch 556: mean loss = 1.8570909e-05  learning rate = 6.597066e-05
============================
Start of epoch 557
step 0: mean loss = 1.6719767e-05
step 100: mean loss = 1.885837e-05
step 200: mean loss = 1.9932626e-05
step 300: mean loss = 1.9036746e-05
epoch 557: mean loss = 1.8998839e-05  learning rate = 6.597066e-05
============================
Start of epoch 558
step 0: mean loss = 1.5737507e-05
step 100: mean loss = 1.8204111e-05
step 200: mean loss = 1.8277471e-05
step 300: mean loss = 1.7886572e-05
epoch 558: mean loss = 1.8070903e-05  learning rate = 6.597066e-05
============================
Start of epoch 559
step 0: mean loss = 2.0374697e-05
step 100: mean loss = 1.7094624e-05
step 200: mean loss = 1.7891978e-05
step 300: mean loss = 1.833659e-05
epoch 559: mean loss = 1.8262708e-05  learning rate = 6.267212e-05
============================
Start of epoch 560
step 0: mean loss = 1.5304842e-05
step 100: mean loss = 1.8019282e-05
step 200: mean loss = 1.7772245e-05
step 300: mean loss = 1.8039816e-05
epoch 560: mean loss = 1.8012657e-05  learning rate = 6.267212e-05
============================
Start of epoch 561
step 0: mean loss = 1.8549646e-05
step 100: mean loss = 1.7990718e-05
step 200: mean loss = 1.8255272e-05
step 300: mean loss = 1.8142548e-05
epoch 561: mean loss = 1.8159251e-05  learning rate = 6.267212e-05
============================
Start of epoch 562
step 0: mean loss = 2.0296306e-05
step 100: mean loss = 1.8231198e-05
step 200: mean loss = 1.8159284e-05
step 300: mean loss = 1.7899816e-05
epoch 562: mean loss = 1.783998e-05  learning rate = 6.267212e-05
============================
Start of epoch 563
step 0: mean loss = 1.6885708e-05
step 100: mean loss = 1.6660064e-05
step 200: mean loss = 1.766795e-05
step 300: mean loss = 1.7922477e-05
epoch 563: mean loss = 1.8146211e-05  learning rate = 6.267212e-05
============================
Start of epoch 564
step 0: mean loss = 1.8820392e-05
step 100: mean loss = 1.853378e-05
step 200: mean loss = 1.7751967e-05
step 300: mean loss = 1.8238083e-05
epoch 564: mean loss = 1.822269e-05  learning rate = 6.267212e-05
============================
Start of epoch 565
step 0: mean loss = 1.82466e-05
step 100: mean loss = 1.8096871e-05
step 200: mean loss = 1.8458744e-05
step 300: mean loss = 1.8034776e-05
epoch 565: mean loss = 1.7976245e-05  learning rate = 6.267212e-05
============================
Start of epoch 566
step 0: mean loss = 1.87228e-05
step 100: mean loss = 1.6428057e-05
step 200: mean loss = 1.7442379e-05
step 300: mean loss = 1.7753155e-05
epoch 566: mean loss = 1.7702363e-05  learning rate = 6.267212e-05
============================
Start of epoch 567
step 0: mean loss = 2.1410311e-05
step 100: mean loss = 1.7461274e-05
step 200: mean loss = 1.8683786e-05
step 300: mean loss = 1.8014453e-05
epoch 567: mean loss = 1.7987928e-05  learning rate = 6.267212e-05
============================
Start of epoch 568
step 0: mean loss = 2.0693988e-05
step 100: mean loss = 1.7731585e-05
step 200: mean loss = 1.6796781e-05
step 300: mean loss = 1.8001489e-05
epoch 568: mean loss = 1.7938559e-05  learning rate = 6.267212e-05
============================
Start of epoch 569
step 0: mean loss = 1.7644752e-05
step 100: mean loss = 1.7470802e-05
step 200: mean loss = 1.7718274e-05
step 300: mean loss = 1.813566e-05
epoch 569: mean loss = 1.8112298e-05  learning rate = 6.267212e-05
============================
Start of epoch 570
step 0: mean loss = 1.681683e-05
step 100: mean loss = 1.7670442e-05
step 200: mean loss = 1.7398052e-05
step 300: mean loss = 1.7814764e-05
epoch 570: mean loss = 1.784194e-05  learning rate = 6.267212e-05
============================
Start of epoch 571
step 0: mean loss = 1.619018e-05
step 100: mean loss = 1.801082e-05
step 200: mean loss = 1.7283084e-05
step 300: mean loss = 1.8040799e-05
epoch 571: mean loss = 1.8093779e-05  learning rate = 6.267212e-05
============================
Start of epoch 572
step 0: mean loss = 2.040143e-05
step 100: mean loss = 1.7981638e-05
step 200: mean loss = 1.7425904e-05
step 300: mean loss = 1.8004614e-05
epoch 572: mean loss = 1.808284e-05  learning rate = 6.267212e-05
============================
Start of epoch 573
step 0: mean loss = 1.6506932e-05
step 100: mean loss = 1.768031e-05
step 200: mean loss = 1.8376786e-05
step 300: mean loss = 1.7699876e-05
epoch 573: mean loss = 1.7675417e-05  learning rate = 6.267212e-05
============================
Start of epoch 574
step 0: mean loss = 1.5097117e-05
step 100: mean loss = 1.7453729e-05
step 200: mean loss = 1.6938258e-05
step 300: mean loss = 1.7693706e-05
epoch 574: mean loss = 1.776002e-05  learning rate = 6.267212e-05
============================
Start of epoch 575
step 0: mean loss = 1.6448043e-05
step 100: mean loss = 1.6673117e-05
step 200: mean loss = 1.8174842e-05
step 300: mean loss = 1.7719138e-05
epoch 575: mean loss = 1.7938508e-05  learning rate = 6.267212e-05
============================
Start of epoch 576
step 0: mean loss = 2.093739e-05
step 100: mean loss = 1.7554117e-05
step 200: mean loss = 1.8029741e-05
step 300: mean loss = 1.7908473e-05
epoch 576: mean loss = 1.7850587e-05  learning rate = 6.267212e-05
============================
Start of epoch 577
step 0: mean loss = 1.24882745e-05
step 100: mean loss = 1.8345783e-05
step 200: mean loss = 1.818051e-05
step 300: mean loss = 1.7715567e-05
epoch 577: mean loss = 1.7668652e-05  learning rate = 6.267212e-05
============================
Start of epoch 578
step 0: mean loss = 1.8593484e-05
step 100: mean loss = 1.7887349e-05
step 200: mean loss = 1.7256212e-05
step 300: mean loss = 1.7813923e-05
epoch 578: mean loss = 1.7827548e-05  learning rate = 6.267212e-05
============================
Start of epoch 579
step 0: mean loss = 2.2892607e-05
step 100: mean loss = 1.6894539e-05
step 200: mean loss = 1.7270955e-05
step 300: mean loss = 1.767121e-05
epoch 579: mean loss = 1.7641773e-05  learning rate = 6.267212e-05
============================
Start of epoch 580
step 0: mean loss = 1.8148934e-05
step 100: mean loss = 1.631947e-05
step 200: mean loss = 1.7262944e-05
step 300: mean loss = 1.7406175e-05
epoch 580: mean loss = 1.761439e-05  learning rate = 6.267212e-05
============================
Start of epoch 581
step 0: mean loss = 1.9513838e-05
step 100: mean loss = 1.8030814e-05
step 200: mean loss = 1.8696968e-05
step 300: mean loss = 1.8254419e-05
epoch 581: mean loss = 1.8132707e-05  learning rate = 6.267212e-05
============================
Start of epoch 582
step 0: mean loss = 1.6214897e-05
step 100: mean loss = 1.725602e-05
step 200: mean loss = 1.8628329e-05
step 300: mean loss = 1.8086164e-05
epoch 582: mean loss = 1.8019608e-05  learning rate = 6.267212e-05
============================
Start of epoch 583
step 0: mean loss = 1.9086365e-05
step 100: mean loss = 1.8185894e-05
step 200: mean loss = 1.7142438e-05
step 300: mean loss = 1.7397382e-05
epoch 583: mean loss = 1.7340095e-05  learning rate = 6.267212e-05
============================
Start of epoch 584
step 0: mean loss = 1.5846214e-05
step 100: mean loss = 1.6594415e-05
step 200: mean loss = 1.8222521e-05
step 300: mean loss = 1.7839327e-05
epoch 584: mean loss = 1.7839831e-05  learning rate = 6.267212e-05
============================
Start of epoch 585
step 0: mean loss = 1.763503e-05
step 100: mean loss = 1.7037048e-05
step 200: mean loss = 1.7617085e-05
step 300: mean loss = 1.7374336e-05
epoch 585: mean loss = 1.7547549e-05  learning rate = 6.267212e-05
============================
Start of epoch 586
step 0: mean loss = 1.6556673e-05
step 100: mean loss = 1.9220248e-05
step 200: mean loss = 1.8441311e-05
step 300: mean loss = 1.7858963e-05
epoch 586: mean loss = 1.7774446e-05  learning rate = 6.267212e-05
============================
Start of epoch 587
step 0: mean loss = 1.7117418e-05
step 100: mean loss = 1.7969049e-05
step 200: mean loss = 1.7893786e-05
step 300: mean loss = 1.7655211e-05
epoch 587: mean loss = 1.7594752e-05  learning rate = 6.267212e-05
============================
Start of epoch 588
step 0: mean loss = 1.5546095e-05
step 100: mean loss = 1.850933e-05
step 200: mean loss = 1.7847246e-05
step 300: mean loss = 1.7604636e-05
epoch 588: mean loss = 1.7587825e-05  learning rate = 6.267212e-05
============================
Start of epoch 589
step 0: mean loss = 1.3857229e-05
step 100: mean loss = 1.85213e-05
step 200: mean loss = 1.799569e-05
step 300: mean loss = 1.7993067e-05
epoch 589: mean loss = 1.7945309e-05  learning rate = 6.267212e-05
============================
Start of epoch 590
step 0: mean loss = 1.7403694e-05
step 100: mean loss = 1.722687e-05
step 200: mean loss = 1.683329e-05
step 300: mean loss = 1.7488563e-05
epoch 590: mean loss = 1.7457343e-05  learning rate = 6.267212e-05
============================
Start of epoch 591
step 0: mean loss = 1.5372336e-05
step 100: mean loss = 1.7988623e-05
step 200: mean loss = 1.8459048e-05
step 300: mean loss = 1.773513e-05
epoch 591: mean loss = 1.767085e-05  learning rate = 6.267212e-05
============================
Start of epoch 592
step 0: mean loss = 1.6575315e-05
step 100: mean loss = 1.7290226e-05
step 200: mean loss = 1.7294418e-05
step 300: mean loss = 1.777898e-05
epoch 592: mean loss = 1.776138e-05  learning rate = 6.267212e-05
============================
Start of epoch 593
step 0: mean loss = 1.6895487e-05
step 100: mean loss = 1.719192e-05
step 200: mean loss = 1.8266743e-05
step 300: mean loss = 1.7674174e-05
epoch 593: mean loss = 1.7661752e-05  learning rate = 6.267212e-05
============================
Start of epoch 594
step 0: mean loss = 2.144396e-05
step 100: mean loss = 1.7673137e-05
step 200: mean loss = 1.7391045e-05
step 300: mean loss = 1.7385255e-05
epoch 594: mean loss = 1.7394152e-05  learning rate = 6.267212e-05
============================
Start of epoch 595
step 0: mean loss = 1.8105002e-05
step 100: mean loss = 1.8841962e-05
step 200: mean loss = 1.7733315e-05
step 300: mean loss = 1.7265877e-05
epoch 595: mean loss = 1.743119e-05  learning rate = 6.267212e-05
============================
Start of epoch 596
step 0: mean loss = 8.659036e-05
step 100: mean loss = 1.9313411e-05
step 200: mean loss = 1.816815e-05
step 300: mean loss = 1.77428e-05
epoch 596: mean loss = 1.7671508e-05  learning rate = 6.267212e-05
============================
Start of epoch 597
step 0: mean loss = 2.0046224e-05
step 100: mean loss = 1.5991393e-05
step 200: mean loss = 1.6815178e-05
step 300: mean loss = 1.7079592e-05
epoch 597: mean loss = 1.7342461e-05  learning rate = 6.267212e-05
============================
Start of epoch 598
step 0: mean loss = 1.7887289e-05
step 100: mean loss = 1.7848453e-05
step 200: mean loss = 1.7207412e-05
step 300: mean loss = 1.7155502e-05
epoch 598: mean loss = 1.7208276e-05  learning rate = 6.267212e-05
============================
Start of epoch 599
step 0: mean loss = 3.926985e-05
step 100: mean loss = 1.593069e-05
step 200: mean loss = 1.6020156e-05
step 300: mean loss = 1.7102217e-05
epoch 599: mean loss = 1.7187067e-05  learning rate = 5.9538517e-05
============================
Start of epoch 600
step 0: mean loss = 1.9322657e-05
step 100: mean loss = 1.701608e-05
step 200: mean loss = 1.701372e-05
step 300: mean loss = 1.7318973e-05
epoch 600: mean loss = 1.725173e-05  learning rate = 5.9538517e-05
============================
Start of epoch 601
step 0: mean loss = 2.1978376e-05
step 100: mean loss = 1.7069275e-05
step 200: mean loss = 1.7069515e-05
step 300: mean loss = 1.6958467e-05
epoch 601: mean loss = 1.6891594e-05  learning rate = 5.9538517e-05
============================
Start of epoch 602
step 0: mean loss = 1.38449195e-05
step 100: mean loss = 1.8039927e-05
step 200: mean loss = 1.660343e-05
step 300: mean loss = 1.702977e-05
epoch 602: mean loss = 1.7108407e-05  learning rate = 5.9538517e-05
============================
Start of epoch 603
step 0: mean loss = 1.8605464e-05
step 100: mean loss = 1.6568298e-05
step 200: mean loss = 1.6466101e-05
step 300: mean loss = 1.671916e-05
epoch 603: mean loss = 1.6735037e-05  learning rate = 5.9538517e-05
============================
Start of epoch 604
step 0: mean loss = 1.4773933e-05
step 100: mean loss = 1.6661092e-05
step 200: mean loss = 1.7759041e-05
step 300: mean loss = 1.7117805e-05
epoch 604: mean loss = 1.7023413e-05  learning rate = 5.9538517e-05
============================
Start of epoch 605
step 0: mean loss = 1.8343524e-05
step 100: mean loss = 1.7892085e-05
step 200: mean loss = 1.7834873e-05
step 300: mean loss = 1.7307042e-05
epoch 605: mean loss = 1.7212293e-05  learning rate = 5.9538517e-05
============================
Start of epoch 606
step 0: mean loss = 1.7820801e-05
step 100: mean loss = 1.8166915e-05
step 200: mean loss = 1.7664246e-05
step 300: mean loss = 1.704277e-05
epoch 606: mean loss = 1.6991153e-05  learning rate = 5.9538517e-05
============================
Start of epoch 607
step 0: mean loss = 1.2769214e-05
step 100: mean loss = 1.6995631e-05
step 200: mean loss = 1.6838816e-05
step 300: mean loss = 1.6785914e-05
epoch 607: mean loss = 1.6811186e-05  learning rate = 5.9538517e-05
============================
Start of epoch 608
step 0: mean loss = 1.4208239e-05
step 100: mean loss = 1.8975526e-05
step 200: mean loss = 1.7406916e-05
step 300: mean loss = 1.7290604e-05
epoch 608: mean loss = 1.7219774e-05  learning rate = 5.9538517e-05
============================
Start of epoch 609
step 0: mean loss = 1.5155978e-05
step 100: mean loss = 1.715601e-05
step 200: mean loss = 1.689695e-05
step 300: mean loss = 1.6824104e-05
epoch 609: mean loss = 1.6787892e-05  learning rate = 5.9538517e-05
============================
Start of epoch 610
step 0: mean loss = 1.5940139e-05
step 100: mean loss = 1.7087066e-05
step 200: mean loss = 1.7894876e-05
step 300: mean loss = 1.7003747e-05
epoch 610: mean loss = 1.6911863e-05  learning rate = 5.9538517e-05
============================
Start of epoch 611
step 0: mean loss = 1.4948371e-05
step 100: mean loss = 1.4962853e-05
step 200: mean loss = 1.5411211e-05
step 300: mean loss = 1.6691543e-05
epoch 611: mean loss = 1.6666743e-05  learning rate = 5.9538517e-05
============================
Start of epoch 612
step 0: mean loss = 1.7207722e-05
step 100: mean loss = 1.7297332e-05
step 200: mean loss = 1.6714312e-05
step 300: mean loss = 1.6904176e-05
epoch 612: mean loss = 1.686395e-05  learning rate = 5.9538517e-05
============================
Start of epoch 613
step 0: mean loss = 1.6428068e-05
step 100: mean loss = 1.6272797e-05
step 200: mean loss = 1.6551003e-05
step 300: mean loss = 1.6443266e-05
epoch 613: mean loss = 1.6694976e-05  learning rate = 5.9538517e-05
============================
Start of epoch 614
step 0: mean loss = 1.8266765e-05
step 100: mean loss = 1.7577127e-05
step 200: mean loss = 1.7136446e-05
step 300: mean loss = 1.7197832e-05
epoch 614: mean loss = 1.7169874e-05  learning rate = 5.9538517e-05
============================
Start of epoch 615
step 0: mean loss = 1.5895635e-05
step 100: mean loss = 1.5672791e-05
step 200: mean loss = 1.6171101e-05
step 300: mean loss = 1.6739368e-05
epoch 615: mean loss = 1.6727137e-05  learning rate = 5.9538517e-05
============================
Start of epoch 616
step 0: mean loss = 1.5627025e-05
step 100: mean loss = 1.759595e-05
step 200: mean loss = 1.7273436e-05
step 300: mean loss = 1.6747385e-05
epoch 616: mean loss = 1.670104e-05  learning rate = 5.9538517e-05
============================
Start of epoch 617
step 0: mean loss = 1.41523715e-05
step 100: mean loss = 1.5821353e-05
step 200: mean loss = 1.6869248e-05
step 300: mean loss = 1.690355e-05
epoch 617: mean loss = 1.6853584e-05  learning rate = 5.9538517e-05
============================
Start of epoch 618
step 0: mean loss = 1.2998176e-05
step 100: mean loss = 1.634359e-05
step 200: mean loss = 1.6157537e-05
step 300: mean loss = 1.695192e-05
epoch 618: mean loss = 1.6947206e-05  learning rate = 5.9538517e-05
============================
Start of epoch 619
step 0: mean loss = 1.7728154e-05
step 100: mean loss = 1.6959268e-05
step 200: mean loss = 1.7061771e-05
step 300: mean loss = 1.636116e-05
epoch 619: mean loss = 1.6580732e-05  learning rate = 5.9538517e-05
============================
Start of epoch 620
step 0: mean loss = 1.958808e-05
step 100: mean loss = 1.7318753e-05
step 200: mean loss = 1.644887e-05
step 300: mean loss = 1.6827787e-05
epoch 620: mean loss = 1.6786833e-05  learning rate = 5.9538517e-05
============================
Start of epoch 621
step 0: mean loss = 1.8983414e-05
step 100: mean loss = 1.6769716e-05
step 200: mean loss = 1.68475e-05
step 300: mean loss = 1.6827365e-05
epoch 621: mean loss = 1.6795135e-05  learning rate = 5.9538517e-05
============================
Start of epoch 622
step 0: mean loss = 1.5344613e-05
step 100: mean loss = 1.5280762e-05
step 200: mean loss = 1.63101e-05
step 300: mean loss = 1.6684731e-05
epoch 622: mean loss = 1.6699789e-05  learning rate = 5.9538517e-05
============================
Start of epoch 623
step 0: mean loss = 1.9027271e-05
step 100: mean loss = 1.6783933e-05
step 200: mean loss = 1.6614918e-05
step 300: mean loss = 1.6693632e-05
epoch 623: mean loss = 1.6955524e-05  learning rate = 5.9538517e-05
============================
Start of epoch 624
step 0: mean loss = 1.7013761e-05
step 100: mean loss = 1.6638953e-05
step 200: mean loss = 1.618717e-05
step 300: mean loss = 1.6746682e-05
epoch 624: mean loss = 1.6710526e-05  learning rate = 5.9538517e-05
============================
Start of epoch 625
step 0: mean loss = 1.7067425e-05
step 100: mean loss = 1.5335418e-05
step 200: mean loss = 1.6792472e-05
step 300: mean loss = 1.6844908e-05
epoch 625: mean loss = 1.676448e-05  learning rate = 5.9538517e-05
============================
Start of epoch 626
step 0: mean loss = 1.278606e-05
step 100: mean loss = 1.6539714e-05
step 200: mean loss = 1.6588594e-05
step 300: mean loss = 1.6457467e-05
epoch 626: mean loss = 1.641521e-05  learning rate = 5.9538517e-05
============================
Start of epoch 627
step 0: mean loss = 1.4160458e-05
step 100: mean loss = 1.7851633e-05
step 200: mean loss = 1.6599985e-05
step 300: mean loss = 1.6623624e-05
epoch 627: mean loss = 1.6595637e-05  learning rate = 5.9538517e-05
============================
Start of epoch 628
step 0: mean loss = 1.3781356e-05
step 100: mean loss = 1.5645755e-05
step 200: mean loss = 1.6590078e-05
step 300: mean loss = 1.6448237e-05
epoch 628: mean loss = 1.6441785e-05  learning rate = 5.9538517e-05
============================
Start of epoch 629
step 0: mean loss = 1.4260979e-05
step 100: mean loss = 1.7723687e-05
step 200: mean loss = 1.7534378e-05
step 300: mean loss = 1.69594e-05
epoch 629: mean loss = 1.6887458e-05  learning rate = 5.9538517e-05
============================
Start of epoch 630
step 0: mean loss = 1.6372363e-05
step 100: mean loss = 1.5254167e-05
step 200: mean loss = 1.5331158e-05
step 300: mean loss = 1.6181113e-05
epoch 630: mean loss = 1.6210246e-05  learning rate = 5.9538517e-05
============================
Start of epoch 631
step 0: mean loss = 1.7113436e-05
step 100: mean loss = 1.550156e-05
step 200: mean loss = 1.589799e-05
step 300: mean loss = 1.639547e-05
epoch 631: mean loss = 1.6433232e-05  learning rate = 5.9538517e-05
============================
Start of epoch 632
step 0: mean loss = 2.0136004e-05
step 100: mean loss = 1.6957123e-05
step 200: mean loss = 1.6090697e-05
step 300: mean loss = 1.6291766e-05
epoch 632: mean loss = 1.6224725e-05  learning rate = 5.9538517e-05
============================
Start of epoch 633
step 0: mean loss = 2.0487501e-05
step 100: mean loss = 1.6838654e-05
step 200: mean loss = 1.702648e-05
step 300: mean loss = 1.6572507e-05
epoch 633: mean loss = 1.6567063e-05  learning rate = 5.9538517e-05
============================
Start of epoch 634
step 0: mean loss = 1.377194e-05
step 100: mean loss = 1.5378038e-05
step 200: mean loss = 1.6724318e-05
step 300: mean loss = 1.6251252e-05
epoch 634: mean loss = 1.6212329e-05  learning rate = 5.9538517e-05
============================
Start of epoch 635
step 0: mean loss = 1.530778e-05
step 100: mean loss = 1.6945703e-05
step 200: mean loss = 1.7412416e-05
step 300: mean loss = 1.6728925e-05
epoch 635: mean loss = 1.6631242e-05  learning rate = 5.9538517e-05
============================
Start of epoch 636
step 0: mean loss = 1.6375467e-05
step 100: mean loss = 1.779907e-05
step 200: mean loss = 1.6677066e-05
step 300: mean loss = 1.6263477e-05
epoch 636: mean loss = 1.621763e-05  learning rate = 5.9538517e-05
============================
Start of epoch 637
step 0: mean loss = 1.4214068e-05
step 100: mean loss = 1.6826309e-05
step 200: mean loss = 1.7005475e-05
step 300: mean loss = 1.6481963e-05
epoch 637: mean loss = 1.64286e-05  learning rate = 5.9538517e-05
============================
Start of epoch 638
step 0: mean loss = 1.4929389e-05
step 100: mean loss = 1.506709e-05
step 200: mean loss = 1.5321968e-05
step 300: mean loss = 1.6134281e-05
epoch 638: mean loss = 1.6102302e-05  learning rate = 5.6561592e-05
============================
Start of epoch 639
step 0: mean loss = 1.6349772e-05
step 100: mean loss = 1.4700017e-05
step 200: mean loss = 1.6055597e-05
step 300: mean loss = 1.5682264e-05
epoch 639: mean loss = 1.5703168e-05  learning rate = 5.6561592e-05
============================
Start of epoch 640
step 0: mean loss = 1.4131849e-05
step 100: mean loss = 1.5183434e-05
step 200: mean loss = 1.5615315e-05
step 300: mean loss = 1.5889746e-05
epoch 640: mean loss = 1.5869095e-05  learning rate = 5.6561592e-05
============================
Start of epoch 641
step 0: mean loss = 1.6126573e-05
step 100: mean loss = 1.5037575e-05
step 200: mean loss = 1.5837002e-05
step 300: mean loss = 1.5836493e-05
epoch 641: mean loss = 1.5744796e-05  learning rate = 5.6561592e-05
============================
Start of epoch 642
step 0: mean loss = 1.0612392e-05
step 100: mean loss = 1.690069e-05
step 200: mean loss = 1.601782e-05
step 300: mean loss = 1.5559912e-05
epoch 642: mean loss = 1.5527865e-05  learning rate = 5.6561592e-05
============================
Start of epoch 643
step 0: mean loss = 1.597552e-05
step 100: mean loss = 1.7025151e-05
step 200: mean loss = 1.6641938e-05
step 300: mean loss = 1.5943939e-05
epoch 643: mean loss = 1.585211e-05  learning rate = 5.6561592e-05
============================
Start of epoch 644
step 0: mean loss = 1.5184022e-05
step 100: mean loss = 1.7004471e-05
step 200: mean loss = 1.578781e-05
step 300: mean loss = 1.6110786e-05
epoch 644: mean loss = 1.6086971e-05  learning rate = 5.6561592e-05
============================
Start of epoch 645
step 0: mean loss = 1.4174799e-05
step 100: mean loss = 1.5645524e-05
step 200: mean loss = 1.5341537e-05
step 300: mean loss = 1.5679618e-05
epoch 645: mean loss = 1.5653968e-05  learning rate = 5.6561592e-05
============================
Start of epoch 646
step 0: mean loss = 1.6561833e-05
step 100: mean loss = 1.5100454e-05
step 200: mean loss = 1.502444e-05
step 300: mean loss = 1.528255e-05
epoch 646: mean loss = 1.5583924e-05  learning rate = 5.6561592e-05
============================
Start of epoch 647
step 0: mean loss = 1.420053e-05
step 100: mean loss = 1.6029373e-05
step 200: mean loss = 1.6128317e-05
step 300: mean loss = 1.5792024e-05
epoch 647: mean loss = 1.5714153e-05  learning rate = 5.6561592e-05
============================
Start of epoch 648
step 0: mean loss = 1.4084848e-05
step 100: mean loss = 1.5020965e-05
step 200: mean loss = 1.6236603e-05
step 300: mean loss = 1.5784155e-05
epoch 648: mean loss = 1.576157e-05  learning rate = 5.6561592e-05
============================
Start of epoch 649
step 0: mean loss = 1.6027221e-05
step 100: mean loss = 1.4815804e-05
step 200: mean loss = 1.573284e-05
step 300: mean loss = 1.585702e-05
epoch 649: mean loss = 1.581128e-05  learning rate = 5.6561592e-05
============================
Start of epoch 650
step 0: mean loss = 1.3397437e-05
step 100: mean loss = 1.4925824e-05
step 200: mean loss = 1.5007003e-05
step 300: mean loss = 1.5657346e-05
epoch 650: mean loss = 1.577023e-05  learning rate = 5.6561592e-05
============================
Start of epoch 651
step 0: mean loss = 1.5160202e-05
step 100: mean loss = 1.5282969e-05
step 200: mean loss = 1.5661353e-05
step 300: mean loss = 1.5739532e-05
epoch 651: mean loss = 1.5702855e-05  learning rate = 5.6561592e-05
============================
Start of epoch 652
step 0: mean loss = 1.4483441e-05
step 100: mean loss = 1.629804e-05
step 200: mean loss = 1.640111e-05
step 300: mean loss = 1.5897387e-05
epoch 652: mean loss = 1.5879408e-05  learning rate = 5.6561592e-05
============================
Start of epoch 653
step 0: mean loss = 1.2841165e-05
step 100: mean loss = 1.4995029e-05
step 200: mean loss = 1.549154e-05
step 300: mean loss = 1.5676784e-05
epoch 653: mean loss = 1.568981e-05  learning rate = 5.6561592e-05
============================
Start of epoch 654
step 0: mean loss = 1.4266772e-05
step 100: mean loss = 1.5912234e-05
step 200: mean loss = 1.5953103e-05
step 300: mean loss = 1.5702239e-05
epoch 654: mean loss = 1.56138e-05  learning rate = 5.6561592e-05
============================
Start of epoch 655
step 0: mean loss = 1.17981435e-05
step 100: mean loss = 1.5417641e-05
step 200: mean loss = 1.635696e-05
step 300: mean loss = 1.590178e-05
epoch 655: mean loss = 1.582755e-05  learning rate = 5.6561592e-05
============================
Start of epoch 656
step 0: mean loss = 1.2908221e-05
step 100: mean loss = 1.5846892e-05
step 200: mean loss = 1.5807269e-05
step 300: mean loss = 1.5450429e-05
epoch 656: mean loss = 1.5388034e-05  learning rate = 5.6561592e-05
============================
Start of epoch 657
step 0: mean loss = 1.3336312e-05
step 100: mean loss = 1.6196613e-05
step 200: mean loss = 1.612096e-05
step 300: mean loss = 1.6043465e-05
epoch 657: mean loss = 1.5932752e-05  learning rate = 5.6561592e-05
============================
Start of epoch 658
step 0: mean loss = 1.2416187e-05
step 100: mean loss = 1.4612733e-05
step 200: mean loss = 1.5846677e-05
step 300: mean loss = 1.5839103e-05
epoch 658: mean loss = 1.5877285e-05  learning rate = 5.6561592e-05
============================
Start of epoch 659
step 0: mean loss = 1.6297734e-05
step 100: mean loss = 1.5191155e-05
step 200: mean loss = 1.49001835e-05
step 300: mean loss = 1.5615502e-05
epoch 659: mean loss = 1.5578538e-05  learning rate = 5.6561592e-05
============================
Start of epoch 660
step 0: mean loss = 1.3138805e-05
step 100: mean loss = 1.5278387e-05
step 200: mean loss = 1.547527e-05
step 300: mean loss = 1.5566831e-05
epoch 660: mean loss = 1.5577061e-05  learning rate = 5.6561592e-05
============================
Start of epoch 661
step 0: mean loss = 1.6898133e-05
step 100: mean loss = 1.5169774e-05
step 200: mean loss = 1.5620522e-05
step 300: mean loss = 1.580135e-05
epoch 661: mean loss = 1.579244e-05  learning rate = 5.6561592e-05
============================
Start of epoch 662
step 0: mean loss = 1.3986897e-05
step 100: mean loss = 1.6554264e-05
step 200: mean loss = 1.5515976e-05
step 300: mean loss = 1.533353e-05
epoch 662: mean loss = 1.5679376e-05  learning rate = 5.6561592e-05
============================
Start of epoch 663
step 0: mean loss = 1.5756352e-05
step 100: mean loss = 1.6626249e-05
step 200: mean loss = 1.5386006e-05
step 300: mean loss = 1.5515214e-05
epoch 663: mean loss = 1.5599615e-05  learning rate = 5.6561592e-05
============================
Start of epoch 664
step 0: mean loss = 1.9838433e-05
step 100: mean loss = 1.6184611e-05
step 200: mean loss = 1.6020307e-05
step 300: mean loss = 1.57725e-05
epoch 664: mean loss = 1.5717704e-05  learning rate = 5.6561592e-05
============================
Start of epoch 665
step 0: mean loss = 2.1672986e-05
step 100: mean loss = 1.5059542e-05
step 200: mean loss = 1.5694694e-05
step 300: mean loss = 1.5547523e-05
epoch 665: mean loss = 1.5555299e-05  learning rate = 5.6561592e-05
============================
Start of epoch 666
step 0: mean loss = 1.7696751e-05
step 100: mean loss = 1.453827e-05
step 200: mean loss = 1.614524e-05
step 300: mean loss = 1.5986669e-05
epoch 666: mean loss = 1.5907388e-05  learning rate = 5.6561592e-05
============================
Start of epoch 667
step 0: mean loss = 1.5170147e-05
step 100: mean loss = 1.4093171e-05
step 200: mean loss = 1.5117208e-05
step 300: mean loss = 1.538762e-05
epoch 667: mean loss = 1.541693e-05  learning rate = 5.6561592e-05
============================
Start of epoch 668
step 0: mean loss = 1.3484826e-05
step 100: mean loss = 1.5810212e-05
step 200: mean loss = 1.5296924e-05
step 300: mean loss = 1.5416366e-05
epoch 668: mean loss = 1.5367257e-05  learning rate = 5.6561592e-05
============================
Start of epoch 669
step 0: mean loss = 1.6542346e-05
step 100: mean loss = 1.6863418e-05
step 200: mean loss = 1.5653632e-05
step 300: mean loss = 1.5394735e-05
epoch 669: mean loss = 1.5368272e-05  learning rate = 5.6561592e-05
============================
Start of epoch 670
step 0: mean loss = 1.5052108e-05
step 100: mean loss = 1.700275e-05
step 200: mean loss = 1.5665437e-05
step 300: mean loss = 1.536365e-05
epoch 670: mean loss = 1.5371561e-05  learning rate = 5.6561592e-05
============================
Start of epoch 671
step 0: mean loss = 1.4676842e-05
step 100: mean loss = 1.643215e-05
step 200: mean loss = 1.5529087e-05
step 300: mean loss = 1.5702055e-05
epoch 671: mean loss = 1.5668607e-05  learning rate = 5.6561592e-05
============================
Start of epoch 672
step 0: mean loss = 1.5544418e-05
step 100: mean loss = 1.4914626e-05
step 200: mean loss = 1.5452952e-05
step 300: mean loss = 1.5638137e-05
epoch 672: mean loss = 1.5579302e-05  learning rate = 5.6561592e-05
============================
Start of epoch 673
step 0: mean loss = 1.7503131e-05
step 100: mean loss = 1.6515196e-05
step 200: mean loss = 1.6111082e-05
step 300: mean loss = 1.5588308e-05
epoch 673: mean loss = 1.5576708e-05  learning rate = 5.6561592e-05
============================
Start of epoch 674
step 0: mean loss = 1.1052103e-05
step 100: mean loss = 1.6111691e-05
step 200: mean loss = 1.557842e-05
step 300: mean loss = 1.542219e-05
epoch 674: mean loss = 1.5409943e-05  learning rate = 5.6561592e-05
============================
Start of epoch 675
step 0: mean loss = 1.3388329e-05
step 100: mean loss = 1.46828625e-05
step 200: mean loss = 1.452048e-05
step 300: mean loss = 1.5405243e-05
epoch 675: mean loss = 1.5396907e-05  learning rate = 5.6561592e-05
============================
Start of epoch 676
step 0: mean loss = 1.7616636e-05
step 100: mean loss = 1.6321845e-05
step 200: mean loss = 1.5313091e-05
step 300: mean loss = 1.5391111e-05
epoch 676: mean loss = 1.5377329e-05  learning rate = 5.6561592e-05
============================
Start of epoch 677
step 0: mean loss = 1.4745252e-05
step 100: mean loss = 1.4838126e-05
step 200: mean loss = 1.5662838e-05
step 300: mean loss = 1.5244453e-05
epoch 677: mean loss = 1.5514608e-05  learning rate = 5.6561592e-05
============================
Start of epoch 678
step 0: mean loss = 1.4337821e-05
step 100: mean loss = 1.727641e-05
step 200: mean loss = 1.5751504e-05
step 300: mean loss = 1.5468062e-05
epoch 678: mean loss = 1.5418444e-05  learning rate = 5.3733507e-05
============================
Start of epoch 679
step 0: mean loss = 1.622158e-05
step 100: mean loss = 1.5562293e-05
step 200: mean loss = 1.4827799e-05
step 300: mean loss = 1.4955076e-05
epoch 679: mean loss = 1.4898394e-05  learning rate = 5.3733507e-05
============================
Start of epoch 680
step 0: mean loss = 1.4372684e-05
step 100: mean loss = 1.4244727e-05
step 200: mean loss = 1.4690711e-05
step 300: mean loss = 1.5009311e-05
epoch 680: mean loss = 1.49338985e-05  learning rate = 5.3733507e-05
============================
Start of epoch 681
step 0: mean loss = 1.1027899e-05
step 100: mean loss = 1.6055625e-05
step 200: mean loss = 1.5093244e-05
step 300: mean loss = 1.4785238e-05
epoch 681: mean loss = 1.47617575e-05  learning rate = 5.3733507e-05
============================
Start of epoch 682
step 0: mean loss = 1.4411292e-05
step 100: mean loss = 1.5404443e-05
step 200: mean loss = 1.551767e-05
step 300: mean loss = 1.5164728e-05
epoch 682: mean loss = 1.5113239e-05  learning rate = 5.3733507e-05
============================
Start of epoch 683
step 0: mean loss = 1.3918816e-05
step 100: mean loss = 1.7034958e-05
step 200: mean loss = 1.5733858e-05
step 300: mean loss = 1.5107926e-05
epoch 683: mean loss = 1.50532915e-05  learning rate = 5.3733507e-05
============================
Start of epoch 684
step 0: mean loss = 1.37538755e-05
step 100: mean loss = 1.440139e-05
step 200: mean loss = 1.4555815e-05
step 300: mean loss = 1.5021255e-05
epoch 684: mean loss = 1.4977756e-05  learning rate = 5.3733507e-05
============================
Start of epoch 685
step 0: mean loss = 1.9758012e-05
step 100: mean loss = 1.411759e-05
step 200: mean loss = 1.4554075e-05
step 300: mean loss = 1.4762966e-05
epoch 685: mean loss = 1.4758343e-05  learning rate = 5.3733507e-05
============================
Start of epoch 686
step 0: mean loss = 1.2509896e-05
step 100: mean loss = 1.5492216e-05
step 200: mean loss = 1.50678525e-05
step 300: mean loss = 1.5183069e-05
epoch 686: mean loss = 1.513106e-05  learning rate = 5.3733507e-05
============================
Start of epoch 687
step 0: mean loss = 1.803536e-05
step 100: mean loss = 1.44406085e-05
step 200: mean loss = 1.5094503e-05
step 300: mean loss = 1.50988735e-05
epoch 687: mean loss = 1.5021515e-05  learning rate = 5.3733507e-05
============================
Start of epoch 688
step 0: mean loss = 1.5271273e-05
step 100: mean loss = 1.3758904e-05
step 200: mean loss = 1.4744982e-05
step 300: mean loss = 1.5006694e-05
epoch 688: mean loss = 1.4997492e-05  learning rate = 5.3733507e-05
============================
Start of epoch 689
step 0: mean loss = 1.3659391e-05
step 100: mean loss = 1.669324e-05
step 200: mean loss = 1.5507094e-05
step 300: mean loss = 1.5072889e-05
epoch 689: mean loss = 1.5038138e-05  learning rate = 5.3733507e-05
============================
Start of epoch 690
step 0: mean loss = 1.7069764e-05
step 100: mean loss = 1.4978184e-05
step 200: mean loss = 1.4449657e-05
step 300: mean loss = 1.4722173e-05
epoch 690: mean loss = 1.4698185e-05  learning rate = 5.3733507e-05
============================
Start of epoch 691
step 0: mean loss = 3.5996803e-05
step 100: mean loss = 1.5797656e-05
step 200: mean loss = 1.485457e-05
step 300: mean loss = 1.4718752e-05
epoch 691: mean loss = 1.4725036e-05  learning rate = 5.3733507e-05
============================
Start of epoch 692
step 0: mean loss = 1.3914249e-05
step 100: mean loss = 1.6861197e-05
step 200: mean loss = 1.5536965e-05
step 300: mean loss = 1.4971127e-05
epoch 692: mean loss = 1.4938016e-05  learning rate = 5.3733507e-05
============================
Start of epoch 693
step 0: mean loss = 1.4702045e-05
step 100: mean loss = 1.5368834e-05
step 200: mean loss = 1.5166581e-05
step 300: mean loss = 1.4795394e-05
epoch 693: mean loss = 1.4752633e-05  learning rate = 5.3733507e-05
============================
Start of epoch 694
step 0: mean loss = 1.7384129e-05
step 100: mean loss = 1.6517859e-05
step 200: mean loss = 1.5474789e-05
step 300: mean loss = 1.5150414e-05
epoch 694: mean loss = 1.5131818e-05  learning rate = 5.3733507e-05
============================
Start of epoch 695
step 0: mean loss = 1.3798162e-05
step 100: mean loss = 1.4029503e-05
step 200: mean loss = 1.3821547e-05
step 300: mean loss = 1.454733e-05
epoch 695: mean loss = 1.4549587e-05  learning rate = 5.3733507e-05
============================
Start of epoch 696
step 0: mean loss = 1.51820705e-05
step 100: mean loss = 1.4480387e-05
step 200: mean loss = 1.5851534e-05
step 300: mean loss = 1.5276355e-05
epoch 696: mean loss = 1.5188696e-05  learning rate = 5.3733507e-05
============================
Start of epoch 697
step 0: mean loss = 1.7097162e-05
step 100: mean loss = 1.3536191e-05
step 200: mean loss = 1.4886085e-05
step 300: mean loss = 1.5048787e-05
epoch 697: mean loss = 1.5015929e-05  learning rate = 5.3733507e-05
============================
Start of epoch 698
step 0: mean loss = 1.7629238e-05
step 100: mean loss = 1.3662006e-05
step 200: mean loss = 1.4871752e-05
step 300: mean loss = 1.46986695e-05
epoch 698: mean loss = 1.4675065e-05  learning rate = 5.3733507e-05
============================
Start of epoch 699
step 0: mean loss = 1.2389235e-05
step 100: mean loss = 1.3506843e-05
step 200: mean loss = 1.4501647e-05
step 300: mean loss = 1.4744727e-05
epoch 699: mean loss = 1.4716032e-05  learning rate = 5.3733507e-05
============================
Start of epoch 700
step 0: mean loss = 1.4388025e-05
step 100: mean loss = 1.4745471e-05
step 200: mean loss = 1.4319978e-05
step 300: mean loss = 1.4592015e-05
epoch 700: mean loss = 1.4618393e-05  learning rate = 5.3733507e-05
============================
Start of epoch 701
step 0: mean loss = 1.1479127e-05
step 100: mean loss = 1.59674e-05
step 200: mean loss = 1.5313466e-05
step 300: mean loss = 1.4773506e-05
epoch 701: mean loss = 1.4730739e-05  learning rate = 5.3733507e-05
============================
Start of epoch 702
step 0: mean loss = 1.2213387e-05
step 100: mean loss = 1.5127698e-05
step 200: mean loss = 1.4483009e-05
step 300: mean loss = 1.4871853e-05
epoch 702: mean loss = 1.4821288e-05  learning rate = 5.3733507e-05
============================
Start of epoch 703
step 0: mean loss = 1.324858e-05
step 100: mean loss = 1.46280345e-05
step 200: mean loss = 1.4934428e-05
step 300: mean loss = 1.4632326e-05
epoch 703: mean loss = 1.458688e-05  learning rate = 5.3733507e-05
============================
Start of epoch 704
step 0: mean loss = 1.280321e-05
step 100: mean loss = 1.5331005e-05
step 200: mean loss = 1.5352296e-05
step 300: mean loss = 1.5123512e-05
epoch 704: mean loss = 1.5070992e-05  learning rate = 5.3733507e-05
============================
Start of epoch 705
step 0: mean loss = 1.2078901e-05
step 100: mean loss = 1.3426749e-05
step 200: mean loss = 1.3937542e-05
step 300: mean loss = 1.454322e-05
epoch 705: mean loss = 1.4499623e-05  learning rate = 5.3733507e-05
============================
Start of epoch 706
step 0: mean loss = 9.609809e-06
step 100: mean loss = 1.3146497e-05
step 200: mean loss = 1.4277056e-05
step 300: mean loss = 1.5104073e-05
epoch 706: mean loss = 1.5046034e-05  learning rate = 5.3733507e-05
============================
Start of epoch 707
step 0: mean loss = 1.3551056e-05
step 100: mean loss = 1.3007195e-05
step 200: mean loss = 1.4646577e-05
step 300: mean loss = 1.4634174e-05
epoch 707: mean loss = 1.4595098e-05  learning rate = 5.3733507e-05
============================
Start of epoch 708
step 0: mean loss = 1.2080813e-05
step 100: mean loss = 1.4856239e-05
step 200: mean loss = 1.4184602e-05
step 300: mean loss = 1.430602e-05
epoch 708: mean loss = 1.4371005e-05  learning rate = 5.3733507e-05
============================
Start of epoch 709
step 0: mean loss = 1.1552665e-05
step 100: mean loss = 1.5361784e-05
step 200: mean loss = 1.5149884e-05
step 300: mean loss = 1.4901401e-05
epoch 709: mean loss = 1.4855346e-05  learning rate = 5.3733507e-05
============================
Start of epoch 710
step 0: mean loss = 1.3159423e-05
step 100: mean loss = 1.50439655e-05
step 200: mean loss = 1.5150224e-05
step 300: mean loss = 1.4789634e-05
epoch 710: mean loss = 1.477793e-05  learning rate = 5.3733507e-05
============================
Start of epoch 711
step 0: mean loss = 1.38012565e-05
step 100: mean loss = 1.4876555e-05
step 200: mean loss = 1.4400706e-05
step 300: mean loss = 1.4141895e-05
epoch 711: mean loss = 1.4481137e-05  learning rate = 5.3733507e-05
============================
Start of epoch 712
step 0: mean loss = 1.704505e-05
step 100: mean loss = 1.5074758e-05
step 200: mean loss = 1.4767703e-05
step 300: mean loss = 1.49814e-05
epoch 712: mean loss = 1.4969637e-05  learning rate = 5.3733507e-05
============================
Start of epoch 713
step 0: mean loss = 1.3822995e-05
step 100: mean loss = 1.3480028e-05
step 200: mean loss = 1.4108018e-05
step 300: mean loss = 1.4630559e-05
epoch 713: mean loss = 1.4584994e-05  learning rate = 5.3733507e-05
============================
Start of epoch 714
step 0: mean loss = 9.511958e-06
step 100: mean loss = 1.5269345e-05
step 200: mean loss = 1.4698671e-05
step 300: mean loss = 1.4385083e-05
epoch 714: mean loss = 1.4619536e-05  learning rate = 5.3733507e-05
============================
Start of epoch 715
step 0: mean loss = 6.875888e-05
step 100: mean loss = 1.499429e-05
step 200: mean loss = 1.4564449e-05
step 300: mean loss = 1.4879504e-05
epoch 715: mean loss = 1.49045145e-05  learning rate = 5.3733507e-05
============================
Start of epoch 716
step 0: mean loss = 1.3573603e-05
step 100: mean loss = 1.3958352e-05
step 200: mean loss = 1.5696418e-05
step 300: mean loss = 1.5722546e-05
epoch 716: mean loss = 1.5604648e-05  learning rate = 5.3733507e-05
============================
Start of epoch 717
step 0: mean loss = 1.4496486e-05
step 100: mean loss = 1.5109746e-05
step 200: mean loss = 1.4624961e-05
step 300: mean loss = 1.4676728e-05
epoch 717: mean loss = 1.4604484e-05  learning rate = 5.3733507e-05
============================
Start of epoch 718
step 0: mean loss = 1.1016382e-05
step 100: mean loss = 1.4751416e-05
step 200: mean loss = 1.41413575e-05
step 300: mean loss = 1.4578021e-05
epoch 718: mean loss = 1.4888934e-05  learning rate = 5.104683e-05
============================
Start of epoch 719
step 0: mean loss = 1.9049729e-05
step 100: mean loss = 1.3925722e-05
step 200: mean loss = 1.4868823e-05
step 300: mean loss = 1.4271817e-05
epoch 719: mean loss = 1.4162298e-05  learning rate = 5.104683e-05
============================
Start of epoch 720
step 0: mean loss = 1.33855265e-05
step 100: mean loss = 1.3428434e-05
step 200: mean loss = 1.41035935e-05
step 300: mean loss = 1.4144049e-05
epoch 720: mean loss = 1.4132308e-05  learning rate = 5.104683e-05
============================
Start of epoch 721
step 0: mean loss = 1.4166393e-05
step 100: mean loss = 1.5335756e-05
step 200: mean loss = 1.4084815e-05
step 300: mean loss = 1.43454645e-05
epoch 721: mean loss = 1.4586704e-05  learning rate = 5.104683e-05
============================
Start of epoch 722
step 0: mean loss = 1.4276304e-05
step 100: mean loss = 1.3199509e-05
step 200: mean loss = 1.4739043e-05
step 300: mean loss = 1.46292305e-05
epoch 722: mean loss = 1.4536235e-05  learning rate = 5.104683e-05
============================
Start of epoch 723
step 0: mean loss = 1.3157296e-05
step 100: mean loss = 1.660372e-05
step 200: mean loss = 1.5615795e-05
step 300: mean loss = 1.4755795e-05
epoch 723: mean loss = 1.4691798e-05  learning rate = 5.104683e-05
============================
Start of epoch 724
step 0: mean loss = 1.3658781e-05
step 100: mean loss = 1.3567405e-05
step 200: mean loss = 1.4061507e-05
step 300: mean loss = 1.45912645e-05
epoch 724: mean loss = 1.4554739e-05  learning rate = 5.104683e-05
============================
Start of epoch 725
step 0: mean loss = 1.2481072e-05
step 100: mean loss = 1.3112431e-05
step 200: mean loss = 1.5399573e-05
step 300: mean loss = 1.4736571e-05
epoch 725: mean loss = 1.46751145e-05  learning rate = 5.104683e-05
============================
Start of epoch 726
step 0: mean loss = 1.40892735e-05
step 100: mean loss = 1.4974606e-05
step 200: mean loss = 1.488121e-05
step 300: mean loss = 1.4398675e-05
epoch 726: mean loss = 1.4330091e-05  learning rate = 5.104683e-05
============================
Start of epoch 727
step 0: mean loss = 1.4286667e-05
step 100: mean loss = 1.4587069e-05
step 200: mean loss = 1.4136527e-05
step 300: mean loss = 1.4873839e-05
epoch 727: mean loss = 1.48167765e-05  learning rate = 5.104683e-05
============================
Start of epoch 728
step 0: mean loss = 1.0582571e-05
step 100: mean loss = 1.4521571e-05
step 200: mean loss = 1.5250345e-05
step 300: mean loss = 1.4665043e-05
epoch 728: mean loss = 1.4706941e-05  learning rate = 5.104683e-05
============================
Start of epoch 729
step 0: mean loss = 1.481513e-05
step 100: mean loss = 1.5360603e-05
step 200: mean loss = 1.4965786e-05
step 300: mean loss = 1.4679312e-05
epoch 729: mean loss = 1.4609772e-05  learning rate = 5.104683e-05
============================
Start of epoch 730
step 0: mean loss = 1.286804e-05
step 100: mean loss = 1.4486331e-05
step 200: mean loss = 1.4105007e-05
step 300: mean loss = 1.4628083e-05
epoch 730: mean loss = 1.4621533e-05  learning rate = 5.104683e-05
============================
Start of epoch 731
step 0: mean loss = 1.3950333e-05
step 100: mean loss = 1.501691e-05
step 200: mean loss = 1.4985275e-05
step 300: mean loss = 1.4901413e-05
epoch 731: mean loss = 1.4838924e-05  learning rate = 5.104683e-05
============================
Start of epoch 732
step 0: mean loss = 1.1079499e-05
step 100: mean loss = 1.3280548e-05
step 200: mean loss = 1.4591653e-05
step 300: mean loss = 1.4041178e-05
epoch 732: mean loss = 1.4535428e-05  learning rate = 5.104683e-05
============================
Start of epoch 733
step 0: mean loss = 2.2202667e-05
step 100: mean loss = 1.5188137e-05
step 200: mean loss = 1.5085546e-05
step 300: mean loss = 1.5724941e-05
epoch 733: mean loss = 1.5640715e-05  learning rate = 5.104683e-05
============================
Start of epoch 734
step 0: mean loss = 1.4195209e-05
step 100: mean loss = 1.268485e-05
step 200: mean loss = 1.44161695e-05
step 300: mean loss = 1.4450812e-05
epoch 734: mean loss = 1.44612e-05  learning rate = 5.104683e-05
============================
Start of epoch 735
step 0: mean loss = 1.1616225e-05
step 100: mean loss = 1.4915447e-05
step 200: mean loss = 1.4083366e-05
step 300: mean loss = 1.4755701e-05
epoch 735: mean loss = 1.4702052e-05  learning rate = 5.104683e-05
============================
Start of epoch 736
step 0: mean loss = 1.3399274e-05
step 100: mean loss = 1.3218499e-05
step 200: mean loss = 1.535691e-05
step 300: mean loss = 1.4616587e-05
epoch 736: mean loss = 1.45202175e-05  learning rate = 5.104683e-05
============================
Start of epoch 737
step 0: mean loss = 1.3105982e-05
step 100: mean loss = 1.6954944e-05
step 200: mean loss = 1.51866025e-05
step 300: mean loss = 1.4479954e-05
epoch 737: mean loss = 1.4419559e-05  learning rate = 5.104683e-05
============================
Start of epoch 738
step 0: mean loss = 1.37394145e-05
step 100: mean loss = 1.5707332e-05
step 200: mean loss = 1.43248835e-05
step 300: mean loss = 1.4672255e-05
epoch 738: mean loss = 1.4630963e-05  learning rate = 5.104683e-05
============================
Start of epoch 739
step 0: mean loss = 1.1243831e-05
step 100: mean loss = 1.3354227e-05
step 200: mean loss = 1.4332075e-05
step 300: mean loss = 1.4727555e-05
epoch 739: mean loss = 1.4657024e-05  learning rate = 5.104683e-05
============================
Start of epoch 740
step 0: mean loss = 1.0823702e-05
step 100: mean loss = 1.6807106e-05
step 200: mean loss = 1.5287551e-05
step 300: mean loss = 1.467091e-05
epoch 740: mean loss = 1.4638763e-05  learning rate = 5.104683e-05
============================
Start of epoch 741
step 0: mean loss = 1.5280837e-05
step 100: mean loss = 1.5079139e-05
step 200: mean loss = 1.4858396e-05
step 300: mean loss = 1.4529432e-05
epoch 741: mean loss = 1.4496993e-05  learning rate = 5.104683e-05
============================
Start of epoch 742
step 0: mean loss = 1.2490399e-05
step 100: mean loss = 1.5587824e-05
step 200: mean loss = 1.4932865e-05
step 300: mean loss = 1.47499995e-05
epoch 742: mean loss = 1.4744006e-05  learning rate = 5.104683e-05
============================
Start of epoch 743
step 0: mean loss = 1.28740485e-05
step 100: mean loss = 1.4762519e-05
step 200: mean loss = 1.4705699e-05
step 300: mean loss = 1.4130353e-05
epoch 743: mean loss = 1.4487909e-05  learning rate = 5.104683e-05
============================
Start of epoch 744
step 0: mean loss = 1.3688574e-05
step 100: mean loss = 1.4565066e-05
step 200: mean loss = 1.549768e-05
step 300: mean loss = 1.4526211e-05
epoch 744: mean loss = 1.4442552e-05  learning rate = 5.104683e-05
============================
Start of epoch 745
step 0: mean loss = 1.5656024e-05
step 100: mean loss = 1.297021e-05
step 200: mean loss = 1.460006e-05
step 300: mean loss = 1.4661767e-05
epoch 745: mean loss = 1.461821e-05  learning rate = 5.104683e-05
============================
Start of epoch 746
step 0: mean loss = 1.38792e-05
step 100: mean loss = 1.4848916e-05
step 200: mean loss = 1.4098162e-05
step 300: mean loss = 1.4721063e-05
epoch 746: mean loss = 1.465639e-05  learning rate = 5.104683e-05
============================
Start of epoch 747
step 0: mean loss = 1.4248447e-05
step 100: mean loss = 1.3049999e-05
step 200: mean loss = 1.3714636e-05
step 300: mean loss = 1.4133691e-05
epoch 747: mean loss = 1.4381086e-05  learning rate = 5.104683e-05
============================
Start of epoch 748
step 0: mean loss = 1.4008574e-05
step 100: mean loss = 1.6446715e-05
step 200: mean loss = 1.4958962e-05
step 300: mean loss = 1.4913346e-05
epoch 748: mean loss = 1.48492645e-05  learning rate = 5.104683e-05
============================
Start of epoch 749
step 0: mean loss = 1.1137862e-05
step 100: mean loss = 1.4762048e-05
step 200: mean loss = 1.3641641e-05
step 300: mean loss = 1.4465728e-05
epoch 749: mean loss = 1.44149735e-05  learning rate = 5.104683e-05
============================
Start of epoch 750
step 0: mean loss = 1.36398e-05
step 100: mean loss = 1.4504857e-05
step 200: mean loss = 1.4769963e-05
step 300: mean loss = 1.4154103e-05
epoch 750: mean loss = 1.4427954e-05  learning rate = 5.104683e-05
============================
Start of epoch 751
step 0: mean loss = 1.5028975e-05
step 100: mean loss = 1.4713953e-05
step 200: mean loss = 1.4147052e-05
step 300: mean loss = 1.4513905e-05
epoch 751: mean loss = 1.4489728e-05  learning rate = 5.104683e-05
============================
Start of epoch 752
step 0: mean loss = 1.2054572e-05
step 100: mean loss = 1.4497639e-05
step 200: mean loss = 1.3435904e-05
step 300: mean loss = 1.4304086e-05
epoch 752: mean loss = 1.432727e-05  learning rate = 5.104683e-05
============================
Start of epoch 753
step 0: mean loss = 1.9816876e-05
step 100: mean loss = 1.4488645e-05
step 200: mean loss = 1.4112827e-05
step 300: mean loss = 1.4583744e-05
epoch 753: mean loss = 1.4591229e-05  learning rate = 5.104683e-05
============================
Start of epoch 754
step 0: mean loss = 2.671124e-05
step 100: mean loss = 1.4683267e-05
step 200: mean loss = 1.4452136e-05
step 300: mean loss = 1.4414722e-05
epoch 754: mean loss = 1.4371283e-05  learning rate = 5.104683e-05
============================
Start of epoch 755
step 0: mean loss = 1.3054234e-05
step 100: mean loss = 1.4314631e-05
step 200: mean loss = 1.3347375e-05
step 300: mean loss = 1.3681733e-05
epoch 755: mean loss = 1.4072939e-05  learning rate = 5.104683e-05
============================
Start of epoch 756
step 0: mean loss = 1.6720922e-05
step 100: mean loss = 1.4477007e-05
step 200: mean loss = 1.4817214e-05
step 300: mean loss = 1.4864052e-05
epoch 756: mean loss = 1.4813348e-05  learning rate = 5.104683e-05
============================
Start of epoch 757
step 0: mean loss = 1.3891355e-05
step 100: mean loss = 1.4845053e-05
step 200: mean loss = 1.4591097e-05
step 300: mean loss = 1.4291655e-05
epoch 757: mean loss = 1.4278212e-05  learning rate = 5.104683e-05
============================
Start of epoch 758
step 0: mean loss = 1.4220373e-05
step 100: mean loss = 1.4691655e-05
step 200: mean loss = 1.4082278e-05
step 300: mean loss = 1.4396739e-05
epoch 758: mean loss = 1.4314793e-05  learning rate = 4.849449e-05
============================
Start of epoch 759
step 0: mean loss = 1.2497778e-05
step 100: mean loss = 1.4415101e-05
step 200: mean loss = 1.4363145e-05
step 300: mean loss = 1.3943356e-05
epoch 759: mean loss = 1.3911408e-05  learning rate = 4.849449e-05
============================
Start of epoch 760
step 0: mean loss = 1.352271e-05
step 100: mean loss = 1.2147664e-05
step 200: mean loss = 1.2570954e-05
step 300: mean loss = 1.35079845e-05
epoch 760: mean loss = 1.3981337e-05  learning rate = 4.849449e-05
============================
Start of epoch 761
step 0: mean loss = 1.97897e-05
step 100: mean loss = 1.5110492e-05
step 200: mean loss = 1.462107e-05
step 300: mean loss = 1.4454875e-05
epoch 761: mean loss = 1.439908e-05  learning rate = 4.849449e-05
============================
Start of epoch 762
step 0: mean loss = 1.2566323e-05
step 100: mean loss = 1.4642731e-05
step 200: mean loss = 1.3866472e-05
step 300: mean loss = 1.39250005e-05
epoch 762: mean loss = 1.42241415e-05  learning rate = 4.849449e-05
============================
Start of epoch 763
step 0: mean loss = 1.8789757e-05
step 100: mean loss = 1.4352578e-05
step 200: mean loss = 1.4012938e-05
step 300: mean loss = 1.4240462e-05
epoch 763: mean loss = 1.4196915e-05  learning rate = 4.849449e-05
============================
Start of epoch 764
step 0: mean loss = 1.1740235e-05
step 100: mean loss = 1.2377829e-05
step 200: mean loss = 1.3178756e-05
step 300: mean loss = 1.345736e-05
epoch 764: mean loss = 1.337408e-05  learning rate = 4.849449e-05
============================
Start of epoch 765
step 0: mean loss = 1.2785357e-05
step 100: mean loss = 1.2479909e-05
step 200: mean loss = 1.3430913e-05
step 300: mean loss = 1.3585997e-05
epoch 765: mean loss = 1.35830705e-05  learning rate = 4.849449e-05
============================
Start of epoch 766
step 0: mean loss = 1.1772296e-05
step 100: mean loss = 1.350122e-05
step 200: mean loss = 1.4382865e-05
step 300: mean loss = 1.4068158e-05
epoch 766: mean loss = 1.4000289e-05  learning rate = 4.849449e-05
============================
Start of epoch 767
step 0: mean loss = 1.183515e-05
step 100: mean loss = 1.3281195e-05
step 200: mean loss = 1.42416575e-05
step 300: mean loss = 1.4037404e-05
epoch 767: mean loss = 1.3984133e-05  learning rate = 4.849449e-05
============================
Start of epoch 768
step 0: mean loss = 1.2612974e-05
step 100: mean loss = 1.2763376e-05
step 200: mean loss = 1.4548165e-05
step 300: mean loss = 1.4099953e-05
epoch 768: mean loss = 1.4016381e-05  learning rate = 4.849449e-05
============================
Start of epoch 769
step 0: mean loss = 9.442413e-06
step 100: mean loss = 1.5555315e-05
step 200: mean loss = 1.3986997e-05
step 300: mean loss = 1.3675181e-05
epoch 769: mean loss = 1.3883345e-05  learning rate = 4.849449e-05
============================
Start of epoch 770
step 0: mean loss = 1.3718434e-05
step 100: mean loss = 1.2982213e-05
step 200: mean loss = 1.4156044e-05
step 300: mean loss = 1.4251734e-05
epoch 770: mean loss = 1.4173129e-05  learning rate = 4.849449e-05
============================
Start of epoch 771
step 0: mean loss = 1.2982346e-05
step 100: mean loss = 1.4019344e-05
step 200: mean loss = 1.4218565e-05
step 300: mean loss = 1.4092812e-05
epoch 771: mean loss = 1.40476295e-05  learning rate = 4.849449e-05
============================
Start of epoch 772
step 0: mean loss = 1.0914033e-05
step 100: mean loss = 1.2464708e-05
step 200: mean loss = 1.3792375e-05
step 300: mean loss = 1.3947692e-05
epoch 772: mean loss = 1.3930346e-05  learning rate = 4.849449e-05
============================
Start of epoch 773
step 0: mean loss = 1.3494868e-05
step 100: mean loss = 1.3470582e-05
step 200: mean loss = 1.3731961e-05
step 300: mean loss = 1.4390829e-05
epoch 773: mean loss = 1.4295153e-05  learning rate = 4.849449e-05
============================
Start of epoch 774
step 0: mean loss = 1.1864546e-05
step 100: mean loss = 1.3655581e-05
step 200: mean loss = 1.3336882e-05
step 300: mean loss = 1.3841208e-05
epoch 774: mean loss = 1.3872685e-05  learning rate = 4.849449e-05
============================
Start of epoch 775
step 0: mean loss = 1.37740435e-05
step 100: mean loss = 1.3139492e-05
step 200: mean loss = 1.3892527e-05
step 300: mean loss = 1.4050113e-05
epoch 775: mean loss = 1.3987849e-05  learning rate = 4.849449e-05
============================
Start of epoch 776
step 0: mean loss = 1.30259305e-05
step 100: mean loss = 1.4622328e-05
step 200: mean loss = 1.42042345e-05
step 300: mean loss = 1.34883685e-05
epoch 776: mean loss = 1.3422822e-05  learning rate = 4.849449e-05
============================
Start of epoch 777
step 0: mean loss = 9.963941e-06
step 100: mean loss = 1.5169322e-05
step 200: mean loss = 1.4578601e-05
step 300: mean loss = 1.3782033e-05
epoch 777: mean loss = 1.3750012e-05  learning rate = 4.849449e-05
============================
Start of epoch 778
step 0: mean loss = 1.1889084e-05
step 100: mean loss = 1.43428715e-05
step 200: mean loss = 1.42694e-05
step 300: mean loss = 1.4117753e-05
epoch 778: mean loss = 1.4084981e-05  learning rate = 4.849449e-05
============================
Start of epoch 779
step 0: mean loss = 1.1861466e-05
step 100: mean loss = 1.2789882e-05
step 200: mean loss = 1.32214855e-05
step 300: mean loss = 1.3967142e-05
epoch 779: mean loss = 1.3931493e-05  learning rate = 4.849449e-05
============================
Start of epoch 780
step 0: mean loss = 1.1145148e-05
step 100: mean loss = 1.4163993e-05
step 200: mean loss = 1.3998704e-05
step 300: mean loss = 1.3829926e-05
epoch 780: mean loss = 1.3842505e-05  learning rate = 4.849449e-05
============================
Start of epoch 781
step 0: mean loss = 1.14638315e-05
step 100: mean loss = 1.2509849e-05
step 200: mean loss = 1.2570457e-05
step 300: mean loss = 1.3970001e-05
epoch 781: mean loss = 1.39538915e-05  learning rate = 4.849449e-05
============================
Start of epoch 782
step 0: mean loss = 1.2161361e-05
step 100: mean loss = 1.2534157e-05
step 200: mean loss = 1.3115939e-05
step 300: mean loss = 1.3321607e-05
epoch 782: mean loss = 1.3749173e-05  learning rate = 4.849449e-05
============================
Start of epoch 783
step 0: mean loss = 1.6963302e-05
step 100: mean loss = 1.5794612e-05
step 200: mean loss = 1.4445957e-05
step 300: mean loss = 1.4150051e-05
epoch 783: mean loss = 1.4073632e-05  learning rate = 4.849449e-05
============================
Start of epoch 784
step 0: mean loss = 1.0015821e-05
step 100: mean loss = 1.39850235e-05
step 200: mean loss = 1.3242729e-05
step 300: mean loss = 1.3842665e-05
epoch 784: mean loss = 1.3785392e-05  learning rate = 4.849449e-05
============================
Start of epoch 785
step 0: mean loss = 1.4106082e-05
step 100: mean loss = 1.3495437e-05
step 200: mean loss = 1.3571436e-05
step 300: mean loss = 1.366128e-05
epoch 785: mean loss = 1.3641226e-05  learning rate = 4.849449e-05
============================
Start of epoch 786
step 0: mean loss = 1.0638608e-05
step 100: mean loss = 1.3721933e-05
step 200: mean loss = 1.3930524e-05
step 300: mean loss = 1.3455789e-05
epoch 786: mean loss = 1.3727638e-05  learning rate = 4.849449e-05
============================
Start of epoch 787
step 0: mean loss = 1.1962223e-05
step 100: mean loss = 1.2587062e-05
step 200: mean loss = 1.3399242e-05
step 300: mean loss = 1.40381035e-05
epoch 787: mean loss = 1.4139567e-05  learning rate = 4.849449e-05
============================
Start of epoch 788
step 0: mean loss = 9.00131e-05
step 100: mean loss = 1.566671e-05
step 200: mean loss = 1.4723917e-05
step 300: mean loss = 1.4323132e-05
epoch 788: mean loss = 1.4221111e-05  learning rate = 4.849449e-05
============================
Start of epoch 789
step 0: mean loss = 1.1539649e-05
step 100: mean loss = 1.2993606e-05
step 200: mean loss = 1.3300221e-05
step 300: mean loss = 1.3942049e-05
epoch 789: mean loss = 1.3839349e-05  learning rate = 4.849449e-05
============================
Start of epoch 790
step 0: mean loss = 1.19661045e-05
step 100: mean loss = 1.2831364e-05
step 200: mean loss = 1.311758e-05
step 300: mean loss = 1.3548282e-05
epoch 790: mean loss = 1.35863e-05  learning rate = 4.849449e-05
============================
Start of epoch 791
step 0: mean loss = 1.7327888e-05
step 100: mean loss = 1.4778704e-05
step 200: mean loss = 1.4424682e-05
step 300: mean loss = 1.3920378e-05
epoch 791: mean loss = 1.38713285e-05  learning rate = 4.849449e-05
============================
Start of epoch 792
step 0: mean loss = 9.316383e-06
step 100: mean loss = 1.2112222e-05
step 200: mean loss = 1.3307699e-05
step 300: mean loss = 1.3851726e-05
epoch 792: mean loss = 1.3764529e-05  learning rate = 4.849449e-05
============================
Start of epoch 793
step 0: mean loss = 1.2392332e-05
step 100: mean loss = 1.2133123e-05
step 200: mean loss = 1.2775385e-05
step 300: mean loss = 1.3080227e-05
epoch 793: mean loss = 1.3583391e-05  learning rate = 4.849449e-05
============================
Start of epoch 794
step 0: mean loss = 1.4899554e-05
step 100: mean loss = 1.6744174e-05
step 200: mean loss = 1.501189e-05
step 300: mean loss = 1.4004957e-05
epoch 794: mean loss = 1.3948039e-05  learning rate = 4.849449e-05
============================
Start of epoch 795
step 0: mean loss = 1.27100175e-05
step 100: mean loss = 1.6285589e-05
step 200: mean loss = 1.4272078e-05
step 300: mean loss = 1.3676997e-05
epoch 795: mean loss = 1.3629641e-05  learning rate = 4.849449e-05
============================
Start of epoch 796
step 0: mean loss = 1.5485717e-05
step 100: mean loss = 1.22300735e-05
step 200: mean loss = 1.2345108e-05
step 300: mean loss = 1.3644013e-05
epoch 796: mean loss = 1.3774557e-05  learning rate = 4.849449e-05
============================
Start of epoch 797
step 0: mean loss = 1.3774581e-05
step 100: mean loss = 1.43107145e-05
step 200: mean loss = 1.50345895e-05
step 300: mean loss = 1.3892393e-05
epoch 797: mean loss = 1.3876547e-05  learning rate = 4.849449e-05
============================
Start of epoch 798
step 0: mean loss = 1.1873539e-05
step 100: mean loss = 1.2378931e-05
step 200: mean loss = 1.3388367e-05
step 300: mean loss = 1.4007922e-05
epoch 798: mean loss = 1.4034308e-05  learning rate = 4.6069767e-05
============================
Start of epoch 799
step 0: mean loss = 1.4189972e-05
step 100: mean loss = 1.372688e-05
step 200: mean loss = 1.3701744e-05
step 300: mean loss = 1.37265515e-05
epoch 799: mean loss = 1.3634204e-05  learning rate = 4.6069767e-05
saving the weights
++++++++++++++++++++++++++++++
Start of cycle 3
Total number of epochs in this cycle: 1600
Batch size in this cycle: 64
============================
WARNING:tensorflow:6 out of the last 7 calls to <function genDistInvPer at 0x7f4ef0a2e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function pyramidLayer.call at 0x7f4ed00a5cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function pyramidLayer.call at 0x7f4eec059950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 5 calls to <function gaussianPer at 0x7f4ef09d5b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function NUFFTLayerMultiChannelInit.call at 0x7f4eec059f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function pyramidLayer.call at 0x7f4eec059200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function pyramidLayer.call at 0x7f4e5a3135f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function MyDenseLayer.call at 0x7f4e5a313710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function DeepMDsimpleForces.call at 0x7f4f538dc440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Start of epoch 0
computing the FFT
applying the multipliers
(64, 1, 1001)
inverse fft
step 0: mean loss = 1.293443e-05
step 100: mean loss = 1.0715941e-05
epoch 0: mean loss = 1.0963814e-05  learning rate = 4.6069767e-05
============================
Start of epoch 1
step 0: mean loss = 1.1629005e-05
step 100: mean loss = 9.649274e-06
epoch 1: mean loss = 1.080967e-05  learning rate = 4.6069767e-05
============================
Start of epoch 2
step 0: mean loss = 7.9614365e-06
step 100: mean loss = 1.0284487e-05
epoch 2: mean loss = 1.10668925e-05  learning rate = 4.6069767e-05
============================
Start of epoch 3
step 0: mean loss = 9.829278e-06
step 100: mean loss = 1.0220516e-05
epoch 3: mean loss = 1.06236885e-05  learning rate = 4.6069767e-05
============================
Start of epoch 4
step 0: mean loss = 1.0523973e-05
step 100: mean loss = 1.1383152e-05
epoch 4: mean loss = 1.0810694e-05  learning rate = 4.6069767e-05
============================
Start of epoch 5
step 0: mean loss = 9.821072e-06
step 100: mean loss = 1.1339586e-05
epoch 5: mean loss = 1.0819811e-05  learning rate = 4.6069767e-05
============================
Start of epoch 6
step 0: mean loss = 1.1793545e-05
step 100: mean loss = 1.0696083e-05
epoch 6: mean loss = 1.0902754e-05  learning rate = 4.6069767e-05
============================
Start of epoch 7
step 0: mean loss = 8.821422e-06
step 100: mean loss = 1.1005323e-05
epoch 7: mean loss = 1.0958561e-05  learning rate = 4.6069767e-05
============================
Start of epoch 8
step 0: mean loss = 9.456857e-06
step 100: mean loss = 1.0737332e-05
epoch 8: mean loss = 1.0938307e-05  learning rate = 4.6069767e-05
============================
Start of epoch 9
step 0: mean loss = 1.0045458e-05
step 100: mean loss = 1.1974446e-05
epoch 9: mean loss = 1.1696842e-05  learning rate = 4.6069767e-05
============================
Start of epoch 10
step 0: mean loss = 9.365957e-06
step 100: mean loss = 1.1719163e-05
epoch 10: mean loss = 1.1177238e-05  learning rate = 4.6069767e-05
============================
Start of epoch 11
step 0: mean loss = 9.81643e-06
step 100: mean loss = 1.0916734e-05
epoch 11: mean loss = 1.08899585e-05  learning rate = 4.6069767e-05
============================
Start of epoch 12
step 0: mean loss = 1.1412393e-05
step 100: mean loss = 1.0785633e-05
epoch 12: mean loss = 1.1292822e-05  learning rate = 4.6069767e-05
============================
Start of epoch 13
step 0: mean loss = 9.200117e-06
step 100: mean loss = 1.1495322e-05
epoch 13: mean loss = 1.1288922e-05  learning rate = 4.6069767e-05
============================
Start of epoch 14
step 0: mean loss = 1.1342225e-05
step 100: mean loss = 1.14859795e-05
epoch 14: mean loss = 1.1160628e-05  learning rate = 4.6069767e-05
============================
Start of epoch 15
step 0: mean loss = 1.05661775e-05
step 100: mean loss = 1.0659638e-05
epoch 15: mean loss = 1.1073863e-05  learning rate = 4.6069767e-05
============================
Start of epoch 16
step 0: mean loss = 1.1948565e-05
step 100: mean loss = 1.1979713e-05
epoch 16: mean loss = 1.1348477e-05  learning rate = 4.6069767e-05
============================
Start of epoch 17
step 0: mean loss = 9.169497e-06
step 100: mean loss = 1.145305e-05
epoch 17: mean loss = 1.12927e-05  learning rate = 4.6069767e-05
============================
Start of epoch 18
step 0: mean loss = 9.636039e-06
step 100: mean loss = 1.0978621e-05
epoch 18: mean loss = 1.1033692e-05  learning rate = 4.6069767e-05
============================
Start of epoch 19
step 0: mean loss = 9.430218e-06
step 100: mean loss = 1.1858216e-05
epoch 19: mean loss = 1.1376942e-05  learning rate = 4.6069767e-05
============================
Start of epoch 20
step 0: mean loss = 9.570372e-06
step 100: mean loss = 1.0641332e-05
epoch 20: mean loss = 1.1068534e-05  learning rate = 4.6069767e-05
============================
Start of epoch 21
step 0: mean loss = 1.0171514e-05
step 100: mean loss = 1.2030571e-05
epoch 21: mean loss = 1.1364961e-05  learning rate = 4.6069767e-05
============================
Start of epoch 22
step 0: mean loss = 9.13398e-06
step 100: mean loss = 1.1648301e-05
epoch 22: mean loss = 1.1312496e-05  learning rate = 4.6069767e-05
============================
Start of epoch 23
step 0: mean loss = 9.594809e-06
step 100: mean loss = 1.0756073e-05
epoch 23: mean loss = 1.1109933e-05  learning rate = 4.6069767e-05
============================
Start of epoch 24
step 0: mean loss = 9.722171e-06
step 100: mean loss = 1.1202987e-05
epoch 24: mean loss = 1.12481675e-05  learning rate = 4.6069767e-05
============================
Start of epoch 25
step 0: mean loss = 1.2324176e-05
step 100: mean loss = 1.1367197e-05
epoch 25: mean loss = 1.1354547e-05  learning rate = 4.6069767e-05
============================
Start of epoch 26
step 0: mean loss = 1.0098656e-05
step 100: mean loss = 1.1923662e-05
epoch 26: mean loss = 1.1248929e-05  learning rate = 4.6069767e-05
============================
Start of epoch 27
step 0: mean loss = 9.82875e-06
step 100: mean loss = 1.1655084e-05
epoch 27: mean loss = 1.1178746e-05  learning rate = 4.6069767e-05
============================
Start of epoch 28
step 0: mean loss = 1.4306392e-05
step 100: mean loss = 1.0889911e-05
epoch 28: mean loss = 1.1038671e-05  learning rate = 4.6069767e-05
============================
Start of epoch 29
step 0: mean loss = 8.838019e-06
step 100: mean loss = 1.0908461e-05
epoch 29: mean loss = 1.0992223e-05  learning rate = 4.6069767e-05
============================
Start of epoch 30
step 0: mean loss = 8.7601165e-06
step 100: mean loss = 1.17046675e-05
epoch 30: mean loss = 1.1287548e-05  learning rate = 4.6069767e-05
============================
Start of epoch 31
step 0: mean loss = 1.193996e-05
step 100: mean loss = 1.0991124e-05
epoch 31: mean loss = 1.10992605e-05  learning rate = 4.6069767e-05
============================
Start of epoch 32
step 0: mean loss = 1.0264808e-05
step 100: mean loss = 1.1095626e-05
epoch 32: mean loss = 1.1048918e-05  learning rate = 4.6069767e-05
============================
Start of epoch 33
step 0: mean loss = 1.1335802e-05
step 100: mean loss = 1.0908676e-05
epoch 33: mean loss = 1.10286455e-05  learning rate = 4.6069767e-05
============================
Start of epoch 34
step 0: mean loss = 1.1338821e-05
step 100: mean loss = 1.08277245e-05
epoch 34: mean loss = 1.08910335e-05  learning rate = 4.6069767e-05
============================
Start of epoch 35
step 0: mean loss = 8.269909e-06
step 100: mean loss = 1.0742331e-05
epoch 35: mean loss = 1.0975552e-05  learning rate = 4.6069767e-05
============================
Start of epoch 36
step 0: mean loss = 9.21828e-06
step 100: mean loss = 1.08021295e-05
epoch 36: mean loss = 1.0820204e-05  learning rate = 4.6069767e-05
============================
Start of epoch 37
step 0: mean loss = 1.2059097e-05
step 100: mean loss = 1.1493689e-05
epoch 37: mean loss = 1.1017427e-05  learning rate = 4.6069767e-05
============================
Start of epoch 38
step 0: mean loss = 8.045339e-06
step 100: mean loss = 1.1241305e-05
epoch 38: mean loss = 1.0894547e-05  learning rate = 4.6069767e-05
============================
Start of epoch 39
step 0: mean loss = 9.476383e-06
step 100: mean loss = 1.075261e-05
epoch 39: mean loss = 1.0859268e-05  learning rate = 4.6069767e-05
============================
Start of epoch 40
step 0: mean loss = 9.3052995e-06
step 100: mean loss = 1.0152085e-05
epoch 40: mean loss = 1.0807789e-05  learning rate = 4.6069767e-05
============================
Start of epoch 41
step 0: mean loss = 9.881568e-06
step 100: mean loss = 1.0768843e-05
epoch 41: mean loss = 1.0980964e-05  learning rate = 4.6069767e-05
============================
Start of epoch 42
step 0: mean loss = 9.977866e-06
step 100: mean loss = 1.1389718e-05
epoch 42: mean loss = 1.0907607e-05  learning rate = 4.6069767e-05
============================
Start of epoch 43
step 0: mean loss = 8.826472e-06
step 100: mean loss = 1.1176473e-05
epoch 43: mean loss = 1.090372e-05  learning rate = 4.6069767e-05
============================
Start of epoch 44
step 0: mean loss = 8.645898e-06
step 100: mean loss = 1.0354497e-05
epoch 44: mean loss = 1.1102342e-05  learning rate = 4.6069767e-05
============================
Start of epoch 45
step 0: mean loss = 8.893714e-06
step 100: mean loss = 1.1051069e-05
epoch 45: mean loss = 1.0835397e-05  learning rate = 4.6069767e-05
============================
Start of epoch 46
step 0: mean loss = 1.2979803e-05
step 100: mean loss = 1.0870828e-05
epoch 46: mean loss = 1.0944574e-05  learning rate = 4.6069767e-05
============================
Start of epoch 47
step 0: mean loss = 1.0327273e-05
step 100: mean loss = 1.0443628e-05
epoch 47: mean loss = 1.0715859e-05  learning rate = 4.6069767e-05
============================
Start of epoch 48
step 0: mean loss = 8.92588e-06
step 100: mean loss = 1.0696111e-05
epoch 48: mean loss = 1.0882642e-05  learning rate = 4.6069767e-05
============================
Start of epoch 49
step 0: mean loss = 7.4269137e-06
step 100: mean loss = 1.0430065e-05
epoch 49: mean loss = 1.09184475e-05  learning rate = 4.6069767e-05
============================
Start of epoch 50
step 0: mean loss = 8.380519e-06
step 100: mean loss = 1.0223293e-05
epoch 50: mean loss = 1.0905255e-05  learning rate = 4.6069767e-05
============================
Start of epoch 51
step 0: mean loss = 1.0169068e-05
step 100: mean loss = 1.11347545e-05
epoch 51: mean loss = 1.0759087e-05  learning rate = 4.6069767e-05
============================
Start of epoch 52
step 0: mean loss = 1.086466e-05
step 100: mean loss = 1.1192969e-05
epoch 52: mean loss = 1.0913965e-05  learning rate = 4.6069767e-05
============================
Start of epoch 53
step 0: mean loss = 1.4503287e-05
step 100: mean loss = 1.0750518e-05
epoch 53: mean loss = 1.0892782e-05  learning rate = 4.6069767e-05
============================
Start of epoch 54
step 0: mean loss = 1.0093958e-05
step 100: mean loss = 1.13676115e-05
epoch 54: mean loss = 1.0817004e-05  learning rate = 4.6069767e-05
============================
Start of epoch 55
step 0: mean loss = 9.924973e-06
step 100: mean loss = 1.14543545e-05
epoch 55: mean loss = 1.1051694e-05  learning rate = 4.6069767e-05
============================
Start of epoch 56
step 0: mean loss = 9.544609e-06
step 100: mean loss = 1.05561785e-05
epoch 56: mean loss = 1.0837849e-05  learning rate = 4.6069767e-05
============================
Start of epoch 57
step 0: mean loss = 9.773901e-06
step 100: mean loss = 1.065733e-05
epoch 57: mean loss = 1.0985603e-05  learning rate = 4.6069767e-05
============================
Start of epoch 58
step 0: mean loss = 1.09272205e-05
step 100: mean loss = 1.0707209e-05
epoch 58: mean loss = 1.0902435e-05  learning rate = 4.6069767e-05
============================
Start of epoch 59
step 0: mean loss = 1.0556461e-05
step 100: mean loss = 1.1256078e-05
epoch 59: mean loss = 1.0875509e-05  learning rate = 4.6069767e-05
============================
Start of epoch 60
step 0: mean loss = 7.899536e-06
step 100: mean loss = 1.1242037e-05
epoch 60: mean loss = 1.090154e-05  learning rate = 4.6069767e-05
============================
Start of epoch 61
step 0: mean loss = 1.0699568e-05
step 100: mean loss = 1.1238855e-05
epoch 61: mean loss = 1.0713878e-05  learning rate = 4.6069767e-05
============================
Start of epoch 62
step 0: mean loss = 1.1579332e-05
step 100: mean loss = 1.057657e-05
epoch 62: mean loss = 1.0666219e-05  learning rate = 4.6069767e-05
============================
Start of epoch 63
step 0: mean loss = 1.1290115e-05
step 100: mean loss = 1.1226687e-05
epoch 63: mean loss = 1.0782187e-05  learning rate = 4.6069767e-05
============================
Start of epoch 64
step 0: mean loss = 1.027728e-05
step 100: mean loss = 1.1015891e-05
epoch 64: mean loss = 1.0859088e-05  learning rate = 4.6069767e-05
============================
Start of epoch 65
step 0: mean loss = 1.00854295e-05
step 100: mean loss = 1.1357565e-05
epoch 65: mean loss = 1.0828757e-05  learning rate = 4.6069767e-05
============================
Start of epoch 66
step 0: mean loss = 8.486588e-06
step 100: mean loss = 1.099493e-05
epoch 66: mean loss = 1.0597698e-05  learning rate = 4.6069767e-05
============================
Start of epoch 67
step 0: mean loss = 9.315032e-06
step 100: mean loss = 1.0568325e-05
epoch 67: mean loss = 1.0824415e-05  learning rate = 4.6069767e-05
============================
Start of epoch 68
step 0: mean loss = 9.901696e-06
step 100: mean loss = 1.0860246e-05
epoch 68: mean loss = 1.060966e-05  learning rate = 4.6069767e-05
============================
Start of epoch 69
step 0: mean loss = 1.0258833e-05
step 100: mean loss = 1.1050174e-05
epoch 69: mean loss = 1.113231e-05  learning rate = 4.6069767e-05
============================
Start of epoch 70
step 0: mean loss = 1.0224241e-05
step 100: mean loss = 1.1185955e-05
epoch 70: mean loss = 1.0781098e-05  learning rate = 4.6069767e-05
============================
Start of epoch 71
step 0: mean loss = 1.0159312e-05
step 100: mean loss = 1.0860385e-05
epoch 71: mean loss = 1.101112e-05  learning rate = 4.6069767e-05
============================
Start of epoch 72
step 0: mean loss = 1.0139696e-05
step 100: mean loss = 1.0457876e-05
epoch 72: mean loss = 1.0633701e-05  learning rate = 4.6069767e-05
============================
Start of epoch 73
step 0: mean loss = 1.0399981e-05
step 100: mean loss = 1.1531212e-05
epoch 73: mean loss = 1.0898946e-05  learning rate = 4.6069767e-05
============================
Start of epoch 74
step 0: mean loss = 8.731662e-06
step 100: mean loss = 1.09983275e-05
epoch 74: mean loss = 1.1020696e-05  learning rate = 4.6069767e-05
============================
Start of epoch 75
step 0: mean loss = 1.2736589e-05
step 100: mean loss = 1.18052e-05
epoch 75: mean loss = 1.1218258e-05  learning rate = 4.6069767e-05
============================
Start of epoch 76
step 0: mean loss = 1.1165295e-05
step 100: mean loss = 1.1832153e-05
epoch 76: mean loss = 1.1199405e-05  learning rate = 4.6069767e-05
============================
Start of epoch 77
step 0: mean loss = 1.0539148e-05
step 100: mean loss = 1.0395151e-05
epoch 77: mean loss = 1.098343e-05  learning rate = 4.376628e-05
============================
Start of epoch 78
step 0: mean loss = 9.619789e-06
step 100: mean loss = 9.883429e-06
epoch 78: mean loss = 1.0936854e-05  learning rate = 4.376628e-05
============================
Start of epoch 79
step 0: mean loss = 9.82432e-06
step 100: mean loss = 1.0479603e-05
epoch 79: mean loss = 1.0875219e-05  learning rate = 4.376628e-05
============================
Start of epoch 80
step 0: mean loss = 1.0267688e-05
step 100: mean loss = 1.1401615e-05
epoch 80: mean loss = 1.10726005e-05  learning rate = 4.376628e-05
============================
Start of epoch 81
step 0: mean loss = 4.76196e-05
step 100: mean loss = 1.1029577e-05
epoch 81: mean loss = 1.0928927e-05  learning rate = 4.376628e-05
============================
Start of epoch 82
step 0: mean loss = 8.677063e-06
step 100: mean loss = 1.1332304e-05
epoch 82: mean loss = 1.1161855e-05  learning rate = 4.376628e-05
============================
Start of epoch 83
step 0: mean loss = 1.0303807e-05
step 100: mean loss = 1.09595485e-05
epoch 83: mean loss = 1.099731e-05  learning rate = 4.376628e-05
============================
Start of epoch 84
step 0: mean loss = 1.0183358e-05
step 100: mean loss = 1.0230922e-05
epoch 84: mean loss = 1.08444865e-05  learning rate = 4.376628e-05
============================
Start of epoch 85
step 0: mean loss = 9.005772e-06
step 100: mean loss = 1.1065788e-05
epoch 85: mean loss = 1.1065684e-05  learning rate = 4.376628e-05
============================
Start of epoch 86
step 0: mean loss = 9.467397e-06
step 100: mean loss = 1.0997205e-05
epoch 86: mean loss = 1.0507491e-05  learning rate = 4.376628e-05
============================
Start of epoch 87
step 0: mean loss = 1.0670143e-05
step 100: mean loss = 1.0383264e-05
epoch 87: mean loss = 1.0842897e-05  learning rate = 4.376628e-05
============================
Start of epoch 88
step 0: mean loss = 9.880769e-06
step 100: mean loss = 1.0812952e-05
epoch 88: mean loss = 1.0990138e-05  learning rate = 4.376628e-05
============================
Start of epoch 89
step 0: mean loss = 9.004067e-06
step 100: mean loss = 1.0446334e-05
epoch 89: mean loss = 1.0581321e-05  learning rate = 4.376628e-05
============================
Start of epoch 90
step 0: mean loss = 9.496662e-06
step 100: mean loss = 9.691361e-06
epoch 90: mean loss = 1.0373819e-05  learning rate = 4.376628e-05
============================
Start of epoch 91
step 0: mean loss = 1.07917585e-05
step 100: mean loss = 1.0338396e-05
epoch 91: mean loss = 1.0466622e-05  learning rate = 4.376628e-05
============================
Start of epoch 92
step 0: mean loss = 1.0337874e-05
step 100: mean loss = 1.1515246e-05
epoch 92: mean loss = 1.0843387e-05  learning rate = 4.376628e-05
============================
Start of epoch 93
step 0: mean loss = 9.2190785e-06
step 100: mean loss = 1.0741606e-05
epoch 93: mean loss = 1.0755905e-05  learning rate = 4.376628e-05
============================
Start of epoch 94
step 0: mean loss = 9.934305e-06
step 100: mean loss = 1.0311048e-05
epoch 94: mean loss = 1.0371485e-05  learning rate = 4.376628e-05
============================
Start of epoch 95
step 0: mean loss = 9.91977e-06
step 100: mean loss = 1.0945249e-05
epoch 95: mean loss = 1.050556e-05  learning rate = 4.376628e-05
============================
Start of epoch 96
step 0: mean loss = 7.030678e-06
step 100: mean loss = 9.481008e-06
epoch 96: mean loss = 1.0382482e-05  learning rate = 4.376628e-05
============================
Start of epoch 97
step 0: mean loss = 1.0376533e-05
step 100: mean loss = 1.1175021e-05
epoch 97: mean loss = 1.1061044e-05  learning rate = 4.376628e-05
============================
Start of epoch 98
step 0: mean loss = 9.582468e-06
step 100: mean loss = 1.0328863e-05
epoch 98: mean loss = 1.03869215e-05  learning rate = 4.376628e-05
============================
Start of epoch 99
step 0: mean loss = 9.148982e-06
step 100: mean loss = 1.0274083e-05
epoch 99: mean loss = 1.03685825e-05  learning rate = 4.376628e-05
============================
Start of epoch 100
step 0: mean loss = 9.8843675e-06
step 100: mean loss = 1.1308989e-05
epoch 100: mean loss = 1.0957976e-05  learning rate = 4.376628e-05
============================
Start of epoch 101
step 0: mean loss = 8.135141e-06
step 100: mean loss = 1.0886212e-05
epoch 101: mean loss = 1.0874947e-05  learning rate = 4.376628e-05
============================
Start of epoch 102
step 0: mean loss = 1.1291953e-05
step 100: mean loss = 1.0927462e-05
epoch 102: mean loss = 1.0746667e-05  learning rate = 4.376628e-05
============================
Start of epoch 103
step 0: mean loss = 8.774816e-06
step 100: mean loss = 1.0624967e-05
epoch 103: mean loss = 1.10892115e-05  learning rate = 4.376628e-05
============================
Start of epoch 104
step 0: mean loss = 1.0428175e-05
step 100: mean loss = 1.1234414e-05
epoch 104: mean loss = 1.0725861e-05  learning rate = 4.376628e-05
============================
Start of epoch 105
step 0: mean loss = 1.0936282e-05
step 100: mean loss = 1.0487737e-05
epoch 105: mean loss = 1.0682045e-05  learning rate = 4.376628e-05
============================
Start of epoch 106
step 0: mean loss = 1.1363109e-05
step 100: mean loss = 1.1389269e-05
epoch 106: mean loss = 1.0720844e-05  learning rate = 4.376628e-05
============================
Start of epoch 107
step 0: mean loss = 1.0212691e-05
step 100: mean loss = 1.0901815e-05
epoch 107: mean loss = 1.0328179e-05  learning rate = 4.376628e-05
============================
Start of epoch 108
step 0: mean loss = 9.738246e-06
step 100: mean loss = 1.0141078e-05
epoch 108: mean loss = 1.056112e-05  learning rate = 4.376628e-05
============================
Start of epoch 109
step 0: mean loss = 9.585746e-06
step 100: mean loss = 1.1121397e-05
epoch 109: mean loss = 1.0935457e-05  learning rate = 4.376628e-05
============================
Start of epoch 110
step 0: mean loss = 7.453078e-06
step 100: mean loss = 1.02251715e-05
epoch 110: mean loss = 1.0781361e-05  learning rate = 4.376628e-05
============================
Start of epoch 111
step 0: mean loss = 9.385634e-06
step 100: mean loss = 9.517123e-06
epoch 111: mean loss = 1.0306701e-05  learning rate = 4.376628e-05
============================
Start of epoch 112
step 0: mean loss = 1.1074659e-05
step 100: mean loss = 1.0773841e-05
epoch 112: mean loss = 1.0953716e-05  learning rate = 4.376628e-05
============================
Start of epoch 113
step 0: mean loss = 1.0103864e-05
step 100: mean loss = 1.1529076e-05
epoch 113: mean loss = 1.0795933e-05  learning rate = 4.376628e-05
============================
Start of epoch 114
step 0: mean loss = 8.490299e-06
step 100: mean loss = 9.959361e-06
epoch 114: mean loss = 1.0214822e-05  learning rate = 4.376628e-05
============================
Start of epoch 115
step 0: mean loss = 9.47103e-06
step 100: mean loss = 1.0821611e-05
epoch 115: mean loss = 1.0816608e-05  learning rate = 4.376628e-05
============================
Start of epoch 116
step 0: mean loss = 1.0623447e-05
step 100: mean loss = 1.0268192e-05
epoch 116: mean loss = 1.03720695e-05  learning rate = 4.376628e-05
============================
Start of epoch 117
step 0: mean loss = 1.07621045e-05
step 100: mean loss = 1.04688415e-05
epoch 117: mean loss = 1.0812021e-05  learning rate = 4.376628e-05
============================
Start of epoch 118
step 0: mean loss = 1.06947655e-05
step 100: mean loss = 1.08478125e-05
epoch 118: mean loss = 1.0726668e-05  learning rate = 4.376628e-05
============================
Start of epoch 119
step 0: mean loss = 7.883645e-06
step 100: mean loss = 1.01804935e-05
epoch 119: mean loss = 1.0382441e-05  learning rate = 4.376628e-05
============================
Start of epoch 120
step 0: mean loss = 1.3356272e-05
step 100: mean loss = 1.0932383e-05
epoch 120: mean loss = 1.0344619e-05  learning rate = 4.376628e-05
============================
Start of epoch 121
step 0: mean loss = 9.7479315e-06
step 100: mean loss = 1.0723866e-05
epoch 121: mean loss = 1.0414043e-05  learning rate = 4.376628e-05
============================
Start of epoch 122
step 0: mean loss = 8.352784e-06
step 100: mean loss = 1.1250639e-05
epoch 122: mean loss = 1.0592973e-05  learning rate = 4.376628e-05
============================
Start of epoch 123
step 0: mean loss = 8.412058e-06
step 100: mean loss = 1.0035796e-05
epoch 123: mean loss = 1.025333e-05  learning rate = 4.376628e-05
============================
Start of epoch 124
step 0: mean loss = 9.1631155e-06
step 100: mean loss = 1.0075644e-05
epoch 124: mean loss = 1.04806195e-05  learning rate = 4.376628e-05
============================
Start of epoch 125
step 0: mean loss = 1.0742919e-05
step 100: mean loss = 9.7017255e-06
epoch 125: mean loss = 1.145806e-05  learning rate = 4.376628e-05
============================
Start of epoch 126
step 0: mean loss = 2.2746604e-05
step 100: mean loss = 1.3998261e-05
epoch 126: mean loss = 1.2331146e-05  learning rate = 4.376628e-05
============================
Start of epoch 127
step 0: mean loss = 8.574998e-06
step 100: mean loss = 1.1204853e-05
epoch 127: mean loss = 1.04424325e-05  learning rate = 4.376628e-05
============================
Start of epoch 128
step 0: mean loss = 7.652193e-06
step 100: mean loss = 1.0615e-05
epoch 128: mean loss = 1.0581725e-05  learning rate = 4.376628e-05
============================
Start of epoch 129
step 0: mean loss = 8.236451e-06
step 100: mean loss = 1.1308717e-05
epoch 129: mean loss = 1.064897e-05  learning rate = 4.376628e-05
============================
Start of epoch 130
step 0: mean loss = 5.0245697e-05
step 100: mean loss = 1.1622579e-05
epoch 130: mean loss = 1.0818813e-05  learning rate = 4.376628e-05
============================
Start of epoch 131
step 0: mean loss = 8.55968e-06
step 100: mean loss = 1.0001836e-05
epoch 131: mean loss = 1.00372545e-05  learning rate = 4.376628e-05
============================
Start of epoch 132
step 0: mean loss = 5.1139385e-05
step 100: mean loss = 1.127293e-05
epoch 132: mean loss = 1.0524521e-05  learning rate = 4.376628e-05
============================
Start of epoch 133
step 0: mean loss = 1.0600443e-05
step 100: mean loss = 1.0886569e-05
epoch 133: mean loss = 1.0767515e-05  learning rate = 4.376628e-05
============================
Start of epoch 134
step 0: mean loss = 1.08797285e-05
step 100: mean loss = 1.0528102e-05
epoch 134: mean loss = 1.0590769e-05  learning rate = 4.376628e-05
============================
Start of epoch 135
step 0: mean loss = 9.472013e-06
step 100: mean loss = 1.1006093e-05
epoch 135: mean loss = 1.0517255e-05  learning rate = 4.376628e-05
============================
Start of epoch 136
step 0: mean loss = 9.44882e-06
step 100: mean loss = 9.922902e-06
epoch 136: mean loss = 1.0077903e-05  learning rate = 4.376628e-05
============================
Start of epoch 137
step 0: mean loss = 9.378777e-06
step 100: mean loss = 1.0215691e-05
epoch 137: mean loss = 1.0707877e-05  learning rate = 4.376628e-05
============================
Start of epoch 138
step 0: mean loss = 1.0807406e-05
step 100: mean loss = 9.953953e-06
epoch 138: mean loss = 1.0247755e-05  learning rate = 4.376628e-05
============================
Start of epoch 139
step 0: mean loss = 9.323392e-06
step 100: mean loss = 1.0118134e-05
epoch 139: mean loss = 1.0392558e-05  learning rate = 4.376628e-05
============================
Start of epoch 140
step 0: mean loss = 9.101848e-06
step 100: mean loss = 9.890218e-06
epoch 140: mean loss = 1.0108308e-05  learning rate = 4.376628e-05
============================
Start of epoch 141
step 0: mean loss = 9.456175e-06
step 100: mean loss = 9.5576515e-06
epoch 141: mean loss = 1.0658114e-05  learning rate = 4.376628e-05
============================
Start of epoch 142
step 0: mean loss = 1.168336e-05
step 100: mean loss = 9.904761e-06
epoch 142: mean loss = 1.0596478e-05  learning rate = 4.376628e-05
============================
Start of epoch 143
step 0: mean loss = 8.374094e-06
step 100: mean loss = 1.0743027e-05
epoch 143: mean loss = 1.0601436e-05  learning rate = 4.376628e-05
============================
Start of epoch 144
step 0: mean loss = 1.0878644e-05
step 100: mean loss = 1.0806079e-05
epoch 144: mean loss = 1.031403e-05  learning rate = 4.376628e-05
============================
Start of epoch 145
step 0: mean loss = 1.02441945e-05
step 100: mean loss = 1.059438e-05
epoch 145: mean loss = 1.051418e-05  learning rate = 4.376628e-05
============================
Start of epoch 146
step 0: mean loss = 8.761227e-06
step 100: mean loss = 1.0202987e-05
epoch 146: mean loss = 1.03972525e-05  learning rate = 4.376628e-05
============================
Start of epoch 147
step 0: mean loss = 1.1154858e-05
step 100: mean loss = 1.0443177e-05
epoch 147: mean loss = 1.0262344e-05  learning rate = 4.376628e-05
============================
Start of epoch 148
step 0: mean loss = 9.790652e-06
step 100: mean loss = 9.874931e-06
epoch 148: mean loss = 1.0079124e-05  learning rate = 4.376628e-05
============================
Start of epoch 149
step 0: mean loss = 1.228859e-05
step 100: mean loss = 1.0725532e-05
epoch 149: mean loss = 1.0584958e-05  learning rate = 4.376628e-05
============================
Start of epoch 150
step 0: mean loss = 8.12749e-06
step 100: mean loss = 1.0702729e-05
epoch 150: mean loss = 1.0698997e-05  learning rate = 4.376628e-05
============================
Start of epoch 151
step 0: mean loss = 8.04609e-06
step 100: mean loss = 9.787896e-06
epoch 151: mean loss = 1.0551333e-05  learning rate = 4.376628e-05
============================
Start of epoch 152
step 0: mean loss = 9.937846e-06
step 100: mean loss = 1.0607552e-05
epoch 152: mean loss = 1.06815005e-05  learning rate = 4.376628e-05
============================
Start of epoch 153
step 0: mean loss = 9.126151e-06
step 100: mean loss = 9.863578e-06
epoch 153: mean loss = 1.0088058e-05  learning rate = 4.376628e-05
============================
Start of epoch 154
step 0: mean loss = 5.3196403e-05
step 100: mean loss = 1.0867406e-05
epoch 154: mean loss = 1.0727014e-05  learning rate = 4.376628e-05
============================
Start of epoch 155
step 0: mean loss = 1.1642797e-05
step 100: mean loss = 1.1119682e-05
epoch 155: mean loss = 1.0442322e-05  learning rate = 4.376628e-05
============================
Start of epoch 156
step 0: mean loss = 1.0743458e-05
step 100: mean loss = 1.0697427e-05
epoch 156: mean loss = 1.0574461e-05  learning rate = 4.1577965e-05
============================
Start of epoch 157
step 0: mean loss = 1.081502e-05
step 100: mean loss = 1.06407515e-05
epoch 157: mean loss = 1.0332823e-05  learning rate = 4.1577965e-05
============================
Start of epoch 158
step 0: mean loss = 1.0308783e-05
step 100: mean loss = 9.894241e-06
epoch 158: mean loss = 1.0030976e-05  learning rate = 4.1577965e-05
============================
Start of epoch 159
step 0: mean loss = 8.461675e-06
step 100: mean loss = 9.591816e-06
epoch 159: mean loss = 9.846084e-06  learning rate = 4.1577965e-05
============================
Start of epoch 160
step 0: mean loss = 1.0132258e-05
step 100: mean loss = 9.852631e-06
epoch 160: mean loss = 9.885283e-06  learning rate = 4.1577965e-05
============================
Start of epoch 161
step 0: mean loss = 1.06060925e-05
step 100: mean loss = 1.068057e-05
epoch 161: mean loss = 1.0203459e-05  learning rate = 4.1577965e-05
============================
Start of epoch 162
step 0: mean loss = 8.677034e-06
step 100: mean loss = 9.864514e-06
epoch 162: mean loss = 9.895665e-06  learning rate = 4.1577965e-05
============================
Start of epoch 163
step 0: mean loss = 8.5095635e-06
step 100: mean loss = 9.173766e-06
epoch 163: mean loss = 9.827496e-06  learning rate = 4.1577965e-05
============================
Start of epoch 164
step 0: mean loss = 7.4920354e-06
step 100: mean loss = 1.0565509e-05
epoch 164: mean loss = 1.0097534e-05  learning rate = 4.1577965e-05
============================
Start of epoch 165
step 0: mean loss = 1.1306016e-05
step 100: mean loss = 9.796884e-06
epoch 165: mean loss = 9.848911e-06  learning rate = 4.1577965e-05
============================
Start of epoch 166
step 0: mean loss = 8.754838e-06
step 100: mean loss = 9.645153e-06
epoch 166: mean loss = 9.883439e-06  learning rate = 4.1577965e-05
============================
Start of epoch 167
step 0: mean loss = 8.571208e-06
step 100: mean loss = 1.09515095e-05
epoch 167: mean loss = 1.0520295e-05  learning rate = 4.1577965e-05
============================
Start of epoch 168
step 0: mean loss = 9.484133e-06
step 100: mean loss = 9.559116e-06
epoch 168: mean loss = 9.782948e-06  learning rate = 4.1577965e-05
============================
Start of epoch 169
step 0: mean loss = 8.092221e-06
step 100: mean loss = 1.0077408e-05
epoch 169: mean loss = 9.791109e-06  learning rate = 4.1577965e-05
============================
Start of epoch 170
step 0: mean loss = 9.514781e-06
step 100: mean loss = 9.78048e-06
epoch 170: mean loss = 9.998433e-06  learning rate = 4.1577965e-05
============================
Start of epoch 171
step 0: mean loss = 8.317589e-06
step 100: mean loss = 9.846939e-06
epoch 171: mean loss = 9.894092e-06  learning rate = 4.1577965e-05
============================
Start of epoch 172
step 0: mean loss = 9.45512e-06
step 100: mean loss = 1.0405448e-05
epoch 172: mean loss = 1.009571e-05  learning rate = 4.1577965e-05
============================
Start of epoch 173
step 0: mean loss = 9.304149e-06
step 100: mean loss = 9.11485e-06
epoch 173: mean loss = 9.812909e-06  learning rate = 4.1577965e-05
============================
Start of epoch 174
step 0: mean loss = 1.08780805e-05
step 100: mean loss = 9.616806e-06
epoch 174: mean loss = 9.755977e-06  learning rate = 4.1577965e-05
============================
Start of epoch 175
step 0: mean loss = 1.1585942e-05
step 100: mean loss = 9.721177e-06
epoch 175: mean loss = 9.888653e-06  learning rate = 4.1577965e-05
============================
Start of epoch 176
step 0: mean loss = 9.034653e-06
step 100: mean loss = 1.0220859e-05
epoch 176: mean loss = 9.805215e-06  learning rate = 4.1577965e-05
============================
Start of epoch 177
step 0: mean loss = 7.771124e-06
step 100: mean loss = 9.549127e-06
epoch 177: mean loss = 9.690118e-06  learning rate = 4.1577965e-05
============================
Start of epoch 178
step 0: mean loss = 9.726016e-06
step 100: mean loss = 1.0360234e-05
epoch 178: mean loss = 9.918297e-06  learning rate = 4.1577965e-05
============================
Start of epoch 179
step 0: mean loss = 9.681926e-06
step 100: mean loss = 1.0882115e-05
epoch 179: mean loss = 1.0230701e-05  learning rate = 4.1577965e-05
============================
Start of epoch 180
step 0: mean loss = 1.0001895e-05
step 100: mean loss = 9.715461e-06
epoch 180: mean loss = 9.844541e-06  learning rate = 4.1577965e-05
============================
Start of epoch 181
step 0: mean loss = 9.462623e-06
step 100: mean loss = 1.1143027e-05
epoch 181: mean loss = 1.0351998e-05  learning rate = 4.1577965e-05
============================
Start of epoch 182
step 0: mean loss = 8.916053e-06
step 100: mean loss = 1.0347327e-05
epoch 182: mean loss = 9.791982e-06  learning rate = 4.1577965e-05
============================
Start of epoch 183
step 0: mean loss = 9.122112e-06
step 100: mean loss = 1.0362356e-05
epoch 183: mean loss = 1.0403806e-05  learning rate = 4.1577965e-05
============================
Start of epoch 184
step 0: mean loss = 1.03197735e-05
step 100: mean loss = 1.0852202e-05
epoch 184: mean loss = 1.0296762e-05  learning rate = 4.1577965e-05
============================
Start of epoch 185
step 0: mean loss = 9.246638e-06
step 100: mean loss = 1.0256453e-05
epoch 185: mean loss = 9.943581e-06  learning rate = 4.1577965e-05
============================
Start of epoch 186
step 0: mean loss = 8.384659e-06
step 100: mean loss = 9.128579e-06
epoch 186: mean loss = 9.863988e-06  learning rate = 4.1577965e-05
============================
Start of epoch 187
step 0: mean loss = 8.386205e-06
step 100: mean loss = 9.706748e-06
epoch 187: mean loss = 1.01553605e-05  learning rate = 4.1577965e-05
============================
Start of epoch 188
step 0: mean loss = 7.920054e-06
step 100: mean loss = 1.0273211e-05
epoch 188: mean loss = 1.0243027e-05  learning rate = 4.1577965e-05
============================
Start of epoch 189
step 0: mean loss = 8.600542e-06
step 100: mean loss = 1.0199956e-05
epoch 189: mean loss = 9.732618e-06  learning rate = 4.1577965e-05
============================
Start of epoch 190
step 0: mean loss = 8.283258e-06
step 100: mean loss = 1.0334872e-05
epoch 190: mean loss = 9.849077e-06  learning rate = 4.1577965e-05
============================
Start of epoch 191
step 0: mean loss = 8.567495e-06
step 100: mean loss = 9.454032e-06
epoch 191: mean loss = 9.706149e-06  learning rate = 4.1577965e-05
============================
Start of epoch 192
step 0: mean loss = 1.0889861e-05
step 100: mean loss = 1.0945416e-05
epoch 192: mean loss = 1.0330069e-05  learning rate = 4.1577965e-05
============================
Start of epoch 193
step 0: mean loss = 8.4143885e-06
step 100: mean loss = 1.1144451e-05
epoch 193: mean loss = 1.0281743e-05  learning rate = 4.1577965e-05
============================
Start of epoch 194
step 0: mean loss = 7.0096976e-06
step 100: mean loss = 1.0753465e-05
epoch 194: mean loss = 1.0155613e-05  learning rate = 4.1577965e-05
============================
Start of epoch 195
step 0: mean loss = 9.066175e-06
step 100: mean loss = 9.683476e-06
epoch 195: mean loss = 9.692698e-06  learning rate = 4.1577965e-05
============================
Start of epoch 196
step 0: mean loss = 9.161193e-06
step 100: mean loss = 9.1048605e-06
epoch 196: mean loss = 9.641331e-06  learning rate = 4.1577965e-05
============================
Start of epoch 197
step 0: mean loss = 1.03585135e-05
step 100: mean loss = 9.798077e-06
epoch 197: mean loss = 9.9788e-06  learning rate = 4.1577965e-05
============================
Start of epoch 198
step 0: mean loss = 9.692942e-06
step 100: mean loss = 9.49145e-06
epoch 198: mean loss = 9.6806325e-06  learning rate = 4.1577965e-05
============================
Start of epoch 199
step 0: mean loss = 9.326662e-06
step 100: mean loss = 9.54609e-06
epoch 199: mean loss = 9.969585e-06  learning rate = 4.1577965e-05
============================
Start of epoch 200
step 0: mean loss = 1.0424845e-05
step 100: mean loss = 1.0650606e-05
epoch 200: mean loss = 1.0324e-05  learning rate = 4.1577965e-05
============================
Start of epoch 201
step 0: mean loss = 7.9323345e-06
step 100: mean loss = 9.617614e-06
epoch 201: mean loss = 9.786337e-06  learning rate = 4.1577965e-05
============================
Start of epoch 202
step 0: mean loss = 8.313897e-06
step 100: mean loss = 1.0733006e-05
epoch 202: mean loss = 1.0193073e-05  learning rate = 4.1577965e-05
============================
Start of epoch 203
step 0: mean loss = 8.725107e-06
step 100: mean loss = 1.0259336e-05
epoch 203: mean loss = 1.01408e-05  learning rate = 4.1577965e-05
============================
Start of epoch 204
step 0: mean loss = 9.446033e-06
step 100: mean loss = 9.485263e-06
epoch 204: mean loss = 9.9346735e-06  learning rate = 4.1577965e-05
============================
Start of epoch 205
step 0: mean loss = 1.0140621e-05
step 100: mean loss = 1.0899434e-05
epoch 205: mean loss = 1.0161106e-05  learning rate = 4.1577965e-05
============================
Start of epoch 206
step 0: mean loss = 8.43541e-06
step 100: mean loss = 1.04858955e-05
epoch 206: mean loss = 1.0311764e-05  learning rate = 4.1577965e-05
============================
Start of epoch 207
step 0: mean loss = 9.604179e-06
step 100: mean loss = 9.52268e-06
epoch 207: mean loss = 9.939908e-06  learning rate = 4.1577965e-05
============================
Start of epoch 208
step 0: mean loss = 7.99309e-06
step 100: mean loss = 8.954877e-06
epoch 208: mean loss = 1.0128246e-05  learning rate = 4.1577965e-05
============================
Start of epoch 209
step 0: mean loss = 1.0803355e-05
step 100: mean loss = 1.0304137e-05
epoch 209: mean loss = 9.863519e-06  learning rate = 4.1577965e-05
============================
Start of epoch 210
step 0: mean loss = 9.317965e-06
step 100: mean loss = 8.8695115e-06
epoch 210: mean loss = 9.565752e-06  learning rate = 4.1577965e-05
============================
Start of epoch 211
step 0: mean loss = 9.338674e-06
step 100: mean loss = 1.0920442e-05
epoch 211: mean loss = 1.024064e-05  learning rate = 4.1577965e-05
============================
Start of epoch 212
step 0: mean loss = 7.0440883e-06
step 100: mean loss = 1.0161954e-05
epoch 212: mean loss = 1.00695415e-05  learning rate = 4.1577965e-05
============================
Start of epoch 213
step 0: mean loss = 9.336366e-06
step 100: mean loss = 9.433584e-06
epoch 213: mean loss = 9.743005e-06  learning rate = 4.1577965e-05
============================
Start of epoch 214
step 0: mean loss = 8.492513e-06
step 100: mean loss = 8.763557e-06
epoch 214: mean loss = 9.941401e-06  learning rate = 4.1577965e-05
============================
Start of epoch 215
step 0: mean loss = 7.304061e-06
step 100: mean loss = 1.0863799e-05
epoch 215: mean loss = 1.0186098e-05  learning rate = 4.1577965e-05
============================
Start of epoch 216
step 0: mean loss = 7.661655e-06
step 100: mean loss = 9.630668e-06
epoch 216: mean loss = 1.0061012e-05  learning rate = 4.1577965e-05
============================
Start of epoch 217
step 0: mean loss = 9.079822e-06
step 100: mean loss = 9.648166e-06
epoch 217: mean loss = 9.706054e-06  learning rate = 4.1577965e-05
============================
Start of epoch 218
step 0: mean loss = 8.567582e-06
step 100: mean loss = 1.0446362e-05
epoch 218: mean loss = 1.0226978e-05  learning rate = 4.1577965e-05
============================
Start of epoch 219
step 0: mean loss = 8.483508e-06
step 100: mean loss = 1.0386283e-05
epoch 219: mean loss = 1.0243232e-05  learning rate = 4.1577965e-05
============================
Start of epoch 220
step 0: mean loss = 7.433964e-06
step 100: mean loss = 9.311838e-06
epoch 220: mean loss = 9.960186e-06  learning rate = 4.1577965e-05
============================
Start of epoch 221
step 0: mean loss = 8.6064065e-06
step 100: mean loss = 9.594518e-06
epoch 221: mean loss = 1.0051602e-05  learning rate = 4.1577965e-05
============================
Start of epoch 222
step 0: mean loss = 8.488689e-06
step 100: mean loss = 9.991935e-06
epoch 222: mean loss = 9.953362e-06  learning rate = 4.1577965e-05
============================
Start of epoch 223
step 0: mean loss = 8.973393e-06
step 100: mean loss = 1.0213245e-05
epoch 223: mean loss = 1.0117533e-05  learning rate = 4.1577965e-05
============================
Start of epoch 224
step 0: mean loss = 9.049936e-06
step 100: mean loss = 9.710951e-06
epoch 224: mean loss = 1.0197929e-05  learning rate = 4.1577965e-05
============================
Start of epoch 225
step 0: mean loss = 8.606434e-06
step 100: mean loss = 1.0203953e-05
epoch 225: mean loss = 1.0101279e-05  learning rate = 4.1577965e-05
============================
Start of epoch 226
step 0: mean loss = 8.70883e-06
step 100: mean loss = 1.0486899e-05
epoch 226: mean loss = 1.0348834e-05  learning rate = 4.1577965e-05
============================
Start of epoch 227
step 0: mean loss = 9.113506e-06
step 100: mean loss = 9.9922e-06
epoch 227: mean loss = 9.579021e-06  learning rate = 4.1577965e-05
============================
Start of epoch 228
step 0: mean loss = 6.9592916e-06
step 100: mean loss = 1.0342696e-05
epoch 228: mean loss = 9.936552e-06  learning rate = 4.1577965e-05
============================
Start of epoch 229
step 0: mean loss = 7.914987e-06
step 100: mean loss = 9.702752e-06
epoch 229: mean loss = 9.797409e-06  learning rate = 4.1577965e-05
============================
Start of epoch 230
step 0: mean loss = 9.12822e-06
step 100: mean loss = 8.754963e-06
epoch 230: mean loss = 9.844314e-06  learning rate = 4.1577965e-05
============================
Start of epoch 231
step 0: mean loss = 1.0726682e-05
step 100: mean loss = 9.963158e-06
epoch 231: mean loss = 1.011304e-05  learning rate = 4.1577965e-05
============================
Start of epoch 232
step 0: mean loss = 8.508572e-06
step 100: mean loss = 9.586234e-06
epoch 232: mean loss = 1.0050189e-05  learning rate = 4.1577965e-05
============================
Start of epoch 233
step 0: mean loss = 9.618751e-06
step 100: mean loss = 1.0758927e-05
epoch 233: mean loss = 9.991152e-06  learning rate = 4.1577965e-05
============================
Start of epoch 234
step 0: mean loss = 7.932155e-06
step 100: mean loss = 1.0022062e-05
epoch 234: mean loss = 1.0147671e-05  learning rate = 4.1577965e-05
============================
Start of epoch 235
step 0: mean loss = 1.1509415e-05
step 100: mean loss = 1.0127068e-05
epoch 235: mean loss = 1.0118399e-05  learning rate = 4.1577965e-05
============================
Start of epoch 236
step 0: mean loss = 1.1384435e-05
step 100: mean loss = 1.0271047e-05
epoch 236: mean loss = 1.0067058e-05  learning rate = 3.9499064e-05
============================
Start of epoch 237
step 0: mean loss = 7.0353312e-06
step 100: mean loss = 1.0009312e-05
epoch 237: mean loss = 1.0006651e-05  learning rate = 3.9499064e-05
============================
Start of epoch 238
step 0: mean loss = 8.609508e-06
step 100: mean loss = 1.0547531e-05
epoch 238: mean loss = 1.0067291e-05  learning rate = 3.9499064e-05
============================
Start of epoch 239
step 0: mean loss = 9.387102e-06
step 100: mean loss = 9.339371e-06
epoch 239: mean loss = 1.0044582e-05  learning rate = 3.9499064e-05
============================
Start of epoch 240
step 0: mean loss = 9.100752e-06
step 100: mean loss = 1.0471551e-05
epoch 240: mean loss = 9.91686e-06  learning rate = 3.9499064e-05
============================
Start of epoch 241
step 0: mean loss = 8.40152e-06
step 100: mean loss = 9.953951e-06
epoch 241: mean loss = 9.628065e-06  learning rate = 3.9499064e-05
============================
Start of epoch 242
step 0: mean loss = 9.940048e-06
step 100: mean loss = 9.2264545e-06
epoch 242: mean loss = 9.553036e-06  learning rate = 3.9499064e-05
============================
Start of epoch 243
step 0: mean loss = 9.4156985e-06
step 100: mean loss = 1.0221864e-05
epoch 243: mean loss = 1.0155419e-05  learning rate = 3.9499064e-05
============================
Start of epoch 244
step 0: mean loss = 9.597405e-06
step 100: mean loss = 1.0497468e-05
epoch 244: mean loss = 1.0133345e-05  learning rate = 3.9499064e-05
============================
Start of epoch 245
step 0: mean loss = 8.441153e-06
step 100: mean loss = 9.648709e-06
epoch 245: mean loss = 1.0020677e-05  learning rate = 3.9499064e-05
============================
Start of epoch 246
step 0: mean loss = 8.704341e-06
step 100: mean loss = 9.029614e-06
epoch 246: mean loss = 1.0480637e-05  learning rate = 3.9499064e-05
============================
Start of epoch 247
step 0: mean loss = 1.6789185e-05
step 100: mean loss = 1.2515492e-05
epoch 247: mean loss = 1.14510885e-05  learning rate = 3.9499064e-05
============================
Start of epoch 248
step 0: mean loss = 7.843165e-06
step 100: mean loss = 9.241446e-06
epoch 248: mean loss = 9.865224e-06  learning rate = 3.9499064e-05
============================
Start of epoch 249
step 0: mean loss = 1.008632e-05
step 100: mean loss = 8.800354e-06
epoch 249: mean loss = 9.615886e-06  learning rate = 3.9499064e-05
============================
Start of epoch 250
step 0: mean loss = 8.6893015e-06
step 100: mean loss = 9.697805e-06
epoch 250: mean loss = 9.559888e-06  learning rate = 3.9499064e-05
============================
Start of epoch 251
step 0: mean loss = 1.0285952e-05
step 100: mean loss = 8.702096e-06
epoch 251: mean loss = 9.594161e-06  learning rate = 3.9499064e-05
============================
Start of epoch 252
step 0: mean loss = 1.2350538e-05
step 100: mean loss = 1.05902545e-05
epoch 252: mean loss = 9.901054e-06  learning rate = 3.9499064e-05
============================
Start of epoch 253
step 0: mean loss = 7.695308e-06
step 100: mean loss = 9.593005e-06
epoch 253: mean loss = 9.786625e-06  learning rate = 3.9499064e-05
============================
Start of epoch 254
step 0: mean loss = 1.0336469e-05
step 100: mean loss = 1.0467829e-05
epoch 254: mean loss = 9.64403e-06  learning rate = 3.9499064e-05
============================
Start of epoch 255
step 0: mean loss = 7.9775e-06
step 100: mean loss = 9.470849e-06
epoch 255: mean loss = 9.558832e-06  learning rate = 3.9499064e-05
============================
Start of epoch 256
step 0: mean loss = 9.798691e-06
step 100: mean loss = 8.571651e-06
epoch 256: mean loss = 9.4078705e-06  learning rate = 3.9499064e-05
============================
Start of epoch 257
step 0: mean loss = 7.7365585e-06
step 100: mean loss = 1.0089581e-05
epoch 257: mean loss = 9.560331e-06  learning rate = 3.9499064e-05
============================
Start of epoch 258
step 0: mean loss = 5.6689478e-05
step 100: mean loss = 9.708011e-06
epoch 258: mean loss = 9.227353e-06  learning rate = 3.9499064e-05
============================
Start of epoch 259
step 0: mean loss = 8.38167e-06
step 100: mean loss = 9.354955e-06
epoch 259: mean loss = 9.607263e-06  learning rate = 3.9499064e-05
============================
Start of epoch 260
step 0: mean loss = 8.56772e-06
step 100: mean loss = 9.124214e-06
epoch 260: mean loss = 9.221349e-06  learning rate = 3.9499064e-05
============================
Start of epoch 261
step 0: mean loss = 8.105975e-06
step 100: mean loss = 9.749885e-06
epoch 261: mean loss = 9.348135e-06  learning rate = 3.9499064e-05
============================
Start of epoch 262
step 0: mean loss = 9.448808e-06
step 100: mean loss = 9.1037255e-06
epoch 262: mean loss = 9.352162e-06  learning rate = 3.9499064e-05
============================
Start of epoch 263
step 0: mean loss = 8.820193e-06
step 100: mean loss = 9.132571e-06
epoch 263: mean loss = 9.30245e-06  learning rate = 3.9499064e-05
============================
Start of epoch 264
step 0: mean loss = 8.530511e-06
step 100: mean loss = 9.130162e-06
epoch 264: mean loss = 9.202766e-06  learning rate = 3.9499064e-05
============================
Start of epoch 265
step 0: mean loss = 9.183328e-06
step 100: mean loss = 9.120779e-06
epoch 265: mean loss = 9.272935e-06  learning rate = 3.9499064e-05
============================
Start of epoch 266
step 0: mean loss = 9.250365e-06
step 100: mean loss = 9.184422e-06
epoch 266: mean loss = 9.2794235e-06  learning rate = 3.9499064e-05
============================
Start of epoch 267
step 0: mean loss = 9.75769e-06
step 100: mean loss = 1.0004381e-05
epoch 267: mean loss = 9.368152e-06  learning rate = 3.9499064e-05
============================
Start of epoch 268
step 0: mean loss = 7.779341e-06
step 100: mean loss = 9.007809e-06
epoch 268: mean loss = 9.180949e-06  learning rate = 3.9499064e-05
============================
Start of epoch 269
step 0: mean loss = 9.336499e-06
step 100: mean loss = 1.0028184e-05
epoch 269: mean loss = 9.4331745e-06  learning rate = 3.9499064e-05
============================
Start of epoch 270
step 0: mean loss = 8.503899e-06
step 100: mean loss = 9.010036e-06
epoch 270: mean loss = 9.134347e-06  learning rate = 3.9499064e-05
============================
Start of epoch 271
step 0: mean loss = 7.312337e-06
step 100: mean loss = 9.758125e-06
epoch 271: mean loss = 9.358345e-06  learning rate = 3.9499064e-05
============================
Start of epoch 272
step 0: mean loss = 9.248294e-06
step 100: mean loss = 9.524077e-06
epoch 272: mean loss = 9.188391e-06  learning rate = 3.9499064e-05
============================
Start of epoch 273
step 0: mean loss = 9.238332e-06
step 100: mean loss = 9.0601125e-06
epoch 273: mean loss = 9.203194e-06  learning rate = 3.9499064e-05
============================
Start of epoch 274
step 0: mean loss = 9.419346e-06
step 100: mean loss = 8.689552e-06
epoch 274: mean loss = 9.285069e-06  learning rate = 3.9499064e-05
============================
Start of epoch 275
step 0: mean loss = 8.944206e-06
step 100: mean loss = 8.592515e-06
epoch 275: mean loss = 9.440289e-06  learning rate = 3.9499064e-05
============================
Start of epoch 276
step 0: mean loss = 7.2704966e-06
step 100: mean loss = 9.719725e-06
epoch 276: mean loss = 9.76655e-06  learning rate = 3.9499064e-05
============================
Start of epoch 277
step 0: mean loss = 8.883726e-06
step 100: mean loss = 8.988414e-06
epoch 277: mean loss = 9.2100545e-06  learning rate = 3.9499064e-05
============================
Start of epoch 278
step 0: mean loss = 8.59692e-06
step 100: mean loss = 9.1177e-06
epoch 278: mean loss = 9.276957e-06  learning rate = 3.9499064e-05
============================
Start of epoch 279
step 0: mean loss = 9.366887e-06
step 100: mean loss = 9.0033745e-06
epoch 279: mean loss = 9.6249105e-06  learning rate = 3.9499064e-05
============================
Start of epoch 280
step 0: mean loss = 9.152414e-06
step 100: mean loss = 9.397901e-06
epoch 280: mean loss = 9.946174e-06  learning rate = 3.9499064e-05
============================
Start of epoch 281
step 0: mean loss = 9.551055e-06
step 100: mean loss = 9.713444e-06
epoch 281: mean loss = 9.567416e-06  learning rate = 3.9499064e-05
============================
Start of epoch 282
step 0: mean loss = 8.084553e-06
step 100: mean loss = 9.522993e-06
epoch 282: mean loss = 9.844098e-06  learning rate = 3.9499064e-05
============================
Start of epoch 283
step 0: mean loss = 8.764883e-06
step 100: mean loss = 9.90155e-06
epoch 283: mean loss = 9.933447e-06  learning rate = 3.9499064e-05
============================
Start of epoch 284
step 0: mean loss = 7.716185e-06
step 100: mean loss = 9.324295e-06
epoch 284: mean loss = 9.702459e-06  learning rate = 3.9499064e-05
============================
Start of epoch 285
step 0: mean loss = 9.041214e-06
step 100: mean loss = 9.061242e-06
epoch 285: mean loss = 9.746136e-06  learning rate = 3.9499064e-05
============================
Start of epoch 286
step 0: mean loss = 8.204033e-06
step 100: mean loss = 9.774889e-06
epoch 286: mean loss = 9.7164875e-06  learning rate = 3.9499064e-05
============================
Start of epoch 287
step 0: mean loss = 8.388194e-06
step 100: mean loss = 9.676286e-06
epoch 287: mean loss = 9.331549e-06  learning rate = 3.9499064e-05
============================
Start of epoch 288
step 0: mean loss = 8.0852915e-06
step 100: mean loss = 9.785511e-06
epoch 288: mean loss = 9.304027e-06  learning rate = 3.9499064e-05
============================
Start of epoch 289
step 0: mean loss = 1.0414079e-05
step 100: mean loss = 9.308832e-06
epoch 289: mean loss = 9.454798e-06  learning rate = 3.9499064e-05
============================
Start of epoch 290
step 0: mean loss = 7.5262087e-06
step 100: mean loss = 1.0296901e-05
epoch 290: mean loss = 9.691203e-06  learning rate = 3.9499064e-05
============================
Start of epoch 291
step 0: mean loss = 8.0322e-06
step 100: mean loss = 9.151112e-06
epoch 291: mean loss = 9.373268e-06  learning rate = 3.9499064e-05
============================
Start of epoch 292
step 0: mean loss = 7.2667203e-06
step 100: mean loss = 8.914699e-06
epoch 292: mean loss = 9.52255e-06  learning rate = 3.9499064e-05
============================
Start of epoch 293
step 0: mean loss = 7.932678e-06
step 100: mean loss = 9.794005e-06
epoch 293: mean loss = 9.310435e-06  learning rate = 3.9499064e-05
============================
Start of epoch 294
step 0: mean loss = 8.866916e-06
step 100: mean loss = 9.2608825e-06
epoch 294: mean loss = 9.31118e-06  learning rate = 3.9499064e-05
============================
Start of epoch 295
step 0: mean loss = 7.603859e-06
step 100: mean loss = 9.986321e-06
epoch 295: mean loss = 9.891782e-06  learning rate = 3.9499064e-05
============================
Start of epoch 296
step 0: mean loss = 9.535879e-06
step 100: mean loss = 9.2452765e-06
epoch 296: mean loss = 9.34383e-06  learning rate = 3.9499064e-05
============================
Start of epoch 297
step 0: mean loss = 8.911693e-06
step 100: mean loss = 8.909248e-06
epoch 297: mean loss = 9.232588e-06  learning rate = 3.9499064e-05
============================
Start of epoch 298
step 0: mean loss = 7.0115707e-06
step 100: mean loss = 8.860911e-06
epoch 298: mean loss = 9.2903865e-06  learning rate = 3.9499064e-05
============================
Start of epoch 299
step 0: mean loss = 7.2061657e-06
step 100: mean loss = 8.764813e-06
epoch 299: mean loss = 9.279027e-06  learning rate = 3.9499064e-05
============================
Start of epoch 300
step 0: mean loss = 7.800062e-06
step 100: mean loss = 9.103604e-06
epoch 300: mean loss = 9.616538e-06  learning rate = 3.9499064e-05
============================
Start of epoch 301
step 0: mean loss = 8.749645e-06
step 100: mean loss = 9.581334e-06
epoch 301: mean loss = 9.540769e-06  learning rate = 3.9499064e-05
============================
Start of epoch 302
step 0: mean loss = 8.2012575e-06
step 100: mean loss = 9.3346825e-06
epoch 302: mean loss = 9.601264e-06  learning rate = 3.9499064e-05
============================
Start of epoch 303
step 0: mean loss = 9.7428265e-06
step 100: mean loss = 9.662014e-06
epoch 303: mean loss = 9.654246e-06  learning rate = 3.9499064e-05
============================
Start of epoch 304
step 0: mean loss = 8.948555e-06
step 100: mean loss = 8.947645e-06
epoch 304: mean loss = 9.383884e-06  learning rate = 3.9499064e-05
============================
Start of epoch 305
step 0: mean loss = 7.919645e-06
step 100: mean loss = 9.213882e-06
epoch 305: mean loss = 9.309911e-06  learning rate = 3.9499064e-05
============================
Start of epoch 306
step 0: mean loss = 8.260894e-06
step 100: mean loss = 9.712114e-06
epoch 306: mean loss = 9.654735e-06  learning rate = 3.9499064e-05
============================
Start of epoch 307
step 0: mean loss = 8.592732e-06
step 100: mean loss = 9.898518e-06
epoch 307: mean loss = 9.74465e-06  learning rate = 3.9499064e-05
============================
Start of epoch 308
step 0: mean loss = 7.853867e-06
step 100: mean loss = 9.079414e-06
epoch 308: mean loss = 9.629595e-06  learning rate = 3.9499064e-05
============================
Start of epoch 309
step 0: mean loss = 8.987602e-06
step 100: mean loss = 1.0267779e-05
epoch 309: mean loss = 9.589767e-06  learning rate = 3.9499064e-05
============================
Start of epoch 310
step 0: mean loss = 7.3870306e-06
step 100: mean loss = 1.02561e-05
epoch 310: mean loss = 9.474541e-06  learning rate = 3.9499064e-05
============================
Start of epoch 311
step 0: mean loss = 8.398663e-06
step 100: mean loss = 1.0207459e-05
epoch 311: mean loss = 9.598102e-06  learning rate = 3.9499064e-05
============================
Start of epoch 312
step 0: mean loss = 8.024606e-06
step 100: mean loss = 1.0502297e-05
epoch 312: mean loss = 1.0005236e-05  learning rate = 3.9499064e-05
============================
Start of epoch 313
step 0: mean loss = 8.162175e-06
step 100: mean loss = 9.730652e-06
epoch 313: mean loss = 9.7312695e-06  learning rate = 3.9499064e-05
============================
Start of epoch 314
step 0: mean loss = 7.5903563e-06
step 100: mean loss = 9.496754e-06
epoch 314: mean loss = 9.550074e-06  learning rate = 3.9499064e-05
============================
Start of epoch 315
step 0: mean loss = 7.988516e-06
step 100: mean loss = 9.517385e-06
epoch 315: mean loss = 9.651261e-06  learning rate = 3.752411e-05
============================
Start of epoch 316
step 0: mean loss = 1.3241626e-05
step 100: mean loss = 9.734851e-06
epoch 316: mean loss = 9.60976e-06  learning rate = 3.752411e-05
============================
Start of epoch 317
step 0: mean loss = 9.078349e-06
step 100: mean loss = 8.509151e-06
epoch 317: mean loss = 9.4959305e-06  learning rate = 3.752411e-05
============================
Start of epoch 318
step 0: mean loss = 9.030462e-06
step 100: mean loss = 9.829277e-06
epoch 318: mean loss = 9.412198e-06  learning rate = 3.752411e-05
============================
Start of epoch 319
step 0: mean loss = 7.5859316e-06
step 100: mean loss = 9.832253e-06
epoch 319: mean loss = 9.334962e-06  learning rate = 3.752411e-05
============================
Start of epoch 320
step 0: mean loss = 8.5043885e-06
step 100: mean loss = 8.150586e-06
epoch 320: mean loss = 9.4938205e-06  learning rate = 3.752411e-05
============================
Start of epoch 321
step 0: mean loss = 8.102038e-06
step 100: mean loss = 9.536313e-06
epoch 321: mean loss = 9.489346e-06  learning rate = 3.752411e-05
============================
Start of epoch 322
step 0: mean loss = 8.01177e-06
step 100: mean loss = 1.0259884e-05
epoch 322: mean loss = 9.524558e-06  learning rate = 3.752411e-05
============================
Start of epoch 323
step 0: mean loss = 7.925471e-06
step 100: mean loss = 9.63639e-06
epoch 323: mean loss = 9.465047e-06  learning rate = 3.752411e-05
============================
Start of epoch 324
step 0: mean loss = 7.829898e-06
step 100: mean loss = 9.320479e-06
epoch 324: mean loss = 9.363453e-06  learning rate = 3.752411e-05
============================
Start of epoch 325
step 0: mean loss = 8.432483e-06
step 100: mean loss = 9.888872e-06
epoch 325: mean loss = 9.294035e-06  learning rate = 3.752411e-05
============================
Start of epoch 326
step 0: mean loss = 8.541203e-06
step 100: mean loss = 9.196481e-06
epoch 326: mean loss = 9.531221e-06  learning rate = 3.752411e-05
============================
Start of epoch 327
step 0: mean loss = 9.699465e-06
step 100: mean loss = 1.0151631e-05
epoch 327: mean loss = 9.769648e-06  learning rate = 3.752411e-05
============================
Start of epoch 328
step 0: mean loss = 8.138344e-06
step 100: mean loss = 9.18589e-06
epoch 328: mean loss = 9.452754e-06  learning rate = 3.752411e-05
============================
Start of epoch 329
step 0: mean loss = 8.433435e-06
step 100: mean loss = 9.97795e-06
epoch 329: mean loss = 9.795806e-06  learning rate = 3.752411e-05
============================
Start of epoch 330
step 0: mean loss = 7.0071137e-06
step 100: mean loss = 1.0044839e-05
epoch 330: mean loss = 9.605322e-06  learning rate = 3.752411e-05
============================
Start of epoch 331
step 0: mean loss = 7.431483e-06
step 100: mean loss = 9.100821e-06
epoch 331: mean loss = 9.398255e-06  learning rate = 3.752411e-05
============================
Start of epoch 332
step 0: mean loss = 9.6486765e-06
step 100: mean loss = 9.9285035e-06
epoch 332: mean loss = 9.7804705e-06  learning rate = 3.752411e-05
============================
Start of epoch 333
step 0: mean loss = 8.515078e-06
step 100: mean loss = 9.868618e-06
epoch 333: mean loss = 9.619703e-06  learning rate = 3.752411e-05
============================
Start of epoch 334
step 0: mean loss = 9.05424e-06
step 100: mean loss = 9.857436e-06
epoch 334: mean loss = 9.670212e-06  learning rate = 3.752411e-05
============================
Start of epoch 335
step 0: mean loss = 1.0694328e-05
step 100: mean loss = 9.4389225e-06
epoch 335: mean loss = 9.742146e-06  learning rate = 3.752411e-05
============================
Start of epoch 336
step 0: mean loss = 7.628122e-06
step 100: mean loss = 1.0001785e-05
epoch 336: mean loss = 9.6543445e-06  learning rate = 3.752411e-05
============================
Start of epoch 337
step 0: mean loss = 7.816172e-06
step 100: mean loss = 8.712794e-06
epoch 337: mean loss = 9.603026e-06  learning rate = 3.752411e-05
============================
Start of epoch 338
step 0: mean loss = 8.022833e-06
step 100: mean loss = 9.7041575e-06
epoch 338: mean loss = 9.7674165e-06  learning rate = 3.752411e-05
============================
Start of epoch 339
step 0: mean loss = 7.994749e-06
step 100: mean loss = 9.492827e-06
epoch 339: mean loss = 9.572248e-06  learning rate = 3.752411e-05
============================
Start of epoch 340
step 0: mean loss = 7.1747872e-06
step 100: mean loss = 8.612346e-06
epoch 340: mean loss = 9.513856e-06  learning rate = 3.752411e-05
============================
Start of epoch 341
step 0: mean loss = 8.219919e-06
step 100: mean loss = 9.99429e-06
epoch 341: mean loss = 9.751005e-06  learning rate = 3.752411e-05
============================
Start of epoch 342
step 0: mean loss = 7.1436393e-06
step 100: mean loss = 9.807185e-06
epoch 342: mean loss = 9.618509e-06  learning rate = 3.752411e-05
============================
Start of epoch 343
step 0: mean loss = 8.17846e-06
step 100: mean loss = 9.706078e-06
epoch 343: mean loss = 9.759465e-06  learning rate = 3.752411e-05
============================
Start of epoch 344
step 0: mean loss = 8.128842e-06
step 100: mean loss = 9.294046e-06
epoch 344: mean loss = 9.44106e-06  learning rate = 3.752411e-05
============================
Start of epoch 345
step 0: mean loss = 8.371333e-06
step 100: mean loss = 9.569782e-06
epoch 345: mean loss = 9.928023e-06  learning rate = 3.752411e-05
============================
Start of epoch 346
step 0: mean loss = 8.293072e-06
step 100: mean loss = 9.0378535e-06
epoch 346: mean loss = 9.3237495e-06  learning rate = 3.752411e-05
============================
Start of epoch 347
step 0: mean loss = 9.137904e-06
step 100: mean loss = 9.2559285e-06
epoch 347: mean loss = 9.204155e-06  learning rate = 3.752411e-05
============================
Start of epoch 348
step 0: mean loss = 9.009725e-06
step 100: mean loss = 9.866543e-06
epoch 348: mean loss = 9.359485e-06  learning rate = 3.752411e-05
============================
Start of epoch 349
step 0: mean loss = 7.6197566e-06
step 100: mean loss = 9.242785e-06
epoch 349: mean loss = 9.395753e-06  learning rate = 3.752411e-05
============================
Start of epoch 350
step 0: mean loss = 8.566862e-06
step 100: mean loss = 9.7820775e-06
epoch 350: mean loss = 9.278764e-06  learning rate = 3.752411e-05
============================
Start of epoch 351
step 0: mean loss = 8.279334e-06
step 100: mean loss = 1.0051476e-05
epoch 351: mean loss = 9.537218e-06  learning rate = 3.752411e-05
============================
Start of epoch 352
step 0: mean loss = 8.408e-06
step 100: mean loss = 8.675543e-06
epoch 352: mean loss = 9.470814e-06  learning rate = 3.752411e-05
============================
Start of epoch 353
step 0: mean loss = 8.633252e-06
step 100: mean loss = 8.3051045e-06
epoch 353: mean loss = 9.19135e-06  learning rate = 3.752411e-05
============================
Start of epoch 354
step 0: mean loss = 9.014933e-06
step 100: mean loss = 9.0237945e-06
epoch 354: mean loss = 9.269693e-06  learning rate = 3.752411e-05
============================
Start of epoch 355
step 0: mean loss = 8.553825e-06
step 100: mean loss = 9.680286e-06
epoch 355: mean loss = 9.335415e-06  learning rate = 3.752411e-05
============================
Start of epoch 356
step 0: mean loss = 8.41152e-06
step 100: mean loss = 8.8381075e-06
epoch 356: mean loss = 9.369712e-06  learning rate = 3.752411e-05
============================
Start of epoch 357
step 0: mean loss = 7.2577986e-06
step 100: mean loss = 8.877934e-06
epoch 357: mean loss = 9.512232e-06  learning rate = 3.752411e-05
============================
Start of epoch 358
step 0: mean loss = 8.198954e-06
step 100: mean loss = 9.925253e-06
epoch 358: mean loss = 9.351808e-06  learning rate = 3.752411e-05
============================
Start of epoch 359
step 0: mean loss = 8.1516e-06
step 100: mean loss = 9.09163e-06
epoch 359: mean loss = 9.2845785e-06  learning rate = 3.752411e-05
============================
Start of epoch 360
step 0: mean loss = 7.622387e-06
step 100: mean loss = 9.955446e-06
epoch 360: mean loss = 9.245638e-06  learning rate = 3.752411e-05
============================
Start of epoch 361
step 0: mean loss = 7.4902146e-06
step 100: mean loss = 9.17855e-06
epoch 361: mean loss = 9.483698e-06  learning rate = 3.752411e-05
============================
Start of epoch 362
step 0: mean loss = 8.00568e-06
step 100: mean loss = 9.3467e-06
epoch 362: mean loss = 9.318266e-06  learning rate = 3.752411e-05
============================
Start of epoch 363
step 0: mean loss = 8.289381e-06
step 100: mean loss = 8.856183e-06
epoch 363: mean loss = 9.452597e-06  learning rate = 3.752411e-05
============================
Start of epoch 364
step 0: mean loss = 7.875164e-06
step 100: mean loss = 9.623039e-06
epoch 364: mean loss = 9.4087345e-06  learning rate = 3.752411e-05
============================
Start of epoch 365
step 0: mean loss = 8.3996e-06
step 100: mean loss = 8.895794e-06
epoch 365: mean loss = 9.459746e-06  learning rate = 3.752411e-05
============================
Start of epoch 366
step 0: mean loss = 8.067233e-06
step 100: mean loss = 9.464203e-06
epoch 366: mean loss = 9.7296415e-06  learning rate = 3.752411e-05
============================
Start of epoch 367
step 0: mean loss = 8.794397e-06
step 100: mean loss = 9.0140775e-06
epoch 367: mean loss = 9.587136e-06  learning rate = 3.752411e-05
============================
Start of epoch 368
step 0: mean loss = 8.66866e-06
step 100: mean loss = 1.0148818e-05
epoch 368: mean loss = 9.470248e-06  learning rate = 3.752411e-05
============================
Start of epoch 369
step 0: mean loss = 6.081228e-06
step 100: mean loss = 1.0268198e-05
epoch 369: mean loss = 9.8291175e-06  learning rate = 3.752411e-05
============================
Start of epoch 370
step 0: mean loss = 7.135456e-06
step 100: mean loss = 9.951769e-06
epoch 370: mean loss = 9.598192e-06  learning rate = 3.752411e-05
============================
Start of epoch 371
step 0: mean loss = 9.995343e-06
step 100: mean loss = 9.8375995e-06
epoch 371: mean loss = 9.677267e-06  learning rate = 3.752411e-05
============================
Start of epoch 372
step 0: mean loss = 8.351742e-06
step 100: mean loss = 8.812083e-06
epoch 372: mean loss = 9.257177e-06  learning rate = 3.752411e-05
============================
Start of epoch 373
step 0: mean loss = 7.875013e-06
step 100: mean loss = 1.0045115e-05
epoch 373: mean loss = 9.452341e-06  learning rate = 3.752411e-05
============================
Start of epoch 374
step 0: mean loss = 7.792409e-06
step 100: mean loss = 1.0055887e-05
epoch 374: mean loss = 9.423706e-06  learning rate = 3.752411e-05
============================
Start of epoch 375
step 0: mean loss = 7.709948e-06
step 100: mean loss = 8.50017e-06
epoch 375: mean loss = 9.173101e-06  learning rate = 3.752411e-05
============================
Start of epoch 376
step 0: mean loss = 9.243879e-06
step 100: mean loss = 1.0808851e-05
epoch 376: mean loss = 9.809783e-06  learning rate = 3.752411e-05
============================
Start of epoch 377
step 0: mean loss = 8.701565e-06
step 100: mean loss = 9.522817e-06
epoch 377: mean loss = 9.636821e-06  learning rate = 3.752411e-05
============================
Start of epoch 378
step 0: mean loss = 8.982797e-06
step 100: mean loss = 1.040875e-05
epoch 378: mean loss = 9.857832e-06  learning rate = 3.752411e-05
============================
Start of epoch 379
step 0: mean loss = 7.099218e-06
step 100: mean loss = 1.0225345e-05
epoch 379: mean loss = 9.636374e-06  learning rate = 3.752411e-05
============================
Start of epoch 380
step 0: mean loss = 7.2318726e-06
step 100: mean loss = 1.0259076e-05
epoch 380: mean loss = 9.730247e-06  learning rate = 3.752411e-05
============================
Start of epoch 381
step 0: mean loss = 7.954823e-06
step 100: mean loss = 1.0128202e-05
epoch 381: mean loss = 9.620776e-06  learning rate = 3.752411e-05
============================
Start of epoch 382
step 0: mean loss = 8.704866e-06
step 100: mean loss = 8.972559e-06
epoch 382: mean loss = 9.528896e-06  learning rate = 3.752411e-05
============================
Start of epoch 383
step 0: mean loss = 7.635018e-06
step 100: mean loss = 9.581767e-06
epoch 383: mean loss = 9.860435e-06  learning rate = 3.752411e-05
============================
Start of epoch 384
step 0: mean loss = 7.4734335e-06
step 100: mean loss = 9.961261e-06
epoch 384: mean loss = 9.567873e-06  learning rate = 3.752411e-05
============================
Start of epoch 385
step 0: mean loss = 7.0768665e-06
step 100: mean loss = 9.677877e-06
epoch 385: mean loss = 9.6318145e-06  learning rate = 3.752411e-05
============================
Start of epoch 386
step 0: mean loss = 7.5364915e-06
step 100: mean loss = 1.0388532e-05
epoch 386: mean loss = 9.660188e-06  learning rate = 3.752411e-05
============================
Start of epoch 387
step 0: mean loss = 8.53108e-06
step 100: mean loss = 9.111112e-06
epoch 387: mean loss = 9.493924e-06  learning rate = 3.752411e-05
============================
Start of epoch 388
step 0: mean loss = 7.779538e-06
step 100: mean loss = 9.753302e-06
epoch 388: mean loss = 9.694444e-06  learning rate = 3.752411e-05
============================
Start of epoch 389
step 0: mean loss = 7.662477e-06
step 100: mean loss = 9.486712e-06
epoch 389: mean loss = 9.416661e-06  learning rate = 3.752411e-05
============================
Start of epoch 390
step 0: mean loss = 9.607714e-06
step 100: mean loss = 1.0136025e-05
epoch 390: mean loss = 9.611182e-06  learning rate = 3.752411e-05
============================
Start of epoch 391
step 0: mean loss = 7.907689e-06
step 100: mean loss = 1.0252196e-05
epoch 391: mean loss = 9.51565e-06  learning rate = 3.752411e-05
============================
Start of epoch 392
step 0: mean loss = 8.912824e-06
step 100: mean loss = 9.441341e-06
epoch 392: mean loss = 9.332344e-06  learning rate = 3.752411e-05
============================
Start of epoch 393
step 0: mean loss = 7.468032e-06
step 100: mean loss = 9.537335e-06
epoch 393: mean loss = 9.346132e-06  learning rate = 3.752411e-05
============================
Start of epoch 394
step 0: mean loss = 1.00523475e-05
step 100: mean loss = 9.864647e-06
epoch 394: mean loss = 9.457924e-06  learning rate = 3.752411e-05
============================
Start of epoch 395
step 0: mean loss = 6.483832e-06
step 100: mean loss = 8.612432e-06
epoch 395: mean loss = 9.050314e-06  learning rate = 3.5647903e-05
============================
Start of epoch 396
step 0: mean loss = 6.869142e-06
step 100: mean loss = 9.526522e-06
epoch 396: mean loss = 9.280058e-06  learning rate = 3.5647903e-05
============================
Start of epoch 397
step 0: mean loss = 7.552373e-06
step 100: mean loss = 7.688718e-06
epoch 397: mean loss = 8.902687e-06  learning rate = 3.5647903e-05
============================
Start of epoch 398
step 0: mean loss = 9.427356e-06
step 100: mean loss = 9.99413e-06
epoch 398: mean loss = 9.186327e-06  learning rate = 3.5647903e-05
============================
Start of epoch 399
step 0: mean loss = 7.924542e-06
step 100: mean loss = 9.318711e-06
epoch 399: mean loss = 8.946775e-06  learning rate = 3.5647903e-05
============================
Start of epoch 400
step 0: mean loss = 7.721712e-06
step 100: mean loss = 9.60794e-06
epoch 400: mean loss = 9.006148e-06  learning rate = 3.5647903e-05
============================
Start of epoch 401
step 0: mean loss = 6.541113e-06
step 100: mean loss = 9.406799e-06
epoch 401: mean loss = 9.04281e-06  learning rate = 3.5647903e-05
============================
Start of epoch 402
step 0: mean loss = 6.532897e-06
step 100: mean loss = 8.030188e-06
epoch 402: mean loss = 9.011879e-06  learning rate = 3.5647903e-05
============================
Start of epoch 403
step 0: mean loss = 8.459154e-06
step 100: mean loss = 8.693628e-06
epoch 403: mean loss = 8.899876e-06  learning rate = 3.5647903e-05
============================
Start of epoch 404
step 0: mean loss = 7.5938165e-06
step 100: mean loss = 9.417094e-06
epoch 404: mean loss = 9.213241e-06  learning rate = 3.5647903e-05
============================
Start of epoch 405
step 0: mean loss = 7.131971e-06
step 100: mean loss = 8.691442e-06
epoch 405: mean loss = 8.90458e-06  learning rate = 3.5647903e-05
============================
Start of epoch 406
step 0: mean loss = 7.857622e-06
step 100: mean loss = 8.432715e-06
epoch 406: mean loss = 8.959827e-06  learning rate = 3.5647903e-05
============================
Start of epoch 407
step 0: mean loss = 9.833222e-06
step 100: mean loss = 8.748412e-06
epoch 407: mean loss = 9.063436e-06  learning rate = 3.5647903e-05
============================
Start of epoch 408
step 0: mean loss = 9.851292e-06
step 100: mean loss = 9.1426655e-06
epoch 408: mean loss = 8.985329e-06  learning rate = 3.5647903e-05
============================
Start of epoch 409
step 0: mean loss = 8.328338e-06
step 100: mean loss = 8.897363e-06
epoch 409: mean loss = 8.936622e-06  learning rate = 3.5647903e-05
============================
Start of epoch 410
step 0: mean loss = 7.551797e-06
step 100: mean loss = 8.947929e-06
epoch 410: mean loss = 8.888079e-06  learning rate = 3.5647903e-05
============================
Start of epoch 411
step 0: mean loss = 8.526348e-06
step 100: mean loss = 8.99289e-06
epoch 411: mean loss = 8.965257e-06  learning rate = 3.5647903e-05
============================
Start of epoch 412
step 0: mean loss = 7.4679187e-06
step 100: mean loss = 8.180744e-06
epoch 412: mean loss = 8.787376e-06  learning rate = 3.5647903e-05
============================
Start of epoch 413
step 0: mean loss = 8.896804e-06
step 100: mean loss = 8.979596e-06
epoch 413: mean loss = 8.934217e-06  learning rate = 3.5647903e-05
============================
Start of epoch 414
step 0: mean loss = 6.9389066e-06
step 100: mean loss = 9.333733e-06
epoch 414: mean loss = 8.947832e-06  learning rate = 3.5647903e-05
============================
Start of epoch 415
step 0: mean loss = 7.2399525e-06
step 100: mean loss = 9.609378e-06
epoch 415: mean loss = 9.019117e-06  learning rate = 3.5647903e-05
============================
Start of epoch 416
step 0: mean loss = 6.9283396e-06
step 100: mean loss = 8.616038e-06
epoch 416: mean loss = 8.982957e-06  learning rate = 3.5647903e-05
============================
Start of epoch 417
step 0: mean loss = 8.01995e-06
step 100: mean loss = 8.9314335e-06
epoch 417: mean loss = 9.108359e-06  learning rate = 3.5647903e-05
============================
Start of epoch 418
step 0: mean loss = 8.792542e-06
step 100: mean loss = 8.641247e-06
epoch 418: mean loss = 9.01593e-06  learning rate = 3.5647903e-05
============================
Start of epoch 419
step 0: mean loss = 7.983115e-06
step 100: mean loss = 8.8705465e-06
epoch 419: mean loss = 8.828895e-06  learning rate = 3.5647903e-05
============================
Start of epoch 420
step 0: mean loss = 7.662337e-06
step 100: mean loss = 9.065642e-06
epoch 420: mean loss = 8.861163e-06  learning rate = 3.5647903e-05
============================
Start of epoch 421
step 0: mean loss = 7.081382e-06
step 100: mean loss = 8.837026e-06
epoch 421: mean loss = 8.912318e-06  learning rate = 3.5647903e-05
============================
Start of epoch 422
step 0: mean loss = 6.695535e-06
step 100: mean loss = 9.5214355e-06
epoch 422: mean loss = 8.858787e-06  learning rate = 3.5647903e-05
============================
Start of epoch 423
step 0: mean loss = 7.946738e-06
step 100: mean loss = 8.642995e-06
epoch 423: mean loss = 8.82364e-06  learning rate = 3.5647903e-05
============================
Start of epoch 424
step 0: mean loss = 8.304935e-06
step 100: mean loss = 9.443421e-06
epoch 424: mean loss = 8.9872365e-06  learning rate = 3.5647903e-05
============================
Start of epoch 425
step 0: mean loss = 7.454588e-06
step 100: mean loss = 9.41907e-06
epoch 425: mean loss = 8.918736e-06  learning rate = 3.5647903e-05
============================
Start of epoch 426
step 0: mean loss = 7.4034538e-06
step 100: mean loss = 9.26546e-06
epoch 426: mean loss = 8.882663e-06  learning rate = 3.5647903e-05
============================
Start of epoch 427
step 0: mean loss = 7.390382e-06
step 100: mean loss = 8.670864e-06
epoch 427: mean loss = 8.915582e-06  learning rate = 3.5647903e-05
============================
Start of epoch 428
step 0: mean loss = 8.934335e-06
step 100: mean loss = 8.450537e-06
epoch 428: mean loss = 8.882804e-06  learning rate = 3.5647903e-05
============================
Start of epoch 429
step 0: mean loss = 7.323487e-06
step 100: mean loss = 9.029477e-06
epoch 429: mean loss = 8.973353e-06  learning rate = 3.5647903e-05
============================
Start of epoch 430
step 0: mean loss = 7.799257e-06
step 100: mean loss = 8.768011e-06
epoch 430: mean loss = 8.749064e-06  learning rate = 3.5647903e-05
============================
Start of epoch 431
step 0: mean loss = 8.187801e-06
step 100: mean loss = 9.500412e-06
epoch 431: mean loss = 8.83136e-06  learning rate = 3.5647903e-05
============================
Start of epoch 432
step 0: mean loss = 7.2316393e-06
step 100: mean loss = 8.977786e-06
epoch 432: mean loss = 8.855033e-06  learning rate = 3.5647903e-05
============================
Start of epoch 433
step 0: mean loss = 7.260017e-06
step 100: mean loss = 9.153006e-06
epoch 433: mean loss = 9.112517e-06  learning rate = 3.5647903e-05
============================
Start of epoch 434
step 0: mean loss = 7.851605e-06
step 100: mean loss = 9.444329e-06
epoch 434: mean loss = 8.810532e-06  learning rate = 3.5647903e-05
============================
Start of epoch 435
step 0: mean loss = 7.3047636e-06
step 100: mean loss = 9.049868e-06
epoch 435: mean loss = 8.824377e-06  learning rate = 3.5647903e-05
============================
Start of epoch 436
step 0: mean loss = 6.489331e-06
step 100: mean loss = 9.1459315e-06
epoch 436: mean loss = 8.792764e-06  learning rate = 3.5647903e-05
============================
Start of epoch 437
step 0: mean loss = 6.9899324e-06
step 100: mean loss = 9.2164855e-06
epoch 437: mean loss = 8.875109e-06  learning rate = 3.5647903e-05
============================
Start of epoch 438
step 0: mean loss = 6.7977267e-06
step 100: mean loss = 8.664315e-06
epoch 438: mean loss = 8.641037e-06  learning rate = 3.5647903e-05
============================
Start of epoch 439
step 0: mean loss = 8.436195e-06
step 100: mean loss = 8.833416e-06
epoch 439: mean loss = 9.036806e-06  learning rate = 3.5647903e-05
============================
Start of epoch 440
step 0: mean loss = 7.967557e-06
step 100: mean loss = 8.9408195e-06
epoch 440: mean loss = 8.851055e-06  learning rate = 3.5647903e-05
============================
Start of epoch 441
step 0: mean loss = 7.640546e-06
step 100: mean loss = 9.035257e-06
epoch 441: mean loss = 8.922486e-06  learning rate = 3.5647903e-05
============================
Start of epoch 442
step 0: mean loss = 8.438565e-06
step 100: mean loss = 9.000384e-06
epoch 442: mean loss = 8.826391e-06  learning rate = 3.5647903e-05
============================
Start of epoch 443
step 0: mean loss = 5.3629716e-05
step 100: mean loss = 8.713695e-06
epoch 443: mean loss = 8.767571e-06  learning rate = 3.5647903e-05
============================
Start of epoch 444
step 0: mean loss = 8.236204e-06
step 100: mean loss = 9.347677e-06
epoch 444: mean loss = 8.743828e-06  learning rate = 3.5647903e-05
============================
Start of epoch 445
step 0: mean loss = 9.192536e-06
step 100: mean loss = 7.766721e-06
epoch 445: mean loss = 8.780059e-06  learning rate = 3.5647903e-05
============================
Start of epoch 446
step 0: mean loss = 8.691e-06
step 100: mean loss = 9.197804e-06
epoch 446: mean loss = 8.686218e-06  learning rate = 3.5647903e-05
============================
Start of epoch 447
step 0: mean loss = 7.805573e-06
step 100: mean loss = 8.582133e-06
epoch 447: mean loss = 8.593895e-06  learning rate = 3.5647903e-05
============================
Start of epoch 448
step 0: mean loss = 7.614472e-06
step 100: mean loss = 8.940183e-06
epoch 448: mean loss = 8.717266e-06  learning rate = 3.5647903e-05
============================
Start of epoch 449
step 0: mean loss = 8.708515e-06
step 100: mean loss = 8.6166065e-06
epoch 449: mean loss = 8.6185255e-06  learning rate = 3.5647903e-05
============================
Start of epoch 450
step 0: mean loss = 8.614326e-06
step 100: mean loss = 8.448147e-06
epoch 450: mean loss = 8.75151e-06  learning rate = 3.5647903e-05
============================
Start of epoch 451
step 0: mean loss = 9.1717375e-06
step 100: mean loss = 7.864023e-06
epoch 451: mean loss = 8.50291e-06  learning rate = 3.5647903e-05
============================
Start of epoch 452
step 0: mean loss = 7.0139076e-06
step 100: mean loss = 8.188003e-06
epoch 452: mean loss = 8.632289e-06  learning rate = 3.5647903e-05
============================
Start of epoch 453
step 0: mean loss = 8.195784e-06
step 100: mean loss = 8.1586795e-06
epoch 453: mean loss = 8.661671e-06  learning rate = 3.5647903e-05
============================
Start of epoch 454
step 0: mean loss = 8.481255e-06
step 100: mean loss = 8.732328e-06
epoch 454: mean loss = 8.690522e-06  learning rate = 3.5647903e-05
============================
Start of epoch 455
step 0: mean loss = 8.7748995e-06
step 100: mean loss = 9.071737e-06
epoch 455: mean loss = 8.572249e-06  learning rate = 3.5647903e-05
============================
Start of epoch 456
step 0: mean loss = 8.358418e-06
step 100: mean loss = 7.8058465e-06
epoch 456: mean loss = 8.483903e-06  learning rate = 3.5647903e-05
============================
Start of epoch 457
step 0: mean loss = 8.488624e-06
step 100: mean loss = 8.7369435e-06
epoch 457: mean loss = 8.701904e-06  learning rate = 3.5647903e-05
============================
Start of epoch 458
step 0: mean loss = 9.407692e-06
step 100: mean loss = 9.137049e-06
epoch 458: mean loss = 8.678304e-06  learning rate = 3.5647903e-05
============================
Start of epoch 459
step 0: mean loss = 8.026215e-06
step 100: mean loss = 8.201314e-06
epoch 459: mean loss = 8.52282e-06  learning rate = 3.5647903e-05
============================
Start of epoch 460
step 0: mean loss = 8.337733e-06
step 100: mean loss = 8.253596e-06
epoch 460: mean loss = 8.613936e-06  learning rate = 3.5647903e-05
============================
Start of epoch 461
step 0: mean loss = 1.012666e-05
step 100: mean loss = 9.131617e-06
epoch 461: mean loss = 8.856145e-06  learning rate = 3.5647903e-05
============================
Start of epoch 462
step 0: mean loss = 6.9000093e-06
step 100: mean loss = 8.502053e-06
epoch 462: mean loss = 8.541109e-06  learning rate = 3.5647903e-05
============================
Start of epoch 463
step 0: mean loss = 7.683294e-06
step 100: mean loss = 7.687446e-06
epoch 463: mean loss = 8.592016e-06  learning rate = 3.5647903e-05
============================
Start of epoch 464
step 0: mean loss = 7.737692e-06
step 100: mean loss = 9.009691e-06
epoch 464: mean loss = 8.490199e-06  learning rate = 3.5647903e-05
============================
Start of epoch 465
step 0: mean loss = 7.742762e-06
step 100: mean loss = 8.864833e-06
epoch 465: mean loss = 8.391642e-06  learning rate = 3.5647903e-05
============================
Start of epoch 466
step 0: mean loss = 7.973008e-06
step 100: mean loss = 8.243406e-06
epoch 466: mean loss = 8.642118e-06  learning rate = 3.5647903e-05
============================
Start of epoch 467
step 0: mean loss = 6.9732255e-06
step 100: mean loss = 7.777446e-06
epoch 467: mean loss = 8.494499e-06  learning rate = 3.5647903e-05
============================
Start of epoch 468
step 0: mean loss = 9.874693e-06
step 100: mean loss = 9.363672e-06
epoch 468: mean loss = 8.653578e-06  learning rate = 3.5647903e-05
============================
Start of epoch 469
step 0: mean loss = 6.8795807e-06
step 100: mean loss = 8.573196e-06
epoch 469: mean loss = 8.587834e-06  learning rate = 3.5647903e-05
============================
Start of epoch 470
step 0: mean loss = 9.068772e-06
step 100: mean loss = 8.1855815e-06
epoch 470: mean loss = 8.629881e-06  learning rate = 3.5647903e-05
============================
Start of epoch 471
step 0: mean loss = 9.083058e-06
step 100: mean loss = 7.387419e-06
epoch 471: mean loss = 8.448671e-06  learning rate = 3.5647903e-05
============================
Start of epoch 472
step 0: mean loss = 8.506628e-06
step 100: mean loss = 8.85537e-06
epoch 472: mean loss = 8.511902e-06  learning rate = 3.5647903e-05
============================
Start of epoch 473
step 0: mean loss = 7.564362e-06
step 100: mean loss = 9.069629e-06
epoch 473: mean loss = 8.563184e-06  learning rate = 3.5647903e-05
============================
Start of epoch 474
step 0: mean loss = 8.5929205e-06
step 100: mean loss = 8.2746665e-06
epoch 474: mean loss = 8.358742e-06  learning rate = 3.5647903e-05
============================
Start of epoch 475
step 0: mean loss = 8.862857e-06
step 100: mean loss = 8.461336e-06
epoch 475: mean loss = 8.406465e-06  learning rate = 3.3865508e-05
============================
Start of epoch 476
step 0: mean loss = 7.0650094e-06
step 100: mean loss = 8.80549e-06
epoch 476: mean loss = 8.4212115e-06  learning rate = 3.3865508e-05
============================
Start of epoch 477
step 0: mean loss = 6.306666e-06
step 100: mean loss = 8.279956e-06
epoch 477: mean loss = 8.350021e-06  learning rate = 3.3865508e-05
============================
Start of epoch 478
step 0: mean loss = 7.3513484e-06
step 100: mean loss = 8.64507e-06
epoch 478: mean loss = 8.302265e-06  learning rate = 3.3865508e-05
============================
Start of epoch 479
step 0: mean loss = 6.6361263e-06
step 100: mean loss = 7.970841e-06
epoch 479: mean loss = 8.313615e-06  learning rate = 3.3865508e-05
============================
Start of epoch 480
step 0: mean loss = 6.7504143e-06
step 100: mean loss = 8.9659825e-06
epoch 480: mean loss = 8.610127e-06  learning rate = 3.3865508e-05
============================
Start of epoch 481
step 0: mean loss = 7.9949e-06
step 100: mean loss = 8.7383405e-06
epoch 481: mean loss = 8.316746e-06  learning rate = 3.3865508e-05
============================
Start of epoch 482
step 0: mean loss = 7.0177175e-06
step 100: mean loss = 9.357996e-06
epoch 482: mean loss = 8.617471e-06  learning rate = 3.3865508e-05
============================
Start of epoch 483
step 0: mean loss = 6.6351754e-06
step 100: mean loss = 8.9216055e-06
epoch 483: mean loss = 8.4121675e-06  learning rate = 3.3865508e-05
============================
Start of epoch 484
step 0: mean loss = 7.5043654e-06
step 100: mean loss = 8.621035e-06
epoch 484: mean loss = 8.221882e-06  learning rate = 3.3865508e-05
============================
Start of epoch 485
step 0: mean loss = 6.608607e-06
step 100: mean loss = 8.360541e-06
epoch 485: mean loss = 8.332131e-06  learning rate = 3.3865508e-05
============================
Start of epoch 486
step 0: mean loss = 8.184045e-06
step 100: mean loss = 8.171395e-06
epoch 486: mean loss = 8.4436615e-06  learning rate = 3.3865508e-05
============================
Start of epoch 487
step 0: mean loss = 8.006742e-06
step 100: mean loss = 9.122711e-06
epoch 487: mean loss = 8.571554e-06  learning rate = 3.3865508e-05
============================
Start of epoch 488
step 0: mean loss = 9.401575e-06
step 100: mean loss = 7.54043e-06
epoch 488: mean loss = 8.387874e-06  learning rate = 3.3865508e-05
============================
Start of epoch 489
step 0: mean loss = 8.865778e-06
step 100: mean loss = 8.1108e-06
epoch 489: mean loss = 8.554334e-06  learning rate = 3.3865508e-05
============================
Start of epoch 490
step 0: mean loss = 6.7572996e-06
step 100: mean loss = 8.033807e-06
epoch 490: mean loss = 8.488153e-06  learning rate = 3.3865508e-05
============================
Start of epoch 491
step 0: mean loss = 7.179029e-06
step 100: mean loss = 9.220624e-06
epoch 491: mean loss = 8.732444e-06  learning rate = 3.3865508e-05
============================
Start of epoch 492
step 0: mean loss = 7.279974e-06
step 100: mean loss = 8.117528e-06
epoch 492: mean loss = 8.567811e-06  learning rate = 3.3865508e-05
============================
Start of epoch 493
step 0: mean loss = 7.8811245e-06
step 100: mean loss = 8.434214e-06
epoch 493: mean loss = 8.80319e-06  learning rate = 3.3865508e-05
============================
Start of epoch 494
step 0: mean loss = 7.4375466e-06
step 100: mean loss = 8.964962e-06
epoch 494: mean loss = 8.467096e-06  learning rate = 3.3865508e-05
============================
Start of epoch 495
step 0: mean loss = 7.884651e-06
step 100: mean loss = 9.4504285e-06
epoch 495: mean loss = 8.6675645e-06  learning rate = 3.3865508e-05
============================
Start of epoch 496
step 0: mean loss = 9.437956e-06
step 100: mean loss = 8.467808e-06
epoch 496: mean loss = 8.568552e-06  learning rate = 3.3865508e-05
============================
Start of epoch 497
step 0: mean loss = 6.8049458e-06
step 100: mean loss = 8.936538e-06
epoch 497: mean loss = 8.613129e-06  learning rate = 3.3865508e-05
============================
Start of epoch 498
step 0: mean loss = 8.731624e-06
step 100: mean loss = 8.710163e-06
epoch 498: mean loss = 8.5890415e-06  learning rate = 3.3865508e-05
============================
Start of epoch 499
step 0: mean loss = 6.3650405e-06
step 100: mean loss = 9.25508e-06
epoch 499: mean loss = 8.638123e-06  learning rate = 3.3865508e-05
============================
Start of epoch 500
step 0: mean loss = 6.9208063e-06
step 100: mean loss = 8.372424e-06
epoch 500: mean loss = 8.673734e-06  learning rate = 3.3865508e-05
============================
Start of epoch 501
step 0: mean loss = 8.859616e-06
step 100: mean loss = 7.964892e-06
epoch 501: mean loss = 8.628337e-06  learning rate = 3.3865508e-05
============================
Start of epoch 502
step 0: mean loss = 7.5694384e-06
step 100: mean loss = 8.050209e-06
epoch 502: mean loss = 8.6699965e-06  learning rate = 3.3865508e-05
============================
Start of epoch 503
step 0: mean loss = 7.0148367e-06
step 100: mean loss = 8.941363e-06
epoch 503: mean loss = 8.479654e-06  learning rate = 3.3865508e-05
============================
Start of epoch 504
step 0: mean loss = 8.693987e-06
step 100: mean loss = 8.722653e-06
epoch 504: mean loss = 8.499982e-06  learning rate = 3.3865508e-05
============================
Start of epoch 505
step 0: mean loss = 8.628172e-06
step 100: mean loss = 8.574659e-06
epoch 505: mean loss = 8.689963e-06  learning rate = 3.3865508e-05
============================
Start of epoch 506
step 0: mean loss = 7.3278443e-06
step 100: mean loss = 8.142358e-06
epoch 506: mean loss = 8.4524845e-06  learning rate = 3.3865508e-05
============================
Start of epoch 507
step 0: mean loss = 8.7657745e-06
step 100: mean loss = 7.5559533e-06
epoch 507: mean loss = 8.718859e-06  learning rate = 3.3865508e-05
============================
Start of epoch 508
step 0: mean loss = 7.892402e-06
step 100: mean loss = 8.153753e-06
epoch 508: mean loss = 8.76959e-06  learning rate = 3.3865508e-05
============================
Start of epoch 509
step 0: mean loss = 9.32769e-06
step 100: mean loss = 9.118586e-06
epoch 509: mean loss = 8.614788e-06  learning rate = 3.3865508e-05
============================
Start of epoch 510
step 0: mean loss = 7.976685e-06
step 100: mean loss = 8.80332e-06
epoch 510: mean loss = 8.602808e-06  learning rate = 3.3865508e-05
============================
Start of epoch 511
step 0: mean loss = 7.5944126e-06
step 100: mean loss = 8.027367e-06
epoch 511: mean loss = 8.647652e-06  learning rate = 3.3865508e-05
============================
Start of epoch 512
step 0: mean loss = 9.099154e-06
step 100: mean loss = 8.73507e-06
epoch 512: mean loss = 8.855735e-06  learning rate = 3.3865508e-05
============================
Start of epoch 513
step 0: mean loss = 7.2489934e-06
step 100: mean loss = 8.303884e-06
epoch 513: mean loss = 8.652358e-06  learning rate = 3.3865508e-05
============================
Start of epoch 514
step 0: mean loss = 6.575038e-06
step 100: mean loss = 9.054112e-06
epoch 514: mean loss = 8.7076005e-06  learning rate = 3.3865508e-05
============================
Start of epoch 515
step 0: mean loss = 7.6139786e-06
step 100: mean loss = 8.520869e-06
epoch 515: mean loss = 8.605888e-06  learning rate = 3.3865508e-05
============================
Start of epoch 516
step 0: mean loss = 6.7222854e-06
step 100: mean loss = 8.487147e-06
epoch 516: mean loss = 8.879206e-06  learning rate = 3.3865508e-05
============================
Start of epoch 517
step 0: mean loss = 8.604322e-06
step 100: mean loss = 8.44499e-06
epoch 517: mean loss = 8.662639e-06  learning rate = 3.3865508e-05
============================
Start of epoch 518
step 0: mean loss = 7.343242e-06
step 100: mean loss = 8.554199e-06
epoch 518: mean loss = 8.871953e-06  learning rate = 3.3865508e-05
============================
Start of epoch 519
step 0: mean loss = 2.4921908e-05
step 100: mean loss = 9.260745e-06
epoch 519: mean loss = 8.648721e-06  learning rate = 3.3865508e-05
============================
Start of epoch 520
step 0: mean loss = 6.5285863e-06
step 100: mean loss = 8.7298295e-06
epoch 520: mean loss = 8.648055e-06  learning rate = 3.3865508e-05
============================
Start of epoch 521
step 0: mean loss = 8.040061e-06
step 100: mean loss = 8.053226e-06
epoch 521: mean loss = 8.7672615e-06  learning rate = 3.3865508e-05
============================
Start of epoch 522
step 0: mean loss = 7.529431e-06
step 100: mean loss = 7.824756e-06
epoch 522: mean loss = 8.768673e-06  learning rate = 3.3865508e-05
============================
Start of epoch 523
step 0: mean loss = 8.404326e-06
step 100: mean loss = 8.430798e-06
epoch 523: mean loss = 8.693549e-06  learning rate = 3.3865508e-05
============================
Start of epoch 524
step 0: mean loss = 8.228031e-06
step 100: mean loss = 8.289688e-06
epoch 524: mean loss = 8.545289e-06  learning rate = 3.3865508e-05
============================
Start of epoch 525
step 0: mean loss = 1.1922024e-05
step 100: mean loss = 9.166854e-06
epoch 525: mean loss = 8.925603e-06  learning rate = 3.3865508e-05
============================
Start of epoch 526
step 0: mean loss = 8.462289e-06
step 100: mean loss = 8.05617e-06
epoch 526: mean loss = 8.695098e-06  learning rate = 3.3865508e-05
============================
Start of epoch 527
step 0: mean loss = 6.6537705e-06
step 100: mean loss = 9.222062e-06
epoch 527: mean loss = 8.6443815e-06  learning rate = 3.3865508e-05
============================
Start of epoch 528
step 0: mean loss = 6.6688594e-06
step 100: mean loss = 8.160782e-06
epoch 528: mean loss = 8.603846e-06  learning rate = 3.3865508e-05
============================
Start of epoch 529
step 0: mean loss = 7.221989e-06
step 100: mean loss = 8.944917e-06
epoch 529: mean loss = 8.84413e-06  learning rate = 3.3865508e-05
============================
Start of epoch 530
step 0: mean loss = 7.6151023e-06
step 100: mean loss = 9.046566e-06
epoch 530: mean loss = 8.579618e-06  learning rate = 3.3865508e-05
============================
Start of epoch 531
step 0: mean loss = 7.859799e-06
step 100: mean loss = 8.471417e-06
epoch 531: mean loss = 8.63488e-06  learning rate = 3.3865508e-05
============================
Start of epoch 532
step 0: mean loss = 8.922405e-06
step 100: mean loss = 9.116187e-06
epoch 532: mean loss = 8.631045e-06  learning rate = 3.3865508e-05
============================
Start of epoch 533
step 0: mean loss = 8.225121e-06
step 100: mean loss = 8.0410255e-06
epoch 533: mean loss = 8.473785e-06  learning rate = 3.3865508e-05
============================
Start of epoch 534
step 0: mean loss = 7.3849224e-06
step 100: mean loss = 8.5655465e-06
epoch 534: mean loss = 8.69075e-06  learning rate = 3.3865508e-05
============================
Start of epoch 535
step 0: mean loss = 6.1554947e-06
step 100: mean loss = 8.575454e-06
epoch 535: mean loss = 8.744491e-06  learning rate = 3.3865508e-05
============================
Start of epoch 536
step 0: mean loss = 8.524621e-06
step 100: mean loss = 7.853014e-06
epoch 536: mean loss = 8.575073e-06  learning rate = 3.3865508e-05
============================
Start of epoch 537
step 0: mean loss = 8.937395e-06
step 100: mean loss = 8.345999e-06
epoch 537: mean loss = 8.391186e-06  learning rate = 3.3865508e-05
============================
Start of epoch 538
step 0: mean loss = 8.674568e-06
step 100: mean loss = 8.308203e-06
epoch 538: mean loss = 8.637535e-06  learning rate = 3.3865508e-05
============================
Start of epoch 539
step 0: mean loss = 6.1968913e-06
step 100: mean loss = 7.83065e-06
epoch 539: mean loss = 8.521211e-06  learning rate = 3.3865508e-05
============================
Start of epoch 540
step 0: mean loss = 8.255915e-06
step 100: mean loss = 8.3822815e-06
epoch 540: mean loss = 8.72031e-06  learning rate = 3.3865508e-05
============================
Start of epoch 541
step 0: mean loss = 7.0801175e-06
step 100: mean loss = 8.3721e-06
epoch 541: mean loss = 8.579402e-06  learning rate = 3.3865508e-05
============================
Start of epoch 542
step 0: mean loss = 7.961689e-06
step 100: mean loss = 8.356547e-06
epoch 542: mean loss = 8.491905e-06  learning rate = 3.3865508e-05
============================
Start of epoch 543
step 0: mean loss = 8.20684e-06
step 100: mean loss = 9.04188e-06
epoch 543: mean loss = 8.3783525e-06  learning rate = 3.3865508e-05
============================
Start of epoch 544
step 0: mean loss = 5.6348395e-06
step 100: mean loss = 8.6539485e-06
epoch 544: mean loss = 8.457796e-06  learning rate = 3.3865508e-05
============================
Start of epoch 545
step 0: mean loss = 7.2719977e-06
step 100: mean loss = 8.464192e-06
epoch 545: mean loss = 8.623449e-06  learning rate = 3.3865508e-05
============================
Start of epoch 546
step 0: mean loss = 8.171095e-06
step 100: mean loss = 8.1342905e-06
epoch 546: mean loss = 8.283427e-06  learning rate = 3.3865508e-05
============================
Start of epoch 547
step 0: mean loss = 8.9463665e-06
step 100: mean loss = 8.6199025e-06
epoch 547: mean loss = 8.341452e-06  learning rate = 3.3865508e-05
============================
Start of epoch 548
step 0: mean loss = 6.658369e-06
step 100: mean loss = 7.694692e-06
epoch 548: mean loss = 8.28537e-06  learning rate = 3.3865508e-05
============================
Start of epoch 549
step 0: mean loss = 7.259364e-06
step 100: mean loss = 8.4959875e-06
epoch 549: mean loss = 8.3636205e-06  learning rate = 3.3865508e-05
============================
Start of epoch 550
step 0: mean loss = 6.6085186e-06
step 100: mean loss = 7.533851e-06
epoch 550: mean loss = 8.396832e-06  learning rate = 3.3865508e-05
============================
Start of epoch 551
step 0: mean loss = 6.5710137e-06
step 100: mean loss = 8.865351e-06
epoch 551: mean loss = 8.316542e-06  learning rate = 3.3865508e-05
============================
Start of epoch 552
step 0: mean loss = 7.2228586e-06
step 100: mean loss = 8.306931e-06
epoch 552: mean loss = 8.306859e-06  learning rate = 3.3865508e-05
============================
Start of epoch 553
step 0: mean loss = 6.2118725e-06
step 100: mean loss = 7.984233e-06
epoch 553: mean loss = 8.283591e-06  learning rate = 3.3865508e-05
============================
Start of epoch 554
step 0: mean loss = 5.853831e-06
step 100: mean loss = 7.898864e-06
epoch 554: mean loss = 8.290388e-06  learning rate = 3.217223e-05
============================
Start of epoch 555
step 0: mean loss = 6.8015784e-06
step 100: mean loss = 8.801503e-06
epoch 555: mean loss = 8.191695e-06  learning rate = 3.217223e-05
============================
Start of epoch 556
step 0: mean loss = 6.389794e-06
step 100: mean loss = 8.080959e-06
epoch 556: mean loss = 8.102145e-06  learning rate = 3.217223e-05
============================
Start of epoch 557
step 0: mean loss = 7.193e-06
step 100: mean loss = 7.743093e-06
epoch 557: mean loss = 8.245534e-06  learning rate = 3.217223e-05
============================
Start of epoch 558
step 0: mean loss = 7.882875e-06
step 100: mean loss = 8.192408e-06
epoch 558: mean loss = 8.126686e-06  learning rate = 3.217223e-05
============================
Start of epoch 559
step 0: mean loss = 8.1311955e-06
step 100: mean loss = 7.853868e-06
epoch 559: mean loss = 8.064744e-06  learning rate = 3.217223e-05
============================
Start of epoch 560
step 0: mean loss = 7.4578e-06
step 100: mean loss = 8.352184e-06
epoch 560: mean loss = 8.1208e-06  learning rate = 3.217223e-05
============================
Start of epoch 561
step 0: mean loss = 8.347478e-06
step 100: mean loss = 8.608787e-06
epoch 561: mean loss = 8.194346e-06  learning rate = 3.217223e-05
============================
Start of epoch 562
step 0: mean loss = 6.3596967e-06
step 100: mean loss = 7.6161123e-06
epoch 562: mean loss = 8.130406e-06  learning rate = 3.217223e-05
============================
Start of epoch 563
step 0: mean loss = 8.685989e-06
step 100: mean loss = 8.565352e-06
epoch 563: mean loss = 8.136594e-06  learning rate = 3.217223e-05
============================
Start of epoch 564
step 0: mean loss = 7.2730136e-06
step 100: mean loss = 8.507895e-06
epoch 564: mean loss = 8.147587e-06  learning rate = 3.217223e-05
============================
Start of epoch 565
step 0: mean loss = 7.165017e-06
step 100: mean loss = 8.621185e-06
epoch 565: mean loss = 8.160287e-06  learning rate = 3.217223e-05
============================
Start of epoch 566
step 0: mean loss = 7.928406e-06
step 100: mean loss = 8.450038e-06
epoch 566: mean loss = 8.113702e-06  learning rate = 3.217223e-05
============================
Start of epoch 567
step 0: mean loss = 7.476825e-06
step 100: mean loss = 8.354089e-06
epoch 567: mean loss = 8.252251e-06  learning rate = 3.217223e-05
============================
Start of epoch 568
step 0: mean loss = 7.4764853e-06
step 100: mean loss = 8.263337e-06
epoch 568: mean loss = 8.0698455e-06  learning rate = 3.217223e-05
============================
Start of epoch 569
step 0: mean loss = 7.329632e-06
step 100: mean loss = 8.263182e-06
epoch 569: mean loss = 8.136333e-06  learning rate = 3.217223e-05
============================
Start of epoch 570
step 0: mean loss = 6.7164374e-06
step 100: mean loss = 8.0837735e-06
epoch 570: mean loss = 8.124104e-06  learning rate = 3.217223e-05
============================
Start of epoch 571
step 0: mean loss = 6.912108e-06
step 100: mean loss = 8.64759e-06
epoch 571: mean loss = 8.1388e-06  learning rate = 3.217223e-05
============================
Start of epoch 572
step 0: mean loss = 6.996569e-06
step 100: mean loss = 8.4612775e-06
epoch 572: mean loss = 8.098968e-06  learning rate = 3.217223e-05
============================
Start of epoch 573
step 0: mean loss = 7.5724593e-06
step 100: mean loss = 7.5192825e-06
epoch 573: mean loss = 8.002835e-06  learning rate = 3.217223e-05
============================
Start of epoch 574
step 0: mean loss = 6.612905e-06
step 100: mean loss = 8.765023e-06
epoch 574: mean loss = 8.137694e-06  learning rate = 3.217223e-05
============================
Start of epoch 575
step 0: mean loss = 8.139659e-06
step 100: mean loss = 8.908908e-06
epoch 575: mean loss = 8.280022e-06  learning rate = 3.217223e-05
============================
Start of epoch 576
step 0: mean loss = 6.7718474e-06
step 100: mean loss = 8.001513e-06
epoch 576: mean loss = 8.1069875e-06  learning rate = 3.217223e-05
============================
Start of epoch 577
step 0: mean loss = 7.4878903e-06
step 100: mean loss = 8.688678e-06
epoch 577: mean loss = 8.056081e-06  learning rate = 3.217223e-05
============================
Start of epoch 578
step 0: mean loss = 7.931455e-06
step 100: mean loss = 8.648679e-06
epoch 578: mean loss = 8.057552e-06  learning rate = 3.217223e-05
============================
Start of epoch 579
step 0: mean loss = 6.5195154e-06
step 100: mean loss = 7.944018e-06
epoch 579: mean loss = 8.002038e-06  learning rate = 3.217223e-05
============================
Start of epoch 580
step 0: mean loss = 6.9595862e-06
step 100: mean loss = 8.41669e-06
epoch 580: mean loss = 8.1485605e-06  learning rate = 3.217223e-05
============================
Start of epoch 581
step 0: mean loss = 7.855453e-06
step 100: mean loss = 8.023425e-06
epoch 581: mean loss = 7.993098e-06  learning rate = 3.217223e-05
============================
Start of epoch 582
step 0: mean loss = 7.724556e-06
step 100: mean loss = 8.020094e-06
epoch 582: mean loss = 8.165918e-06  learning rate = 3.217223e-05
============================
Start of epoch 583
step 0: mean loss = 6.5397426e-06
step 100: mean loss = 8.740724e-06
epoch 583: mean loss = 8.302351e-06  learning rate = 3.217223e-05
============================
Start of epoch 584
step 0: mean loss = 8.117813e-06
step 100: mean loss = 8.09474e-06
epoch 584: mean loss = 8.106273e-06  learning rate = 3.217223e-05
============================
Start of epoch 585
step 0: mean loss = 7.682829e-06
step 100: mean loss = 8.133314e-06
epoch 585: mean loss = 8.126426e-06  learning rate = 3.217223e-05
============================
Start of epoch 586
step 0: mean loss = 6.2817394e-06
step 100: mean loss = 8.661669e-06
epoch 586: mean loss = 8.16053e-06  learning rate = 3.217223e-05
============================
Start of epoch 587
step 0: mean loss = 6.544419e-06
step 100: mean loss = 7.338204e-06
epoch 587: mean loss = 8.1236985e-06  learning rate = 3.217223e-05
============================
Start of epoch 588
step 0: mean loss = 7.3165434e-06
step 100: mean loss = 7.110033e-06
epoch 588: mean loss = 8.013078e-06  learning rate = 3.217223e-05
============================
Start of epoch 589
step 0: mean loss = 7.833807e-06
step 100: mean loss = 8.335287e-06
epoch 589: mean loss = 8.15355e-06  learning rate = 3.217223e-05
============================
Start of epoch 590
step 0: mean loss = 6.469276e-06
step 100: mean loss = 7.94998e-06
epoch 590: mean loss = 8.030339e-06  learning rate = 3.217223e-05
============================
Start of epoch 591
step 0: mean loss = 8.068579e-06
step 100: mean loss = 8.008759e-06
epoch 591: mean loss = 8.140826e-06  learning rate = 3.217223e-05
============================
Start of epoch 592
step 0: mean loss = 7.88117e-06
step 100: mean loss = 7.982658e-06
epoch 592: mean loss = 7.9943875e-06  learning rate = 3.217223e-05
============================
Start of epoch 593
step 0: mean loss = 7.065072e-06
step 100: mean loss = 7.3357064e-06
epoch 593: mean loss = 7.982668e-06  learning rate = 3.217223e-05
============================
Start of epoch 594
step 0: mean loss = 6.609437e-06
step 100: mean loss = 8.155729e-06
epoch 594: mean loss = 8.032956e-06  learning rate = 3.217223e-05
============================
Start of epoch 595
step 0: mean loss = 7.2418356e-06
step 100: mean loss = 7.133897e-06
epoch 595: mean loss = 8.038018e-06  learning rate = 3.217223e-05
============================
Start of epoch 596
step 0: mean loss = 7.020962e-06
step 100: mean loss = 8.789621e-06
epoch 596: mean loss = 8.209372e-06  learning rate = 3.217223e-05
============================
Start of epoch 597
step 0: mean loss = 6.8301956e-06
step 100: mean loss = 8.133961e-06
epoch 597: mean loss = 8.0501895e-06  learning rate = 3.217223e-05
============================
Start of epoch 598
step 0: mean loss = 7.8581e-06
step 100: mean loss = 7.898774e-06
epoch 598: mean loss = 8.03292e-06  learning rate = 3.217223e-05
============================
Start of epoch 599
step 0: mean loss = 6.7110905e-06
step 100: mean loss = 8.345465e-06
epoch 599: mean loss = 7.968928e-06  learning rate = 3.217223e-05
============================
Start of epoch 600
step 0: mean loss = 5.809541e-06
step 100: mean loss = 7.631688e-06
epoch 600: mean loss = 8.035114e-06  learning rate = 3.217223e-05
============================
Start of epoch 601
step 0: mean loss = 7.0065316e-06
step 100: mean loss = 7.1075992e-06
epoch 601: mean loss = 8.1746375e-06  learning rate = 3.217223e-05
============================
Start of epoch 602
step 0: mean loss = 7.2494595e-06
step 100: mean loss = 7.912472e-06
epoch 602: mean loss = 8.062036e-06  learning rate = 3.217223e-05
============================
Start of epoch 603
step 0: mean loss = 5.8713076e-06
step 100: mean loss = 8.2961415e-06
epoch 603: mean loss = 8.012692e-06  learning rate = 3.217223e-05
============================
Start of epoch 604
step 0: mean loss = 5.4198365e-05
step 100: mean loss = 8.608546e-06
epoch 604: mean loss = 8.028243e-06  learning rate = 3.217223e-05
============================
Start of epoch 605
step 0: mean loss = 6.2223685e-06
step 100: mean loss = 7.762147e-06
epoch 605: mean loss = 8.864251e-06  learning rate = 3.217223e-05
============================
Start of epoch 606
step 0: mean loss = 1.6099279e-05
step 100: mean loss = 1.0429433e-05
epoch 606: mean loss = 9.43829e-06  learning rate = 3.217223e-05
============================
Start of epoch 607
step 0: mean loss = 7.956313e-06
step 100: mean loss = 8.418752e-06
epoch 607: mean loss = 7.800664e-06  learning rate = 3.217223e-05
============================
Start of epoch 608
step 0: mean loss = 6.356685e-06
step 100: mean loss = 8.504047e-06
epoch 608: mean loss = 7.980644e-06  learning rate = 3.217223e-05
============================
Start of epoch 609
step 0: mean loss = 6.9033085e-06
step 100: mean loss = 8.521016e-06
epoch 609: mean loss = 7.955521e-06  learning rate = 3.217223e-05
============================
Start of epoch 610
step 0: mean loss = 7.1350933e-06
step 100: mean loss = 6.9707603e-06
epoch 610: mean loss = 7.818664e-06  learning rate = 3.217223e-05
============================
Start of epoch 611
step 0: mean loss = 7.062657e-06
step 100: mean loss = 8.0084055e-06
epoch 611: mean loss = 7.942477e-06  learning rate = 3.217223e-05
============================
Start of epoch 612
step 0: mean loss = 6.835405e-06
step 100: mean loss = 8.480855e-06
epoch 612: mean loss = 8.048422e-06  learning rate = 3.217223e-05
============================
Start of epoch 613
step 0: mean loss = 6.6515167e-06
step 100: mean loss = 7.12211e-06
epoch 613: mean loss = 7.938206e-06  learning rate = 3.217223e-05
============================
Start of epoch 614
step 0: mean loss = 8.124755e-06
step 100: mean loss = 8.403005e-06
epoch 614: mean loss = 8.000389e-06  learning rate = 3.217223e-05
============================
Start of epoch 615
step 0: mean loss = 6.6987654e-06
step 100: mean loss = 8.470358e-06
epoch 615: mean loss = 8.0148675e-06  learning rate = 3.217223e-05
============================
Start of epoch 616
step 0: mean loss = 6.873131e-06
step 100: mean loss = 7.5236017e-06
epoch 616: mean loss = 7.891572e-06  learning rate = 3.217223e-05
============================
Start of epoch 617
step 0: mean loss = 6.2107847e-06
step 100: mean loss = 8.028189e-06
epoch 617: mean loss = 8.030897e-06  learning rate = 3.217223e-05
============================
Start of epoch 618
step 0: mean loss = 7.2184716e-06
step 100: mean loss = 7.089216e-06
epoch 618: mean loss = 7.821006e-06  learning rate = 3.217223e-05
============================
Start of epoch 619
step 0: mean loss = 8.605641e-06
step 100: mean loss = 8.82455e-06
epoch 619: mean loss = 8.137144e-06  learning rate = 3.217223e-05
============================
Start of epoch 620
step 0: mean loss = 6.3008106e-06
step 100: mean loss = 6.8563195e-06
epoch 620: mean loss = 7.838081e-06  learning rate = 3.217223e-05
============================
Start of epoch 621
step 0: mean loss = 9.685703e-06
step 100: mean loss = 8.691252e-06
epoch 621: mean loss = 8.388935e-06  learning rate = 3.217223e-05
============================
Start of epoch 622
step 0: mean loss = 7.228442e-06
step 100: mean loss = 7.930118e-06
epoch 622: mean loss = 7.966307e-06  learning rate = 3.217223e-05
============================
Start of epoch 623
step 0: mean loss = 9.604181e-06
step 100: mean loss = 8.6756245e-06
epoch 623: mean loss = 8.047283e-06  learning rate = 3.217223e-05
============================
Start of epoch 624
step 0: mean loss = 7.652974e-06
step 100: mean loss = 8.502824e-06
epoch 624: mean loss = 7.930404e-06  learning rate = 3.217223e-05
============================
Start of epoch 625
step 0: mean loss = 8.541598e-06
step 100: mean loss = 7.812359e-06
epoch 625: mean loss = 7.79625e-06  learning rate = 3.217223e-05
============================
Start of epoch 626
step 0: mean loss = 6.254624e-06
step 100: mean loss = 8.224457e-06
epoch 626: mean loss = 7.903065e-06  learning rate = 3.217223e-05
============================
Start of epoch 627
step 0: mean loss = 6.8185163e-06
step 100: mean loss = 8.087349e-06
epoch 627: mean loss = 7.931084e-06  learning rate = 3.217223e-05
============================
Start of epoch 628
step 0: mean loss = 6.2794916e-06
step 100: mean loss = 8.260725e-06
epoch 628: mean loss = 8.085547e-06  learning rate = 3.217223e-05
============================
Start of epoch 629
step 0: mean loss = 7.1610602e-06
step 100: mean loss = 8.283281e-06
epoch 629: mean loss = 7.935369e-06  learning rate = 3.217223e-05
============================
Start of epoch 630
step 0: mean loss = 6.339901e-06
step 100: mean loss = 8.173115e-06
epoch 630: mean loss = 7.931201e-06  learning rate = 3.217223e-05
============================
Start of epoch 631
step 0: mean loss = 6.931895e-06
step 100: mean loss = 7.445158e-06
epoch 631: mean loss = 7.937357e-06  learning rate = 3.217223e-05
============================
Start of epoch 632
step 0: mean loss = 7.727009e-06
step 100: mean loss = 7.192496e-06
epoch 632: mean loss = 7.748341e-06  learning rate = 3.217223e-05
============================
Start of epoch 633
step 0: mean loss = 8.710702e-06
step 100: mean loss = 7.449557e-06
epoch 633: mean loss = 7.973595e-06  learning rate = 3.217223e-05
============================
Start of epoch 634
step 0: mean loss = 7.5506223e-06
step 100: mean loss = 8.542277e-06
epoch 634: mean loss = 7.87775e-06  learning rate = 3.056362e-05
============================
Start of epoch 635
step 0: mean loss = 5.844918e-06
step 100: mean loss = 7.451329e-06
epoch 635: mean loss = 7.757719e-06  learning rate = 3.056362e-05
============================
Start of epoch 636
step 0: mean loss = 5.91315e-06
step 100: mean loss = 7.741244e-06
epoch 636: mean loss = 7.953814e-06  learning rate = 3.056362e-05
============================
Start of epoch 637
step 0: mean loss = 7.282964e-06
step 100: mean loss = 7.77678e-06
epoch 637: mean loss = 7.814206e-06  learning rate = 3.056362e-05
============================
Start of epoch 638
step 0: mean loss = 7.448387e-06
step 100: mean loss = 7.009883e-06
epoch 638: mean loss = 7.863332e-06  learning rate = 3.056362e-05
============================
Start of epoch 639
step 0: mean loss = 7.6562255e-06
step 100: mean loss = 8.0060345e-06
epoch 639: mean loss = 8.107798e-06  learning rate = 3.056362e-05
============================
Start of epoch 640
step 0: mean loss = 5.7523102e-06
step 100: mean loss = 6.9820676e-06
epoch 640: mean loss = 7.821091e-06  learning rate = 3.056362e-05
============================
Start of epoch 641
step 0: mean loss = 7.63424e-06
step 100: mean loss = 8.403692e-06
epoch 641: mean loss = 7.873209e-06  learning rate = 3.056362e-05
============================
Start of epoch 642
step 0: mean loss = 6.343351e-06
step 100: mean loss = 7.812166e-06
epoch 642: mean loss = 7.781202e-06  learning rate = 3.056362e-05
============================
Start of epoch 643
step 0: mean loss = 8.750223e-06
step 100: mean loss = 8.619366e-06
epoch 643: mean loss = 8.0880445e-06  learning rate = 3.056362e-05
============================
Start of epoch 644
step 0: mean loss = 5.9090335e-06
step 100: mean loss = 7.695108e-06
epoch 644: mean loss = 7.829743e-06  learning rate = 3.056362e-05
============================
Start of epoch 645
step 0: mean loss = 7.2245566e-06
step 100: mean loss = 7.762149e-06
epoch 645: mean loss = 7.897456e-06  learning rate = 3.056362e-05
============================
Start of epoch 646
step 0: mean loss = 5.8073947e-06
step 100: mean loss = 7.720911e-06
epoch 646: mean loss = 7.988203e-06  learning rate = 3.056362e-05
============================
Start of epoch 647
step 0: mean loss = 6.4486935e-06
step 100: mean loss = 7.1611535e-06
epoch 647: mean loss = 7.801581e-06  learning rate = 3.056362e-05
============================
Start of epoch 648
step 0: mean loss = 5.996992e-06
step 100: mean loss = 7.3119445e-06
epoch 648: mean loss = 7.832452e-06  learning rate = 3.056362e-05
============================
Start of epoch 649
step 0: mean loss = 6.8504214e-06
step 100: mean loss = 8.021795e-06
epoch 649: mean loss = 7.8435605e-06  learning rate = 3.056362e-05
============================
Start of epoch 650
step 0: mean loss = 7.781711e-06
step 100: mean loss = 7.86106e-06
epoch 650: mean loss = 8.0087375e-06  learning rate = 3.056362e-05
============================
Start of epoch 651
step 0: mean loss = 6.1259507e-06
step 100: mean loss = 8.393602e-06
epoch 651: mean loss = 7.7947425e-06  learning rate = 3.056362e-05
============================
Start of epoch 652
step 0: mean loss = 6.205343e-06
step 100: mean loss = 8.210572e-06
epoch 652: mean loss = 7.87305e-06  learning rate = 3.056362e-05
============================
Start of epoch 653
step 0: mean loss = 7.2599432e-06
step 100: mean loss = 8.279769e-06
epoch 653: mean loss = 7.9035e-06  learning rate = 3.056362e-05
============================
Start of epoch 654
step 0: mean loss = 6.465805e-06
step 100: mean loss = 8.1822245e-06
epoch 654: mean loss = 7.811077e-06  learning rate = 3.056362e-05
============================
Start of epoch 655
step 0: mean loss = 7.2181074e-06
step 100: mean loss = 8.201693e-06
epoch 655: mean loss = 7.738748e-06  learning rate = 3.056362e-05
============================
Start of epoch 656
step 0: mean loss = 6.2108184e-06
step 100: mean loss = 8.254273e-06
epoch 656: mean loss = 7.7541545e-06  learning rate = 3.056362e-05
============================
Start of epoch 657
step 0: mean loss = 6.035785e-06
step 100: mean loss = 6.68945e-06
epoch 657: mean loss = 7.698645e-06  learning rate = 3.056362e-05
============================
Start of epoch 658
step 0: mean loss = 8.942436e-06
step 100: mean loss = 7.1363447e-06
epoch 658: mean loss = 7.804485e-06  learning rate = 3.056362e-05
============================
Start of epoch 659
step 0: mean loss = 8.343544e-06
step 100: mean loss = 7.435917e-06
epoch 659: mean loss = 7.890564e-06  learning rate = 3.056362e-05
============================
Start of epoch 660
step 0: mean loss = 5.2519454e-06
step 100: mean loss = 6.7788706e-06
epoch 660: mean loss = 7.675056e-06  learning rate = 3.056362e-05
============================
Start of epoch 661
step 0: mean loss = 7.941324e-06
step 100: mean loss = 8.182394e-06
epoch 661: mean loss = 7.862627e-06  learning rate = 3.056362e-05
============================
Start of epoch 662
step 0: mean loss = 8.804177e-06
step 100: mean loss = 7.4940094e-06
epoch 662: mean loss = 7.892284e-06  learning rate = 3.056362e-05
============================
Start of epoch 663
step 0: mean loss = 6.9621237e-06
step 100: mean loss = 7.475316e-06
epoch 663: mean loss = 7.741696e-06  learning rate = 3.056362e-05
============================
Start of epoch 664
step 0: mean loss = 7.4995714e-06
step 100: mean loss = 7.3062356e-06
epoch 664: mean loss = 7.658748e-06  learning rate = 3.056362e-05
============================
Start of epoch 665
step 0: mean loss = 6.2503937e-06
step 100: mean loss = 8.201372e-06
epoch 665: mean loss = 7.7311715e-06  learning rate = 3.056362e-05
============================
Start of epoch 666
step 0: mean loss = 5.6705326e-06
step 100: mean loss = 7.638644e-06
epoch 666: mean loss = 7.824397e-06  learning rate = 3.056362e-05
============================
Start of epoch 667
step 0: mean loss = 6.213114e-06
step 100: mean loss = 8.162664e-06
epoch 667: mean loss = 7.762684e-06  learning rate = 3.056362e-05
============================
Start of epoch 668
step 0: mean loss = 6.90849e-06
step 100: mean loss = 7.605792e-06
epoch 668: mean loss = 7.6582355e-06  learning rate = 3.056362e-05
============================
Start of epoch 669
step 0: mean loss = 6.680367e-06
step 100: mean loss = 7.739104e-06
epoch 669: mean loss = 7.675276e-06  learning rate = 3.056362e-05
============================
Start of epoch 670
step 0: mean loss = 7.4844975e-06
step 100: mean loss = 7.884919e-06
epoch 670: mean loss = 7.79796e-06  learning rate = 3.056362e-05
============================
Start of epoch 671
step 0: mean loss = 6.9039124e-06
step 100: mean loss = 7.729496e-06
epoch 671: mean loss = 7.637018e-06  learning rate = 3.056362e-05
============================
Start of epoch 672
step 0: mean loss = 5.5874007e-06
step 100: mean loss = 8.481807e-06
epoch 672: mean loss = 7.791386e-06  learning rate = 3.056362e-05
============================
Start of epoch 673
step 0: mean loss = 5.6922354e-06
step 100: mean loss = 7.704402e-06
epoch 673: mean loss = 7.693746e-06  learning rate = 3.056362e-05
============================
Start of epoch 674
step 0: mean loss = 6.896016e-06
step 100: mean loss = 7.7517125e-06
epoch 674: mean loss = 7.814867e-06  learning rate = 3.056362e-05
============================
Start of epoch 675
step 0: mean loss = 6.9158255e-06
step 100: mean loss = 7.364574e-06
epoch 675: mean loss = 7.708397e-06  learning rate = 3.056362e-05
============================
Start of epoch 676
step 0: mean loss = 8.079618e-06
step 100: mean loss = 7.756627e-06
epoch 676: mean loss = 7.770709e-06  learning rate = 3.056362e-05
============================
Start of epoch 677
step 0: mean loss = 6.384722e-06
step 100: mean loss = 7.4847144e-06
epoch 677: mean loss = 7.731447e-06  learning rate = 3.056362e-05
============================
Start of epoch 678
step 0: mean loss = 6.903894e-06
step 100: mean loss = 8.103882e-06
epoch 678: mean loss = 7.638424e-06  learning rate = 3.056362e-05
============================
Start of epoch 679
step 0: mean loss = 6.474487e-06
step 100: mean loss = 7.84515e-06
epoch 679: mean loss = 7.834069e-06  learning rate = 3.056362e-05
============================
Start of epoch 680
step 0: mean loss = 6.7558612e-06
step 100: mean loss = 7.2306375e-06
epoch 680: mean loss = 7.5423663e-06  learning rate = 3.056362e-05
============================
Start of epoch 681
step 0: mean loss = 7.488599e-06
step 100: mean loss = 8.171699e-06
epoch 681: mean loss = 7.744829e-06  learning rate = 3.056362e-05
============================
Start of epoch 682
step 0: mean loss = 7.427818e-06
step 100: mean loss = 8.517697e-06
epoch 682: mean loss = 7.842793e-06  learning rate = 3.056362e-05
============================
Start of epoch 683
step 0: mean loss = 6.222798e-06
step 100: mean loss = 8.102175e-06
epoch 683: mean loss = 7.637459e-06  learning rate = 3.056362e-05
============================
Start of epoch 684
step 0: mean loss = 6.754516e-06
step 100: mean loss = 7.9836755e-06
epoch 684: mean loss = 7.705431e-06  learning rate = 3.056362e-05
============================
Start of epoch 685
step 0: mean loss = 6.7045225e-06
step 100: mean loss = 7.590365e-06
epoch 685: mean loss = 7.576519e-06  learning rate = 3.056362e-05
============================
Start of epoch 686
step 0: mean loss = 7.240732e-06
step 100: mean loss = 7.3565507e-06
epoch 686: mean loss = 7.762824e-06  learning rate = 3.056362e-05
============================
Start of epoch 687
step 0: mean loss = 6.9680564e-06
step 100: mean loss = 8.555604e-06
epoch 687: mean loss = 7.824462e-06  learning rate = 3.056362e-05
============================
Start of epoch 688
step 0: mean loss = 1.2018438e-05
step 100: mean loss = 8.207232e-06
epoch 688: mean loss = 7.74221e-06  learning rate = 3.056362e-05
============================
Start of epoch 689
step 0: mean loss = 7.595039e-06
step 100: mean loss = 7.942057e-06
epoch 689: mean loss = 7.6719725e-06  learning rate = 3.056362e-05
============================
Start of epoch 690
step 0: mean loss = 7.801207e-06
step 100: mean loss = 6.789235e-06
epoch 690: mean loss = 7.6066867e-06  learning rate = 3.056362e-05
============================
Start of epoch 691
step 0: mean loss = 5.3991203e-06
step 100: mean loss = 7.2626685e-06
epoch 691: mean loss = 7.734805e-06  learning rate = 3.056362e-05
============================
Start of epoch 692
step 0: mean loss = 8.4145595e-06
step 100: mean loss = 7.897194e-06
epoch 692: mean loss = 7.745926e-06  learning rate = 3.056362e-05
============================
Start of epoch 693
step 0: mean loss = 6.2240774e-06
step 100: mean loss = 7.29372e-06
epoch 693: mean loss = 7.663965e-06  learning rate = 3.056362e-05
============================
Start of epoch 694
step 0: mean loss = 7.273894e-06
step 100: mean loss = 7.5749967e-06
epoch 694: mean loss = 7.645112e-06  learning rate = 3.056362e-05
============================
Start of epoch 695
step 0: mean loss = 5.981849e-06
step 100: mean loss = 7.587574e-06
epoch 695: mean loss = 7.832118e-06  learning rate = 3.056362e-05
============================
Start of epoch 696
step 0: mean loss = 8.258868e-06
step 100: mean loss = 7.463419e-06
epoch 696: mean loss = 7.626752e-06  learning rate = 3.056362e-05
============================
Start of epoch 697
step 0: mean loss = 6.4651845e-06
step 100: mean loss = 8.268776e-06
epoch 697: mean loss = 7.5784387e-06  learning rate = 3.056362e-05
============================
Start of epoch 698
step 0: mean loss = 5.8261076e-06
step 100: mean loss = 8.299935e-06
epoch 698: mean loss = 7.5674357e-06  learning rate = 3.056362e-05
============================
Start of epoch 699
step 0: mean loss = 5.5660494e-06
step 100: mean loss = 7.393499e-06
epoch 699: mean loss = 7.693464e-06  learning rate = 3.056362e-05
============================
Start of epoch 700
step 0: mean loss = 5.707725e-06
step 100: mean loss = 8.086365e-06
epoch 700: mean loss = 7.703572e-06  learning rate = 3.056362e-05
============================
Start of epoch 701
step 0: mean loss = 6.2038916e-06
step 100: mean loss = 7.4836453e-06
epoch 701: mean loss = 7.772105e-06  learning rate = 3.056362e-05
============================
Start of epoch 702
step 0: mean loss = 5.73399e-06
step 100: mean loss = 7.955647e-06
epoch 702: mean loss = 7.661415e-06  learning rate = 3.056362e-05
============================
Start of epoch 703
step 0: mean loss = 6.570268e-06
step 100: mean loss = 7.472003e-06
epoch 703: mean loss = 7.5808925e-06  learning rate = 3.056362e-05
============================
Start of epoch 704
step 0: mean loss = 6.8449895e-06
step 100: mean loss = 7.5922803e-06
epoch 704: mean loss = 7.69017e-06  learning rate = 3.056362e-05
============================
Start of epoch 705
step 0: mean loss = 6.0252296e-06
step 100: mean loss = 7.920721e-06
epoch 705: mean loss = 7.644944e-06  learning rate = 3.056362e-05
============================
Start of epoch 706
step 0: mean loss = 6.642831e-06
step 100: mean loss = 8.189058e-06
epoch 706: mean loss = 7.5773078e-06  learning rate = 3.056362e-05
============================
Start of epoch 707
step 0: mean loss = 6.3342786e-06
step 100: mean loss = 7.199977e-06
epoch 707: mean loss = 7.5856447e-06  learning rate = 3.056362e-05
============================
Start of epoch 708
step 0: mean loss = 5.73369e-06
step 100: mean loss = 6.8310223e-06
epoch 708: mean loss = 7.763799e-06  learning rate = 3.056362e-05
============================
Start of epoch 709
step 0: mean loss = 1.1484035e-05
step 100: mean loss = 8.109043e-06
epoch 709: mean loss = 8.226641e-06  learning rate = 3.056362e-05
============================
Start of epoch 710
step 0: mean loss = 6.253972e-06
step 100: mean loss = 8.240492e-06
epoch 710: mean loss = 7.60766e-06  learning rate = 3.056362e-05
============================
Start of epoch 711
step 0: mean loss = 6.286299e-06
step 100: mean loss = 7.5684193e-06
epoch 711: mean loss = 7.5157623e-06  learning rate = 3.056362e-05
============================
Start of epoch 712
step 0: mean loss = 6.143717e-06
step 100: mean loss = 7.821365e-06
epoch 712: mean loss = 7.6210517e-06  learning rate = 3.056362e-05
============================
Start of epoch 713
step 0: mean loss = 5.546035e-05
step 100: mean loss = 7.7264485e-06
epoch 713: mean loss = 7.4254863e-06  learning rate = 3.056362e-05
============================
Start of epoch 714
step 0: mean loss = 5.443305e-06
step 100: mean loss = 7.74733e-06
epoch 714: mean loss = 7.4477693e-06  learning rate = 2.9035442e-05
============================
Start of epoch 715
step 0: mean loss = 7.406067e-06
step 100: mean loss = 7.2975013e-06
epoch 715: mean loss = 7.3949614e-06  learning rate = 2.9035442e-05
============================
Start of epoch 716
step 0: mean loss = 6.4924925e-06
step 100: mean loss = 6.7540627e-06
epoch 716: mean loss = 7.3218803e-06  learning rate = 2.9035442e-05
============================
Start of epoch 717
step 0: mean loss = 7.5566018e-06
step 100: mean loss = 6.925245e-06
epoch 717: mean loss = 7.3839924e-06  learning rate = 2.9035442e-05
============================
Start of epoch 718
step 0: mean loss = 5.90354e-06
step 100: mean loss = 7.421518e-06
epoch 718: mean loss = 7.403283e-06  learning rate = 2.9035442e-05
============================
Start of epoch 719
step 0: mean loss = 6.5306494e-06
step 100: mean loss = 6.7216292e-06
epoch 719: mean loss = 7.5296057e-06  learning rate = 2.9035442e-05
============================
Start of epoch 720
step 0: mean loss = 5.840688e-06
step 100: mean loss = 7.2470543e-06
epoch 720: mean loss = 8.124111e-06  learning rate = 2.9035442e-05
============================
Start of epoch 721
step 0: mean loss = 1.3176239e-05
step 100: mean loss = 9.881859e-06
epoch 721: mean loss = 8.647158e-06  learning rate = 2.9035442e-05
============================
Start of epoch 722
step 0: mean loss = 6.8111576e-06
step 100: mean loss = 7.4180043e-06
epoch 722: mean loss = 7.394619e-06  learning rate = 2.9035442e-05
============================
Start of epoch 723
step 0: mean loss = 6.202603e-06
step 100: mean loss = 7.1471068e-06
epoch 723: mean loss = 7.2544135e-06  learning rate = 2.9035442e-05
============================
Start of epoch 724
step 0: mean loss = 6.7164747e-06
step 100: mean loss = 7.1666946e-06
epoch 724: mean loss = 7.2576227e-06  learning rate = 2.9035442e-05
============================
Start of epoch 725
step 0: mean loss = 6.4137093e-06
step 100: mean loss = 7.453856e-06
epoch 725: mean loss = 7.469963e-06  learning rate = 2.9035442e-05
============================
Start of epoch 726
step 0: mean loss = 5.9715385e-06
step 100: mean loss = 7.255708e-06
epoch 726: mean loss = 7.3060714e-06  learning rate = 2.9035442e-05
============================
Start of epoch 727
step 0: mean loss = 5.9722206e-06
step 100: mean loss = 7.447441e-06
epoch 727: mean loss = 7.3173564e-06  learning rate = 2.9035442e-05
============================
Start of epoch 728
step 0: mean loss = 6.2694226e-06
step 100: mean loss = 7.6265383e-06
epoch 728: mean loss = 7.2909143e-06  learning rate = 2.9035442e-05
============================
Start of epoch 729
step 0: mean loss = 6.4216874e-06
step 100: mean loss = 7.903321e-06
epoch 729: mean loss = 7.2989124e-06  learning rate = 2.9035442e-05
============================
Start of epoch 730
step 0: mean loss = 5.7659618e-06
step 100: mean loss = 6.5153554e-06
epoch 730: mean loss = 7.3456235e-06  learning rate = 2.9035442e-05
============================
Start of epoch 731
step 0: mean loss = 6.757674e-06
step 100: mean loss = 7.5384846e-06
epoch 731: mean loss = 7.494469e-06  learning rate = 2.9035442e-05
============================
Start of epoch 732
step 0: mean loss = 5.2597993e-06
step 100: mean loss = 7.186738e-06
epoch 732: mean loss = 7.297022e-06  learning rate = 2.9035442e-05
============================
Start of epoch 733
step 0: mean loss = 6.099426e-06
step 100: mean loss = 7.701408e-06
epoch 733: mean loss = 7.3850692e-06  learning rate = 2.9035442e-05
============================
Start of epoch 734
step 0: mean loss = 5.904227e-06
step 100: mean loss = 7.0535284e-06
epoch 734: mean loss = 7.207074e-06  learning rate = 2.9035442e-05
============================
Start of epoch 735
step 0: mean loss = 6.66453e-06
step 100: mean loss = 7.617649e-06
epoch 735: mean loss = 7.5586e-06  learning rate = 2.9035442e-05
============================
Start of epoch 736
step 0: mean loss = 6.7478013e-06
step 100: mean loss = 6.9193925e-06
epoch 736: mean loss = 7.232612e-06  learning rate = 2.9035442e-05
============================
Start of epoch 737
step 0: mean loss = 5.6997205e-06
step 100: mean loss = 7.347704e-06
epoch 737: mean loss = 7.3452293e-06  learning rate = 2.9035442e-05
============================
Start of epoch 738
step 0: mean loss = 5.4377606e-06
step 100: mean loss = 7.775661e-06
epoch 738: mean loss = 7.2497887e-06  learning rate = 2.9035442e-05
============================
Start of epoch 739
step 0: mean loss = 6.345156e-06
step 100: mean loss = 7.163758e-06
epoch 739: mean loss = 7.3857173e-06  learning rate = 2.9035442e-05
============================
Start of epoch 740
step 0: mean loss = 5.6656418e-06
step 100: mean loss = 6.674653e-06
epoch 740: mean loss = 8.159853e-06  learning rate = 2.9035442e-05
============================
Start of epoch 741
step 0: mean loss = 1.3022817e-05
step 100: mean loss = 9.3665485e-06
epoch 741: mean loss = 8.634662e-06  learning rate = 2.9035442e-05
============================
Start of epoch 742
step 0: mean loss = 5.053961e-06
step 100: mean loss = 6.9232256e-06
epoch 742: mean loss = 7.276924e-06  learning rate = 2.9035442e-05
============================
Start of epoch 743
step 0: mean loss = 6.8717945e-06
step 100: mean loss = 7.733782e-06
epoch 743: mean loss = 7.3208207e-06  learning rate = 2.9035442e-05
============================
Start of epoch 744
step 0: mean loss = 7.554909e-06
step 100: mean loss = 7.175312e-06
epoch 744: mean loss = 7.160317e-06  learning rate = 2.9035442e-05
============================
Start of epoch 745
step 0: mean loss = 6.109031e-06
step 100: mean loss = 7.219753e-06
epoch 745: mean loss = 7.1646273e-06  learning rate = 2.9035442e-05
============================
Start of epoch 746
step 0: mean loss = 8.573319e-06
step 100: mean loss = 7.634676e-06
epoch 746: mean loss = 7.269049e-06  learning rate = 2.9035442e-05
============================
Start of epoch 747
step 0: mean loss = 8.894047e-06
step 100: mean loss = 7.166465e-06
epoch 747: mean loss = 7.301336e-06  learning rate = 2.9035442e-05
============================
Start of epoch 748
step 0: mean loss = 5.7605357e-06
step 100: mean loss = 7.719729e-06
epoch 748: mean loss = 7.335826e-06  learning rate = 2.9035442e-05
============================
Start of epoch 749
step 0: mean loss = 7.936129e-06
step 100: mean loss = 7.653713e-06
epoch 749: mean loss = 7.271133e-06  learning rate = 2.9035442e-05
============================
Start of epoch 750
step 0: mean loss = 7.508731e-06
step 100: mean loss = 6.9618277e-06
epoch 750: mean loss = 7.2223465e-06  learning rate = 2.9035442e-05
============================
Start of epoch 751
step 0: mean loss = 7.530619e-06
step 100: mean loss = 7.207745e-06
epoch 751: mean loss = 7.2554462e-06  learning rate = 2.9035442e-05
============================
Start of epoch 752
step 0: mean loss = 8.457498e-06
step 100: mean loss = 6.73528e-06
epoch 752: mean loss = 7.2008543e-06  learning rate = 2.9035442e-05
============================
Start of epoch 753
step 0: mean loss = 8.18208e-06
step 100: mean loss = 7.6292736e-06
epoch 753: mean loss = 7.3508504e-06  learning rate = 2.9035442e-05
============================
Start of epoch 754
step 0: mean loss = 6.317367e-06
step 100: mean loss = 6.840051e-06
epoch 754: mean loss = 7.1902796e-06  learning rate = 2.9035442e-05
============================
Start of epoch 755
step 0: mean loss = 9.127314e-06
step 100: mean loss = 7.855117e-06
epoch 755: mean loss = 7.43787e-06  learning rate = 2.9035442e-05
============================
Start of epoch 756
step 0: mean loss = 6.0550146e-06
step 100: mean loss = 6.9628495e-06
epoch 756: mean loss = 6.9940666e-06  learning rate = 2.9035442e-05
============================
Start of epoch 757
step 0: mean loss = 6.7522906e-06
step 100: mean loss = 6.5254876e-06
epoch 757: mean loss = 7.1016498e-06  learning rate = 2.9035442e-05
============================
Start of epoch 758
step 0: mean loss = 7.2398775e-06
step 100: mean loss = 6.676287e-06
epoch 758: mean loss = 7.4027985e-06  learning rate = 2.9035442e-05
============================
Start of epoch 759
step 0: mean loss = 5.838194e-06
step 100: mean loss = 7.4910336e-06
epoch 759: mean loss = 7.1800923e-06  learning rate = 2.9035442e-05
============================
Start of epoch 760
step 0: mean loss = 7.2190633e-06
step 100: mean loss = 7.05572e-06
epoch 760: mean loss = 7.1342083e-06  learning rate = 2.9035442e-05
============================
Start of epoch 761
step 0: mean loss = 6.9615317e-06
step 100: mean loss = 7.889329e-06
epoch 761: mean loss = 7.331802e-06  learning rate = 2.9035442e-05
============================
Start of epoch 762
step 0: mean loss = 9.447044e-06
step 100: mean loss = 7.791155e-06
epoch 762: mean loss = 7.260401e-06  learning rate = 2.9035442e-05
============================
Start of epoch 763
step 0: mean loss = 6.9830458e-06
step 100: mean loss = 6.8925265e-06
epoch 763: mean loss = 7.1111467e-06  learning rate = 2.9035442e-05
============================
Start of epoch 764
step 0: mean loss = 6.6635657e-06
step 100: mean loss = 7.5071744e-06
epoch 764: mean loss = 7.252651e-06  learning rate = 2.9035442e-05
============================
Start of epoch 765
step 0: mean loss = 8.010553e-06
step 100: mean loss = 7.030457e-06
epoch 765: mean loss = 7.294169e-06  learning rate = 2.9035442e-05
============================
Start of epoch 766
step 0: mean loss = 6.2579898e-06
step 100: mean loss = 7.743551e-06
epoch 766: mean loss = 7.158887e-06  learning rate = 2.9035442e-05
============================
Start of epoch 767
step 0: mean loss = 5.5741243e-06
step 100: mean loss = 7.6283245e-06
epoch 767: mean loss = 7.1184245e-06  learning rate = 2.9035442e-05
============================
Start of epoch 768
step 0: mean loss = 5.642316e-05
step 100: mean loss = 7.155093e-06
epoch 768: mean loss = 7.3334104e-06  learning rate = 2.9035442e-05
============================
Start of epoch 769
step 0: mean loss = 7.029633e-06
step 100: mean loss = 7.2498424e-06
epoch 769: mean loss = 7.1561476e-06  learning rate = 2.9035442e-05
============================
Start of epoch 770
step 0: mean loss = 6.16919e-06
step 100: mean loss = 7.643313e-06
epoch 770: mean loss = 7.227855e-06  learning rate = 2.9035442e-05
============================
Start of epoch 771
step 0: mean loss = 6.8775835e-06
step 100: mean loss = 6.505041e-06
epoch 771: mean loss = 7.2958564e-06  learning rate = 2.9035442e-05
============================
Start of epoch 772
step 0: mean loss = 5.616649e-06
step 100: mean loss = 7.557248e-06
epoch 772: mean loss = 7.048476e-06  learning rate = 2.9035442e-05
============================
Start of epoch 773
step 0: mean loss = 5.664683e-06
step 100: mean loss = 7.657256e-06
epoch 773: mean loss = 7.201331e-06  learning rate = 2.9035442e-05
============================
Start of epoch 774
step 0: mean loss = 5.1690417e-06
step 100: mean loss = 7.492297e-06
epoch 774: mean loss = 7.090001e-06  learning rate = 2.9035442e-05
============================
Start of epoch 775
step 0: mean loss = 7.067308e-06
step 100: mean loss = 7.8903495e-06
epoch 775: mean loss = 7.3716096e-06  learning rate = 2.9035442e-05
============================
Start of epoch 776
step 0: mean loss = 6.2519875e-06
step 100: mean loss = 7.0008423e-06
epoch 776: mean loss = 7.1660565e-06  learning rate = 2.9035442e-05
============================
Start of epoch 777
step 0: mean loss = 1.391116e-05
step 100: mean loss = 7.64092e-06
epoch 777: mean loss = 7.1742143e-06  learning rate = 2.9035442e-05
============================
Start of epoch 778
step 0: mean loss = 6.4025035e-06
step 100: mean loss = 7.0879514e-06
epoch 778: mean loss = 7.1539534e-06  learning rate = 2.9035442e-05
============================
Start of epoch 779
step 0: mean loss = 5.8652754e-06
step 100: mean loss = 6.8258846e-06
epoch 779: mean loss = 7.1849304e-06  learning rate = 2.9035442e-05
============================
Start of epoch 780
step 0: mean loss = 7.043965e-06
step 100: mean loss = 7.6135225e-06
epoch 780: mean loss = 7.212103e-06  learning rate = 2.9035442e-05
============================
Start of epoch 781
step 0: mean loss = 6.4375463e-06
step 100: mean loss = 7.5925323e-06
epoch 781: mean loss = 7.224213e-06  learning rate = 2.9035442e-05
============================
Start of epoch 782
step 0: mean loss = 5.655072e-06
step 100: mean loss = 7.75991e-06
epoch 782: mean loss = 7.270765e-06  learning rate = 2.9035442e-05
============================
Start of epoch 783
step 0: mean loss = 5.8174983e-06
step 100: mean loss = 7.769955e-06
epoch 783: mean loss = 7.2813477e-06  learning rate = 2.9035442e-05
============================
Start of epoch 784
step 0: mean loss = 5.9174627e-06
step 100: mean loss = 7.018414e-06
epoch 784: mean loss = 7.1796776e-06  learning rate = 2.9035442e-05
============================
Start of epoch 785
step 0: mean loss = 7.059669e-06
step 100: mean loss = 6.965635e-06
epoch 785: mean loss = 7.078489e-06  learning rate = 2.9035442e-05
============================
Start of epoch 786
step 0: mean loss = 5.539741e-06
step 100: mean loss = 6.9963503e-06
epoch 786: mean loss = 7.2015764e-06  learning rate = 2.9035442e-05
============================
Start of epoch 787
step 0: mean loss = 7.5190105e-06
step 100: mean loss = 6.918716e-06
epoch 787: mean loss = 7.022446e-06  learning rate = 2.9035442e-05
============================
Start of epoch 788
step 0: mean loss = 7.2541834e-06
step 100: mean loss = 7.534163e-06
epoch 788: mean loss = 7.0933124e-06  learning rate = 2.9035442e-05
============================
Start of epoch 789
step 0: mean loss = 6.970952e-06
step 100: mean loss = 6.311957e-06
epoch 789: mean loss = 7.0294122e-06  learning rate = 2.9035442e-05
============================
Start of epoch 790
step 0: mean loss = 5.5287464e-06
step 100: mean loss = 7.824497e-06
epoch 790: mean loss = 7.284891e-06  learning rate = 2.9035442e-05
============================
Start of epoch 791
step 0: mean loss = 5.31999e-06
step 100: mean loss = 6.6659095e-06
epoch 791: mean loss = 7.2044973e-06  learning rate = 2.9035442e-05
============================
Start of epoch 792
step 0: mean loss = 7.068476e-06
step 100: mean loss = 6.4512155e-06
epoch 792: mean loss = 7.1225177e-06  learning rate = 2.9035442e-05
============================
Start of epoch 793
step 0: mean loss = 5.8150677e-06
step 100: mean loss = 7.126361e-06
epoch 793: mean loss = 7.1875384e-06  learning rate = 2.7583666e-05
============================
Start of epoch 794
step 0: mean loss = 7.055084e-06
step 100: mean loss = 7.465124e-06
epoch 794: mean loss = 6.9945113e-06  learning rate = 2.7583666e-05
============================
Start of epoch 795
step 0: mean loss = 6.269427e-06
step 100: mean loss = 7.4256595e-06
epoch 795: mean loss = 6.9309026e-06  learning rate = 2.7583666e-05
============================
Start of epoch 796
step 0: mean loss = 6.7142164e-06
step 100: mean loss = 7.344282e-06
epoch 796: mean loss = 6.9637304e-06  learning rate = 2.7583666e-05
============================
Start of epoch 797
step 0: mean loss = 5.329448e-06
step 100: mean loss = 7.1989043e-06
epoch 797: mean loss = 6.8924965e-06  learning rate = 2.7583666e-05
============================
Start of epoch 798
step 0: mean loss = 6.9245066e-06
step 100: mean loss = 6.9696366e-06
epoch 798: mean loss = 7.040513e-06  learning rate = 2.7583666e-05
============================
Start of epoch 799
step 0: mean loss = 5.3985195e-06
step 100: mean loss = 6.804191e-06
epoch 799: mean loss = 7.155581e-06  learning rate = 2.7583666e-05
============================
Start of epoch 800
step 0: mean loss = 6.3084535e-06
step 100: mean loss = 6.661477e-06
epoch 800: mean loss = 6.793256e-06  learning rate = 2.7583666e-05
============================
Start of epoch 801
step 0: mean loss = 7.673981e-06
step 100: mean loss = 7.22867e-06
epoch 801: mean loss = 7.1760815e-06  learning rate = 2.7583666e-05
============================
Start of epoch 802
step 0: mean loss = 6.707767e-06
step 100: mean loss = 7.645122e-06
epoch 802: mean loss = 7.1222426e-06  learning rate = 2.7583666e-05
============================
Start of epoch 803
step 0: mean loss = 5.382957e-06
step 100: mean loss = 6.155768e-06
epoch 803: mean loss = 6.915926e-06  learning rate = 2.7583666e-05
============================
Start of epoch 804
step 0: mean loss = 6.4153314e-06
step 100: mean loss = 7.3909605e-06
epoch 804: mean loss = 7.025752e-06  learning rate = 2.7583666e-05
============================
Start of epoch 805
step 0: mean loss = 6.9260627e-06
step 100: mean loss = 7.630229e-06
epoch 805: mean loss = 7.1246177e-06  learning rate = 2.7583666e-05
============================
Start of epoch 806
step 0: mean loss = 7.183866e-06
step 100: mean loss = 6.7903693e-06
epoch 806: mean loss = 7.0790584e-06  learning rate = 2.7583666e-05
============================
Start of epoch 807
step 0: mean loss = 7.28955e-06
step 100: mean loss = 7.203687e-06
epoch 807: mean loss = 6.9009557e-06  learning rate = 2.7583666e-05
============================
Start of epoch 808
step 0: mean loss = 6.8101685e-06
step 100: mean loss = 7.2700705e-06
epoch 808: mean loss = 6.8411864e-06  learning rate = 2.7583666e-05
============================
Start of epoch 809
step 0: mean loss = 5.978163e-06
step 100: mean loss = 6.7459237e-06
epoch 809: mean loss = 6.9400103e-06  learning rate = 2.7583666e-05
============================
Start of epoch 810
step 0: mean loss = 6.4041724e-06
step 100: mean loss = 7.280193e-06
epoch 810: mean loss = 7.039854e-06  learning rate = 2.7583666e-05
============================
Start of epoch 811
step 0: mean loss = 6.459378e-06
step 100: mean loss = 7.816613e-06
epoch 811: mean loss = 7.1717095e-06  learning rate = 2.7583666e-05
============================
Start of epoch 812
step 0: mean loss = 5.18469e-05
step 100: mean loss = 6.716671e-06
epoch 812: mean loss = 7.0286983e-06  learning rate = 2.7583666e-05
============================
Start of epoch 813
step 0: mean loss = 6.8870995e-06
step 100: mean loss = 7.2886605e-06
epoch 813: mean loss = 7.073842e-06  learning rate = 2.7583666e-05
============================
Start of epoch 814
step 0: mean loss = 5.45429e-06
step 100: mean loss = 7.4316113e-06
epoch 814: mean loss = 7.058094e-06  learning rate = 2.7583666e-05
============================
Start of epoch 815
step 0: mean loss = 6.0059683e-06
step 100: mean loss = 7.571158e-06
epoch 815: mean loss = 6.9837924e-06  learning rate = 2.7583666e-05
============================
Start of epoch 816
step 0: mean loss = 5.333038e-06
step 100: mean loss = 7.5648704e-06
epoch 816: mean loss = 7.0503834e-06  learning rate = 2.7583666e-05
============================
Start of epoch 817
step 0: mean loss = 6.347943e-06
step 100: mean loss = 7.4509608e-06
epoch 817: mean loss = 7.0804554e-06  learning rate = 2.7583666e-05
============================
Start of epoch 818
step 0: mean loss = 6.2451763e-06
step 100: mean loss = 7.545312e-06
epoch 818: mean loss = 7.023951e-06  learning rate = 2.7583666e-05
============================
Start of epoch 819
step 0: mean loss = 6.2479576e-06
step 100: mean loss = 6.3543666e-06
epoch 819: mean loss = 7.0155997e-06  learning rate = 2.7583666e-05
============================
Start of epoch 820
step 0: mean loss = 5.999801e-06
step 100: mean loss = 7.674898e-06
epoch 820: mean loss = 7.1345644e-06  learning rate = 2.7583666e-05
============================
Start of epoch 821
step 0: mean loss = 5.9569147e-06
step 100: mean loss = 7.2567127e-06
epoch 821: mean loss = 6.9116704e-06  learning rate = 2.7583666e-05
============================
Start of epoch 822
step 0: mean loss = 5.4873713e-06
step 100: mean loss = 6.266993e-06
epoch 822: mean loss = 6.967217e-06  learning rate = 2.7583666e-05
============================
Start of epoch 823
step 0: mean loss = 5.861165e-06
step 100: mean loss = 6.7226392e-06
epoch 823: mean loss = 6.9522926e-06  learning rate = 2.7583666e-05
============================
Start of epoch 824
step 0: mean loss = 5.335798e-06
step 100: mean loss = 6.1233022e-06
epoch 824: mean loss = 7.0190963e-06  learning rate = 2.7583666e-05
============================
Start of epoch 825
step 0: mean loss = 7.0861943e-06
step 100: mean loss = 7.467387e-06
epoch 825: mean loss = 7.0830283e-06  learning rate = 2.7583666e-05
============================
Start of epoch 826
step 0: mean loss = 7.390753e-06
step 100: mean loss = 7.5013836e-06
epoch 826: mean loss = 7.041521e-06  learning rate = 2.7583666e-05
============================
Start of epoch 827
step 0: mean loss = 6.4588603e-06
step 100: mean loss = 6.7075252e-06
epoch 827: mean loss = 7.0204906e-06  learning rate = 2.7583666e-05
============================
Start of epoch 828
step 0: mean loss = 5.5066116e-06
step 100: mean loss = 7.3291953e-06
epoch 828: mean loss = 6.860637e-06  learning rate = 2.7583666e-05
============================
Start of epoch 829
step 0: mean loss = 5.980871e-06
step 100: mean loss = 6.6697858e-06
epoch 829: mean loss = 6.7976925e-06  learning rate = 2.7583666e-05
============================
Start of epoch 830
step 0: mean loss = 7.673715e-06
step 100: mean loss = 7.4627087e-06
epoch 830: mean loss = 7.0369015e-06  learning rate = 2.7583666e-05
============================
Start of epoch 831
step 0: mean loss = 6.2302875e-06
step 100: mean loss = 7.4370523e-06
epoch 831: mean loss = 7.0642745e-06  learning rate = 2.7583666e-05
============================
Start of epoch 832
step 0: mean loss = 5.8969877e-06
step 100: mean loss = 7.499613e-06
epoch 832: mean loss = 7.032109e-06  learning rate = 2.7583666e-05
============================
Start of epoch 833
step 0: mean loss = 6.1719797e-06
step 100: mean loss = 7.1878185e-06
epoch 833: mean loss = 6.8444447e-06  learning rate = 2.7583666e-05
============================
Start of epoch 834
step 0: mean loss = 6.743518e-06
step 100: mean loss = 7.40173e-06
epoch 834: mean loss = 7.017045e-06  learning rate = 2.7583666e-05
============================
Start of epoch 835
step 0: mean loss = 5.502133e-06
step 100: mean loss = 7.284008e-06
epoch 835: mean loss = 7.001009e-06  learning rate = 2.7583666e-05
============================
Start of epoch 836
step 0: mean loss = 7.060581e-06
step 100: mean loss = 6.7834276e-06
epoch 836: mean loss = 6.85188e-06  learning rate = 2.7583666e-05
============================
Start of epoch 837
step 0: mean loss = 7.1003924e-06
step 100: mean loss = 6.596456e-06
epoch 837: mean loss = 6.8352797e-06  learning rate = 2.7583666e-05
============================
Start of epoch 838
step 0: mean loss = 6.7506926e-06
step 100: mean loss = 7.687855e-06
epoch 838: mean loss = 7.0891356e-06  learning rate = 2.7583666e-05
============================
Start of epoch 839
step 0: mean loss = 6.025631e-06
step 100: mean loss = 7.19748e-06
epoch 839: mean loss = 6.9577627e-06  learning rate = 2.7583666e-05
============================
Start of epoch 840
step 0: mean loss = 6.1892397e-06
step 100: mean loss = 6.909566e-06
epoch 840: mean loss = 6.8908757e-06  learning rate = 2.7583666e-05
============================
Start of epoch 841
step 0: mean loss = 5.722326e-06
step 100: mean loss = 7.288546e-06
epoch 841: mean loss = 7.1568165e-06  learning rate = 2.7583666e-05
============================
Start of epoch 842
step 0: mean loss = 6.472157e-06
step 100: mean loss = 6.621947e-06
epoch 842: mean loss = 6.825755e-06  learning rate = 2.7583666e-05
============================
Start of epoch 843
step 0: mean loss = 6.409401e-06
step 100: mean loss = 6.1371134e-06
epoch 843: mean loss = 7.0068336e-06  learning rate = 2.7583666e-05
============================
Start of epoch 844
step 0: mean loss = 6.4499227e-06
step 100: mean loss = 6.086244e-06
epoch 844: mean loss = 6.8716363e-06  learning rate = 2.7583666e-05
============================
Start of epoch 845
step 0: mean loss = 6.2808826e-06
step 100: mean loss = 7.414528e-06
epoch 845: mean loss = 7.0277943e-06  learning rate = 2.7583666e-05
============================
Start of epoch 846
step 0: mean loss = 7.5694834e-06
step 100: mean loss = 6.065757e-06
epoch 846: mean loss = 6.945869e-06  learning rate = 2.7583666e-05
============================
Start of epoch 847
step 0: mean loss = 5.467573e-06
step 100: mean loss = 7.0312935e-06
epoch 847: mean loss = 6.924547e-06  learning rate = 2.7583666e-05
============================
Start of epoch 848
step 0: mean loss = 7.2009484e-06
step 100: mean loss = 6.916112e-06
epoch 848: mean loss = 7.127078e-06  learning rate = 2.7583666e-05
============================
Start of epoch 849
step 0: mean loss = 5.7875077e-06
step 100: mean loss = 6.715427e-06
epoch 849: mean loss = 7.805881e-06  learning rate = 2.7583666e-05
============================
Start of epoch 850
step 0: mean loss = 1.5147636e-05
step 100: mean loss = 9.656814e-06
epoch 850: mean loss = 8.392342e-06  learning rate = 2.7583666e-05
============================
Start of epoch 851
step 0: mean loss = 6.272811e-06
step 100: mean loss = 6.723193e-06
epoch 851: mean loss = 6.8250033e-06  learning rate = 2.7583666e-05
============================
Start of epoch 852
step 0: mean loss = 5.3014055e-06
step 100: mean loss = 6.636531e-06
epoch 852: mean loss = 6.863489e-06  learning rate = 2.7583666e-05
============================
Start of epoch 853
step 0: mean loss = 7.083904e-06
step 100: mean loss = 7.2894945e-06
epoch 853: mean loss = 6.882335e-06  learning rate = 2.7583666e-05
============================
Start of epoch 854
step 0: mean loss = 6.576297e-06
step 100: mean loss = 6.5606396e-06
epoch 854: mean loss = 6.837115e-06  learning rate = 2.7583666e-05
============================
Start of epoch 855
step 0: mean loss = 5.5232845e-06
step 100: mean loss = 7.3670612e-06
epoch 855: mean loss = 6.837928e-06  learning rate = 2.7583666e-05
============================
Start of epoch 856
step 0: mean loss = 5.6764247e-06
step 100: mean loss = 6.8214313e-06
epoch 856: mean loss = 7.0340866e-06  learning rate = 2.7583666e-05
============================
Start of epoch 857
step 0: mean loss = 6.5232944e-06
step 100: mean loss = 6.586742e-06
epoch 857: mean loss = 6.905435e-06  learning rate = 2.7583666e-05
============================
Start of epoch 858
step 0: mean loss = 5.1553316e-06
step 100: mean loss = 6.559816e-06
epoch 858: mean loss = 6.725888e-06  learning rate = 2.7583666e-05
============================
Start of epoch 859
step 0: mean loss = 6.7998008e-06
step 100: mean loss = 6.6507646e-06
epoch 859: mean loss = 7.021409e-06  learning rate = 2.7583666e-05
============================
Start of epoch 860
step 0: mean loss = 5.6128647e-06
step 100: mean loss = 7.4322943e-06
epoch 860: mean loss = 7.0447636e-06  learning rate = 2.7583666e-05
============================
Start of epoch 861
step 0: mean loss = 7.163567e-06
step 100: mean loss = 7.321966e-06
epoch 861: mean loss = 6.9236917e-06  learning rate = 2.7583666e-05
============================
Start of epoch 862
step 0: mean loss = 5.327385e-06
step 100: mean loss = 7.199643e-06
epoch 862: mean loss = 6.887095e-06  learning rate = 2.7583666e-05
============================
Start of epoch 863
step 0: mean loss = 4.6573587e-06
step 100: mean loss = 5.9737017e-06
epoch 863: mean loss = 6.6895104e-06  learning rate = 2.7583666e-05
============================
Start of epoch 864
step 0: mean loss = 1.2152219e-05
step 100: mean loss = 6.252548e-06
epoch 864: mean loss = 6.900664e-06  learning rate = 2.7583666e-05
============================
Start of epoch 865
step 0: mean loss = 6.631554e-06
step 100: mean loss = 6.8087184e-06
epoch 865: mean loss = 6.85196e-06  learning rate = 2.7583666e-05
============================
Start of epoch 866
step 0: mean loss = 5.5836226e-06
step 100: mean loss = 7.2974026e-06
epoch 866: mean loss = 6.806281e-06  learning rate = 2.7583666e-05
============================
Start of epoch 867
step 0: mean loss = 5.7894717e-06
step 100: mean loss = 6.721827e-06
epoch 867: mean loss = 6.817011e-06  learning rate = 2.7583666e-05
============================
Start of epoch 868
step 0: mean loss = 5.019279e-06
step 100: mean loss = 6.6111597e-06
epoch 868: mean loss = 6.874346e-06  learning rate = 2.7583666e-05
============================
Start of epoch 869
step 0: mean loss = 6.0046846e-06
step 100: mean loss = 6.6484818e-06
epoch 869: mean loss = 6.880127e-06  learning rate = 2.7583666e-05
============================
Start of epoch 870
step 0: mean loss = 5.767658e-06
step 100: mean loss = 6.8282784e-06
epoch 870: mean loss = 6.9539633e-06  learning rate = 2.7583666e-05
============================
Start of epoch 871
step 0: mean loss = 5.5854325e-06
step 100: mean loss = 7.2799626e-06
epoch 871: mean loss = 6.8015784e-06  learning rate = 2.7583666e-05
============================
Start of epoch 872
step 0: mean loss = 5.0232875e-06
step 100: mean loss = 7.503411e-06
epoch 872: mean loss = 7.0228957e-06  learning rate = 2.7583666e-05
============================
Start of epoch 873
step 0: mean loss = 5.3781578e-06
step 100: mean loss = 6.770999e-06
epoch 873: mean loss = 6.8251893e-06  learning rate = 2.6204483e-05
============================
Start of epoch 874
step 0: mean loss = 6.2858303e-06
step 100: mean loss = 6.5230774e-06
epoch 874: mean loss = 6.6776297e-06  learning rate = 2.6204483e-05
============================
Start of epoch 875
step 0: mean loss = 4.9992645e-06
step 100: mean loss = 7.281237e-06
epoch 875: mean loss = 6.896882e-06  learning rate = 2.6204483e-05
============================
Start of epoch 876
step 0: mean loss = 6.330396e-06
step 100: mean loss = 6.7456335e-06
epoch 876: mean loss = 6.749717e-06  learning rate = 2.6204483e-05
============================
Start of epoch 877
step 0: mean loss = 5.2735386e-06
step 100: mean loss = 6.7913415e-06
epoch 877: mean loss = 6.885586e-06  learning rate = 2.6204483e-05
============================
Start of epoch 878
step 0: mean loss = 5.582169e-06
step 100: mean loss = 6.917836e-06
epoch 878: mean loss = 6.8703234e-06  learning rate = 2.6204483e-05
============================
Start of epoch 879
step 0: mean loss = 6.862917e-06
step 100: mean loss = 7.1902573e-06
epoch 879: mean loss = 6.9964467e-06  learning rate = 2.6204483e-05
============================
Start of epoch 880
step 0: mean loss = 6.1654932e-06
step 100: mean loss = 7.12603e-06
epoch 880: mean loss = 6.86726e-06  learning rate = 2.6204483e-05
============================
Start of epoch 881
step 0: mean loss = 5.7994753e-06
step 100: mean loss = 6.7985343e-06
epoch 881: mean loss = 6.818217e-06  learning rate = 2.6204483e-05
============================
Start of epoch 882
step 0: mean loss = 5.913723e-06
step 100: mean loss = 7.072772e-06
epoch 882: mean loss = 6.673613e-06  learning rate = 2.6204483e-05
============================
Start of epoch 883
step 0: mean loss = 4.4080402e-06
step 100: mean loss = 6.8715485e-06
epoch 883: mean loss = 6.952003e-06  learning rate = 2.6204483e-05
============================
Start of epoch 884
step 0: mean loss = 5.492453e-06
step 100: mean loss = 7.082737e-06
epoch 884: mean loss = 6.8681375e-06  learning rate = 2.6204483e-05
============================
Start of epoch 885
step 0: mean loss = 5.2386695e-06
step 100: mean loss = 6.015971e-06
epoch 885: mean loss = 6.758241e-06  learning rate = 2.6204483e-05
============================
Start of epoch 886
step 0: mean loss = 6.5195054e-06
step 100: mean loss = 6.2341915e-06
epoch 886: mean loss = 6.9084203e-06  learning rate = 2.6204483e-05
============================
Start of epoch 887
step 0: mean loss = 7.3907477e-06
step 100: mean loss = 7.089156e-06
epoch 887: mean loss = 6.9042e-06  learning rate = 2.6204483e-05
============================
Start of epoch 888
step 0: mean loss = 5.9809263e-06
step 100: mean loss = 6.749514e-06
epoch 888: mean loss = 6.82173e-06  learning rate = 2.6204483e-05
============================
Start of epoch 889
step 0: mean loss = 5.049381e-06
step 100: mean loss = 6.6572275e-06
epoch 889: mean loss = 6.9157923e-06  learning rate = 2.6204483e-05
============================
Start of epoch 890
step 0: mean loss = 6.560658e-06
step 100: mean loss = 7.1667037e-06
epoch 890: mean loss = 6.7175097e-06  learning rate = 2.6204483e-05
============================
Start of epoch 891
step 0: mean loss = 5.083378e-06
step 100: mean loss = 6.659335e-06
epoch 891: mean loss = 6.7663364e-06  learning rate = 2.6204483e-05
============================
Start of epoch 892
step 0: mean loss = 5.3896247e-06
step 100: mean loss = 7.3317447e-06
epoch 892: mean loss = 6.7884853e-06  learning rate = 2.6204483e-05
============================
Start of epoch 893
step 0: mean loss = 5.1014686e-06
step 100: mean loss = 6.499692e-06
epoch 893: mean loss = 6.808069e-06  learning rate = 2.6204483e-05
============================
Start of epoch 894
step 0: mean loss = 6.015559e-06
step 100: mean loss = 7.499497e-06
epoch 894: mean loss = 6.978472e-06  learning rate = 2.6204483e-05
============================
Start of epoch 895
step 0: mean loss = 6.815978e-06
step 100: mean loss = 6.552555e-06
epoch 895: mean loss = 6.724869e-06  learning rate = 2.6204483e-05
============================
Start of epoch 896
step 0: mean loss = 6.5825966e-06
step 100: mean loss = 7.1238637e-06
epoch 896: mean loss = 6.7251076e-06  learning rate = 2.6204483e-05
============================
Start of epoch 897
step 0: mean loss = 5.352982e-06
step 100: mean loss = 6.722918e-06
epoch 897: mean loss = 6.927436e-06  learning rate = 2.6204483e-05
============================
Start of epoch 898
step 0: mean loss = 2.2866036e-05
step 100: mean loss = 7.347307e-06
epoch 898: mean loss = 6.857294e-06  learning rate = 2.6204483e-05
============================
Start of epoch 899
step 0: mean loss = 5.475661e-06
step 100: mean loss = 7.254275e-06
epoch 899: mean loss = 6.7407714e-06  learning rate = 2.6204483e-05
============================
Start of epoch 900
step 0: mean loss = 6.1359274e-06
step 100: mean loss = 6.923958e-06
epoch 900: mean loss = 6.756387e-06  learning rate = 2.6204483e-05
============================
Start of epoch 901
step 0: mean loss = 5.60687e-06
step 100: mean loss = 6.5158156e-06
epoch 901: mean loss = 6.8613967e-06  learning rate = 2.6204483e-05
============================
Start of epoch 902
step 0: mean loss = 5.974669e-06
step 100: mean loss = 7.353655e-06
epoch 902: mean loss = 6.826764e-06  learning rate = 2.6204483e-05
============================
Start of epoch 903
step 0: mean loss = 6.3808106e-06
step 100: mean loss = 6.5333293e-06
epoch 903: mean loss = 6.7402248e-06  learning rate = 2.6204483e-05
============================
Start of epoch 904
step 0: mean loss = 6.2065046e-06
step 100: mean loss = 6.814826e-06
epoch 904: mean loss = 6.830001e-06  learning rate = 2.6204483e-05
============================
Start of epoch 905
step 0: mean loss = 5.0294775e-06
step 100: mean loss = 6.784349e-06
epoch 905: mean loss = 6.9196594e-06  learning rate = 2.6204483e-05
============================
Start of epoch 906
step 0: mean loss = 5.269997e-06
step 100: mean loss = 7.2923203e-06
epoch 906: mean loss = 6.814311e-06  learning rate = 2.6204483e-05
============================
Start of epoch 907
step 0: mean loss = 6.4514707e-06
step 100: mean loss = 6.723075e-06
epoch 907: mean loss = 6.7513233e-06  learning rate = 2.6204483e-05
============================
Start of epoch 908
step 0: mean loss = 5.6275094e-06
step 100: mean loss = 6.442312e-06
epoch 908: mean loss = 6.702572e-06  learning rate = 2.6204483e-05
============================
Start of epoch 909
step 0: mean loss = 5.6757212e-06
step 100: mean loss = 7.363162e-06
epoch 909: mean loss = 6.854974e-06  learning rate = 2.6204483e-05
============================
Start of epoch 910
step 0: mean loss = 5.171216e-06
step 100: mean loss = 7.003131e-06
epoch 910: mean loss = 6.818916e-06  learning rate = 2.6204483e-05
============================
Start of epoch 911
step 0: mean loss = 6.4545306e-06
step 100: mean loss = 7.227888e-06
epoch 911: mean loss = 6.864379e-06  learning rate = 2.6204483e-05
============================
Start of epoch 912
step 0: mean loss = 6.4032665e-06
step 100: mean loss = 7.4308705e-06
epoch 912: mean loss = 7.010567e-06  learning rate = 2.6204483e-05
============================
Start of epoch 913
step 0: mean loss = 5.6817726e-06
step 100: mean loss = 6.509427e-06
epoch 913: mean loss = 6.6331895e-06  learning rate = 2.6204483e-05
============================
Start of epoch 914
step 0: mean loss = 1.2916561e-05
step 100: mean loss = 6.7084866e-06
epoch 914: mean loss = 6.6867256e-06  learning rate = 2.6204483e-05
============================
Start of epoch 915
step 0: mean loss = 6.3075713e-06
step 100: mean loss = 6.7942096e-06
epoch 915: mean loss = 6.8275567e-06  learning rate = 2.6204483e-05
============================
Start of epoch 916
step 0: mean loss = 6.098676e-06
step 100: mean loss = 7.204862e-06
epoch 916: mean loss = 6.750052e-06  learning rate = 2.6204483e-05
============================
Start of epoch 917
step 0: mean loss = 6.646571e-06
step 100: mean loss = 6.050914e-06
epoch 917: mean loss = 6.72635e-06  learning rate = 2.6204483e-05
============================
Start of epoch 918
step 0: mean loss = 5.772041e-06
step 100: mean loss = 6.6883777e-06
epoch 918: mean loss = 6.751334e-06  learning rate = 2.6204483e-05
============================
Start of epoch 919
step 0: mean loss = 4.6877467e-06
step 100: mean loss = 7.2234134e-06
epoch 919: mean loss = 6.8080717e-06  learning rate = 2.6204483e-05
============================
Start of epoch 920
step 0: mean loss = 5.504281e-06
step 100: mean loss = 6.6274233e-06
epoch 920: mean loss = 6.8759923e-06  learning rate = 2.6204483e-05
============================
Start of epoch 921
step 0: mean loss = 5.061342e-06
step 100: mean loss = 7.1680915e-06
epoch 921: mean loss = 6.7435312e-06  learning rate = 2.6204483e-05
============================
Start of epoch 922
step 0: mean loss = 5.070654e-06
step 100: mean loss = 6.546073e-06
epoch 922: mean loss = 6.6628922e-06  learning rate = 2.6204483e-05
============================
Start of epoch 923
step 0: mean loss = 6.460095e-06
step 100: mean loss = 7.353137e-06
epoch 923: mean loss = 6.779395e-06  learning rate = 2.6204483e-05
============================
Start of epoch 924
step 0: mean loss = 4.617834e-06
step 100: mean loss = 7.317354e-06
epoch 924: mean loss = 6.8070117e-06  learning rate = 2.6204483e-05
============================
Start of epoch 925
step 0: mean loss = 5.873902e-06
step 100: mean loss = 6.4615074e-06
epoch 925: mean loss = 6.672744e-06  learning rate = 2.6204483e-05
============================
Start of epoch 926
step 0: mean loss = 6.141425e-06
step 100: mean loss = 6.470077e-06
epoch 926: mean loss = 6.7969836e-06  learning rate = 2.6204483e-05
============================
Start of epoch 927
step 0: mean loss = 6.1458322e-06
step 100: mean loss = 7.236515e-06
epoch 927: mean loss = 6.746254e-06  learning rate = 2.6204483e-05
============================
Start of epoch 928
step 0: mean loss = 5.5729142e-06
step 100: mean loss = 6.033022e-06
epoch 928: mean loss = 6.8279633e-06  learning rate = 2.6204483e-05
============================
Start of epoch 929
step 0: mean loss = 6.2446297e-06
step 100: mean loss = 6.7792907e-06
epoch 929: mean loss = 6.6732837e-06  learning rate = 2.6204483e-05
============================
Start of epoch 930
step 0: mean loss = 7.753896e-06
step 100: mean loss = 6.754161e-06
epoch 930: mean loss = 6.7809738e-06  learning rate = 2.6204483e-05
============================
Start of epoch 931
step 0: mean loss = 6.88655e-06
step 100: mean loss = 6.4532696e-06
epoch 931: mean loss = 6.8126e-06  learning rate = 2.6204483e-05
============================
Start of epoch 932
step 0: mean loss = 6.090827e-06
step 100: mean loss = 6.517016e-06
epoch 932: mean loss = 6.740711e-06  learning rate = 2.6204483e-05
============================
Start of epoch 933
step 0: mean loss = 6.3316807e-06
step 100: mean loss = 6.73839e-06
epoch 933: mean loss = 6.732057e-06  learning rate = 2.6204483e-05
============================
Start of epoch 934
step 0: mean loss = 5.3721003e-05
step 100: mean loss = 6.9858243e-06
epoch 934: mean loss = 6.7032897e-06  learning rate = 2.6204483e-05
============================
Start of epoch 935
step 0: mean loss = 6.9085727e-06
step 100: mean loss = 6.2375693e-06
epoch 935: mean loss = 6.621561e-06  learning rate = 2.6204483e-05
============================
Start of epoch 936
step 0: mean loss = 1.5786642e-05
step 100: mean loss = 6.839655e-06
epoch 936: mean loss = 6.822019e-06  learning rate = 2.6204483e-05
============================
Start of epoch 937
step 0: mean loss = 5.410025e-06
step 100: mean loss = 6.7037263e-06
epoch 937: mean loss = 6.7544383e-06  learning rate = 2.6204483e-05
============================
Start of epoch 938
step 0: mean loss = 5.3586764e-06
step 100: mean loss = 5.973637e-06
epoch 938: mean loss = 6.6839325e-06  learning rate = 2.6204483e-05
============================
Start of epoch 939
step 0: mean loss = 6.790965e-06
step 100: mean loss = 6.678566e-06
epoch 939: mean loss = 6.6616753e-06  learning rate = 2.6204483e-05
============================
Start of epoch 940
step 0: mean loss = 5.92122e-06
step 100: mean loss = 7.1096188e-06
epoch 940: mean loss = 6.7440396e-06  learning rate = 2.6204483e-05
============================
Start of epoch 941
step 0: mean loss = 6.2224476e-06
step 100: mean loss = 6.6264124e-06
epoch 941: mean loss = 6.6501098e-06  learning rate = 2.6204483e-05
============================
Start of epoch 942
step 0: mean loss = 5.415748e-06
step 100: mean loss = 7.1527284e-06
epoch 942: mean loss = 6.6814455e-06  learning rate = 2.6204483e-05
============================
Start of epoch 943
step 0: mean loss = 5.0136236e-06
step 100: mean loss = 5.8305604e-06
epoch 943: mean loss = 6.754912e-06  learning rate = 2.6204483e-05
============================
Start of epoch 944
step 0: mean loss = 4.9062423e-06
step 100: mean loss = 6.4197407e-06
epoch 944: mean loss = 6.7488186e-06  learning rate = 2.6204483e-05
============================
Start of epoch 945
step 0: mean loss = 5.681357e-06
step 100: mean loss = 6.4331107e-06
epoch 945: mean loss = 6.7409596e-06  learning rate = 2.6204483e-05
============================
Start of epoch 946
step 0: mean loss = 6.9661446e-06
step 100: mean loss = 5.837396e-06
epoch 946: mean loss = 6.6869975e-06  learning rate = 2.6204483e-05
============================
Start of epoch 947
step 0: mean loss = 6.533859e-06
step 100: mean loss = 7.4167574e-06
epoch 947: mean loss = 6.927591e-06  learning rate = 2.6204483e-05
============================
Start of epoch 948
step 0: mean loss = 1.2336579e-05
step 100: mean loss = 7.2130265e-06
epoch 948: mean loss = 6.6961566e-06  learning rate = 2.6204483e-05
============================
Start of epoch 949
step 0: mean loss = 6.246289e-06
step 100: mean loss = 6.4946926e-06
epoch 949: mean loss = 6.7038764e-06  learning rate = 2.6204483e-05
============================
Start of epoch 950
step 0: mean loss = 5.794718e-06
step 100: mean loss = 6.484411e-06
epoch 950: mean loss = 6.589767e-06  learning rate = 2.6204483e-05
============================
Start of epoch 951
step 0: mean loss = 5.7184125e-06
step 100: mean loss = 7.3943006e-06
epoch 951: mean loss = 6.7656783e-06  learning rate = 2.6204483e-05
============================
Start of epoch 952
step 0: mean loss = 6.0814154e-06
step 100: mean loss = 6.5838485e-06
epoch 952: mean loss = 6.6151597e-06  learning rate = 2.489426e-05
============================
Start of epoch 953
step 0: mean loss = 6.218999e-06
step 100: mean loss = 6.4803166e-06
epoch 953: mean loss = 6.6372536e-06  learning rate = 2.489426e-05
============================
Start of epoch 954
step 0: mean loss = 5.1996335e-06
step 100: mean loss = 6.0521634e-06
epoch 954: mean loss = 6.6414186e-06  learning rate = 2.489426e-05
============================
Start of epoch 955
step 0: mean loss = 6.2942927e-06
step 100: mean loss = 6.5728736e-06
epoch 955: mean loss = 6.6455696e-06  learning rate = 2.489426e-05
============================
Start of epoch 956
step 0: mean loss = 5.5357923e-06
step 100: mean loss = 7.123078e-06
epoch 956: mean loss = 6.6272396e-06  learning rate = 2.489426e-05
============================
Start of epoch 957
step 0: mean loss = 5.5336595e-06
step 100: mean loss = 6.9798016e-06
epoch 957: mean loss = 6.6051293e-06  learning rate = 2.489426e-05
============================
Start of epoch 958
step 0: mean loss = 4.963864e-06
step 100: mean loss = 7.102128e-06
epoch 958: mean loss = 6.60635e-06  learning rate = 2.489426e-05
============================
Start of epoch 959
step 0: mean loss = 6.023669e-06
step 100: mean loss = 7.1011514e-06
epoch 959: mean loss = 6.706127e-06  learning rate = 2.489426e-05
============================
Start of epoch 960
step 0: mean loss = 4.5828483e-06
step 100: mean loss = 6.5437152e-06
epoch 960: mean loss = 6.563884e-06  learning rate = 2.489426e-05
============================
Start of epoch 961
step 0: mean loss = 6.7044266e-06
step 100: mean loss = 6.8140366e-06
epoch 961: mean loss = 6.486305e-06  learning rate = 2.489426e-05
============================
Start of epoch 962
step 0: mean loss = 5.6349895e-06
step 100: mean loss = 6.2035488e-06
epoch 962: mean loss = 6.5891672e-06  learning rate = 2.489426e-05
============================
Start of epoch 963
step 0: mean loss = 6.296981e-06
step 100: mean loss = 7.0684664e-06
epoch 963: mean loss = 6.677115e-06  learning rate = 2.489426e-05
============================
Start of epoch 964
step 0: mean loss = 6.1275114e-06
step 100: mean loss = 6.577598e-06
epoch 964: mean loss = 6.640052e-06  learning rate = 2.489426e-05
============================
Start of epoch 965
step 0: mean loss = 5.7560364e-06
step 100: mean loss = 5.5750324e-06
epoch 965: mean loss = 6.692183e-06  learning rate = 2.489426e-05
============================
Start of epoch 966
step 0: mean loss = 5.8285914e-06
step 100: mean loss = 7.0239703e-06
epoch 966: mean loss = 6.5667427e-06  learning rate = 2.489426e-05
============================
Start of epoch 967
step 0: mean loss = 5.1097577e-06
step 100: mean loss = 6.2849035e-06
epoch 967: mean loss = 6.671209e-06  learning rate = 2.489426e-05
============================
Start of epoch 968
step 0: mean loss = 6.459539e-06
step 100: mean loss = 6.372598e-06
epoch 968: mean loss = 6.5119148e-06  learning rate = 2.489426e-05
============================
Start of epoch 969
step 0: mean loss = 1.1267643e-05
step 100: mean loss = 7.0328915e-06
epoch 969: mean loss = 6.5339473e-06  learning rate = 2.489426e-05
============================
Start of epoch 970
step 0: mean loss = 4.9917426e-06
step 100: mean loss = 6.256247e-06
epoch 970: mean loss = 6.5277786e-06  learning rate = 2.489426e-05
============================
Start of epoch 971
step 0: mean loss = 6.020957e-06
step 100: mean loss = 7.172146e-06
epoch 971: mean loss = 6.6227785e-06  learning rate = 2.489426e-05
============================
Start of epoch 972
step 0: mean loss = 6.412664e-06
step 100: mean loss = 6.4968485e-06
epoch 972: mean loss = 6.5342283e-06  learning rate = 2.489426e-05
============================
Start of epoch 973
step 0: mean loss = 6.106113e-06
step 100: mean loss = 7.1778018e-06
epoch 973: mean loss = 6.609909e-06  learning rate = 2.489426e-05
============================
Start of epoch 974
step 0: mean loss = 5.1089532e-06
step 100: mean loss = 6.2494523e-06
epoch 974: mean loss = 6.5422228e-06  learning rate = 2.489426e-05
============================
Start of epoch 975
step 0: mean loss = 7.156621e-06
step 100: mean loss = 6.6757784e-06
epoch 975: mean loss = 6.6666207e-06  learning rate = 2.489426e-05
============================
Start of epoch 976
step 0: mean loss = 6.7400424e-06
step 100: mean loss = 6.895766e-06
epoch 976: mean loss = 6.526411e-06  learning rate = 2.489426e-05
============================
Start of epoch 977
step 0: mean loss = 5.8761993e-06
step 100: mean loss = 6.896359e-06
epoch 977: mean loss = 6.5559475e-06  learning rate = 2.489426e-05
============================
Start of epoch 978
step 0: mean loss = 7.2081266e-06
step 100: mean loss = 6.7295723e-06
epoch 978: mean loss = 6.6435214e-06  learning rate = 2.489426e-05
============================
Start of epoch 979
step 0: mean loss = 5.224346e-06
step 100: mean loss = 7.183927e-06
epoch 979: mean loss = 6.553744e-06  learning rate = 2.489426e-05
============================
Start of epoch 980
step 0: mean loss = 5.637983e-06
step 100: mean loss = 6.5742843e-06
epoch 980: mean loss = 6.565903e-06  learning rate = 2.489426e-05
============================
Start of epoch 981
step 0: mean loss = 5.1432326e-06
step 100: mean loss = 6.408252e-06
epoch 981: mean loss = 6.5793156e-06  learning rate = 2.489426e-05
============================
Start of epoch 982
step 0: mean loss = 6.4274645e-06
step 100: mean loss = 6.3522243e-06
epoch 982: mean loss = 6.5939053e-06  learning rate = 2.489426e-05
============================
Start of epoch 983
step 0: mean loss = 6.092781e-06
step 100: mean loss = 7.1079785e-06
epoch 983: mean loss = 6.560048e-06  learning rate = 2.489426e-05
============================
Start of epoch 984
step 0: mean loss = 4.523701e-06
step 100: mean loss = 6.1626824e-06
epoch 984: mean loss = 6.534831e-06  learning rate = 2.489426e-05
============================
Start of epoch 985
step 0: mean loss = 4.9136343e-06
step 100: mean loss = 6.4073315e-06
epoch 985: mean loss = 6.5097497e-06  learning rate = 2.489426e-05
============================
Start of epoch 986
step 0: mean loss = 6.2260788e-06
step 100: mean loss = 6.806295e-06
epoch 986: mean loss = 6.674488e-06  learning rate = 2.489426e-05
============================
Start of epoch 987
step 0: mean loss = 5.47765e-06
step 100: mean loss = 6.8733716e-06
epoch 987: mean loss = 6.5100626e-06  learning rate = 2.489426e-05
============================
Start of epoch 988
step 0: mean loss = 4.7347007e-06
step 100: mean loss = 6.275233e-06
epoch 988: mean loss = 6.573081e-06  learning rate = 2.489426e-05
============================
Start of epoch 989
step 0: mean loss = 6.8205104e-06
step 100: mean loss = 5.8875903e-06
epoch 989: mean loss = 6.576182e-06  learning rate = 2.489426e-05
============================
Start of epoch 990
step 0: mean loss = 6.224176e-06
step 100: mean loss = 6.594796e-06
epoch 990: mean loss = 6.6755133e-06  learning rate = 2.489426e-05
============================
Start of epoch 991
step 0: mean loss = 5.190771e-06
step 100: mean loss = 7.0315473e-06
epoch 991: mean loss = 6.616974e-06  learning rate = 2.489426e-05
============================
Start of epoch 992
step 0: mean loss = 5.967746e-06
step 100: mean loss = 6.0398233e-06
epoch 992: mean loss = 6.3906546e-06  learning rate = 2.489426e-05
============================
Start of epoch 993
step 0: mean loss = 6.800726e-06
step 100: mean loss = 6.5967583e-06
epoch 993: mean loss = 6.6155253e-06  learning rate = 2.489426e-05
============================
Start of epoch 994
step 0: mean loss = 6.3739567e-06
step 100: mean loss = 6.9791467e-06
epoch 994: mean loss = 6.6337957e-06  learning rate = 2.489426e-05
============================
Start of epoch 995
step 0: mean loss = 5.3016747e-06
step 100: mean loss = 6.889942e-06
epoch 995: mean loss = 6.4220203e-06  learning rate = 2.489426e-05
============================
Start of epoch 996
step 0: mean loss = 6.1748883e-06
step 100: mean loss = 6.4802166e-06
epoch 996: mean loss = 6.46054e-06  learning rate = 2.489426e-05
============================
Start of epoch 997
step 0: mean loss = 5.8897162e-06
step 100: mean loss = 6.1256615e-06
epoch 997: mean loss = 6.4800743e-06  learning rate = 2.489426e-05
============================
Start of epoch 998
step 0: mean loss = 5.5124497e-06
step 100: mean loss = 6.4425235e-06
epoch 998: mean loss = 6.5819095e-06  learning rate = 2.489426e-05
============================
Start of epoch 999
step 0: mean loss = 5.78501e-06
step 100: mean loss = 5.7448874e-06
epoch 999: mean loss = 6.5707827e-06  learning rate = 2.489426e-05
============================
Start of epoch 1000
step 0: mean loss = 7.5345856e-06
step 100: mean loss = 5.938811e-06
epoch 1000: mean loss = 6.5778772e-06  learning rate = 2.489426e-05
============================
Start of epoch 1001
step 0: mean loss = 5.531587e-06
step 100: mean loss = 6.1206956e-06
epoch 1001: mean loss = 6.510154e-06  learning rate = 2.489426e-05
============================
Start of epoch 1002
step 0: mean loss = 5.7992174e-06
step 100: mean loss = 6.3244306e-06
epoch 1002: mean loss = 6.5998925e-06  learning rate = 2.489426e-05
============================
Start of epoch 1003
step 0: mean loss = 7.649765e-06
step 100: mean loss = 6.4544192e-06
epoch 1003: mean loss = 6.52839e-06  learning rate = 2.489426e-05
============================
Start of epoch 1004
step 0: mean loss = 5.801528e-06
step 100: mean loss = 6.8295544e-06
epoch 1004: mean loss = 6.362248e-06  learning rate = 2.489426e-05
============================
Start of epoch 1005
step 0: mean loss = 5.501459e-06
step 100: mean loss = 6.9933963e-06
epoch 1005: mean loss = 6.482132e-06  learning rate = 2.489426e-05
============================
Start of epoch 1006
step 0: mean loss = 4.721718e-06
step 100: mean loss = 5.893274e-06
epoch 1006: mean loss = 6.4892156e-06  learning rate = 2.489426e-05
============================
Start of epoch 1007
step 0: mean loss = 5.591909e-06
step 100: mean loss = 6.8234485e-06
epoch 1007: mean loss = 6.376122e-06  learning rate = 2.489426e-05
============================
Start of epoch 1008
step 0: mean loss = 5.5702053e-06
step 100: mean loss = 6.1908404e-06
epoch 1008: mean loss = 6.315515e-06  learning rate = 2.489426e-05
============================
Start of epoch 1009
step 0: mean loss = 5.38974e-06
step 100: mean loss = 6.1600786e-06
epoch 1009: mean loss = 6.298155e-06  learning rate = 2.489426e-05
============================
Start of epoch 1010
step 0: mean loss = 5.855424e-06
step 100: mean loss = 6.0976813e-06
epoch 1010: mean loss = 6.505759e-06  learning rate = 2.489426e-05
============================
Start of epoch 1011
step 0: mean loss = 6.0191896e-06
step 100: mean loss = 6.8820386e-06
epoch 1011: mean loss = 6.4760457e-06  learning rate = 2.489426e-05
============================
Start of epoch 1012
step 0: mean loss = 4.6306523e-06
step 100: mean loss = 6.077294e-06
epoch 1012: mean loss = 6.2626304e-06  learning rate = 2.489426e-05
============================
Start of epoch 1013
step 0: mean loss = 5.169752e-06
step 100: mean loss = 5.8081237e-06
epoch 1013: mean loss = 6.461637e-06  learning rate = 2.489426e-05
============================
Start of epoch 1014
step 0: mean loss = 5.3257468e-06
step 100: mean loss = 6.095939e-06
epoch 1014: mean loss = 6.4277365e-06  learning rate = 2.489426e-05
============================
Start of epoch 1015
step 0: mean loss = 5.748723e-06
step 100: mean loss = 6.5667923e-06
epoch 1015: mean loss = 6.4974834e-06  learning rate = 2.489426e-05
============================
Start of epoch 1016
step 0: mean loss = 6.672374e-06
step 100: mean loss = 6.863449e-06
epoch 1016: mean loss = 6.3691473e-06  learning rate = 2.489426e-05
============================
Start of epoch 1017
step 0: mean loss = 5.5603632e-05
step 100: mean loss = 6.3635757e-06
epoch 1017: mean loss = 6.424389e-06  learning rate = 2.489426e-05
============================
Start of epoch 1018
step 0: mean loss = 5.7984334e-06
step 100: mean loss = 6.8514983e-06
epoch 1018: mean loss = 6.3813013e-06  learning rate = 2.489426e-05
============================
Start of epoch 1019
step 0: mean loss = 4.4898e-06
step 100: mean loss = 6.609861e-06
epoch 1019: mean loss = 6.3473794e-06  learning rate = 2.489426e-05
============================
Start of epoch 1020
step 0: mean loss = 5.0629255e-06
step 100: mean loss = 6.1061564e-06
epoch 1020: mean loss = 6.355945e-06  learning rate = 2.489426e-05
============================
Start of epoch 1021
step 0: mean loss = 5.4564393e-06
step 100: mean loss = 5.5989817e-06
epoch 1021: mean loss = 6.385104e-06  learning rate = 2.489426e-05
============================
Start of epoch 1022
step 0: mean loss = 4.782284e-06
step 100: mean loss = 6.828172e-06
epoch 1022: mean loss = 6.432437e-06  learning rate = 2.489426e-05
============================
Start of epoch 1023
step 0: mean loss = 5.7365005e-06
step 100: mean loss = 7.0367623e-06
epoch 1023: mean loss = 6.4305646e-06  learning rate = 2.489426e-05
============================
Start of epoch 1024
step 0: mean loss = 6.12694e-06
step 100: mean loss = 5.5411283e-06
epoch 1024: mean loss = 6.2255763e-06  learning rate = 2.489426e-05
============================
Start of epoch 1025
step 0: mean loss = 6.425138e-06
step 100: mean loss = 6.3684097e-06
epoch 1025: mean loss = 6.442244e-06  learning rate = 2.489426e-05
============================
Start of epoch 1026
step 0: mean loss = 4.900282e-06
step 100: mean loss = 6.2153285e-06
epoch 1026: mean loss = 6.340758e-06  learning rate = 2.489426e-05
============================
Start of epoch 1027
step 0: mean loss = 6.1469977e-06
step 100: mean loss = 6.2902e-06
epoch 1027: mean loss = 6.4975115e-06  learning rate = 2.489426e-05
============================
Start of epoch 1028
step 0: mean loss = 6.753315e-06
step 100: mean loss = 6.261665e-06
epoch 1028: mean loss = 6.342536e-06  learning rate = 2.489426e-05
============================
Start of epoch 1029
step 0: mean loss = 5.160945e-06
step 100: mean loss = 6.6155894e-06
epoch 1029: mean loss = 6.257888e-06  learning rate = 2.489426e-05
============================
Start of epoch 1030
step 0: mean loss = 5.654942e-06
step 100: mean loss = 5.4684356e-06
epoch 1030: mean loss = 6.2974846e-06  learning rate = 2.489426e-05
============================
Start of epoch 1031
step 0: mean loss = 5.404412e-06
step 100: mean loss = 6.1478386e-06
epoch 1031: mean loss = 6.356114e-06  learning rate = 2.489426e-05
============================
Start of epoch 1032
step 0: mean loss = 7.2706594e-06
step 100: mean loss = 6.9891053e-06
epoch 1032: mean loss = 6.4384267e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1033
step 0: mean loss = 4.538232e-06
step 100: mean loss = 6.1854644e-06
epoch 1033: mean loss = 6.3288417e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1034
step 0: mean loss = 5.220863e-06
step 100: mean loss = 5.4324105e-06
epoch 1034: mean loss = 6.279992e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1035
step 0: mean loss = 5.817913e-06
step 100: mean loss = 6.741313e-06
epoch 1035: mean loss = 6.2526055e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1036
step 0: mean loss = 4.373277e-06
step 100: mean loss = 6.093684e-06
epoch 1036: mean loss = 6.1253227e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1037
step 0: mean loss = 6.2083172e-06
step 100: mean loss = 6.6502093e-06
epoch 1037: mean loss = 6.233109e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1038
step 0: mean loss = 5.271948e-06
step 100: mean loss = 6.1149426e-06
epoch 1038: mean loss = 6.2982044e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1039
step 0: mean loss = 4.8393467e-06
step 100: mean loss = 6.258765e-06
epoch 1039: mean loss = 6.3491307e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1040
step 0: mean loss = 5.6177987e-06
step 100: mean loss = 6.1177025e-06
epoch 1040: mean loss = 6.193001e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1041
step 0: mean loss = 6.330867e-06
step 100: mean loss = 6.9514003e-06
epoch 1041: mean loss = 6.4261717e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1042
step 0: mean loss = 5.1989364e-06
step 100: mean loss = 6.041669e-06
epoch 1042: mean loss = 6.1479805e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1043
step 0: mean loss = 5.0629274e-06
step 100: mean loss = 6.047379e-06
epoch 1043: mean loss = 6.2535687e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1044
step 0: mean loss = 7.134264e-06
step 100: mean loss = 6.7350725e-06
epoch 1044: mean loss = 6.310295e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1045
step 0: mean loss = 5.4592683e-06
step 100: mean loss = 6.4706596e-06
epoch 1045: mean loss = 6.3548264e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1046
step 0: mean loss = 6.409361e-06
step 100: mean loss = 6.589419e-06
epoch 1046: mean loss = 6.2039485e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1047
step 0: mean loss = 5.484113e-06
step 100: mean loss = 6.076902e-06
epoch 1047: mean loss = 6.1898504e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1048
step 0: mean loss = 4.887182e-06
step 100: mean loss = 6.041837e-06
epoch 1048: mean loss = 6.22467e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1049
step 0: mean loss = 6.510003e-06
step 100: mean loss = 5.973758e-06
epoch 1049: mean loss = 6.1481305e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1050
step 0: mean loss = 7.675442e-06
step 100: mean loss = 6.1192486e-06
epoch 1050: mean loss = 6.202772e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1051
step 0: mean loss = 4.673568e-06
step 100: mean loss = 6.119171e-06
epoch 1051: mean loss = 6.2306117e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1052
step 0: mean loss = 5.1077286e-06
step 100: mean loss = 6.0883876e-06
epoch 1052: mean loss = 6.1859037e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1053
step 0: mean loss = 5.2229307e-06
step 100: mean loss = 6.6367625e-06
epoch 1053: mean loss = 6.225038e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1054
step 0: mean loss = 5.986166e-06
step 100: mean loss = 6.5679073e-06
epoch 1054: mean loss = 6.3126386e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1055
step 0: mean loss = 6.614231e-06
step 100: mean loss = 5.993675e-06
epoch 1055: mean loss = 6.177201e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1056
step 0: mean loss = 5.382317e-06
step 100: mean loss = 6.68206e-06
epoch 1056: mean loss = 6.190909e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1057
step 0: mean loss = 5.094592e-06
step 100: mean loss = 6.643915e-06
epoch 1057: mean loss = 6.2023933e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1058
step 0: mean loss = 4.4398125e-06
step 100: mean loss = 6.5377635e-06
epoch 1058: mean loss = 6.2793356e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1059
step 0: mean loss = 4.9282908e-06
step 100: mean loss = 6.553611e-06
epoch 1059: mean loss = 6.2059157e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1060
step 0: mean loss = 4.804559e-06
step 100: mean loss = 6.763113e-06
epoch 1060: mean loss = 6.246858e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1061
step 0: mean loss = 4.5324823e-06
step 100: mean loss = 6.6676184e-06
epoch 1061: mean loss = 6.2822096e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1062
step 0: mean loss = 5.10409e-06
step 100: mean loss = 6.6898683e-06
epoch 1062: mean loss = 6.26498e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1063
step 0: mean loss = 5.1719207e-06
step 100: mean loss = 6.1021015e-06
epoch 1063: mean loss = 6.1190453e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1064
step 0: mean loss = 6.7286146e-06
step 100: mean loss = 6.8307854e-06
epoch 1064: mean loss = 6.2793238e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1065
step 0: mean loss = 5.4817165e-06
step 100: mean loss = 6.431891e-06
epoch 1065: mean loss = 6.216654e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1066
step 0: mean loss = 6.5535764e-06
step 100: mean loss = 6.530348e-06
epoch 1066: mean loss = 6.3061466e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1067
step 0: mean loss = 6.646608e-06
step 100: mean loss = 6.0711213e-06
epoch 1067: mean loss = 6.130119e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1068
step 0: mean loss = 6.9037023e-06
step 100: mean loss = 6.2007325e-06
epoch 1068: mean loss = 6.3050115e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1069
step 0: mean loss = 5.0274994e-06
step 100: mean loss = 6.6189614e-06
epoch 1069: mean loss = 6.2537006e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1070
step 0: mean loss = 5.3172907e-06
step 100: mean loss = 5.985473e-06
epoch 1070: mean loss = 6.102775e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1071
step 0: mean loss = 5.9292533e-06
step 100: mean loss = 6.1026694e-06
epoch 1071: mean loss = 6.2191607e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1072
step 0: mean loss = 4.9602727e-06
step 100: mean loss = 5.8257438e-06
epoch 1072: mean loss = 6.192053e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1073
step 0: mean loss = 5.003455e-06
step 100: mean loss = 6.114736e-06
epoch 1073: mean loss = 6.2223235e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1074
step 0: mean loss = 5.27435e-06
step 100: mean loss = 6.0531315e-06
epoch 1074: mean loss = 6.132667e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1075
step 0: mean loss = 5.3382855e-06
step 100: mean loss = 6.0602747e-06
epoch 1075: mean loss = 6.2673626e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1076
step 0: mean loss = 5.6515682e-06
step 100: mean loss = 6.8078953e-06
epoch 1076: mean loss = 6.261451e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1077
step 0: mean loss = 5.2314217e-06
step 100: mean loss = 6.334795e-06
epoch 1077: mean loss = 6.1263604e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1078
step 0: mean loss = 4.5778197e-06
step 100: mean loss = 5.8331493e-06
epoch 1078: mean loss = 6.116082e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1079
step 0: mean loss = 4.9764553e-06
step 100: mean loss = 6.1154524e-06
epoch 1079: mean loss = 6.258906e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1080
step 0: mean loss = 5.19767e-06
step 100: mean loss = 6.0420816e-06
epoch 1080: mean loss = 6.1986e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1081
step 0: mean loss = 5.8892233e-06
step 100: mean loss = 5.3513745e-06
epoch 1081: mean loss = 6.1375526e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1082
step 0: mean loss = 5.2641135e-06
step 100: mean loss = 6.794525e-06
epoch 1082: mean loss = 6.2881263e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1083
step 0: mean loss = 5.5068154e-05
step 100: mean loss = 6.583653e-06
epoch 1083: mean loss = 6.2129034e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1084
step 0: mean loss = 6.1928777e-06
step 100: mean loss = 5.923735e-06
epoch 1084: mean loss = 6.1591586e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1085
step 0: mean loss = 4.8774527e-06
step 100: mean loss = 5.937211e-06
epoch 1085: mean loss = 6.106747e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1086
step 0: mean loss = 6.611297e-06
step 100: mean loss = 5.4971806e-06
epoch 1086: mean loss = 6.222976e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1087
step 0: mean loss = 5.379936e-06
step 100: mean loss = 5.4917873e-06
epoch 1087: mean loss = 6.253668e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1088
step 0: mean loss = 5.024272e-06
step 100: mean loss = 6.2319973e-06
epoch 1088: mean loss = 6.3042835e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1089
step 0: mean loss = 5.499197e-06
step 100: mean loss = 6.6253315e-06
epoch 1089: mean loss = 6.102145e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1090
step 0: mean loss = 5.374385e-06
step 100: mean loss = 6.453069e-06
epoch 1090: mean loss = 6.1272267e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1091
step 0: mean loss = 5.4751677e-06
step 100: mean loss = 5.9142376e-06
epoch 1091: mean loss = 6.1391006e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1092
step 0: mean loss = 4.8407856e-06
step 100: mean loss = 5.822e-06
epoch 1092: mean loss = 6.079401e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1093
step 0: mean loss = 4.458031e-06
step 100: mean loss = 5.8917817e-06
epoch 1093: mean loss = 6.1179903e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1094
step 0: mean loss = 5.1709494e-06
step 100: mean loss = 5.979003e-06
epoch 1094: mean loss = 6.2011504e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1095
step 0: mean loss = 5.595224e-06
step 100: mean loss = 5.77151e-06
epoch 1095: mean loss = 6.1013006e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1096
step 0: mean loss = 6.2939544e-06
step 100: mean loss = 6.0286184e-06
epoch 1096: mean loss = 6.1561213e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1097
step 0: mean loss = 4.9947466e-06
step 100: mean loss = 6.5632453e-06
epoch 1097: mean loss = 6.208818e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1098
step 0: mean loss = 5.560051e-06
step 100: mean loss = 6.5241675e-06
epoch 1098: mean loss = 6.192146e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1099
step 0: mean loss = 4.8757756e-06
step 100: mean loss = 5.384069e-06
epoch 1099: mean loss = 6.1000715e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1100
step 0: mean loss = 5.2383557e-06
step 100: mean loss = 5.942993e-06
epoch 1100: mean loss = 6.205966e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1101
step 0: mean loss = 5.988813e-06
step 100: mean loss = 6.4978444e-06
epoch 1101: mean loss = 6.200097e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1102
step 0: mean loss = 5.4366706e-06
step 100: mean loss = 6.4172154e-06
epoch 1102: mean loss = 6.30809e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1103
step 0: mean loss = 4.6813293e-06
step 100: mean loss = 5.9825798e-06
epoch 1103: mean loss = 6.1267133e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1104
step 0: mean loss = 4.4695244e-06
step 100: mean loss = 6.648852e-06
epoch 1104: mean loss = 6.128226e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1105
step 0: mean loss = 5.4586435e-06
step 100: mean loss = 6.6066486e-06
epoch 1105: mean loss = 6.1153883e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1106
step 0: mean loss = 5.248817e-06
step 100: mean loss = 5.402507e-06
epoch 1106: mean loss = 6.151323e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1107
step 0: mean loss = 5.7338657e-06
step 100: mean loss = 6.695446e-06
epoch 1107: mean loss = 6.1961605e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1108
step 0: mean loss = 4.9834134e-06
step 100: mean loss = 6.3981165e-06
epoch 1108: mean loss = 6.1416736e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1109
step 0: mean loss = 1.0171754e-05
step 100: mean loss = 5.370376e-06
epoch 1109: mean loss = 6.0796224e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1110
step 0: mean loss = 6.9988737e-06
step 100: mean loss = 6.6483494e-06
epoch 1110: mean loss = 6.1543183e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1111
step 0: mean loss = 4.323047e-06
step 100: mean loss = 6.5149056e-06
epoch 1111: mean loss = 6.1139845e-06  learning rate = 2.3649545e-05
============================
Start of epoch 1112
step 0: mean loss = 4.713348e-06
step 100: mean loss = 5.9133868e-06
epoch 1112: mean loss = 6.0136217e-06  learning rate = 2.246707e-05
============================
Start of epoch 1113
step 0: mean loss = 6.2298677e-06
step 100: mean loss = 6.547739e-06
epoch 1113: mean loss = 6.066619e-06  learning rate = 2.246707e-05
============================
Start of epoch 1114
step 0: mean loss = 4.9028695e-06
step 100: mean loss = 5.830252e-06
epoch 1114: mean loss = 6.0655625e-06  learning rate = 2.246707e-05
============================
Start of epoch 1115
step 0: mean loss = 5.5503506e-06
step 100: mean loss = 5.841715e-06
epoch 1115: mean loss = 6.000083e-06  learning rate = 2.246707e-05
============================
Start of epoch 1116
step 0: mean loss = 5.1782326e-06
step 100: mean loss = 5.297844e-06
epoch 1116: mean loss = 6.03977e-06  learning rate = 2.246707e-05
============================
Start of epoch 1117
step 0: mean loss = 4.6302666e-06
step 100: mean loss = 5.930919e-06
epoch 1117: mean loss = 6.0915772e-06  learning rate = 2.246707e-05
============================
Start of epoch 1118
step 0: mean loss = 4.8922193e-06
step 100: mean loss = 5.863722e-06
epoch 1118: mean loss = 6.0010007e-06  learning rate = 2.246707e-05
============================
Start of epoch 1119
step 0: mean loss = 5.5515534e-06
step 100: mean loss = 5.691009e-06
epoch 1119: mean loss = 6.002989e-06  learning rate = 2.246707e-05
============================
Start of epoch 1120
step 0: mean loss = 5.323467e-06
step 100: mean loss = 6.61208e-06
epoch 1120: mean loss = 6.0645125e-06  learning rate = 2.246707e-05
============================
Start of epoch 1121
step 0: mean loss = 4.5994398e-06
step 100: mean loss = 5.820781e-06
epoch 1121: mean loss = 5.915713e-06  learning rate = 2.246707e-05
============================
Start of epoch 1122
step 0: mean loss = 5.610897e-06
step 100: mean loss = 5.9866097e-06
epoch 1122: mean loss = 6.236731e-06  learning rate = 2.246707e-05
============================
Start of epoch 1123
step 0: mean loss = 5.564777e-06
step 100: mean loss = 6.465557e-06
epoch 1123: mean loss = 6.026142e-06  learning rate = 2.246707e-05
============================
Start of epoch 1124
step 0: mean loss = 5.9714293e-06
step 100: mean loss = 6.5418885e-06
epoch 1124: mean loss = 6.0330412e-06  learning rate = 2.246707e-05
============================
Start of epoch 1125
step 0: mean loss = 5.9130525e-06
step 100: mean loss = 5.8157907e-06
epoch 1125: mean loss = 6.019616e-06  learning rate = 2.246707e-05
============================
Start of epoch 1126
step 0: mean loss = 6.2774175e-06
step 100: mean loss = 6.449596e-06
epoch 1126: mean loss = 5.9921526e-06  learning rate = 2.246707e-05
============================
Start of epoch 1127
step 0: mean loss = 4.86684e-06
step 100: mean loss = 6.777138e-06
epoch 1127: mean loss = 6.1912874e-06  learning rate = 2.246707e-05
============================
Start of epoch 1128
step 0: mean loss = 5.194873e-06
step 100: mean loss = 5.810186e-06
epoch 1128: mean loss = 6.0234393e-06  learning rate = 2.246707e-05
============================
Start of epoch 1129
step 0: mean loss = 5.357988e-06
step 100: mean loss = 6.47236e-06
epoch 1129: mean loss = 5.9887448e-06  learning rate = 2.246707e-05
============================
Start of epoch 1130
step 0: mean loss = 4.4816916e-06
step 100: mean loss = 5.2303903e-06
epoch 1130: mean loss = 6.0866705e-06  learning rate = 2.246707e-05
============================
Start of epoch 1131
step 0: mean loss = 5.5244527e-06
step 100: mean loss = 6.3243015e-06
epoch 1131: mean loss = 5.9906715e-06  learning rate = 2.246707e-05
============================
Start of epoch 1132
step 0: mean loss = 5.55988e-06
step 100: mean loss = 5.8392884e-06
epoch 1132: mean loss = 6.103481e-06  learning rate = 2.246707e-05
============================
Start of epoch 1133
step 0: mean loss = 4.9036657e-06
step 100: mean loss = 5.8421792e-06
epoch 1133: mean loss = 5.8979676e-06  learning rate = 2.246707e-05
============================
Start of epoch 1134
step 0: mean loss = 5.6231047e-06
step 100: mean loss = 5.35537e-06
epoch 1134: mean loss = 6.1424544e-06  learning rate = 2.246707e-05
============================
Start of epoch 1135
step 0: mean loss = 5.764712e-06
step 100: mean loss = 6.5250083e-06
epoch 1135: mean loss = 6.0642265e-06  learning rate = 2.246707e-05
============================
Start of epoch 1136
step 0: mean loss = 4.963228e-06
step 100: mean loss = 6.284382e-06
epoch 1136: mean loss = 5.9643767e-06  learning rate = 2.246707e-05
============================
Start of epoch 1137
step 0: mean loss = 4.9687087e-06
step 100: mean loss = 6.371263e-06
epoch 1137: mean loss = 5.96864e-06  learning rate = 2.246707e-05
============================
Start of epoch 1138
step 0: mean loss = 4.5211727e-06
step 100: mean loss = 5.832848e-06
epoch 1138: mean loss = 5.991679e-06  learning rate = 2.246707e-05
============================
Start of epoch 1139
step 0: mean loss = 4.8793318e-06
step 100: mean loss = 5.954484e-06
epoch 1139: mean loss = 6.1314854e-06  learning rate = 2.246707e-05
============================
Start of epoch 1140
step 0: mean loss = 4.686567e-06
step 100: mean loss = 6.350104e-06
epoch 1140: mean loss = 5.9405966e-06  learning rate = 2.246707e-05
============================
Start of epoch 1141
step 0: mean loss = 4.89151e-06
step 100: mean loss = 5.606393e-06
epoch 1141: mean loss = 5.907442e-06  learning rate = 2.246707e-05
============================
Start of epoch 1142
step 0: mean loss = 5.2264063e-06
step 100: mean loss = 5.423508e-06
epoch 1142: mean loss = 6.168969e-06  learning rate = 2.246707e-05
============================
Start of epoch 1143
step 0: mean loss = 5.4098937e-06
step 100: mean loss = 5.7847983e-06
epoch 1143: mean loss = 5.929525e-06  learning rate = 2.246707e-05
============================
Start of epoch 1144
step 0: mean loss = 4.886673e-06
step 100: mean loss = 5.8671935e-06
epoch 1144: mean loss = 5.9155996e-06  learning rate = 2.246707e-05
============================
Start of epoch 1145
step 0: mean loss = 5.123568e-06
step 100: mean loss = 5.9385743e-06
epoch 1145: mean loss = 6.036239e-06  learning rate = 2.246707e-05
============================
Start of epoch 1146
step 0: mean loss = 5.5011906e-06
step 100: mean loss = 5.8370842e-06
epoch 1146: mean loss = 5.9473937e-06  learning rate = 2.246707e-05
============================
Start of epoch 1147
step 0: mean loss = 5.0253548e-06
step 100: mean loss = 6.448986e-06
epoch 1147: mean loss = 6.019464e-06  learning rate = 2.246707e-05
============================
Start of epoch 1148
step 0: mean loss = 5.4650773e-06
step 100: mean loss = 6.176604e-06
epoch 1148: mean loss = 5.978426e-06  learning rate = 2.246707e-05
============================
Start of epoch 1149
step 0: mean loss = 5.2759106e-06
step 100: mean loss = 5.696816e-06
epoch 1149: mean loss = 5.9168106e-06  learning rate = 2.246707e-05
============================
Start of epoch 1150
step 0: mean loss = 4.7892067e-06
step 100: mean loss = 6.3464895e-06
epoch 1150: mean loss = 5.9168938e-06  learning rate = 2.246707e-05
============================
Start of epoch 1151
step 0: mean loss = 5.3700674e-06
step 100: mean loss = 6.4139253e-06
epoch 1151: mean loss = 6.0661137e-06  learning rate = 2.246707e-05
============================
Start of epoch 1152
step 0: mean loss = 5.5922546e-06
step 100: mean loss = 5.7562065e-06
epoch 1152: mean loss = 5.9374765e-06  learning rate = 2.246707e-05
============================
Start of epoch 1153
step 0: mean loss = 5.511454e-06
step 100: mean loss = 6.4258666e-06
epoch 1153: mean loss = 5.938277e-06  learning rate = 2.246707e-05
============================
Start of epoch 1154
step 0: mean loss = 4.871318e-06
step 100: mean loss = 5.7297393e-06
epoch 1154: mean loss = 5.9394497e-06  learning rate = 2.246707e-05
============================
Start of epoch 1155
step 0: mean loss = 6.1596893e-06
step 100: mean loss = 5.2252376e-06
epoch 1155: mean loss = 5.9730132e-06  learning rate = 2.246707e-05
============================
Start of epoch 1156
step 0: mean loss = 6.0447474e-06
step 100: mean loss = 5.2164955e-06
epoch 1156: mean loss = 5.962674e-06  learning rate = 2.246707e-05
============================
Start of epoch 1157
step 0: mean loss = 5.4331003e-06
step 100: mean loss = 6.4403557e-06
epoch 1157: mean loss = 6.0145544e-06  learning rate = 2.246707e-05
============================
Start of epoch 1158
step 0: mean loss = 7.5107487e-06
step 100: mean loss = 5.850081e-06
epoch 1158: mean loss = 5.9351905e-06  learning rate = 2.246707e-05
============================
Start of epoch 1159
step 0: mean loss = 5.4277743e-06
step 100: mean loss = 5.912442e-06
epoch 1159: mean loss = 6.0242864e-06  learning rate = 2.246707e-05
============================
Start of epoch 1160
step 0: mean loss = 4.0773875e-06
step 100: mean loss = 5.6443178e-06
epoch 1160: mean loss = 5.872093e-06  learning rate = 2.246707e-05
============================
Start of epoch 1161
step 0: mean loss = 5.257287e-06
step 100: mean loss = 5.7046523e-06
epoch 1161: mean loss = 6.0361403e-06  learning rate = 2.246707e-05
============================
Start of epoch 1162
step 0: mean loss = 4.7334875e-06
step 100: mean loss = 5.810755e-06
epoch 1162: mean loss = 5.856009e-06  learning rate = 2.246707e-05
============================
Start of epoch 1163
step 0: mean loss = 5.5139253e-06
step 100: mean loss = 5.9372323e-06
epoch 1163: mean loss = 5.998603e-06  learning rate = 2.246707e-05
============================
Start of epoch 1164
step 0: mean loss = 5.2977025e-06
step 100: mean loss = 5.1816373e-06
epoch 1164: mean loss = 5.9349827e-06  learning rate = 2.246707e-05
============================
Start of epoch 1165
step 0: mean loss = 4.9283135e-06
step 100: mean loss = 6.3120274e-06
epoch 1165: mean loss = 5.922461e-06  learning rate = 2.246707e-05
============================
Start of epoch 1166
step 0: mean loss = 5.3146414e-06
step 100: mean loss = 6.172437e-06
epoch 1166: mean loss = 6.0085167e-06  learning rate = 2.246707e-05
============================
Start of epoch 1167
step 0: mean loss = 6.407914e-06
step 100: mean loss = 5.693511e-06
epoch 1167: mean loss = 5.866733e-06  learning rate = 2.246707e-05
============================
Start of epoch 1168
step 0: mean loss = 5.5537685e-06
step 100: mean loss = 5.8379783e-06
epoch 1168: mean loss = 5.954133e-06  learning rate = 2.246707e-05
============================
Start of epoch 1169
step 0: mean loss = 5.4547813e-06
step 100: mean loss = 6.562923e-06
epoch 1169: mean loss = 5.994729e-06  learning rate = 2.246707e-05
============================
Start of epoch 1170
step 0: mean loss = 5.417251e-05
step 100: mean loss = 6.379489e-06
epoch 1170: mean loss = 5.984017e-06  learning rate = 2.246707e-05
============================
Start of epoch 1171
step 0: mean loss = 4.7109606e-06
step 100: mean loss = 5.6735894e-06
epoch 1171: mean loss = 5.94084e-06  learning rate = 2.246707e-05
============================
Start of epoch 1172
step 0: mean loss = 5.110842e-06
step 100: mean loss = 5.658946e-06
epoch 1172: mean loss = 5.845379e-06  learning rate = 2.246707e-05
============================
Start of epoch 1173
step 0: mean loss = 5.36066e-06
step 100: mean loss = 6.0689745e-06
epoch 1173: mean loss = 6.03508e-06  learning rate = 2.246707e-05
============================
Start of epoch 1174
step 0: mean loss = 6.196773e-06
step 100: mean loss = 6.5006375e-06
epoch 1174: mean loss = 6.0111715e-06  learning rate = 2.246707e-05
============================
Start of epoch 1175
step 0: mean loss = 4.847844e-06
step 100: mean loss = 5.083853e-06
epoch 1175: mean loss = 5.832549e-06  learning rate = 2.246707e-05
============================
Start of epoch 1176
step 0: mean loss = 6.1226656e-06
step 100: mean loss = 6.4343267e-06
epoch 1176: mean loss = 5.990582e-06  learning rate = 2.246707e-05
============================
Start of epoch 1177
step 0: mean loss = 5.411738e-06
step 100: mean loss = 5.7173443e-06
epoch 1177: mean loss = 5.904669e-06  learning rate = 2.246707e-05
============================
Start of epoch 1178
step 0: mean loss = 5.106647e-06
step 100: mean loss = 6.456644e-06
epoch 1178: mean loss = 5.9501126e-06  learning rate = 2.246707e-05
============================
Start of epoch 1179
step 0: mean loss = 5.5161536e-06
step 100: mean loss = 6.433341e-06
epoch 1179: mean loss = 5.971746e-06  learning rate = 2.246707e-05
============================
Start of epoch 1180
step 0: mean loss = 5.005702e-06
step 100: mean loss = 5.702175e-06
epoch 1180: mean loss = 5.8684072e-06  learning rate = 2.246707e-05
============================
Start of epoch 1181
step 0: mean loss = 4.8777374e-06
step 100: mean loss = 5.6023837e-06
epoch 1181: mean loss = 5.8640517e-06  learning rate = 2.246707e-05
============================
Start of epoch 1182
step 0: mean loss = 5.985479e-06
step 100: mean loss = 5.113481e-06
epoch 1182: mean loss = 5.934416e-06  learning rate = 2.246707e-05
============================
Start of epoch 1183
step 0: mean loss = 7.3702804e-06
step 100: mean loss = 6.451083e-06
epoch 1183: mean loss = 5.973159e-06  learning rate = 2.246707e-05
============================
Start of epoch 1184
step 0: mean loss = 4.199056e-06
step 100: mean loss = 6.394289e-06
epoch 1184: mean loss = 5.9041813e-06  learning rate = 2.246707e-05
============================
Start of epoch 1185
step 0: mean loss = 5.393914e-06
step 100: mean loss = 5.6654944e-06
epoch 1185: mean loss = 5.944024e-06  learning rate = 2.246707e-05
============================
Start of epoch 1186
step 0: mean loss = 5.240475e-06
step 100: mean loss = 5.1646684e-06
epoch 1186: mean loss = 5.9234785e-06  learning rate = 2.246707e-05
============================
Start of epoch 1187
step 0: mean loss = 4.9910877e-06
step 100: mean loss = 5.5393443e-06
epoch 1187: mean loss = 5.893131e-06  learning rate = 2.246707e-05
============================
Start of epoch 1188
step 0: mean loss = 7.2982666e-06
step 100: mean loss = 5.723018e-06
epoch 1188: mean loss = 5.8743426e-06  learning rate = 2.246707e-05
============================
Start of epoch 1189
step 0: mean loss = 4.835498e-06
step 100: mean loss = 6.273301e-06
epoch 1189: mean loss = 5.8646806e-06  learning rate = 2.246707e-05
============================
Start of epoch 1190
step 0: mean loss = 6.0899683e-06
step 100: mean loss = 6.3469565e-06
epoch 1190: mean loss = 5.9534623e-06  learning rate = 2.246707e-05
============================
Start of epoch 1191
step 0: mean loss = 5.5827845e-06
step 100: mean loss = 6.2854947e-06
epoch 1191: mean loss = 5.830644e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1192
step 0: mean loss = 4.9463342e-06
step 100: mean loss = 6.1274973e-06
epoch 1192: mean loss = 5.7600205e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1193
step 0: mean loss = 4.9510954e-06
step 100: mean loss = 4.975962e-06
epoch 1193: mean loss = 5.78461e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1194
step 0: mean loss = 5.310755e-06
step 100: mean loss = 6.4192654e-06
epoch 1194: mean loss = 5.8994237e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1195
step 0: mean loss = 4.501469e-06
step 100: mean loss = 6.3569096e-06
epoch 1195: mean loss = 5.9021318e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1196
step 0: mean loss = 4.6691976e-06
step 100: mean loss = 5.614172e-06
epoch 1196: mean loss = 5.7530715e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1197
step 0: mean loss = 5.9915983e-06
step 100: mean loss = 5.756553e-06
epoch 1197: mean loss = 5.8398296e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1198
step 0: mean loss = 6.131891e-06
step 100: mean loss = 6.4430214e-06
epoch 1198: mean loss = 5.9080708e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1199
step 0: mean loss = 4.352968e-06
step 100: mean loss = 6.1741466e-06
epoch 1199: mean loss = 5.7604257e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1200
step 0: mean loss = 4.863222e-06
step 100: mean loss = 6.286723e-06
epoch 1200: mean loss = 5.836146e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1201
step 0: mean loss = 5.6076653e-05
step 100: mean loss = 6.10288e-06
epoch 1201: mean loss = 5.7260654e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1202
step 0: mean loss = 4.825095e-06
step 100: mean loss = 5.6322438e-06
epoch 1202: mean loss = 5.8942264e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1203
step 0: mean loss = 4.753677e-06
step 100: mean loss = 6.2734684e-06
epoch 1203: mean loss = 5.81356e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1204
step 0: mean loss = 4.902852e-06
step 100: mean loss = 6.178788e-06
epoch 1204: mean loss = 5.832473e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1205
step 0: mean loss = 5.11896e-06
step 100: mean loss = 5.5226947e-06
epoch 1205: mean loss = 5.753009e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1206
step 0: mean loss = 4.988347e-06
step 100: mean loss = 5.6994563e-06
epoch 1206: mean loss = 5.8211303e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1207
step 0: mean loss = 4.3240516e-06
step 100: mean loss = 5.551719e-06
epoch 1207: mean loss = 5.838902e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1208
step 0: mean loss = 5.416266e-06
step 100: mean loss = 6.350826e-06
epoch 1208: mean loss = 5.8926566e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1209
step 0: mean loss = 4.8542333e-06
step 100: mean loss = 5.6511067e-06
epoch 1209: mean loss = 5.8416063e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1210
step 0: mean loss = 5.645249e-06
step 100: mean loss = 5.628797e-06
epoch 1210: mean loss = 5.7432626e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1211
step 0: mean loss = 6.080255e-06
step 100: mean loss = 5.801761e-06
epoch 1211: mean loss = 5.915862e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1212
step 0: mean loss = 4.373778e-06
step 100: mean loss = 5.637116e-06
epoch 1212: mean loss = 5.845897e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1213
step 0: mean loss = 5.3257054e-06
step 100: mean loss = 5.030671e-06
epoch 1213: mean loss = 5.82771e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1214
step 0: mean loss = 4.5802926e-06
step 100: mean loss = 5.700157e-06
epoch 1214: mean loss = 5.729466e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1215
step 0: mean loss = 6.915595e-06
step 100: mean loss = 5.1009374e-06
epoch 1215: mean loss = 5.968581e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1216
step 0: mean loss = 5.210811e-06
step 100: mean loss = 5.7697976e-06
epoch 1216: mean loss = 5.8201967e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1217
step 0: mean loss = 5.467144e-06
step 100: mean loss = 6.8328027e-06
epoch 1217: mean loss = 6.205492e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1218
step 0: mean loss = 5.1808065e-06
step 100: mean loss = 6.8215495e-06
epoch 1218: mean loss = 6.178795e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1219
step 0: mean loss = 4.5253164e-06
step 100: mean loss = 5.5327314e-06
epoch 1219: mean loss = 5.719097e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1220
step 0: mean loss = 4.6660844e-06
step 100: mean loss = 6.20026e-06
epoch 1220: mean loss = 6.173822e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1221
step 0: mean loss = 5.1304755e-06
step 100: mean loss = 6.5010686e-06
epoch 1221: mean loss = 6.344236e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1222
step 0: mean loss = 4.9737946e-06
step 100: mean loss = 6.163859e-06
epoch 1222: mean loss = 6.2037434e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1223
step 0: mean loss = 4.996966e-06
step 100: mean loss = 6.274246e-06
epoch 1223: mean loss = 6.161898e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1224
step 0: mean loss = 6.0732896e-06
step 100: mean loss = 5.087748e-06
epoch 1224: mean loss = 6.2138356e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1225
step 0: mean loss = 5.213904e-06
step 100: mean loss = 6.479834e-06
epoch 1225: mean loss = 6.2877866e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1226
step 0: mean loss = 5.6078256e-06
step 100: mean loss = 6.793166e-06
epoch 1226: mean loss = 6.1384826e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1227
step 0: mean loss = 4.602679e-06
step 100: mean loss = 5.008159e-06
epoch 1227: mean loss = 6.1502133e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1228
step 0: mean loss = 4.6843643e-06
step 100: mean loss = 5.4193406e-06
epoch 1228: mean loss = 6.0884277e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1229
step 0: mean loss = 5.4771763e-06
step 100: mean loss = 5.6760655e-06
epoch 1229: mean loss = 6.270536e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1230
step 0: mean loss = 5.2791706e-06
step 100: mean loss = 6.822274e-06
epoch 1230: mean loss = 6.222989e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1231
step 0: mean loss = 4.712944e-06
step 100: mean loss = 5.51037e-06
epoch 1231: mean loss = 6.1552482e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1232
step 0: mean loss = 5.690108e-06
step 100: mean loss = 6.904162e-06
epoch 1232: mean loss = 6.1923943e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1233
step 0: mean loss = 4.244621e-06
step 100: mean loss = 6.435598e-06
epoch 1233: mean loss = 6.255173e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1234
step 0: mean loss = 5.334408e-06
step 100: mean loss = 6.2533873e-06
epoch 1234: mean loss = 6.1726087e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1235
step 0: mean loss = 4.6256514e-06
step 100: mean loss = 6.246849e-06
epoch 1235: mean loss = 6.1822907e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1236
step 0: mean loss = 4.8830343e-06
step 100: mean loss = 5.6394974e-06
epoch 1236: mean loss = 6.1295164e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1237
step 0: mean loss = 4.4530793e-06
step 100: mean loss = 6.7503966e-06
epoch 1237: mean loss = 6.1953315e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1238
step 0: mean loss = 4.644812e-06
step 100: mean loss = 6.163275e-06
epoch 1238: mean loss = 6.1214073e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1239
step 0: mean loss = 4.3954196e-06
step 100: mean loss = 6.2864083e-06
epoch 1239: mean loss = 6.237968e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1240
step 0: mean loss = 5.311338e-06
step 100: mean loss = 5.56891e-06
epoch 1240: mean loss = 6.1895353e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1241
step 0: mean loss = 5.122792e-06
step 100: mean loss = 6.325601e-06
epoch 1241: mean loss = 6.271285e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1242
step 0: mean loss = 5.217126e-06
step 100: mean loss = 6.291871e-06
epoch 1242: mean loss = 6.2067625e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1243
step 0: mean loss = 5.8765845e-06
step 100: mean loss = 6.069461e-06
epoch 1243: mean loss = 6.112859e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1244
step 0: mean loss = 4.085686e-06
step 100: mean loss = 6.238738e-06
epoch 1244: mean loss = 6.1438473e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1245
step 0: mean loss = 5.2266196e-06
step 100: mean loss = 6.263422e-06
epoch 1245: mean loss = 6.2948047e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1246
step 0: mean loss = 5.7797456e-06
step 100: mean loss = 6.2370873e-06
epoch 1246: mean loss = 6.199475e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1247
step 0: mean loss = 5.8193796e-06
step 100: mean loss = 5.562052e-06
epoch 1247: mean loss = 6.0846664e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1248
step 0: mean loss = 6.1074234e-06
step 100: mean loss = 5.4640464e-06
epoch 1248: mean loss = 6.0878365e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1249
step 0: mean loss = 4.6489167e-06
step 100: mean loss = 6.1652277e-06
epoch 1249: mean loss = 6.0800885e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1250
step 0: mean loss = 5.05209e-06
step 100: mean loss = 6.8261575e-06
epoch 1250: mean loss = 6.0686907e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1251
step 0: mean loss = 4.9849923e-06
step 100: mean loss = 6.2090658e-06
epoch 1251: mean loss = 6.2099357e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1252
step 0: mean loss = 4.2731062e-06
step 100: mean loss = 6.682099e-06
epoch 1252: mean loss = 6.150276e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1253
step 0: mean loss = 5.62423e-06
step 100: mean loss = 5.4697152e-06
epoch 1253: mean loss = 6.0429757e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1254
step 0: mean loss = 5.520302e-06
step 100: mean loss = 6.1499e-06
epoch 1254: mean loss = 6.079951e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1255
step 0: mean loss = 5.7885177e-06
step 100: mean loss = 6.323641e-06
epoch 1255: mean loss = 6.2518006e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1256
step 0: mean loss = 5.6583262e-06
step 100: mean loss = 6.076564e-06
epoch 1256: mean loss = 6.0912844e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1257
step 0: mean loss = 5.2462137e-06
step 100: mean loss = 6.2240597e-06
epoch 1257: mean loss = 6.1788496e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1258
step 0: mean loss = 4.254371e-06
step 100: mean loss = 5.509402e-06
epoch 1258: mean loss = 6.05984e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1259
step 0: mean loss = 5.5427327e-06
step 100: mean loss = 6.7795017e-06
epoch 1259: mean loss = 6.1639107e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1260
step 0: mean loss = 4.956937e-06
step 100: mean loss = 7.0497363e-06
epoch 1260: mean loss = 6.315612e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1261
step 0: mean loss = 5.3404215e-06
step 100: mean loss = 6.1486503e-06
epoch 1261: mean loss = 6.048326e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1262
step 0: mean loss = 5.464343e-06
step 100: mean loss = 6.0792613e-06
epoch 1262: mean loss = 6.117651e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1263
step 0: mean loss = 4.398586e-06
step 100: mean loss = 6.216179e-06
epoch 1263: mean loss = 6.1100613e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1264
step 0: mean loss = 5.005478e-06
step 100: mean loss = 5.6000144e-06
epoch 1264: mean loss = 6.1103983e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1265
step 0: mean loss = 5.3231806e-06
step 100: mean loss = 6.797212e-06
epoch 1265: mean loss = 6.142354e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1266
step 0: mean loss = 5.242203e-06
step 100: mean loss = 5.532791e-06
epoch 1266: mean loss = 6.0446155e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1267
step 0: mean loss = 5.2221785e-06
step 100: mean loss = 6.804725e-06
epoch 1267: mean loss = 6.1400488e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1268
step 0: mean loss = 5.657985e-06
step 100: mean loss = 6.3182038e-06
epoch 1268: mean loss = 6.15785e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1269
step 0: mean loss = 4.6039913e-06
step 100: mean loss = 6.0485054e-06
epoch 1269: mean loss = 6.0616017e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1270
step 0: mean loss = 5.1302395e-06
step 100: mean loss = 6.150057e-06
epoch 1270: mean loss = 6.1270734e-06  learning rate = 2.1343712e-05
============================
Start of epoch 1271
step 0: mean loss = 5.275494e-06
step 100: mean loss = 6.1311616e-06
epoch 1271: mean loss = 6.0315774e-06  learning rate = 2.027653e-05
============================
Start of epoch 1272
step 0: mean loss = 4.342478e-06
step 100: mean loss = 5.4967795e-06
epoch 1272: mean loss = 6.0871753e-06  learning rate = 2.027653e-05
============================
Start of epoch 1273
step 0: mean loss = 5.1003644e-06
step 100: mean loss = 5.5607184e-06
epoch 1273: mean loss = 6.0327316e-06  learning rate = 2.027653e-05
============================
Start of epoch 1274
step 0: mean loss = 5.127888e-06
step 100: mean loss = 5.9964045e-06
epoch 1274: mean loss = 5.978458e-06  learning rate = 2.027653e-05
============================
Start of epoch 1275
step 0: mean loss = 4.8099173e-06
step 100: mean loss = 6.6311895e-06
epoch 1275: mean loss = 5.9828753e-06  learning rate = 2.027653e-05
============================
Start of epoch 1276
step 0: mean loss = 3.8895196e-06
step 100: mean loss = 6.052669e-06
epoch 1276: mean loss = 5.93673e-06  learning rate = 2.027653e-05
============================
Start of epoch 1277
step 0: mean loss = 5.0461103e-06
step 100: mean loss = 6.128435e-06
epoch 1277: mean loss = 6.0737607e-06  learning rate = 2.027653e-05
============================
Start of epoch 1278
step 0: mean loss = 7.028709e-06
step 100: mean loss = 6.2087015e-06
epoch 1278: mean loss = 6.0999887e-06  learning rate = 2.027653e-05
============================
Start of epoch 1279
step 0: mean loss = 4.3728087e-06
step 100: mean loss = 5.992332e-06
epoch 1279: mean loss = 5.9968756e-06  learning rate = 2.027653e-05
============================
Start of epoch 1280
step 0: mean loss = 4.715724e-06
step 100: mean loss = 6.0271077e-06
epoch 1280: mean loss = 5.995633e-06  learning rate = 2.027653e-05
============================
Start of epoch 1281
step 0: mean loss = 5.6119312e-05
step 100: mean loss = 5.4178454e-06
epoch 1281: mean loss = 5.9585414e-06  learning rate = 2.027653e-05
============================
Start of epoch 1282
step 0: mean loss = 5.561145e-06
step 100: mean loss = 5.737648e-06
epoch 1282: mean loss = 6.1352553e-06  learning rate = 2.027653e-05
============================
Start of epoch 1283
step 0: mean loss = 5.215702e-06
step 100: mean loss = 6.021578e-06
epoch 1283: mean loss = 6.009053e-06  learning rate = 2.027653e-05
============================
Start of epoch 1284
step 0: mean loss = 5.6735416e-06
step 100: mean loss = 6.0749303e-06
epoch 1284: mean loss = 5.9368012e-06  learning rate = 2.027653e-05
============================
Start of epoch 1285
step 0: mean loss = 5.2403684e-06
step 100: mean loss = 6.149942e-06
epoch 1285: mean loss = 6.0317816e-06  learning rate = 2.027653e-05
============================
Start of epoch 1286
step 0: mean loss = 4.36427e-06
step 100: mean loss = 6.6154767e-06
epoch 1286: mean loss = 6.035076e-06  learning rate = 2.027653e-05
============================
Start of epoch 1287
step 0: mean loss = 4.6661035e-06
step 100: mean loss = 6.0526827e-06
epoch 1287: mean loss = 5.9677122e-06  learning rate = 2.027653e-05
============================
Start of epoch 1288
step 0: mean loss = 4.7692824e-06
step 100: mean loss = 6.5748973e-06
epoch 1288: mean loss = 6.04526e-06  learning rate = 2.027653e-05
============================
Start of epoch 1289
step 0: mean loss = 4.2143884e-06
step 100: mean loss = 6.4725846e-06
epoch 1289: mean loss = 5.981402e-06  learning rate = 2.027653e-05
============================
Start of epoch 1290
step 0: mean loss = 4.2385536e-06
step 100: mean loss = 5.4933394e-06
epoch 1290: mean loss = 6.01312e-06  learning rate = 2.027653e-05
============================
Start of epoch 1291
step 0: mean loss = 5.4725147e-05
step 100: mean loss = 6.0594966e-06
epoch 1291: mean loss = 6.0460293e-06  learning rate = 2.027653e-05
============================
Start of epoch 1292
step 0: mean loss = 4.7936273e-06
step 100: mean loss = 6.20085e-06
epoch 1292: mean loss = 6.066032e-06  learning rate = 2.027653e-05
============================
Start of epoch 1293
step 0: mean loss = 5.8950945e-06
step 100: mean loss = 5.885876e-06
epoch 1293: mean loss = 5.9533745e-06  learning rate = 2.027653e-05
============================
Start of epoch 1294
step 0: mean loss = 6.4656692e-06
step 100: mean loss = 6.012181e-06
epoch 1294: mean loss = 6.0442767e-06  learning rate = 2.027653e-05
============================
Start of epoch 1295
step 0: mean loss = 4.33979e-06
step 100: mean loss = 6.5353534e-06
epoch 1295: mean loss = 5.916087e-06  learning rate = 2.027653e-05
============================
Start of epoch 1296
step 0: mean loss = 4.6712894e-06
step 100: mean loss = 6.604114e-06
epoch 1296: mean loss = 5.9596377e-06  learning rate = 2.027653e-05
============================
Start of epoch 1297
step 0: mean loss = 5.3513495e-06
step 100: mean loss = 5.597828e-06
epoch 1297: mean loss = 6.114636e-06  learning rate = 2.027653e-05
============================
Start of epoch 1298
step 0: mean loss = 4.2766424e-06
step 100: mean loss = 5.966476e-06
epoch 1298: mean loss = 5.9477784e-06  learning rate = 2.027653e-05
============================
Start of epoch 1299
step 0: mean loss = 5.2033465e-06
step 100: mean loss = 6.63468e-06
epoch 1299: mean loss = 5.994347e-06  learning rate = 2.027653e-05
============================
Start of epoch 1300
step 0: mean loss = 5.3333697e-06
step 100: mean loss = 5.3164536e-06
epoch 1300: mean loss = 6.0574657e-06  learning rate = 2.027653e-05
============================
Start of epoch 1301
step 0: mean loss = 4.685674e-06
step 100: mean loss = 6.019069e-06
epoch 1301: mean loss = 5.9449612e-06  learning rate = 2.027653e-05
============================
Start of epoch 1302
step 0: mean loss = 5.7913567e-06
step 100: mean loss = 6.1148594e-06
epoch 1302: mean loss = 5.983627e-06  learning rate = 2.027653e-05
============================
Start of epoch 1303
step 0: mean loss = 4.9511928e-06
step 100: mean loss = 5.3513345e-06
epoch 1303: mean loss = 5.9213894e-06  learning rate = 2.027653e-05
============================
Start of epoch 1304
step 0: mean loss = 5.3458953e-06
step 100: mean loss = 5.57296e-06
epoch 1304: mean loss = 6.047691e-06  learning rate = 2.027653e-05
============================
Start of epoch 1305
step 0: mean loss = 4.8478337e-06
step 100: mean loss = 5.9443337e-06
epoch 1305: mean loss = 6.0435964e-06  learning rate = 2.027653e-05
============================
Start of epoch 1306
step 0: mean loss = 6.0919497e-06
step 100: mean loss = 5.8915793e-06
epoch 1306: mean loss = 6.003428e-06  learning rate = 2.027653e-05
============================
Start of epoch 1307
step 0: mean loss = 5.47524e-06
step 100: mean loss = 6.7048677e-06
epoch 1307: mean loss = 6.0872135e-06  learning rate = 2.027653e-05
============================
Start of epoch 1308
step 0: mean loss = 4.7978133e-06
step 100: mean loss = 6.107978e-06
epoch 1308: mean loss = 6.0033835e-06  learning rate = 2.027653e-05
============================
Start of epoch 1309
step 0: mean loss = 4.322775e-06
step 100: mean loss = 6.085978e-06
epoch 1309: mean loss = 6.0074663e-06  learning rate = 2.027653e-05
============================
Start of epoch 1310
step 0: mean loss = 4.825213e-06
step 100: mean loss = 6.199397e-06
epoch 1310: mean loss = 6.1068617e-06  learning rate = 2.027653e-05
============================
Start of epoch 1311
step 0: mean loss = 5.3447775e-06
step 100: mean loss = 6.740981e-06
epoch 1311: mean loss = 6.0475068e-06  learning rate = 2.027653e-05
============================
Start of epoch 1312
step 0: mean loss = 6.5198246e-06
step 100: mean loss = 5.9260574e-06
epoch 1312: mean loss = 6.1007304e-06  learning rate = 2.027653e-05
============================
Start of epoch 1313
step 0: mean loss = 5.2155133e-06
step 100: mean loss = 5.5923683e-06
epoch 1313: mean loss = 6.0383863e-06  learning rate = 2.027653e-05
============================
Start of epoch 1314
step 0: mean loss = 5.2997448e-06
step 100: mean loss = 6.6543967e-06
epoch 1314: mean loss = 6.1234427e-06  learning rate = 2.027653e-05
============================
Start of epoch 1315
step 0: mean loss = 4.161664e-06
step 100: mean loss = 6.050733e-06
epoch 1315: mean loss = 6.01834e-06  learning rate = 2.027653e-05
============================
Start of epoch 1316
step 0: mean loss = 4.1565645e-06
step 100: mean loss = 4.888401e-06
epoch 1316: mean loss = 6.03579e-06  learning rate = 2.027653e-05
============================
Start of epoch 1317
step 0: mean loss = 5.669447e-06
step 100: mean loss = 6.5420945e-06
epoch 1317: mean loss = 6.0013153e-06  learning rate = 2.027653e-05
============================
Start of epoch 1318
step 0: mean loss = 4.357958e-06
step 100: mean loss = 5.9321155e-06
epoch 1318: mean loss = 6.013641e-06  learning rate = 2.027653e-05
============================
Start of epoch 1319
step 0: mean loss = 4.9712057e-06
step 100: mean loss = 5.073958e-06
epoch 1319: mean loss = 5.9339723e-06  learning rate = 2.027653e-05
============================
Start of epoch 1320
step 0: mean loss = 5.236358e-06
step 100: mean loss = 6.688539e-06
epoch 1320: mean loss = 6.060009e-06  learning rate = 2.027653e-05
============================
Start of epoch 1321
step 0: mean loss = 4.8714237e-06
step 100: mean loss = 6.5346558e-06
epoch 1321: mean loss = 5.9748054e-06  learning rate = 2.027653e-05
============================
Start of epoch 1322
step 0: mean loss = 5.414618e-06
step 100: mean loss = 6.472903e-06
epoch 1322: mean loss = 5.9349204e-06  learning rate = 2.027653e-05
============================
Start of epoch 1323
step 0: mean loss = 4.7804106e-06
step 100: mean loss = 5.9857803e-06
epoch 1323: mean loss = 6.0421503e-06  learning rate = 2.027653e-05
============================
Start of epoch 1324
step 0: mean loss = 5.226275e-06
step 100: mean loss = 6.5041577e-06
epoch 1324: mean loss = 5.9867325e-06  learning rate = 2.027653e-05
============================
Start of epoch 1325
step 0: mean loss = 3.9548963e-06
step 100: mean loss = 5.900856e-06
epoch 1325: mean loss = 5.973143e-06  learning rate = 2.027653e-05
============================
Start of epoch 1326
step 0: mean loss = 4.6324158e-06
step 100: mean loss = 4.9421155e-06
epoch 1326: mean loss = 5.9324907e-06  learning rate = 2.027653e-05
============================
Start of epoch 1327
step 0: mean loss = 6.03887e-06
step 100: mean loss = 6.6150096e-06
epoch 1327: mean loss = 5.9881027e-06  learning rate = 2.027653e-05
============================
Start of epoch 1328
step 0: mean loss = 5.8868554e-06
step 100: mean loss = 5.9676872e-06
epoch 1328: mean loss = 5.920706e-06  learning rate = 2.027653e-05
============================
Start of epoch 1329
step 0: mean loss = 4.5148327e-06
step 100: mean loss = 6.2632053e-06
epoch 1329: mean loss = 6.1372903e-06  learning rate = 2.027653e-05
============================
Start of epoch 1330
step 0: mean loss = 5.1536454e-06
step 100: mean loss = 5.3649437e-06
epoch 1330: mean loss = 5.9574077e-06  learning rate = 2.027653e-05
============================
Start of epoch 1331
step 0: mean loss = 4.954423e-06
step 100: mean loss = 6.2005697e-06
epoch 1331: mean loss = 6.1348014e-06  learning rate = 2.027653e-05
============================
Start of epoch 1332
step 0: mean loss = 4.3680816e-06
step 100: mean loss = 6.5910945e-06
epoch 1332: mean loss = 5.986424e-06  learning rate = 2.027653e-05
============================
Start of epoch 1333
step 0: mean loss = 5.6552162e-06
step 100: mean loss = 5.953999e-06
epoch 1333: mean loss = 6.019561e-06  learning rate = 2.027653e-05
============================
Start of epoch 1334
step 0: mean loss = 5.428989e-06
step 100: mean loss = 5.5203695e-06
epoch 1334: mean loss = 6.862913e-06  learning rate = 2.027653e-05
============================
Start of epoch 1335
step 0: mean loss = 7.435376e-06
step 100: mean loss = 7.5706043e-06
epoch 1335: mean loss = 6.979806e-06  learning rate = 2.027653e-05
============================
Start of epoch 1336
step 0: mean loss = 4.1466187e-06
step 100: mean loss = 6.453647e-06
epoch 1336: mean loss = 5.8967657e-06  learning rate = 2.027653e-05
============================
Start of epoch 1337
step 0: mean loss = 5.1381626e-06
step 100: mean loss = 6.495456e-06
epoch 1337: mean loss = 5.8963374e-06  learning rate = 2.027653e-05
============================
Start of epoch 1338
step 0: mean loss = 4.0645327e-06
step 100: mean loss = 6.097691e-06
epoch 1338: mean loss = 6.0091593e-06  learning rate = 2.027653e-05
============================
Start of epoch 1339
step 0: mean loss = 4.6146606e-06
step 100: mean loss = 6.655576e-06
epoch 1339: mean loss = 6.000314e-06  learning rate = 2.027653e-05
============================
Start of epoch 1340
step 0: mean loss = 4.285194e-06
step 100: mean loss = 5.9151753e-06
epoch 1340: mean loss = 5.888552e-06  learning rate = 2.027653e-05
============================
Start of epoch 1341
step 0: mean loss = 5.6379395e-06
step 100: mean loss = 6.5128465e-06
epoch 1341: mean loss = 5.9135405e-06  learning rate = 2.027653e-05
============================
Start of epoch 1342
step 0: mean loss = 5.195867e-06
step 100: mean loss = 6.190423e-06
epoch 1342: mean loss = 6.0410193e-06  learning rate = 2.027653e-05
============================
Start of epoch 1343
step 0: mean loss = 4.3920813e-06
step 100: mean loss = 5.406812e-06
epoch 1343: mean loss = 5.9123217e-06  learning rate = 2.027653e-05
============================
Start of epoch 1344
step 0: mean loss = 4.8195934e-06
step 100: mean loss = 5.960257e-06
epoch 1344: mean loss = 5.781977e-06  learning rate = 2.027653e-05
============================
Start of epoch 1345
step 0: mean loss = 4.883333e-06
step 100: mean loss = 5.971412e-06
epoch 1345: mean loss = 5.9492136e-06  learning rate = 2.027653e-05
============================
Start of epoch 1346
step 0: mean loss = 5.655661e-06
step 100: mean loss = 6.0898133e-06
epoch 1346: mean loss = 5.995364e-06  learning rate = 2.027653e-05
============================
Start of epoch 1347
step 0: mean loss = 4.6376845e-06
step 100: mean loss = 6.099782e-06
epoch 1347: mean loss = 5.8953333e-06  learning rate = 2.027653e-05
============================
Start of epoch 1348
step 0: mean loss = 4.657117e-06
step 100: mean loss = 6.573775e-06
epoch 1348: mean loss = 6.0516045e-06  learning rate = 2.027653e-05
============================
Start of epoch 1349
step 0: mean loss = 4.4061226e-06
step 100: mean loss = 5.340263e-06
epoch 1349: mean loss = 5.8777446e-06  learning rate = 2.027653e-05
============================
Start of epoch 1350
step 0: mean loss = 5.8708783e-06
step 100: mean loss = 6.052737e-06
epoch 1350: mean loss = 5.9776235e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1351
step 0: mean loss = 5.305616e-06
step 100: mean loss = 6.361513e-06
epoch 1351: mean loss = 5.8695214e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1352
step 0: mean loss = 4.779633e-06
step 100: mean loss = 6.45194e-06
epoch 1352: mean loss = 5.847211e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1353
step 0: mean loss = 4.7889616e-06
step 100: mean loss = 5.2538794e-06
epoch 1353: mean loss = 5.6602785e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1354
step 0: mean loss = 4.8684806e-06
step 100: mean loss = 5.6801628e-06
epoch 1354: mean loss = 5.7941725e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1355
step 0: mean loss = 5.906274e-06
step 100: mean loss = 6.4658216e-06
epoch 1355: mean loss = 5.839544e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1356
step 0: mean loss = 4.191869e-06
step 100: mean loss = 5.93505e-06
epoch 1356: mean loss = 5.7794687e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1357
step 0: mean loss = 5.240504e-06
step 100: mean loss = 6.139167e-06
epoch 1357: mean loss = 5.8381374e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1358
step 0: mean loss = 4.715367e-06
step 100: mean loss = 5.8825603e-06
epoch 1358: mean loss = 5.748009e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1359
step 0: mean loss = 5.430952e-06
step 100: mean loss = 5.747444e-06
epoch 1359: mean loss = 5.753494e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1360
step 0: mean loss = 4.548395e-06
step 100: mean loss = 5.4420175e-06
epoch 1360: mean loss = 5.7651487e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1361
step 0: mean loss = 4.8125994e-06
step 100: mean loss = 5.5847863e-06
epoch 1361: mean loss = 5.694754e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1362
step 0: mean loss = 5.122917e-06
step 100: mean loss = 6.3344673e-06
epoch 1362: mean loss = 5.878109e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1363
step 0: mean loss = 4.815125e-06
step 100: mean loss = 4.815556e-06
epoch 1363: mean loss = 5.6436543e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1364
step 0: mean loss = 6.304167e-06
step 100: mean loss = 6.41642e-06
epoch 1364: mean loss = 5.856761e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1365
step 0: mean loss = 4.5765055e-06
step 100: mean loss = 5.7725038e-06
epoch 1365: mean loss = 5.7675866e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1366
step 0: mean loss = 6.581111e-06
step 100: mean loss = 6.4376322e-06
epoch 1366: mean loss = 5.8148867e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1367
step 0: mean loss = 4.2012707e-06
step 100: mean loss = 6.138084e-06
epoch 1367: mean loss = 5.7577845e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1368
step 0: mean loss = 4.5237794e-06
step 100: mean loss = 4.9604355e-06
epoch 1368: mean loss = 5.7020834e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1369
step 0: mean loss = 5.649622e-06
step 100: mean loss = 6.3856196e-06
epoch 1369: mean loss = 5.7932048e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1370
step 0: mean loss = 3.7099892e-06
step 100: mean loss = 4.595703e-06
epoch 1370: mean loss = 5.6894105e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1371
step 0: mean loss = 4.6654523e-06
step 100: mean loss = 6.0887514e-06
epoch 1371: mean loss = 5.9146178e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1372
step 0: mean loss = 4.7700496e-06
step 100: mean loss = 5.1137645e-06
epoch 1372: mean loss = 5.710072e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1373
step 0: mean loss = 4.737786e-06
step 100: mean loss = 5.3968574e-06
epoch 1373: mean loss = 5.772996e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1374
step 0: mean loss = 4.8905927e-06
step 100: mean loss = 6.3954185e-06
epoch 1374: mean loss = 5.812465e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1375
step 0: mean loss = 3.647544e-06
step 100: mean loss = 5.2984683e-06
epoch 1375: mean loss = 5.7139255e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1376
step 0: mean loss = 6.658381e-06
step 100: mean loss = 6.2820245e-06
epoch 1376: mean loss = 5.884124e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1377
step 0: mean loss = 4.815887e-06
step 100: mean loss = 5.4970674e-06
epoch 1377: mean loss = 5.8182227e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1378
step 0: mean loss = 5.301309e-06
step 100: mean loss = 6.2558042e-06
epoch 1378: mean loss = 5.7486836e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1379
step 0: mean loss = 4.6247787e-06
step 100: mean loss = 5.816926e-06
epoch 1379: mean loss = 5.8857668e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1380
step 0: mean loss = 4.0225063e-06
step 100: mean loss = 6.2771264e-06
epoch 1380: mean loss = 5.7485936e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1381
step 0: mean loss = 5.458982e-06
step 100: mean loss = 5.9833164e-06
epoch 1381: mean loss = 5.7582765e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1382
step 0: mean loss = 5.6104336e-06
step 100: mean loss = 4.856551e-06
epoch 1382: mean loss = 5.740767e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1383
step 0: mean loss = 4.369042e-06
step 100: mean loss = 5.6820995e-06
epoch 1383: mean loss = 5.7426582e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1384
step 0: mean loss = 5.0919402e-06
step 100: mean loss = 6.327148e-06
epoch 1384: mean loss = 5.8377973e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1385
step 0: mean loss = 4.3290793e-06
step 100: mean loss = 5.1220195e-06
epoch 1385: mean loss = 5.767464e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1386
step 0: mean loss = 4.188812e-06
step 100: mean loss = 5.690598e-06
epoch 1386: mean loss = 5.7421375e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1387
step 0: mean loss = 4.438837e-06
step 100: mean loss = 5.679847e-06
epoch 1387: mean loss = 5.7011152e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1388
step 0: mean loss = 5.172129e-06
step 100: mean loss = 5.0454464e-06
epoch 1388: mean loss = 5.7381226e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1389
step 0: mean loss = 4.3069267e-06
step 100: mean loss = 5.320344e-06
epoch 1389: mean loss = 5.8850596e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1390
step 0: mean loss = 4.3171385e-06
step 100: mean loss = 5.315676e-06
epoch 1390: mean loss = 5.7011866e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1391
step 0: mean loss = 4.5065303e-06
step 100: mean loss = 5.066364e-06
epoch 1391: mean loss = 5.67706e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1392
step 0: mean loss = 4.4647004e-06
step 100: mean loss = 5.6735803e-06
epoch 1392: mean loss = 5.7401617e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1393
step 0: mean loss = 4.620865e-06
step 100: mean loss = 5.3180884e-06
epoch 1393: mean loss = 5.657992e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1394
step 0: mean loss = 5.139852e-06
step 100: mean loss = 6.020542e-06
epoch 1394: mean loss = 5.7792627e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1395
step 0: mean loss = 4.0109526e-06
step 100: mean loss = 5.4016964e-06
epoch 1395: mean loss = 5.725812e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1396
step 0: mean loss = 4.7042477e-06
step 100: mean loss = 6.355381e-06
epoch 1396: mean loss = 5.7753114e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1397
step 0: mean loss = 4.7831063e-06
step 100: mean loss = 5.6627405e-06
epoch 1397: mean loss = 5.70454e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1398
step 0: mean loss = 4.181783e-06
step 100: mean loss = 5.1495977e-06
epoch 1398: mean loss = 5.722039e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1399
step 0: mean loss = 8.090313e-06
step 100: mean loss = 5.220632e-06
epoch 1399: mean loss = 5.7589973e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1400
step 0: mean loss = 5.201997e-06
step 100: mean loss = 5.7506995e-06
epoch 1400: mean loss = 5.7897487e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1401
step 0: mean loss = 3.9444167e-06
step 100: mean loss = 6.168631e-06
epoch 1401: mean loss = 5.7211446e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1402
step 0: mean loss = 3.9246083e-06
step 100: mean loss = 5.0608796e-06
epoch 1402: mean loss = 5.650057e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1403
step 0: mean loss = 4.700072e-06
step 100: mean loss = 6.3326816e-06
epoch 1403: mean loss = 5.779456e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1404
step 0: mean loss = 4.284162e-06
step 100: mean loss = 6.276357e-06
epoch 1404: mean loss = 5.7226457e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1405
step 0: mean loss = 3.9741008e-06
step 100: mean loss = 5.4598727e-06
epoch 1405: mean loss = 5.7656334e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1406
step 0: mean loss = 4.829691e-06
step 100: mean loss = 6.19071e-06
epoch 1406: mean loss = 5.6952517e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1407
step 0: mean loss = 5.0792128e-06
step 100: mean loss = 6.4440605e-06
epoch 1407: mean loss = 5.8620462e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1408
step 0: mean loss = 4.628284e-06
step 100: mean loss = 4.7767426e-06
epoch 1408: mean loss = 5.704962e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1409
step 0: mean loss = 4.480083e-06
step 100: mean loss = 5.3065787e-06
epoch 1409: mean loss = 5.7210864e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1410
step 0: mean loss = 5.1976995e-06
step 100: mean loss = 6.386185e-06
epoch 1410: mean loss = 5.718615e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1411
step 0: mean loss = 4.2016572e-06
step 100: mean loss = 5.589004e-06
epoch 1411: mean loss = 5.6412846e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1412
step 0: mean loss = 5.144758e-06
step 100: mean loss = 5.426758e-06
epoch 1412: mean loss = 5.6834606e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1413
step 0: mean loss = 4.7410467e-06
step 100: mean loss = 5.981896e-06
epoch 1413: mean loss = 5.869894e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1414
step 0: mean loss = 4.84915e-06
step 100: mean loss = 5.572445e-06
epoch 1414: mean loss = 5.6698063e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1415
step 0: mean loss = 4.3468026e-06
step 100: mean loss = 5.7919883e-06
epoch 1415: mean loss = 5.749152e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1416
step 0: mean loss = 5.100526e-06
step 100: mean loss = 6.2782237e-06
epoch 1416: mean loss = 5.78506e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1417
step 0: mean loss = 3.6665863e-06
step 100: mean loss = 5.9790373e-06
epoch 1417: mean loss = 5.6947256e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1418
step 0: mean loss = 4.9188698e-06
step 100: mean loss = 5.627085e-06
epoch 1418: mean loss = 5.6977233e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1419
step 0: mean loss = 4.278778e-06
step 100: mean loss = 5.7189222e-06
epoch 1419: mean loss = 5.645015e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1420
step 0: mean loss = 4.997071e-06
step 100: mean loss = 6.020037e-06
epoch 1420: mean loss = 5.765323e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1421
step 0: mean loss = 5.201952e-06
step 100: mean loss = 5.7242464e-06
epoch 1421: mean loss = 5.7703714e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1422
step 0: mean loss = 6.4014007e-06
step 100: mean loss = 5.739321e-06
epoch 1422: mean loss = 5.684454e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1423
step 0: mean loss = 5.5150485e-06
step 100: mean loss = 5.0300696e-06
epoch 1423: mean loss = 5.673707e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1424
step 0: mean loss = 7.1570894e-06
step 100: mean loss = 5.7933157e-06
epoch 1424: mean loss = 5.717015e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1425
step 0: mean loss = 5.032977e-06
step 100: mean loss = 5.5942787e-06
epoch 1425: mean loss = 5.6687727e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1426
step 0: mean loss = 4.5401084e-06
step 100: mean loss = 5.240888e-06
epoch 1426: mean loss = 5.692743e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1427
step 0: mean loss = 4.8028546e-06
step 100: mean loss = 6.0242423e-06
epoch 1427: mean loss = 5.827332e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1428
step 0: mean loss = 4.8769334e-06
step 100: mean loss = 5.3744993e-06
epoch 1428: mean loss = 5.7149573e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1429
step 0: mean loss = 4.219364e-06
step 100: mean loss = 5.6979525e-06
epoch 1429: mean loss = 5.6740223e-06  learning rate = 1.9262703e-05
============================
Start of epoch 1430
step 0: mean loss = 4.161456e-06
step 100: mean loss = 4.6584028e-06
epoch 1430: mean loss = 5.7555744e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1431
step 0: mean loss = 4.4468234e-06
step 100: mean loss = 5.799245e-06
epoch 1431: mean loss = 6.202278e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1432
step 0: mean loss = 5.2497007e-06
step 100: mean loss = 6.707816e-06
epoch 1432: mean loss = 6.0160964e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1433
step 0: mean loss = 5.337245e-06
step 100: mean loss = 5.846823e-06
epoch 1433: mean loss = 5.592435e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1434
step 0: mean loss = 3.9173165e-06
step 100: mean loss = 5.928177e-06
epoch 1434: mean loss = 5.6427552e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1435
step 0: mean loss = 4.1280236e-06
step 100: mean loss = 5.571371e-06
epoch 1435: mean loss = 5.6339204e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1436
step 0: mean loss = 4.30458e-06
step 100: mean loss = 5.0103413e-06
epoch 1436: mean loss = 5.593299e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1437
step 0: mean loss = 5.1517763e-06
step 100: mean loss = 5.959497e-06
epoch 1437: mean loss = 5.6758718e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1438
step 0: mean loss = 4.5683373e-06
step 100: mean loss = 5.7077714e-06
epoch 1438: mean loss = 5.692403e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1439
step 0: mean loss = 4.6831947e-06
step 100: mean loss = 5.150318e-06
epoch 1439: mean loss = 5.529696e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1440
step 0: mean loss = 6.771601e-06
step 100: mean loss = 5.0703866e-06
epoch 1440: mean loss = 5.6807835e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1441
step 0: mean loss = 5.2409578e-06
step 100: mean loss = 6.148088e-06
epoch 1441: mean loss = 5.6586955e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1442
step 0: mean loss = 3.961924e-06
step 100: mean loss = 5.6549793e-06
epoch 1442: mean loss = 5.600431e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1443
step 0: mean loss = 5.481942e-05
step 100: mean loss = 5.6504864e-06
epoch 1443: mean loss = 5.6444705e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1444
step 0: mean loss = 4.4635945e-06
step 100: mean loss = 6.2269837e-06
epoch 1444: mean loss = 5.9080976e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1445
step 0: mean loss = 4.5380225e-06
step 100: mean loss = 5.735458e-06
epoch 1445: mean loss = 5.633159e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1446
step 0: mean loss = 4.857823e-06
step 100: mean loss = 5.0273316e-06
epoch 1446: mean loss = 5.6179247e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1447
step 0: mean loss = 4.9510254e-06
step 100: mean loss = 5.674538e-06
epoch 1447: mean loss = 5.6818076e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1448
step 0: mean loss = 4.5377174e-06
step 100: mean loss = 6.1208693e-06
epoch 1448: mean loss = 5.604028e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1449
step 0: mean loss = 4.035869e-06
step 100: mean loss = 4.920707e-06
epoch 1449: mean loss = 5.57794e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1450
step 0: mean loss = 4.3322293e-06
step 100: mean loss = 6.1700766e-06
epoch 1450: mean loss = 5.62165e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1451
step 0: mean loss = 4.6358396e-06
step 100: mean loss = 5.2839896e-06
epoch 1451: mean loss = 5.6903373e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1452
step 0: mean loss = 4.167907e-06
step 100: mean loss = 5.285091e-06
epoch 1452: mean loss = 5.731033e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1453
step 0: mean loss = 4.3540613e-06
step 100: mean loss = 6.009686e-06
epoch 1453: mean loss = 5.5692535e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1454
step 0: mean loss = 4.1128114e-06
step 100: mean loss = 6.089998e-06
epoch 1454: mean loss = 5.61551e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1455
step 0: mean loss = 5.3775988e-05
step 100: mean loss = 5.1709235e-06
epoch 1455: mean loss = 5.582188e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1456
step 0: mean loss = 4.2788192e-06
step 100: mean loss = 5.483976e-06
epoch 1456: mean loss = 5.7202365e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1457
step 0: mean loss = 4.7026724e-06
step 100: mean loss = 6.2074446e-06
epoch 1457: mean loss = 5.601028e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1458
step 0: mean loss = 3.9912393e-06
step 100: mean loss = 6.155676e-06
epoch 1458: mean loss = 5.563608e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1459
step 0: mean loss = 5.409639e-06
step 100: mean loss = 5.0726776e-06
epoch 1459: mean loss = 5.5568808e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1460
step 0: mean loss = 4.3438504e-06
step 100: mean loss = 5.779866e-06
epoch 1460: mean loss = 5.721841e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1461
step 0: mean loss = 6.425379e-06
step 100: mean loss = 5.537971e-06
epoch 1461: mean loss = 5.5823202e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1462
step 0: mean loss = 4.5012393e-06
step 100: mean loss = 5.0519834e-06
epoch 1462: mean loss = 5.6023273e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1463
step 0: mean loss = 4.4336157e-06
step 100: mean loss = 5.468948e-06
epoch 1463: mean loss = 5.667912e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1464
step 0: mean loss = 4.0849827e-06
step 100: mean loss = 6.222186e-06
epoch 1464: mean loss = 5.611588e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1465
step 0: mean loss = 3.8005028e-06
step 100: mean loss = 5.650104e-06
epoch 1465: mean loss = 5.570522e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1466
step 0: mean loss = 4.0641708e-06
step 100: mean loss = 5.2549317e-06
epoch 1466: mean loss = 5.6493473e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1467
step 0: mean loss = 5.03692e-06
step 100: mean loss = 5.667527e-06
epoch 1467: mean loss = 5.6643103e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1468
step 0: mean loss = 4.811659e-06
step 100: mean loss = 4.908376e-06
epoch 1468: mean loss = 5.4916454e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1469
step 0: mean loss = 4.442263e-06
step 100: mean loss = 6.2642657e-06
epoch 1469: mean loss = 5.687606e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1470
step 0: mean loss = 5.0429703e-06
step 100: mean loss = 5.7462516e-06
epoch 1470: mean loss = 5.5703667e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1471
step 0: mean loss = 5.0755907e-06
step 100: mean loss = 5.57785e-06
epoch 1471: mean loss = 5.655752e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1472
step 0: mean loss = 5.0303415e-06
step 100: mean loss = 4.92497e-06
epoch 1472: mean loss = 5.610499e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1473
step 0: mean loss = 4.817425e-06
step 100: mean loss = 5.255785e-06
epoch 1473: mean loss = 5.561316e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1474
step 0: mean loss = 4.9995824e-06
step 100: mean loss = 5.377411e-06
epoch 1474: mean loss = 5.6461795e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1475
step 0: mean loss = 5.3132717e-06
step 100: mean loss = 5.035462e-06
epoch 1475: mean loss = 5.5327564e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1476
step 0: mean loss = 5.0216395e-06
step 100: mean loss = 5.675282e-06
epoch 1476: mean loss = 5.668337e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1477
step 0: mean loss = 4.0586006e-06
step 100: mean loss = 5.774873e-06
epoch 1477: mean loss = 5.7295556e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1478
step 0: mean loss = 4.731327e-06
step 100: mean loss = 5.2148926e-06
epoch 1478: mean loss = 5.5380724e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1479
step 0: mean loss = 4.4700037e-06
step 100: mean loss = 5.843217e-06
epoch 1479: mean loss = 5.66904e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1480
step 0: mean loss = 4.288213e-06
step 100: mean loss = 4.6090086e-06
epoch 1480: mean loss = 5.5546116e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1481
step 0: mean loss = 4.775762e-06
step 100: mean loss = 5.2758273e-06
epoch 1481: mean loss = 5.602512e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1482
step 0: mean loss = 4.929855e-06
step 100: mean loss = 4.9784994e-06
epoch 1482: mean loss = 5.5746564e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1483
step 0: mean loss = 4.0849814e-06
step 100: mean loss = 5.825587e-06
epoch 1483: mean loss = 5.5920927e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1484
step 0: mean loss = 4.573201e-06
step 100: mean loss = 5.024566e-06
epoch 1484: mean loss = 5.6165e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1485
step 0: mean loss = 4.5113643e-06
step 100: mean loss = 5.231905e-06
epoch 1485: mean loss = 5.607438e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1486
step 0: mean loss = 3.4590306e-05
step 100: mean loss = 5.4915013e-06
epoch 1486: mean loss = 5.528271e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1487
step 0: mean loss = 4.8676666e-06
step 100: mean loss = 5.5310306e-06
epoch 1487: mean loss = 5.567025e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1488
step 0: mean loss = 4.3706714e-06
step 100: mean loss = 5.728782e-06
epoch 1488: mean loss = 5.6339054e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1489
step 0: mean loss = 4.597937e-06
step 100: mean loss = 5.857054e-06
epoch 1489: mean loss = 5.623148e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1490
step 0: mean loss = 4.361792e-06
step 100: mean loss = 5.171825e-06
epoch 1490: mean loss = 5.571945e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1491
step 0: mean loss = 4.3739747e-06
step 100: mean loss = 6.1472183e-06
epoch 1491: mean loss = 5.6723115e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1492
step 0: mean loss = 5.516281e-06
step 100: mean loss = 6.217967e-06
epoch 1492: mean loss = 5.6742647e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1493
step 0: mean loss = 4.271382e-06
step 100: mean loss = 6.0418115e-06
epoch 1493: mean loss = 5.5819205e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1494
step 0: mean loss = 4.8600323e-06
step 100: mean loss = 5.6612703e-06
epoch 1494: mean loss = 5.5186397e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1495
step 0: mean loss = 4.4533163e-06
step 100: mean loss = 5.172587e-06
epoch 1495: mean loss = 5.5599007e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1496
step 0: mean loss = 3.7096083e-06
step 100: mean loss = 6.0874427e-06
epoch 1496: mean loss = 5.5309856e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1497
step 0: mean loss = 3.6950487e-06
step 100: mean loss = 5.556704e-06
epoch 1497: mean loss = 5.548768e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1498
step 0: mean loss = 4.3755226e-06
step 100: mean loss = 5.2378364e-06
epoch 1498: mean loss = 5.4799543e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1499
step 0: mean loss = 5.254059e-06
step 100: mean loss = 5.8951755e-06
epoch 1499: mean loss = 5.709763e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1500
step 0: mean loss = 4.3957416e-06
step 100: mean loss = 5.649414e-06
epoch 1500: mean loss = 5.638181e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1501
step 0: mean loss = 4.486067e-06
step 100: mean loss = 4.6328264e-06
epoch 1501: mean loss = 5.521717e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1502
step 0: mean loss = 5.1473844e-06
step 100: mean loss = 6.2601544e-06
epoch 1502: mean loss = 5.749846e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1503
step 0: mean loss = 4.6774176e-06
step 100: mean loss = 5.189307e-06
epoch 1503: mean loss = 5.572678e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1504
step 0: mean loss = 4.5923534e-06
step 100: mean loss = 5.595213e-06
epoch 1504: mean loss = 5.5845267e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1505
step 0: mean loss = 5.390111e-06
step 100: mean loss = 5.851872e-06
epoch 1505: mean loss = 5.5720066e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1506
step 0: mean loss = 4.235745e-06
step 100: mean loss = 5.465762e-06
epoch 1506: mean loss = 5.533073e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1507
step 0: mean loss = 5.817482e-06
step 100: mean loss = 4.642443e-06
epoch 1507: mean loss = 5.5589926e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1508
step 0: mean loss = 4.9983873e-06
step 100: mean loss = 6.200561e-06
epoch 1508: mean loss = 5.671035e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1509
step 0: mean loss = 4.6456785e-06
step 100: mean loss = 4.5318657e-06
epoch 1509: mean loss = 5.5156333e-06  learning rate = 1.8299566e-05
============================
Start of epoch 1510
step 0: mean loss = 5.1590355e-06
step 100: mean loss = 5.7698885e-06
epoch 1510: mean loss = 6.0485604e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1511
step 0: mean loss = 4.777311e-06
step 100: mean loss = 6.489148e-06
epoch 1511: mean loss = 5.7977004e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1512
step 0: mean loss = 4.689726e-06
step 100: mean loss = 5.9274475e-06
epoch 1512: mean loss = 5.6263775e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1513
step 0: mean loss = 4.322862e-06
step 100: mean loss = 4.581166e-06
epoch 1513: mean loss = 5.4151865e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1514
step 0: mean loss = 6.042309e-06
step 100: mean loss = 6.2389713e-06
epoch 1514: mean loss = 5.5839396e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1515
step 0: mean loss = 3.7537677e-06
step 100: mean loss = 5.3315357e-06
epoch 1515: mean loss = 5.482031e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1516
step 0: mean loss = 4.0244804e-06
step 100: mean loss = 5.462593e-06
epoch 1516: mean loss = 5.4627076e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1517
step 0: mean loss = 5.097764e-06
step 100: mean loss = 5.6093177e-06
epoch 1517: mean loss = 5.458455e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1518
step 0: mean loss = 4.663156e-06
step 100: mean loss = 6.1249116e-06
epoch 1518: mean loss = 5.570318e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1519
step 0: mean loss = 4.661999e-06
step 100: mean loss = 6.1070127e-06
epoch 1519: mean loss = 5.4675434e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1520
step 0: mean loss = 4.0286277e-06
step 100: mean loss = 5.9307026e-06
epoch 1520: mean loss = 5.4535294e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1521
step 0: mean loss = 4.1523663e-06
step 100: mean loss = 4.871298e-06
epoch 1521: mean loss = 5.413893e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1522
step 0: mean loss = 4.263044e-06
step 100: mean loss = 5.346395e-06
epoch 1522: mean loss = 5.512859e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1523
step 0: mean loss = 3.978997e-06
step 100: mean loss = 5.1520683e-06
epoch 1523: mean loss = 5.5131227e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1524
step 0: mean loss = 4.609939e-06
step 100: mean loss = 5.2416285e-06
epoch 1524: mean loss = 5.5181895e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1525
step 0: mean loss = 4.2603524e-06
step 100: mean loss = 6.066573e-06
epoch 1525: mean loss = 5.4935035e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1526
step 0: mean loss = 3.9824945e-06
step 100: mean loss = 5.5417463e-06
epoch 1526: mean loss = 5.506632e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1527
step 0: mean loss = 3.9396855e-06
step 100: mean loss = 5.9354475e-06
epoch 1527: mean loss = 5.503909e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1528
step 0: mean loss = 3.7611035e-06
step 100: mean loss = 6.0459497e-06
epoch 1528: mean loss = 5.4791535e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1529
step 0: mean loss = 4.1520534e-06
step 100: mean loss = 4.959946e-06
epoch 1529: mean loss = 5.42973e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1530
step 0: mean loss = 3.7953246e-06
step 100: mean loss = 6.180925e-06
epoch 1530: mean loss = 5.690739e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1531
step 0: mean loss = 3.899134e-06
step 100: mean loss = 5.4188868e-06
epoch 1531: mean loss = 5.423612e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1532
step 0: mean loss = 5.22161e-06
step 100: mean loss = 6.2141553e-06
epoch 1532: mean loss = 5.5887317e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1533
step 0: mean loss = 4.1528583e-06
step 100: mean loss = 6.1289065e-06
epoch 1533: mean loss = 5.5519595e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1534
step 0: mean loss = 5.3492154e-06
step 100: mean loss = 5.1668426e-06
epoch 1534: mean loss = 5.496851e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1535
step 0: mean loss = 4.9130444e-06
step 100: mean loss = 5.1750776e-06
epoch 1535: mean loss = 5.5580545e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1536
step 0: mean loss = 5.691242e-06
step 100: mean loss = 5.234906e-06
epoch 1536: mean loss = 5.551602e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1537
step 0: mean loss = 4.90587e-06
step 100: mean loss = 5.641059e-06
epoch 1537: mean loss = 5.591205e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1538
step 0: mean loss = 5.4994025e-06
step 100: mean loss = 5.0378394e-06
epoch 1538: mean loss = 5.5558726e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1539
step 0: mean loss = 5.476433e-06
step 100: mean loss = 6.1179358e-06
epoch 1539: mean loss = 5.575969e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1540
step 0: mean loss = 4.170146e-06
step 100: mean loss = 5.4850143e-06
epoch 1540: mean loss = 5.5544747e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1541
step 0: mean loss = 4.6391424e-06
step 100: mean loss = 5.8897213e-06
epoch 1541: mean loss = 5.4447846e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1542
step 0: mean loss = 4.513987e-06
step 100: mean loss = 5.7496663e-06
epoch 1542: mean loss = 5.4755374e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1543
step 0: mean loss = 4.512247e-06
step 100: mean loss = 5.5908567e-06
epoch 1543: mean loss = 5.5736687e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1544
step 0: mean loss = 4.9072305e-06
step 100: mean loss = 6.134471e-06
epoch 1544: mean loss = 5.568652e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1545
step 0: mean loss = 3.7097946e-06
step 100: mean loss = 6.0324137e-06
epoch 1545: mean loss = 5.5126425e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1546
step 0: mean loss = 4.3108575e-06
step 100: mean loss = 4.745741e-06
epoch 1546: mean loss = 5.4687116e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1547
step 0: mean loss = 4.294123e-06
step 100: mean loss = 6.0055863e-06
epoch 1547: mean loss = 5.4933785e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1548
step 0: mean loss = 5.12627e-06
step 100: mean loss = 5.401934e-06
epoch 1548: mean loss = 5.4484317e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1549
step 0: mean loss = 5.159634e-06
step 100: mean loss = 5.9661384e-06
epoch 1549: mean loss = 5.453335e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1550
step 0: mean loss = 4.1522253e-06
step 100: mean loss = 5.313361e-06
epoch 1550: mean loss = 5.588357e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1551
step 0: mean loss = 3.8320695e-06
step 100: mean loss = 5.447621e-06
epoch 1551: mean loss = 5.485001e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1552
step 0: mean loss = 4.2652255e-06
step 100: mean loss = 5.301793e-06
epoch 1552: mean loss = 5.3625886e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1553
step 0: mean loss = 5.1389006e-06
step 100: mean loss = 5.4976194e-06
epoch 1553: mean loss = 5.5014616e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1554
step 0: mean loss = 5.439365e-06
step 100: mean loss = 5.5827372e-06
epoch 1554: mean loss = 5.449472e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1555
step 0: mean loss = 4.2806805e-06
step 100: mean loss = 5.5132027e-06
epoch 1555: mean loss = 5.498002e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1556
step 0: mean loss = 3.9897513e-06
step 100: mean loss = 6.1266283e-06
epoch 1556: mean loss = 5.533397e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1557
step 0: mean loss = 4.8336424e-06
step 100: mean loss = 5.6791405e-06
epoch 1557: mean loss = 5.461375e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1558
step 0: mean loss = 4.7327535e-06
step 100: mean loss = 4.575095e-06
epoch 1558: mean loss = 5.5901946e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1559
step 0: mean loss = 4.1291332e-06
step 100: mean loss = 5.5215723e-06
epoch 1559: mean loss = 5.4616235e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1560
step 0: mean loss = 4.45175e-06
step 100: mean loss = 5.9507283e-06
epoch 1560: mean loss = 5.4965753e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1561
step 0: mean loss = 4.5135685e-06
step 100: mean loss = 5.199433e-06
epoch 1561: mean loss = 5.399414e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1562
step 0: mean loss = 4.9099863e-06
step 100: mean loss = 5.393589e-06
epoch 1562: mean loss = 5.4028624e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1563
step 0: mean loss = 4.293348e-06
step 100: mean loss = 5.9931012e-06
epoch 1563: mean loss = 5.4911793e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1564
step 0: mean loss = 4.363337e-06
step 100: mean loss = 5.5388014e-06
epoch 1564: mean loss = 5.5506716e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1565
step 0: mean loss = 4.202929e-06
step 100: mean loss = 5.083372e-06
epoch 1565: mean loss = 5.3897134e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1566
step 0: mean loss = 4.571245e-06
step 100: mean loss = 4.9526698e-06
epoch 1566: mean loss = 5.430688e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1567
step 0: mean loss = 4.6495343e-06
step 100: mean loss = 5.650889e-06
epoch 1567: mean loss = 5.4222473e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1568
step 0: mean loss = 4.5600787e-06
step 100: mean loss = 5.9693702e-06
epoch 1568: mean loss = 5.399999e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1569
step 0: mean loss = 3.7857835e-06
step 100: mean loss = 5.977589e-06
epoch 1569: mean loss = 5.503447e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1570
step 0: mean loss = 4.2213105e-06
step 100: mean loss = 5.435266e-06
epoch 1570: mean loss = 5.5717755e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1571
step 0: mean loss = 5.2557407e-06
step 100: mean loss = 5.9989156e-06
epoch 1571: mean loss = 5.4678853e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1572
step 0: mean loss = 5.3872604e-06
step 100: mean loss = 6.1133196e-06
epoch 1572: mean loss = 5.4935817e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1573
step 0: mean loss = 3.319658e-06
step 100: mean loss = 5.3328286e-06
epoch 1573: mean loss = 5.4739694e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1574
step 0: mean loss = 4.775766e-06
step 100: mean loss = 5.099246e-06
epoch 1574: mean loss = 5.4459915e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1575
step 0: mean loss = 3.7191342e-06
step 100: mean loss = 5.898798e-06
epoch 1575: mean loss = 5.4079014e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1576
step 0: mean loss = 4.6573036e-06
step 100: mean loss = 5.3631397e-06
epoch 1576: mean loss = 5.3960057e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1577
step 0: mean loss = 4.89985e-06
step 100: mean loss = 5.970821e-06
epoch 1577: mean loss = 5.4253865e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1578
step 0: mean loss = 4.3683945e-06
step 100: mean loss = 4.83356e-06
epoch 1578: mean loss = 5.313145e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1579
step 0: mean loss = 5.709538e-06
step 100: mean loss = 6.2121867e-06
epoch 1579: mean loss = 5.528854e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1580
step 0: mean loss = 3.8999588e-06
step 100: mean loss = 4.7705503e-06
epoch 1580: mean loss = 5.5039127e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1581
step 0: mean loss = 5.4440907e-06
step 100: mean loss = 5.188595e-06
epoch 1581: mean loss = 5.461933e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1582
step 0: mean loss = 5.971029e-06
step 100: mean loss = 5.9792865e-06
epoch 1582: mean loss = 5.436111e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1583
step 0: mean loss = 3.8588732e-06
step 100: mean loss = 5.8447113e-06
epoch 1583: mean loss = 5.3770805e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1584
step 0: mean loss = 4.8117054e-06
step 100: mean loss = 5.552854e-06
epoch 1584: mean loss = 5.3900603e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1585
step 0: mean loss = 4.9595897e-06
step 100: mean loss = 4.490117e-06
epoch 1585: mean loss = 5.3760327e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1586
step 0: mean loss = 5.155888e-06
step 100: mean loss = 5.367428e-06
epoch 1586: mean loss = 5.4131788e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1587
step 0: mean loss = 4.850364e-06
step 100: mean loss = 5.8563055e-06
epoch 1587: mean loss = 5.5584283e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1588
step 0: mean loss = 4.5546753e-06
step 100: mean loss = 4.9625464e-06
epoch 1588: mean loss = 5.3892736e-06  learning rate = 1.7384587e-05
============================
Start of epoch 1589
step 0: mean loss = 4.2509237e-06
step 100: mean loss = 5.854621e-06
epoch 1589: mean loss = 5.3957956e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1590
step 0: mean loss = 4.3062673e-06
step 100: mean loss = 5.561548e-06
epoch 1590: mean loss = 5.4453526e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1591
step 0: mean loss = 3.6633878e-06
step 100: mean loss = 4.400512e-06
epoch 1591: mean loss = 5.3334406e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1592
step 0: mean loss = 4.74759e-06
step 100: mean loss = 5.6444737e-06
epoch 1592: mean loss = 5.3912036e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1593
step 0: mean loss = 4.254266e-06
step 100: mean loss = 5.65759e-06
epoch 1593: mean loss = 5.325548e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1594
step 0: mean loss = 4.481751e-06
step 100: mean loss = 5.3602635e-06
epoch 1594: mean loss = 5.445434e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1595
step 0: mean loss = 4.6811965e-06
step 100: mean loss = 4.920221e-06
epoch 1595: mean loss = 5.479224e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1596
step 0: mean loss = 4.3493906e-06
step 100: mean loss = 5.525718e-06
epoch 1596: mean loss = 5.504513e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1597
step 0: mean loss = 5.2497826e-06
step 100: mean loss = 5.9099934e-06
epoch 1597: mean loss = 5.4291186e-06  learning rate = 1.6515358e-05
============================
Start of epoch 1598
step 0: mean loss = 4.684478e-06
step 100: mean loss = 5.527458e-06
epoch 1598: mean loss = 5.318921e-06  learning rate = 1.6515358e-05
============================
WARNING:tensorflow:7 out of the last 8 calls to <function genDistInvPer at 0x7f4ef0a2e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function pyramidLayer.call at 0x7f4ed00a5cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function pyramidLayer.call at 0x7f4eec059950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 6 calls to <function gaussianPer at 0x7f4ef09d5b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function NUFFTLayerMultiChannelInit.call at 0x7f4eec059f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function pyramidLayer.call at 0x7f4eec059200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function pyramidLayer.call at 0x7f4e5a3135f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function MyDenseLayer.call at 0x7f4e5a313710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function DeepMDsimpleForces.call at 0x7f4f538dc440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Start of epoch 1599
step 0: mean loss = 3.7976008e-06
step 100: mean loss = 5.801171e-06
epoch 1599: mean loss = 5.327864e-06  learning rate = 1.6515358e-05
saving the weights
computing the FFT
applying the multipliers
(1000, 1, 1001)
inverse fft
Relative Error in the forces is 0.002177733
