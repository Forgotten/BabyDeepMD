=================================================
Executing 2BodyForcesDist.py following Np20_Per_mu_10.json
2020-04-23 15:25:43.964241: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-04-23 15:25:43.999242: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:03:00.0
2020-04-23 15:25:44.006846: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-23 15:25:44.283594: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-23 15:25:44.342943: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-23 15:25:44.353350: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-23 15:25:45.865056: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-23 15:25:45.941779: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-23 15:25:47.119606: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-23 15:25:47.125044: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-04-23 15:25:47.132157: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-04-23 15:25:47.178624: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2299765000 Hz
2020-04-23 15:25:47.180655: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c2c1708550 executing computations on platform Host. Devices:
2020-04-23 15:25:47.181173: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): Host, Default Version
2020-04-23 15:25:47.185231: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: 
name: GeForce GTX 1080 major: 6 minor: 1 memoryClockRate(GHz): 1.8475
pciBusID: 0000:03:00.0
2020-04-23 15:25:47.185647: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-23 15:25:47.186081: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
2020-04-23 15:25:47.186571: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10.0
2020-04-23 15:25:47.187012: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10.0
2020-04-23 15:25:47.187470: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10.0
2020-04-23 15:25:47.187969: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10.0
2020-04-23 15:25:47.188484: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-04-23 15:25:47.204685: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0
2020-04-23 15:25:47.205509: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.0
2020-04-23 15:25:47.330095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-04-23 15:25:47.330608: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 
2020-04-23 15:25:47.331418: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N 
2020-04-23 15:25:47.337822: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7603 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1080, pci bus id: 0000:03:00.0, compute capability: 6.1)
2020-04-23 15:25:47.344533: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55c2c272d800 executing computations on platform CUDA. Devices:
2020-04-23 15:25:47.345080: I tensorflow/compiler/xla/service/service.cc:175]   StreamExecutor device (0): GeForce GTX 1080, Compute Capability 6.1
2020-04-23 15:26:51.783540: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10.0
=================================================
We are using the random seed 1234567891011121314
Using data in ../../data/data_Periodic_Ncells_10_Np_2_mu_10_minDelta_0.1000_Nsamples_10000.h5
mean of the forces is 0.00000000
std of the forces is 0.81754078
mean of the inputs are 1.79056835 and 0.84226984
std of the inputs are 1.62000453 and 0.39748374
Model: "deepMDsimpleEnergy"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
pyramid_layer (pyramidLayer) multiple                  744       
_________________________________________________________________
pyramid_layer_1 (pyramidLaye multiple                  744       
_________________________________________________________________
pyramid_layer_2 (pyramidLaye multiple                  7360      
_________________________________________________________________
my_dense_layer (MyDenseLayer multiple                  33        
=================================================================
Total params: 8,881
Trainable params: 8,881
Non-trainable params: 0
_________________________________________________________________
Directory  checkpoints/  already exists :)
Training cycles in number of epochs
[200, 400, 800, 1600]
Training batch sizes for each cycle
[8, 16, 32, 64]
++++++++++++++++++++++++++++++
Start of cycle 0
Total number of epochs in this cycle: 200
Batch size in this cycle: 8
============================
WARNING:tensorflow:Layer deepMDsimpleEnergy is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

Start of epoch 0
step 0: mean loss = 3.6583855
step 100: mean loss = 0.42936042
step 200: mean loss = 0.24034834
step 300: mean loss = 0.1685916
step 400: mean loss = 0.130476
step 500: mean loss = 0.10666955
step 600: mean loss = 0.09035925
step 700: mean loss = 0.07847889
step 800: mean loss = 0.069409996
step 900: mean loss = 0.0622499
step 1000: mean loss = 0.056444287
step 1100: mean loss = 0.05166378
step 1200: mean loss = 0.04763773
epoch 0: mean loss = 0.045916375  learning rate = 1e-04
============================
Start of epoch 1
step 0: mean loss = 0.0025654458
step 100: mean loss = 0.002850877
step 200: mean loss = 0.0026935928
step 300: mean loss = 0.0025649893
step 400: mean loss = 0.0024697676
step 500: mean loss = 0.0023481187
step 600: mean loss = 0.0022555008
step 700: mean loss = 0.0021836094
step 800: mean loss = 0.0020956453
step 900: mean loss = 0.0020269603
step 1000: mean loss = 0.0019570333
step 1100: mean loss = 0.0018884924
step 1200: mean loss = 0.0018322234
epoch 1: mean loss = 0.0018037441  learning rate = 1e-04
============================
Start of epoch 2
step 0: mean loss = 0.0013605275
step 100: mean loss = 0.0011114213
step 200: mean loss = 0.001096316
step 300: mean loss = 0.0010816685
step 400: mean loss = 0.0010296803
step 500: mean loss = 0.0009969206
step 600: mean loss = 0.0009633493
step 700: mean loss = 0.00094103476
step 800: mean loss = 0.00091813854
step 900: mean loss = 0.0008859395
step 1000: mean loss = 0.000862133
step 1100: mean loss = 0.00084119145
step 1200: mean loss = 0.0008171437
epoch 2: mean loss = 0.0008070003  learning rate = 1e-04
============================
Start of epoch 3
step 0: mean loss = 0.000562917
step 100: mean loss = 0.0005841548
step 200: mean loss = 0.0005637509
step 300: mean loss = 0.0005363838
step 400: mean loss = 0.0005246101
step 500: mean loss = 0.00052068674
step 600: mean loss = 0.0005113367
step 700: mean loss = 0.0005002677
step 800: mean loss = 0.0004950979
step 900: mean loss = 0.00048143856
step 1000: mean loss = 0.00047212825
step 1100: mean loss = 0.00045934416
step 1200: mean loss = 0.00044943977
epoch 3: mean loss = 0.00044647645  learning rate = 1e-04
============================
Start of epoch 4
step 0: mean loss = 0.00039169434
step 100: mean loss = 0.00038163553
step 200: mean loss = 0.00032873524
step 300: mean loss = 0.00032615653
step 400: mean loss = 0.00030786043
step 500: mean loss = 0.00030041044
step 600: mean loss = 0.00030170547
step 700: mean loss = 0.00028928526
step 800: mean loss = 0.00028278353
step 900: mean loss = 0.00027587923
step 1000: mean loss = 0.0002728395
step 1100: mean loss = 0.00026905473
step 1200: mean loss = 0.00026436537
epoch 4: mean loss = 0.00026105242  learning rate = 1e-04
============================
Start of epoch 5
step 0: mean loss = 0.00014248237
step 100: mean loss = 0.00022174254
step 200: mean loss = 0.00020768467
step 300: mean loss = 0.00019714629
step 400: mean loss = 0.00018733279
step 500: mean loss = 0.00017945259
step 600: mean loss = 0.00018071
step 700: mean loss = 0.00017650795
step 800: mean loss = 0.00017270689
step 900: mean loss = 0.000168962
step 1000: mean loss = 0.00016438366
step 1100: mean loss = 0.00016051187
step 1200: mean loss = 0.00015620732
epoch 5: mean loss = 0.00015488955  learning rate = 1e-04
============================
Start of epoch 6
step 0: mean loss = 4.9877483e-05
step 100: mean loss = 0.00011407914
step 200: mean loss = 0.00013530656
step 300: mean loss = 0.00015074897
step 400: mean loss = 0.00014729885
step 500: mean loss = 0.00018209558
step 600: mean loss = 0.00017078605
step 700: mean loss = 0.00015908424
step 800: mean loss = 0.00014902446
step 900: mean loss = 0.00014229158
step 1000: mean loss = 0.00013596282
step 1100: mean loss = 0.00013030804
step 1200: mean loss = 0.00013055936
epoch 6: mean loss = 0.00013043365  learning rate = 1e-04
============================
Start of epoch 7
step 0: mean loss = 0.00012616921
step 100: mean loss = 0.00013190991
step 200: mean loss = 0.00012392721
step 300: mean loss = 0.000111667745
step 400: mean loss = 0.000110200555
step 500: mean loss = 0.000114791794
step 600: mean loss = 0.00013657109
step 700: mean loss = 0.0001257177
step 800: mean loss = 0.00011759463
step 900: mean loss = 0.00011084185
step 1000: mean loss = 0.000104781844
step 1100: mean loss = 0.00010471694
step 1200: mean loss = 0.00010200508
epoch 7: mean loss = 0.00010022993  learning rate = 1e-04
============================
Start of epoch 8
step 0: mean loss = 3.8341863e-05
step 100: mean loss = 8.603535e-05
step 200: mean loss = 8.03681e-05
step 300: mean loss = 0.00011461676
step 400: mean loss = 9.8374905e-05
step 500: mean loss = 0.00010401375
step 600: mean loss = 9.559635e-05
step 700: mean loss = 8.9731235e-05
step 800: mean loss = 8.505809e-05
step 900: mean loss = 8.139025e-05
step 1000: mean loss = 8.2003215e-05
step 1100: mean loss = 8.146234e-05
step 1200: mean loss = 7.909803e-05
epoch 8: mean loss = 7.907428e-05  learning rate = 1e-04
============================
Start of epoch 9
step 0: mean loss = 0.0011725582
step 100: mean loss = 0.000112865164
step 200: mean loss = 8.0449936e-05
step 300: mean loss = 7.148509e-05
step 400: mean loss = 6.8379435e-05
step 500: mean loss = 6.224613e-05
step 600: mean loss = 5.7274905e-05
step 700: mean loss = 5.5301785e-05
step 800: mean loss = 5.3369742e-05
step 900: mean loss = 5.291387e-05
step 1000: mean loss = 5.943036e-05
step 1100: mean loss = 8.109409e-05
step 1200: mean loss = 7.7493685e-05
epoch 9: mean loss = 7.56371e-05  learning rate = 9.499999e-05
============================
Start of epoch 10
step 0: mean loss = 1.910747e-05
step 100: mean loss = 4.1347503e-05
step 200: mean loss = 4.327057e-05
step 300: mean loss = 4.0768784e-05
step 400: mean loss = 4.1259405e-05
step 500: mean loss = 4.475139e-05
step 600: mean loss = 4.552986e-05
step 700: mean loss = 4.296161e-05
step 800: mean loss = 4.275458e-05
step 900: mean loss = 4.179034e-05
step 1000: mean loss = 4.1114094e-05
step 1100: mean loss = 5.53898e-05
step 1200: mean loss = 5.2904197e-05
epoch 10: mean loss = 5.196715e-05  learning rate = 9.499999e-05
============================
Start of epoch 11
step 0: mean loss = 5.7781675e-05
step 100: mean loss = 2.421556e-05
step 200: mean loss = 2.2824923e-05
step 300: mean loss = 2.488612e-05
step 400: mean loss = 2.6658243e-05
step 500: mean loss = 2.6479796e-05
step 600: mean loss = 2.7682667e-05
step 700: mean loss = 2.6450258e-05
step 800: mean loss = 3.1303516e-05
step 900: mean loss = 3.1712018e-05
step 1000: mean loss = 3.285382e-05
step 1100: mean loss = 3.215229e-05
step 1200: mean loss = 3.270294e-05
epoch 11: mean loss = 3.237838e-05  learning rate = 9.499999e-05
============================
Start of epoch 12
step 0: mean loss = 3.582873e-05
step 100: mean loss = 5.3325293e-05
step 200: mean loss = 3.751249e-05
step 300: mean loss = 3.204214e-05
step 400: mean loss = 3.1683023e-05
step 500: mean loss = 5.436629e-05
step 600: mean loss = 7.1824245e-05
step 700: mean loss = 6.509403e-05
step 800: mean loss = 6.1197126e-05
step 900: mean loss = 5.790628e-05
step 1000: mean loss = 5.3727137e-05
step 1100: mean loss = 5.0661718e-05
step 1200: mean loss = 4.9050694e-05
epoch 12: mean loss = 4.914455e-05  learning rate = 9.499999e-05
============================
Start of epoch 13
step 0: mean loss = 3.4087407e-05
step 100: mean loss = 1.7967832e-05
step 200: mean loss = 1.7414943e-05
step 300: mean loss = 2.6109106e-05
step 400: mean loss = 2.4902458e-05
step 500: mean loss = 2.5238827e-05
step 600: mean loss = 3.1771124e-05
step 700: mean loss = 3.5076086e-05
step 800: mean loss = 3.32948e-05
step 900: mean loss = 3.1522064e-05
step 1000: mean loss = 3.0861644e-05
step 1100: mean loss = 3.27705e-05
step 1200: mean loss = 3.1789237e-05
epoch 13: mean loss = 3.248423e-05  learning rate = 9.499999e-05
============================
Start of epoch 14
step 0: mean loss = 6.5765686e-05
step 100: mean loss = 2.6112162e-05
step 200: mean loss = 2.7279217e-05
step 300: mean loss = 3.1596497e-05
step 400: mean loss = 2.9232353e-05
step 500: mean loss = 2.7879938e-05
step 600: mean loss = 2.8407887e-05
step 700: mean loss = 2.7075364e-05
step 800: mean loss = 2.8175451e-05
step 900: mean loss = 2.683863e-05
step 1000: mean loss = 2.7382725e-05
step 1100: mean loss = 2.6360178e-05
step 1200: mean loss = 2.6662294e-05
epoch 14: mean loss = 2.6244754e-05  learning rate = 9.499999e-05
============================
Start of epoch 15
step 0: mean loss = 1.1203668e-05
step 100: mean loss = 2.0514108e-05
step 200: mean loss = 3.5322806e-05
step 300: mean loss = 5.835664e-05
step 400: mean loss = 4.8508562e-05
step 500: mean loss = 4.129324e-05
step 600: mean loss = 3.7298472e-05
step 700: mean loss = 3.4012934e-05
step 800: mean loss = 3.2284774e-05
step 900: mean loss = 3.2260556e-05
step 1000: mean loss = 3.100199e-05
step 1100: mean loss = 2.9470968e-05
step 1200: mean loss = 2.8204033e-05
epoch 15: mean loss = 2.7730612e-05  learning rate = 9.499999e-05
============================
Start of epoch 16
step 0: mean loss = 6.0858356e-06
step 100: mean loss = 9.825262e-06
step 200: mean loss = 1.6641961e-05
step 300: mean loss = 1.7814582e-05
step 400: mean loss = 1.9768833e-05
step 500: mean loss = 1.9360426e-05
step 600: mean loss = 4.439026e-05
step 700: mean loss = 4.2706743e-05
step 800: mean loss = 3.8910388e-05
step 900: mean loss = 3.6007114e-05
step 1000: mean loss = 3.3983957e-05
step 1100: mean loss = 3.3495995e-05
step 1200: mean loss = 3.161498e-05
epoch 16: mean loss = 3.086542e-05  learning rate = 9.499999e-05
============================
Start of epoch 17
step 0: mean loss = 1.705972e-05
step 100: mean loss = 5.1248997e-05
step 200: mean loss = 3.6540478e-05
step 300: mean loss = 2.863833e-05
step 400: mean loss = 2.4650257e-05
step 500: mean loss = 2.2850827e-05
step 600: mean loss = 2.1747228e-05
step 700: mean loss = 2.0978596e-05
step 800: mean loss = 2.000978e-05
step 900: mean loss = 2.8297649e-05
step 1000: mean loss = 2.8770819e-05
step 1100: mean loss = 2.7546204e-05
step 1200: mean loss = 2.5939024e-05
epoch 17: mean loss = 2.5352336e-05  learning rate = 9.499999e-05
============================
Start of epoch 18
step 0: mean loss = 5.512507e-06
step 100: mean loss = 5.0253282e-05
step 200: mean loss = 2.9992218e-05
step 300: mean loss = 2.4533027e-05
step 400: mean loss = 2.1270267e-05
step 500: mean loss = 1.8758983e-05
step 600: mean loss = 1.8343426e-05
step 700: mean loss = 1.946864e-05
step 800: mean loss = 1.8701878e-05
step 900: mean loss = 1.8315046e-05
step 1000: mean loss = 1.8658844e-05
step 1100: mean loss = 1.8306815e-05
step 1200: mean loss = 1.8422072e-05
epoch 18: mean loss = 1.8468647e-05  learning rate = 9.499999e-05
============================
Start of epoch 19
step 0: mean loss = 6.1083565e-06
step 100: mean loss = 8.102784e-06
step 200: mean loss = 1.0555238e-05
step 300: mean loss = 1.4154714e-05
step 400: mean loss = 1.7178982e-05
step 500: mean loss = 2.085932e-05
step 600: mean loss = 2.0662228e-05
step 700: mean loss = 1.9619842e-05
step 800: mean loss = 1.8805125e-05
step 900: mean loss = 2.1179156e-05
step 1000: mean loss = 2.001002e-05
step 1100: mean loss = 1.9099893e-05
step 1200: mean loss = 1.8159353e-05
epoch 19: mean loss = 1.7838765e-05  learning rate = 9.024999e-05
============================
Start of epoch 20
step 0: mean loss = 1.0216181e-05
step 100: mean loss = 1.4344286e-05
step 200: mean loss = 1.4756263e-05
step 300: mean loss = 1.2375741e-05
step 400: mean loss = 1.2256355e-05
step 500: mean loss = 1.1508645e-05
step 600: mean loss = 1.4215125e-05
step 700: mean loss = 1.534255e-05
step 800: mean loss = 1.4799841e-05
step 900: mean loss = 1.4821968e-05
step 1000: mean loss = 1.9301198e-05
step 1100: mean loss = 1.8683808e-05
step 1200: mean loss = 1.7773396e-05
epoch 20: mean loss = 1.731775e-05  learning rate = 9.024999e-05
============================
Start of epoch 21
step 0: mean loss = 1.3376679e-05
step 100: mean loss = 5.722054e-06
step 200: mean loss = 9.774552e-06
step 300: mean loss = 1.2674498e-05
step 400: mean loss = 1.103515e-05
step 500: mean loss = 1.1787905e-05
step 600: mean loss = 1.3397194e-05
step 700: mean loss = 1.221427e-05
step 800: mean loss = 1.1561677e-05
step 900: mean loss = 1.211714e-05
step 1000: mean loss = 1.1758022e-05
step 1100: mean loss = 1.1526138e-05
step 1200: mean loss = 1.2180365e-05
epoch 21: mean loss = 1.2590968e-05  learning rate = 9.024999e-05
============================
Start of epoch 22
step 0: mean loss = 1.5901209e-05
step 100: mean loss = 1.3645159e-05
step 200: mean loss = 1.27428875e-05
step 300: mean loss = 1.8503975e-05
step 400: mean loss = 1.8800363e-05
step 500: mean loss = 1.650043e-05
step 600: mean loss = 1.6398579e-05
step 700: mean loss = 1.5130036e-05
step 800: mean loss = 1.828339e-05
step 900: mean loss = 1.7610968e-05
step 1000: mean loss = 1.63235e-05
step 1100: mean loss = 1.5281968e-05
step 1200: mean loss = 1.47647e-05
epoch 22: mean loss = 1.4744029e-05  learning rate = 9.024999e-05
============================
Start of epoch 23
step 0: mean loss = 7.33786e-06
step 100: mean loss = 5.0351982e-06
step 200: mean loss = 6.42236e-06
step 300: mean loss = 7.947559e-06
step 400: mean loss = 8.374031e-06
step 500: mean loss = 1.0515283e-05
step 600: mean loss = 1.0733024e-05
step 700: mean loss = 1.2328823e-05
step 800: mean loss = 1.290274e-05
step 900: mean loss = 1.2196212e-05
step 1000: mean loss = 1.15369585e-05
step 1100: mean loss = 1.1052055e-05
step 1200: mean loss = 1.0563742e-05
epoch 23: mean loss = 1.0543555e-05  learning rate = 9.024999e-05
============================
Start of epoch 24
step 0: mean loss = 1.44593605e-05
step 100: mean loss = 2.2071861e-05
step 200: mean loss = 1.3838714e-05
step 300: mean loss = 1.1649883e-05
step 400: mean loss = 1.3924044e-05
step 500: mean loss = 1.4909932e-05
step 600: mean loss = 1.3330949e-05
step 700: mean loss = 1.2885839e-05
step 800: mean loss = 1.2835445e-05
step 900: mean loss = 1.2388459e-05
step 1000: mean loss = 1.1829122e-05
step 1100: mean loss = 1.2434688e-05
step 1200: mean loss = 1.4377417e-05
epoch 24: mean loss = 1.4079077e-05  learning rate = 9.024999e-05
============================
Start of epoch 25
step 0: mean loss = 8.152949e-06
step 100: mean loss = 1.1280827e-05
step 200: mean loss = 1.2812781e-05
step 300: mean loss = 1.0203165e-05
step 400: mean loss = 9.27912e-06
step 500: mean loss = 8.251432e-06
step 600: mean loss = 7.818974e-06
step 700: mean loss = 9.573094e-06
step 800: mean loss = 9.246414e-06
step 900: mean loss = 9.216869e-06
step 1000: mean loss = 9.419396e-06
step 1100: mean loss = 9.29728e-06
step 1200: mean loss = 1.0069409e-05
epoch 25: mean loss = 1.0652626e-05  learning rate = 9.024999e-05
============================
Start of epoch 26
step 0: mean loss = 8.435769e-06
step 100: mean loss = 5.974408e-06
step 200: mean loss = 4.9095447e-06
step 300: mean loss = 4.630401e-06
step 400: mean loss = 5.14623e-06
step 500: mean loss = 5.2006885e-06
step 600: mean loss = 1.0424688e-05
step 700: mean loss = 1.2854013e-05
step 800: mean loss = 1.1860265e-05
step 900: mean loss = 1.1157885e-05
step 1000: mean loss = 1.05540585e-05
step 1100: mean loss = 9.961794e-06
step 1200: mean loss = 9.63861e-06
epoch 26: mean loss = 9.461674e-06  learning rate = 9.024999e-05
============================
Start of epoch 27
step 0: mean loss = 4.9864952e-06
step 100: mean loss = 3.8044493e-06
step 200: mean loss = 6.1501414e-06
step 300: mean loss = 5.573238e-06
step 400: mean loss = 1.0346122e-05
step 500: mean loss = 1.0109904e-05
step 600: mean loss = 1.2760666e-05
step 700: mean loss = 1.2637575e-05
step 800: mean loss = 1.1576752e-05
step 900: mean loss = 1.1356269e-05
step 1000: mean loss = 1.0729961e-05
step 1100: mean loss = 1.0266727e-05
step 1200: mean loss = 9.732101e-06
epoch 27: mean loss = 9.599661e-06  learning rate = 9.024999e-05
============================
Start of epoch 28
step 0: mean loss = 3.4764914e-06
step 100: mean loss = 8.259529e-06
step 200: mean loss = 7.123377e-06
step 300: mean loss = 6.592708e-06
step 400: mean loss = 6.1951805e-06
step 500: mean loss = 8.93935e-06
step 600: mean loss = 8.884588e-06
step 700: mean loss = 8.480536e-06
step 800: mean loss = 8.936223e-06
step 900: mean loss = 8.346699e-06
step 1000: mean loss = 7.961921e-06
step 1100: mean loss = 7.595144e-06
step 1200: mean loss = 7.2862927e-06
epoch 28: mean loss = 8.683834e-06  learning rate = 9.024999e-05
============================
Start of epoch 29
step 0: mean loss = 2.3282368e-05
step 100: mean loss = 1.9369529e-05
step 200: mean loss = 1.3408408e-05
step 300: mean loss = 1.0574676e-05
step 400: mean loss = 9.902359e-06
step 500: mean loss = 8.9650875e-06
step 600: mean loss = 7.948083e-06
step 700: mean loss = 9.953947e-06
step 800: mean loss = 1.0880304e-05
step 900: mean loss = 1.0023893e-05
step 1000: mean loss = 9.290629e-06
step 1100: mean loss = 9.143874e-06
step 1200: mean loss = 8.929821e-06
epoch 29: mean loss = 8.930263e-06  learning rate = 8.573749e-05
============================
Start of epoch 30
step 0: mean loss = 1.4428898e-05
step 100: mean loss = 2.0833817e-05
step 200: mean loss = 1.2565198e-05
step 300: mean loss = 1.0798818e-05
step 400: mean loss = 9.0197145e-06
step 500: mean loss = 8.485978e-06
step 600: mean loss = 7.560538e-06
step 700: mean loss = 7.2090234e-06
step 800: mean loss = 7.5447388e-06
step 900: mean loss = 8.24382e-06
step 1000: mean loss = 7.756013e-06
step 1100: mean loss = 7.2629696e-06
step 1200: mean loss = 6.951093e-06
epoch 30: mean loss = 7.1114882e-06  learning rate = 8.573749e-05
============================
Start of epoch 31
step 0: mean loss = 4.395468e-06
step 100: mean loss = 8.359699e-06
step 200: mean loss = 6.9485172e-06
step 300: mean loss = 7.18148e-06
step 400: mean loss = 6.5297686e-06
step 500: mean loss = 6.0592583e-06
step 600: mean loss = 6.760943e-06
step 700: mean loss = 6.4635183e-06
step 800: mean loss = 6.111514e-06
step 900: mean loss = 5.709699e-06
step 1000: mean loss = 6.1549977e-06
step 1100: mean loss = 6.818784e-06
step 1200: mean loss = 6.494349e-06
epoch 31: mean loss = 6.4643873e-06  learning rate = 8.573749e-05
============================
Start of epoch 32
step 0: mean loss = 1.6386952e-05
step 100: mean loss = 4.189307e-06
step 200: mean loss = 3.652639e-06
step 300: mean loss = 3.6669837e-06
step 400: mean loss = 4.833065e-06
step 500: mean loss = 5.112817e-06
step 600: mean loss = 5.037482e-06
step 700: mean loss = 6.084101e-06
step 800: mean loss = 6.5167956e-06
step 900: mean loss = 6.2454856e-06
step 1000: mean loss = 5.9360586e-06
step 1100: mean loss = 5.58273e-06
step 1200: mean loss = 6.8035224e-06
epoch 32: mean loss = 6.925178e-06  learning rate = 8.573749e-05
============================
Start of epoch 33
step 0: mean loss = 2.3968412e-05
step 100: mean loss = 6.6935427e-06
step 200: mean loss = 4.717879e-06
step 300: mean loss = 4.9491123e-06
step 400: mean loss = 4.3831424e-06
step 500: mean loss = 3.895902e-06
step 600: mean loss = 3.5931514e-06
step 700: mean loss = 5.3584736e-06
step 800: mean loss = 5.430428e-06
step 900: mean loss = 5.0797244e-06
step 1000: mean loss = 4.7961207e-06
step 1100: mean loss = 4.549979e-06
step 1200: mean loss = 4.4049625e-06
epoch 33: mean loss = 4.346934e-06  learning rate = 8.573749e-05
============================
Start of epoch 34
step 0: mean loss = 1.1893846e-06
step 100: mean loss = 2.7999629e-06
step 200: mean loss = 2.838677e-06
step 300: mean loss = 2.7249055e-06
step 400: mean loss = 6.4965325e-06
step 500: mean loss = 6.6898924e-06
step 600: mean loss = 6.1118194e-06
step 700: mean loss = 5.5852715e-06
step 800: mean loss = 5.6225444e-06
step 900: mean loss = 5.622765e-06
step 1000: mean loss = 5.996379e-06
step 1100: mean loss = 7.1059126e-06
step 1200: mean loss = 6.7121023e-06
epoch 34: mean loss = 6.536372e-06  learning rate = 8.573749e-05
============================
Start of epoch 35
step 0: mean loss = 1.0187748e-06
step 100: mean loss = 2.0827604e-06
step 200: mean loss = 1.973468e-06
step 300: mean loss = 2.0605848e-06
step 400: mean loss = 2.1658204e-06
step 500: mean loss = 2.2591264e-06
step 600: mean loss = 2.513043e-06
step 700: mean loss = 4.6379837e-06
step 800: mean loss = 5.082247e-06
step 900: mean loss = 4.7733347e-06
step 1000: mean loss = 4.434146e-06
step 1100: mean loss = 4.6268115e-06
step 1200: mean loss = 4.976669e-06
epoch 35: mean loss = 4.889295e-06  learning rate = 8.573749e-05
============================
Start of epoch 36
step 0: mean loss = 1.2221345e-06
step 100: mean loss = 2.066375e-06
step 200: mean loss = 2.1010012e-06
step 300: mean loss = 1.9781562e-06
step 400: mean loss = 2.3628443e-06
step 500: mean loss = 2.3798016e-06
step 600: mean loss = 2.3948116e-06
step 700: mean loss = 3.4748386e-06
step 800: mean loss = 3.7059067e-06
step 900: mean loss = 3.5370765e-06
step 1000: mean loss = 3.352206e-06
step 1100: mean loss = 3.3838696e-06
step 1200: mean loss = 3.3370668e-06
epoch 36: mean loss = 4.439331e-06  learning rate = 8.573749e-05
============================
Start of epoch 37
step 0: mean loss = 8.984689e-06
step 100: mean loss = 6.852327e-06
step 200: mean loss = 4.589774e-06
step 300: mean loss = 3.5708579e-06
step 400: mean loss = 3.1828129e-06
step 500: mean loss = 3.0427698e-06
step 600: mean loss = 3.1731242e-06
step 700: mean loss = 3.5074115e-06
step 800: mean loss = 3.549621e-06
step 900: mean loss = 3.5627904e-06
step 1000: mean loss = 3.8514427e-06
step 1100: mean loss = 4.0069726e-06
step 1200: mean loss = 4.5648976e-06
epoch 37: mean loss = 4.431534e-06  learning rate = 8.573749e-05
============================
Start of epoch 38
step 0: mean loss = 8.972227e-07
step 100: mean loss = 3.2783134e-06
step 200: mean loss = 2.171746e-06
step 300: mean loss = 1.9050998e-06
step 400: mean loss = 1.8865885e-06
step 500: mean loss = 2.041651e-06
step 600: mean loss = 2.1344615e-06
step 700: mean loss = 2.4294125e-06
step 800: mean loss = 2.7631038e-06
step 900: mean loss = 2.7094584e-06
step 1000: mean loss = 2.744683e-06
step 1100: mean loss = 2.6182652e-06
step 1200: mean loss = 2.5332668e-06
epoch 38: mean loss = 2.499214e-06  learning rate = 8.573749e-05
============================
Start of epoch 39
step 0: mean loss = 1.3818333e-06
step 100: mean loss = 4.6405694e-06
step 200: mean loss = 6.350067e-06
step 300: mean loss = 8.4349485e-06
step 400: mean loss = 6.6112916e-06
step 500: mean loss = 6.4595847e-06
step 600: mean loss = 5.7498037e-06
step 700: mean loss = 5.3363665e-06
step 800: mean loss = 5.148082e-06
step 900: mean loss = 5.09865e-06
step 1000: mean loss = 4.813297e-06
step 1100: mean loss = 4.6803902e-06
step 1200: mean loss = 4.698553e-06
epoch 39: mean loss = 4.623638e-06  learning rate = 8.145061e-05
============================
Start of epoch 40
step 0: mean loss = 1.5774691e-06
step 100: mean loss = 1.1989351e-06
step 200: mean loss = 1.1542021e-06
step 300: mean loss = 1.7043316e-06
step 400: mean loss = 1.5291901e-06
step 500: mean loss = 2.8697273e-06
step 600: mean loss = 2.6697558e-06
step 700: mean loss = 2.448499e-06
step 800: mean loss = 3.304628e-06
step 900: mean loss = 3.1359775e-06
step 1000: mean loss = 3.0273168e-06
step 1100: mean loss = 3.2430669e-06
step 1200: mean loss = 3.141342e-06
epoch 40: mean loss = 3.0741428e-06  learning rate = 8.145061e-05
============================
Start of epoch 41
step 0: mean loss = 9.1849796e-07
step 100: mean loss = 1.6058651e-06
step 200: mean loss = 2.5221823e-06
step 300: mean loss = 2.2372594e-06
step 400: mean loss = 2.3194966e-06
step 500: mean loss = 2.6310483e-06
step 600: mean loss = 2.7637554e-06
step 700: mean loss = 2.9990654e-06
step 800: mean loss = 3.244392e-06
step 900: mean loss = 3.1292172e-06
step 1000: mean loss = 3.051891e-06
step 1100: mean loss = 3.252054e-06
step 1200: mean loss = 3.2768974e-06
epoch 41: mean loss = 3.6949973e-06  learning rate = 8.145061e-05
============================
Start of epoch 42
step 0: mean loss = 1.3746187e-06
step 100: mean loss = 1.2832493e-06
step 200: mean loss = 1.524096e-06
step 300: mean loss = 1.9195622e-06
step 400: mean loss = 2.0148543e-06
step 500: mean loss = 1.9183062e-06
step 600: mean loss = 2.5941238e-06
step 700: mean loss = 2.47728e-06
step 800: mean loss = 2.3162725e-06
step 900: mean loss = 2.4342576e-06
step 1000: mean loss = 2.6218454e-06
step 1100: mean loss = 2.9434404e-06
step 1200: mean loss = 3.123072e-06
epoch 42: mean loss = 3.1117224e-06  learning rate = 8.145061e-05
============================
Start of epoch 43
step 0: mean loss = 2.6152543e-06
step 100: mean loss = 6.64744e-06
step 200: mean loss = 3.7733782e-06
step 300: mean loss = 2.8505717e-06
step 400: mean loss = 3.7802338e-06
step 500: mean loss = 3.2267437e-06
step 600: mean loss = 2.860148e-06
step 700: mean loss = 2.5796232e-06
step 800: mean loss = 2.440918e-06
step 900: mean loss = 2.4817512e-06
step 1000: mean loss = 2.6249406e-06
step 1100: mean loss = 2.4873677e-06
step 1200: mean loss = 2.429693e-06
epoch 43: mean loss = 2.474943e-06  learning rate = 8.145061e-05
============================
Start of epoch 44
step 0: mean loss = 1.5439767e-06
step 100: mean loss = 3.090778e-06
step 200: mean loss = 2.582537e-06
step 300: mean loss = 4.5063375e-06
step 400: mean loss = 3.7637599e-06
step 500: mean loss = 3.531748e-06
step 600: mean loss = 3.2503433e-06
step 700: mean loss = 2.9562998e-06
step 800: mean loss = 2.7844428e-06
step 900: mean loss = 3.2512037e-06
step 1000: mean loss = 3.0946371e-06
step 1100: mean loss = 2.909043e-06
step 1200: mean loss = 2.752864e-06
epoch 44: mean loss = 2.6822313e-06  learning rate = 8.145061e-05
============================
Start of epoch 45
step 0: mean loss = 1.7351773e-06
step 100: mean loss = 1.345713e-06
step 200: mean loss = 3.007451e-06
step 300: mean loss = 2.2240304e-06
step 400: mean loss = 2.2093695e-06
step 500: mean loss = 3.878522e-06
step 600: mean loss = 4.0704986e-06
step 700: mean loss = 4.4973463e-06
step 800: mean loss = 4.056866e-06
step 900: mean loss = 3.6828958e-06
step 1000: mean loss = 3.4633022e-06
step 1100: mean loss = 3.2819853e-06
step 1200: mean loss = 3.1224706e-06
epoch 45: mean loss = 3.3344722e-06  learning rate = 8.145061e-05
============================
Start of epoch 46
step 0: mean loss = 6.531051e-06
step 100: mean loss = 2.0753419e-06
step 200: mean loss = 3.0722836e-06
step 300: mean loss = 2.5063216e-06
step 400: mean loss = 2.26941e-06
step 500: mean loss = 2.1978785e-06
step 600: mean loss = 2.1244364e-06
step 700: mean loss = 1.9301183e-06
step 800: mean loss = 1.906255e-06
step 900: mean loss = 2.0044179e-06
step 1000: mean loss = 1.963763e-06
step 1100: mean loss = 1.9422903e-06
step 1200: mean loss = 2.0233585e-06
epoch 46: mean loss = 2.0022596e-06  learning rate = 8.145061e-05
============================
Start of epoch 47
step 0: mean loss = 6.514353e-07
step 100: mean loss = 2.1748524e-06
step 200: mean loss = 4.493396e-06
step 300: mean loss = 3.4048198e-06
step 400: mean loss = 2.9997764e-06
step 500: mean loss = 3.4620773e-06
step 600: mean loss = 3.1378854e-06
step 700: mean loss = 2.9310745e-06
step 800: mean loss = 2.6582163e-06
step 900: mean loss = 2.720094e-06
step 1000: mean loss = 3.2853884e-06
step 1100: mean loss = 3.0759572e-06
step 1200: mean loss = 2.926343e-06
epoch 47: mean loss = 2.845555e-06  learning rate = 8.145061e-05
============================
Start of epoch 48
step 0: mean loss = 7.288948e-07
step 100: mean loss = 8.935678e-07
step 200: mean loss = 1.8558104e-06
step 300: mean loss = 2.9729013e-06
step 400: mean loss = 2.6816392e-06
step 500: mean loss = 2.3741977e-06
step 600: mean loss = 3.0148076e-06
step 700: mean loss = 2.6731357e-06
step 800: mean loss = 2.6208265e-06
step 900: mean loss = 2.5776192e-06
step 1000: mean loss = 2.588646e-06
step 1100: mean loss = 2.5731683e-06
step 1200: mean loss = 2.4424342e-06
epoch 48: mean loss = 2.3728055e-06  learning rate = 8.145061e-05
============================
Start of epoch 49
step 0: mean loss = 5.106099e-07
step 100: mean loss = 1.0133995e-06
step 200: mean loss = 1.8464333e-06
step 300: mean loss = 2.148742e-06
step 400: mean loss = 2.4379435e-06
step 500: mean loss = 2.408125e-06
step 600: mean loss = 2.1331327e-06
step 700: mean loss = 1.950223e-06
step 800: mean loss = 1.9498505e-06
step 900: mean loss = 1.9062156e-06
step 1000: mean loss = 1.8934924e-06
step 1100: mean loss = 1.8200718e-06
step 1200: mean loss = 2.007626e-06
epoch 49: mean loss = 2.5085703e-06  learning rate = 7.737808e-05
============================
Start of epoch 50
step 0: mean loss = 3.847632e-05
step 100: mean loss = 1.837265e-05
step 200: mean loss = 9.748188e-06
step 300: mean loss = 6.864187e-06
step 400: mean loss = 5.298575e-06
step 500: mean loss = 4.341132e-06
step 600: mean loss = 3.7112e-06
step 700: mean loss = 3.2412493e-06
step 800: mean loss = 2.912775e-06
step 900: mean loss = 2.6750117e-06
step 1000: mean loss = 2.4671474e-06
step 1100: mean loss = 2.2982833e-06
step 1200: mean loss = 2.522217e-06
epoch 50: mean loss = 2.558565e-06  learning rate = 7.737808e-05
============================
Start of epoch 51
step 0: mean loss = 1.955314e-06
step 100: mean loss = 1.570456e-06
step 200: mean loss = 1.5350498e-06
step 300: mean loss = 1.2515158e-06
step 400: mean loss = 1.7189811e-06
step 500: mean loss = 1.6030233e-06
step 600: mean loss = 1.419562e-06
step 700: mean loss = 1.2978179e-06
step 800: mean loss = 1.912764e-06
step 900: mean loss = 2.1189453e-06
step 1000: mean loss = 1.9872386e-06
step 1100: mean loss = 1.8481519e-06
step 1200: mean loss = 1.738506e-06
epoch 51: mean loss = 1.7154398e-06  learning rate = 7.737808e-05
============================
Start of epoch 52
step 0: mean loss = 2.8715367e-06
step 100: mean loss = 3.92324e-06
step 200: mean loss = 2.4085075e-06
step 300: mean loss = 5.1486904e-06
step 400: mean loss = 5.472957e-06
step 500: mean loss = 4.4874787e-06
step 600: mean loss = 3.8587987e-06
step 700: mean loss = 3.492919e-06
step 800: mean loss = 3.124634e-06
step 900: mean loss = 2.9059368e-06
step 1000: mean loss = 2.7210044e-06
step 1100: mean loss = 2.6659436e-06
step 1200: mean loss = 2.6156845e-06
epoch 52: mean loss = 2.5362258e-06  learning rate = 7.737808e-05
============================
Start of epoch 53
step 0: mean loss = 3.7944955e-07
step 100: mean loss = 6.4726294e-07
step 200: mean loss = 6.4932226e-07
step 300: mean loss = 7.856942e-07
step 400: mean loss = 8.0227994e-07
step 500: mean loss = 1.8331611e-06
step 600: mean loss = 3.5086236e-06
step 700: mean loss = 3.1267452e-06
step 800: mean loss = 2.871684e-06
step 900: mean loss = 2.6588236e-06
step 1000: mean loss = 2.476443e-06
step 1100: mean loss = 2.302945e-06
step 1200: mean loss = 2.2474944e-06
epoch 53: mean loss = 2.1953279e-06  learning rate = 7.737808e-05
============================
Start of epoch 54
step 0: mean loss = 2.5909245e-07
step 100: mean loss = 1.9693036e-06
step 200: mean loss = 1.7656912e-06
step 300: mean loss = 1.4207482e-06
step 400: mean loss = 1.2209126e-06
step 500: mean loss = 1.2129242e-06
step 600: mean loss = 1.5152847e-06
step 700: mean loss = 1.3953043e-06
step 800: mean loss = 1.4205775e-06
step 900: mean loss = 1.5822567e-06
step 1000: mean loss = 2.9593796e-06
step 1100: mean loss = 2.750814e-06
step 1200: mean loss = 2.567909e-06
epoch 54: mean loss = 2.4847438e-06  learning rate = 7.737808e-05
============================
Start of epoch 55
step 0: mean loss = 3.9747283e-07
step 100: mean loss = 3.6085046e-07
step 200: mean loss = 4.2663146e-07
step 300: mean loss = 4.1344694e-07
step 400: mean loss = 4.7277297e-07
step 500: mean loss = 5.0499636e-07
step 600: mean loss = 5.3627645e-07
step 700: mean loss = 5.699954e-07
step 800: mean loss = 6.9297977e-07
step 900: mean loss = 7.083559e-07
step 1000: mean loss = 1.3502337e-06
step 1100: mean loss = 1.6201471e-06
step 1200: mean loss = 1.6095214e-06
epoch 55: mean loss = 1.5626518e-06  learning rate = 7.737808e-05
============================
Start of epoch 56
step 0: mean loss = 1.9444539e-07
step 100: mean loss = 8.2682396e-07
step 200: mean loss = 7.342613e-07
step 300: mean loss = 6.9041255e-07
step 400: mean loss = 6.5755756e-07
step 500: mean loss = 6.762854e-07
step 600: mean loss = 1.0303677e-06
step 700: mean loss = 1.0324e-06
step 800: mean loss = 1.1578717e-06
step 900: mean loss = 1.0994289e-06
step 1000: mean loss = 1.0511142e-06
step 1100: mean loss = 1.0427844e-06
step 1200: mean loss = 1.0255844e-06
epoch 56: mean loss = 1.0274948e-06  learning rate = 7.737808e-05
============================
Start of epoch 57
step 0: mean loss = 7.8988495e-07
step 100: mean loss = 2.6611024e-06
step 200: mean loss = 1.6861727e-06
step 300: mean loss = 1.7345906e-06
step 400: mean loss = 1.4695975e-06
step 500: mean loss = 1.3964218e-06
step 600: mean loss = 1.293782e-06
step 700: mean loss = 1.3341689e-06
step 800: mean loss = 1.99483e-06
step 900: mean loss = 1.8283525e-06
step 1000: mean loss = 1.7207461e-06
step 1100: mean loss = 1.6050436e-06
step 1200: mean loss = 1.7358269e-06
epoch 57: mean loss = 1.9998986e-06  learning rate = 7.737808e-05
============================
Start of epoch 58
step 0: mean loss = 1.314788e-06
step 100: mean loss = 1.0758745e-06
step 200: mean loss = 9.0459775e-07
step 300: mean loss = 8.039358e-07
step 400: mean loss = 7.8686696e-07
step 500: mean loss = 8.051141e-07
step 600: mean loss = 1.2176841e-06
step 700: mean loss = 1.2078249e-06
step 800: mean loss = 1.3949564e-06
step 900: mean loss = 1.3216496e-06
step 1000: mean loss = 1.2914734e-06
step 1100: mean loss = 1.264442e-06
step 1200: mean loss = 1.1871086e-06
epoch 58: mean loss = 1.1639336e-06  learning rate = 7.737808e-05
============================
Start of epoch 59
step 0: mean loss = 5.70453e-07
step 100: mean loss = 8.741756e-07
step 200: mean loss = 9.820797e-07
step 300: mean loss = 1.1299801e-06
step 400: mean loss = 3.096242e-06
step 500: mean loss = 2.6636974e-06
step 600: mean loss = 2.3242005e-06
step 700: mean loss = 2.1454396e-06
step 800: mean loss = 1.9307204e-06
step 900: mean loss = 1.8063334e-06
step 1000: mean loss = 1.7867671e-06
step 1100: mean loss = 1.7108625e-06
step 1200: mean loss = 1.7071567e-06
epoch 59: mean loss = 1.6974069e-06  learning rate = 7.350918e-05
============================
Start of epoch 60
step 0: mean loss = 7.281893e-07
step 100: mean loss = 1.0684681e-06
step 200: mean loss = 7.521248e-07
step 300: mean loss = 7.4637114e-07
step 400: mean loss = 6.425586e-07
step 500: mean loss = 1.3749631e-06
step 600: mean loss = 1.3941866e-06
step 700: mean loss = 1.2566014e-06
step 800: mean loss = 1.205168e-06
step 900: mean loss = 1.1212935e-06
step 1000: mean loss = 1.0598483e-06
step 1100: mean loss = 1.0185321e-06
step 1200: mean loss = 1.0757974e-06
epoch 60: mean loss = 1.0762573e-06  learning rate = 7.350918e-05
============================
Start of epoch 61
step 0: mean loss = 3.723195e-07
step 100: mean loss = 1.7674357e-06
step 200: mean loss = 1.2935488e-06
step 300: mean loss = 2.2010565e-06
step 400: mean loss = 2.0136088e-06
step 500: mean loss = 1.7025255e-06
step 600: mean loss = 1.4999197e-06
step 700: mean loss = 1.4475104e-06
step 800: mean loss = 1.6383143e-06
step 900: mean loss = 1.5671498e-06
step 1000: mean loss = 1.4974505e-06
step 1100: mean loss = 1.3891578e-06
step 1200: mean loss = 1.3138085e-06
epoch 61: mean loss = 1.2847088e-06  learning rate = 7.350918e-05
============================
Start of epoch 62
step 0: mean loss = 3.60294e-07
step 100: mean loss = 7.387092e-07
step 200: mean loss = 6.8246885e-07
step 300: mean loss = 9.424058e-07
step 400: mean loss = 3.6297247e-06
step 500: mean loss = 3.0045924e-06
step 600: mean loss = 2.5874117e-06
step 700: mean loss = 2.3218263e-06
step 800: mean loss = 2.0688165e-06
step 900: mean loss = 1.9028738e-06
step 1000: mean loss = 1.7777493e-06
step 1100: mean loss = 1.64993e-06
step 1200: mean loss = 1.5372229e-06
epoch 62: mean loss = 1.5130726e-06  learning rate = 7.350918e-05
============================
Start of epoch 63
step 0: mean loss = 1.1193694e-06
step 100: mean loss = 7.782839e-07
step 200: mean loss = 1.1765088e-06
step 300: mean loss = 2.4490896e-06
step 400: mean loss = 2.1285389e-06
step 500: mean loss = 1.923289e-06
step 600: mean loss = 1.6608748e-06
step 700: mean loss = 1.5312755e-06
step 800: mean loss = 1.4364493e-06
step 900: mean loss = 1.4455806e-06
step 1000: mean loss = 1.6299545e-06
step 1100: mean loss = 1.5290797e-06
step 1200: mean loss = 1.4347017e-06
epoch 63: mean loss = 1.3938844e-06  learning rate = 7.350918e-05
============================
Start of epoch 64
step 0: mean loss = 1.5329515e-07
step 100: mean loss = 9.078283e-07
step 200: mean loss = 6.9871425e-07
step 300: mean loss = 5.781033e-07
step 400: mean loss = 6.487478e-07
step 500: mean loss = 1.3235751e-06
step 600: mean loss = 1.1948553e-06
step 700: mean loss = 1.0742745e-06
step 800: mean loss = 9.924686e-07
step 900: mean loss = 9.880234e-07
step 1000: mean loss = 1.1998848e-06
step 1100: mean loss = 1.2444453e-06
step 1200: mean loss = 1.2051584e-06
epoch 64: mean loss = 1.169845e-06  learning rate = 7.350918e-05
============================
Start of epoch 65
step 0: mean loss = 2.8651803e-07
step 100: mean loss = 9.0342945e-07
step 200: mean loss = 8.17666e-07
step 300: mean loss = 6.786502e-07
step 400: mean loss = 5.9263886e-07
step 500: mean loss = 6.537766e-07
step 600: mean loss = 6.5048954e-07
step 700: mean loss = 1.4214354e-06
step 800: mean loss = 1.3066932e-06
step 900: mean loss = 1.237185e-06
step 1000: mean loss = 1.1734703e-06
step 1100: mean loss = 1.103731e-06
step 1200: mean loss = 1.1127322e-06
epoch 65: mean loss = 1.112702e-06  learning rate = 7.350918e-05
============================
Start of epoch 66
step 0: mean loss = 8.157164e-07
step 100: mean loss = 6.895754e-07
step 200: mean loss = 2.1831777e-06
step 300: mean loss = 1.920176e-06
step 400: mean loss = 1.5246159e-06
step 500: mean loss = 1.2950873e-06
step 600: mean loss = 1.1318374e-06
step 700: mean loss = 1.0231503e-06
step 800: mean loss = 1.0031023e-06
step 900: mean loss = 1.311151e-06
step 1000: mean loss = 1.2068192e-06
step 1100: mean loss = 1.2628045e-06
step 1200: mean loss = 1.2363342e-06
epoch 66: mean loss = 1.209559e-06  learning rate = 7.350918e-05
============================
Start of epoch 67
step 0: mean loss = 2.3635216e-07
step 100: mean loss = 1.6058702e-06
step 200: mean loss = 1.6339587e-06
step 300: mean loss = 1.5016861e-06
step 400: mean loss = 1.2373794e-06
step 500: mean loss = 1.1375691e-06
step 600: mean loss = 1.1988338e-06
step 700: mean loss = 1.0945438e-06
step 800: mean loss = 1.0147586e-06
step 900: mean loss = 9.759237e-07
step 1000: mean loss = 9.310972e-07
step 1100: mean loss = 9.571158e-07
step 1200: mean loss = 1.4113042e-06
epoch 67: mean loss = 1.4951044e-06  learning rate = 7.350918e-05
============================
Start of epoch 68
step 0: mean loss = 2.3125588e-06
step 100: mean loss = 8.149566e-07
step 200: mean loss = 1.0219931e-06
step 300: mean loss = 8.003555e-07
step 400: mean loss = 6.919051e-07
step 500: mean loss = 1.0278487e-06
step 600: mean loss = 1.1095192e-06
step 700: mean loss = 1.0120609e-06
step 800: mean loss = 9.2871653e-07
step 900: mean loss = 8.5511425e-07
step 1000: mean loss = 7.975216e-07
step 1100: mean loss = 7.6816656e-07
step 1200: mean loss = 7.6688514e-07
epoch 68: mean loss = 7.818656e-07  learning rate = 7.350918e-05
============================
Start of epoch 69
step 0: mean loss = 1.0777713e-06
step 100: mean loss = 6.3519997e-07
step 200: mean loss = 5.761324e-07
step 300: mean loss = 8.5815884e-07
step 400: mean loss = 8.175639e-07
step 500: mean loss = 7.3949127e-07
step 600: mean loss = 7.3596294e-07
step 700: mean loss = 6.9781356e-07
step 800: mean loss = 6.54606e-07
step 900: mean loss = 6.3920305e-07
step 1000: mean loss = 7.797471e-07
step 1100: mean loss = 9.081037e-07
step 1200: mean loss = 8.7513195e-07
epoch 69: mean loss = 8.579354e-07  learning rate = 6.983372e-05
============================
Start of epoch 70
step 0: mean loss = 4.648502e-07
step 100: mean loss = 1.0826712e-06
step 200: mean loss = 8.071426e-07
step 300: mean loss = 7.432706e-07
step 400: mean loss = 8.448837e-07
step 500: mean loss = 7.842159e-07
step 600: mean loss = 7.3746145e-07
step 700: mean loss = 7.9291124e-07
step 800: mean loss = 1.2274174e-06
step 900: mean loss = 1.1230186e-06
step 1000: mean loss = 1.0407372e-06
step 1100: mean loss = 9.870016e-07
step 1200: mean loss = 9.3069923e-07
epoch 70: mean loss = 9.154724e-07  learning rate = 6.983372e-05
============================
Start of epoch 71
step 0: mean loss = 4.0455743e-07
step 100: mean loss = 3.1314469e-06
step 200: mean loss = 1.9067072e-06
step 300: mean loss = 1.3785026e-06
step 400: mean loss = 1.1164951e-06
step 500: mean loss = 9.972731e-07
step 600: mean loss = 9.0981877e-07
step 700: mean loss = 8.474454e-07
step 800: mean loss = 9.1430275e-07
step 900: mean loss = 9.188947e-07
step 1000: mean loss = 8.905768e-07
step 1100: mean loss = 8.2920633e-07
step 1200: mean loss = 7.9215664e-07
epoch 71: mean loss = 7.7175207e-07  learning rate = 6.983372e-05
============================
Start of epoch 72
step 0: mean loss = 1.8861924e-07
step 100: mean loss = 3.981313e-06
step 200: mean loss = 3.528242e-06
step 300: mean loss = 2.5216327e-06
step 400: mean loss = 1.9684016e-06
step 500: mean loss = 1.6104275e-06
step 600: mean loss = 1.3980169e-06
step 700: mean loss = 1.2842344e-06
step 800: mean loss = 1.1553282e-06
step 900: mean loss = 1.0889411e-06
step 1000: mean loss = 1.0117525e-06
step 1100: mean loss = 9.599219e-07
step 1200: mean loss = 9.379341e-07
epoch 72: mean loss = 9.796349e-07  learning rate = 6.983372e-05
============================
Start of epoch 73
step 0: mean loss = 1.0074587e-05
step 100: mean loss = 2.5639604e-06
step 200: mean loss = 1.3996671e-06
step 300: mean loss = 1.1607266e-06
step 400: mean loss = 1.2832307e-06
step 500: mean loss = 1.1972458e-06
step 600: mean loss = 1.0837125e-06
step 700: mean loss = 1.0574706e-06
step 800: mean loss = 1.0331518e-06
step 900: mean loss = 9.688331e-07
step 1000: mean loss = 1.2234701e-06
step 1100: mean loss = 1.1937309e-06
step 1200: mean loss = 1.1120018e-06
epoch 73: mean loss = 1.079459e-06  learning rate = 6.983372e-05
============================
Start of epoch 74
step 0: mean loss = 7.604113e-07
step 100: mean loss = 2.41955e-07
step 200: mean loss = 4.3591083e-07
step 300: mean loss = 4.3174575e-07
step 400: mean loss = 3.848035e-07
step 500: mean loss = 3.6062858e-07
step 600: mean loss = 3.501656e-07
step 700: mean loss = 4.2591654e-07
step 800: mean loss = 4.902297e-07
step 900: mean loss = 5.948862e-07
step 1000: mean loss = 6.5365504e-07
step 1100: mean loss = 8.067262e-07
step 1200: mean loss = 8.172313e-07
epoch 74: mean loss = 8.347351e-07  learning rate = 6.983372e-05
============================
Start of epoch 75
step 0: mean loss = 1.8252483e-06
step 100: mean loss = 4.724246e-07
step 200: mean loss = 3.8962386e-07
step 300: mean loss = 4.184824e-07
step 400: mean loss = 4.0588543e-07
step 500: mean loss = 1.0076909e-06
step 600: mean loss = 9.124977e-07
step 700: mean loss = 8.155108e-07
step 800: mean loss = 7.517704e-07
step 900: mean loss = 8.8106316e-07
step 1000: mean loss = 9.813482e-07
step 1100: mean loss = 9.203343e-07
step 1200: mean loss = 9.3343164e-07
epoch 75: mean loss = 9.207205e-07  learning rate = 6.983372e-05
============================
Start of epoch 76
step 0: mean loss = 1.1116563e-06
step 100: mean loss = 4.3943683e-06
step 200: mean loss = 2.2979727e-06
step 300: mean loss = 1.5927678e-06
step 400: mean loss = 1.2634796e-06
step 500: mean loss = 1.0994579e-06
step 600: mean loss = 9.722102e-07
step 700: mean loss = 8.639206e-07
step 800: mean loss = 8.098374e-07
step 900: mean loss = 8.3837904e-07
step 1000: mean loss = 7.9908904e-07
step 1100: mean loss = 7.890859e-07
step 1200: mean loss = 8.092794e-07
epoch 76: mean loss = 7.869563e-07  learning rate = 6.983372e-05
============================
Start of epoch 77
step 0: mean loss = 1.0175719e-07
step 100: mean loss = 7.949393e-07
step 200: mean loss = 2.5183565e-06
step 300: mean loss = 1.7998905e-06
step 400: mean loss = 1.4567072e-06
step 500: mean loss = 1.2269749e-06
step 600: mean loss = 1.0687756e-06
step 700: mean loss = 9.69694e-07
step 800: mean loss = 8.7777266e-07
step 900: mean loss = 8.186192e-07
step 1000: mean loss = 8.3401324e-07
step 1100: mean loss = 1.0635283e-06
step 1200: mean loss = 1.0173029e-06
epoch 77: mean loss = 9.872408e-07  learning rate = 6.983372e-05
============================
Start of epoch 78
step 0: mean loss = 7.2180717e-07
step 100: mean loss = 6.901784e-07
step 200: mean loss = 7.0578915e-07
step 300: mean loss = 5.781937e-07
step 400: mean loss = 5.2299146e-07
step 500: mean loss = 4.8562623e-07
step 600: mean loss = 4.339673e-07
step 700: mean loss = 4.174077e-07
step 800: mean loss = 4.276587e-07
step 900: mean loss = 7.843673e-07
step 1000: mean loss = 1.3499545e-06
step 1100: mean loss = 1.249711e-06
step 1200: mean loss = 1.1620003e-06
epoch 78: mean loss = 1.1239346e-06  learning rate = 6.983372e-05
============================
Start of epoch 79
step 0: mean loss = 1.14931666e-07
step 100: mean loss = 1.7441386e-07
step 200: mean loss = 1.528348e-07
step 300: mean loss = 1.8657629e-07
step 400: mean loss = 2.2123524e-07
step 500: mean loss = 2.247938e-07
step 600: mean loss = 3.15173e-07
step 700: mean loss = 3.3938923e-07
step 800: mean loss = 3.438982e-07
step 900: mean loss = 3.691536e-07
step 1000: mean loss = 4.198531e-07
step 1100: mean loss = 4.5378894e-07
step 1200: mean loss = 5.807586e-07
epoch 79: mean loss = 6.081987e-07  learning rate = 6.634203e-05
============================
Start of epoch 80
step 0: mean loss = 8.053433e-07
step 100: mean loss = 5.1486563e-07
step 200: mean loss = 4.7771124e-07
step 300: mean loss = 4.310376e-07
step 400: mean loss = 4.000938e-07
step 500: mean loss = 4.3983601e-07
step 600: mean loss = 4.771271e-07
step 700: mean loss = 4.6997846e-07
step 800: mean loss = 4.4600102e-07
step 900: mean loss = 5.427157e-07
step 1000: mean loss = 6.226135e-07
step 1100: mean loss = 6.1336584e-07
step 1200: mean loss = 6.879712e-07
epoch 80: mean loss = 6.9337364e-07  learning rate = 6.634203e-05
============================
Start of epoch 81
step 0: mean loss = 4.987895e-07
step 100: mean loss = 6.093288e-07
step 200: mean loss = 4.549123e-07
step 300: mean loss = 3.9402246e-07
step 400: mean loss = 3.5763838e-07
step 500: mean loss = 3.6403316e-07
step 600: mean loss = 4.4107426e-07
step 700: mean loss = 5.625908e-07
step 800: mean loss = 5.4864176e-07
step 900: mean loss = 5.08197e-07
step 1000: mean loss = 4.924929e-07
step 1100: mean loss = 5.0204625e-07
step 1200: mean loss = 5.3237403e-07
epoch 81: mean loss = 5.514103e-07  learning rate = 6.634203e-05
============================
Start of epoch 82
step 0: mean loss = 3.751964e-07
step 100: mean loss = 6.61194e-07
step 200: mean loss = 6.494978e-07
step 300: mean loss = 1.0508803e-06
step 400: mean loss = 9.599876e-07
step 500: mean loss = 8.1367637e-07
step 600: mean loss = 7.165159e-07
step 700: mean loss = 6.5746764e-07
step 800: mean loss = 6.2342303e-07
step 900: mean loss = 6.16437e-07
step 1000: mean loss = 7.342151e-07
step 1100: mean loss = 6.858686e-07
step 1200: mean loss = 6.9364046e-07
epoch 82: mean loss = 6.867362e-07  learning rate = 6.634203e-05
============================
Start of epoch 83
step 0: mean loss = 1.9180338e-07
step 100: mean loss = 6.1066515e-07
step 200: mean loss = 1.1209379e-06
step 300: mean loss = 9.105168e-07
step 400: mean loss = 8.4429917e-07
step 500: mean loss = 7.7683643e-07
step 600: mean loss = 6.9190304e-07
step 700: mean loss = 6.5952077e-07
step 800: mean loss = 7.9298536e-07
step 900: mean loss = 9.210985e-07
step 1000: mean loss = 8.548658e-07
step 1100: mean loss = 8.052799e-07
step 1200: mean loss = 7.62363e-07
epoch 83: mean loss = 7.493287e-07  learning rate = 6.634203e-05
============================
Start of epoch 84
step 0: mean loss = 2.4284947e-07
step 100: mean loss = 2.4578583e-07
step 200: mean loss = 1.3196524e-06
step 300: mean loss = 1.0596759e-06
step 400: mean loss = 8.6069093e-07
step 500: mean loss = 7.695417e-07
step 600: mean loss = 7.231929e-07
step 700: mean loss = 7.6215844e-07
step 800: mean loss = 6.894324e-07
step 900: mean loss = 6.3911443e-07
step 1000: mean loss = 6.1968814e-07
step 1100: mean loss = 6.635587e-07
step 1200: mean loss = 6.2105937e-07
epoch 84: mean loss = 6.155639e-07  learning rate = 6.634203e-05
============================
Start of epoch 85
step 0: mean loss = 7.8903076e-07
step 100: mean loss = 3.024854e-07
step 200: mean loss = 8.981391e-07
step 300: mean loss = 7.9406595e-07
step 400: mean loss = 7.219263e-07
step 500: mean loss = 6.136253e-07
step 600: mean loss = 6.808875e-07
step 700: mean loss = 6.3704135e-07
step 800: mean loss = 6.139385e-07
step 900: mean loss = 5.808841e-07
step 1000: mean loss = 8.4601055e-07
step 1100: mean loss = 8.4426887e-07
step 1200: mean loss = 8.32444e-07
epoch 85: mean loss = 8.415303e-07  learning rate = 6.634203e-05
============================
Start of epoch 86
step 0: mean loss = 3.0449218e-07
step 100: mean loss = 4.014984e-07
step 200: mean loss = 6.3847665e-07
step 300: mean loss = 8.004377e-07
step 400: mean loss = 6.4650646e-07
step 500: mean loss = 5.6232574e-07
step 600: mean loss = 4.975023e-07
step 700: mean loss = 4.6160272e-07
step 800: mean loss = 4.7870253e-07
step 900: mean loss = 5.0906374e-07
step 1000: mean loss = 6.0804894e-07
step 1100: mean loss = 6.1965187e-07
step 1200: mean loss = 7.724356e-07
epoch 86: mean loss = 8.168957e-07  learning rate = 6.634203e-05
============================
Start of epoch 87
step 0: mean loss = 6.0999946e-07
step 100: mean loss = 2.2510619e-07
step 200: mean loss = 2.654911e-07
step 300: mean loss = 2.2194074e-07
step 400: mean loss = 2.1621719e-07
step 500: mean loss = 2.540499e-07
step 600: mean loss = 3.4738935e-07
step 700: mean loss = 4.179418e-07
step 800: mean loss = 3.9847538e-07
step 900: mean loss = 4.0636664e-07
step 1000: mean loss = 3.9088067e-07
step 1100: mean loss = 3.9671994e-07
step 1200: mean loss = 4.1999832e-07
epoch 87: mean loss = 4.1506306e-07  learning rate = 6.634203e-05
============================
Start of epoch 88
step 0: mean loss = 7.149657e-07
step 100: mean loss = 1.871523e-07
step 200: mean loss = 2.3139071e-07
step 300: mean loss = 2.8260578e-07
step 400: mean loss = 3.038099e-07
step 500: mean loss = 2.947396e-07
step 600: mean loss = 5.0410824e-07
step 700: mean loss = 8.795136e-07
step 800: mean loss = 7.926665e-07
step 900: mean loss = 7.4078037e-07
step 1000: mean loss = 6.795009e-07
step 1100: mean loss = 6.401372e-07
step 1200: mean loss = 6.1299545e-07
epoch 88: mean loss = 5.985228e-07  learning rate = 6.634203e-05
============================
Start of epoch 89
step 0: mean loss = 2.4403687e-07
step 100: mean loss = 4.2755966e-07
step 200: mean loss = 6.911575e-07
step 300: mean loss = 7.421579e-07
step 400: mean loss = 1.0299747e-06
step 500: mean loss = 8.607049e-07
step 600: mean loss = 7.6494956e-07
step 700: mean loss = 7.563755e-07
step 800: mean loss = 7.179091e-07
step 900: mean loss = 7.99854e-07
step 1000: mean loss = 7.573337e-07
step 1100: mean loss = 7.005253e-07
step 1200: mean loss = 6.769422e-07
epoch 89: mean loss = 6.7354665e-07  learning rate = 6.302493e-05
============================
Start of epoch 90
step 0: mean loss = 1.7148556e-06
step 100: mean loss = 1.3519863e-06
step 200: mean loss = 9.837771e-07
step 300: mean loss = 7.5823635e-07
step 400: mean loss = 6.2467024e-07
step 500: mean loss = 5.728645e-07
step 600: mean loss = 5.470715e-07
step 700: mean loss = 5.69697e-07
step 800: mean loss = 5.6246046e-07
step 900: mean loss = 5.5814013e-07
step 1000: mean loss = 5.197119e-07
step 1100: mean loss = 4.882469e-07
step 1200: mean loss = 4.6877236e-07
epoch 90: mean loss = 4.5641275e-07  learning rate = 6.302493e-05
============================
Start of epoch 91
step 0: mean loss = 1.1024467e-07
step 100: mean loss = 3.2643513e-07
step 200: mean loss = 3.1432472e-07
step 300: mean loss = 3.6579755e-07
step 400: mean loss = 7.0820636e-07
step 500: mean loss = 8.817706e-07
step 600: mean loss = 8.111559e-07
step 700: mean loss = 7.293858e-07
step 800: mean loss = 6.5333927e-07
step 900: mean loss = 6.028645e-07
step 1000: mean loss = 5.6702544e-07
step 1100: mean loss = 5.916781e-07
step 1200: mean loss = 5.8145116e-07
epoch 91: mean loss = 5.7496493e-07  learning rate = 6.302493e-05
============================
Start of epoch 92
step 0: mean loss = 2.6332934e-06
step 100: mean loss = 2.0760885e-06
step 200: mean loss = 1.1500417e-06
step 300: mean loss = 8.161066e-07
step 400: mean loss = 6.90245e-07
step 500: mean loss = 9.784208e-07
step 600: mean loss = 8.8486365e-07
step 700: mean loss = 7.756926e-07
step 800: mean loss = 7.154907e-07
step 900: mean loss = 6.604704e-07
step 1000: mean loss = 6.089996e-07
step 1100: mean loss = 6.708866e-07
step 1200: mean loss = 6.4362825e-07
epoch 92: mean loss = 6.2264303e-07  learning rate = 6.302493e-05
============================
Start of epoch 93
step 0: mean loss = 7.0030985e-08
step 100: mean loss = 1.3040825e-07
step 200: mean loss = 2.127468e-07
step 300: mean loss = 2.6814925e-07
step 400: mean loss = 3.7641215e-07
step 500: mean loss = 3.87402e-07
step 600: mean loss = 4.2015273e-07
step 700: mean loss = 7.750081e-07
step 800: mean loss = 9.2876405e-07
step 900: mean loss = 8.4219056e-07
step 1000: mean loss = 7.830518e-07
step 1100: mean loss = 7.284402e-07
step 1200: mean loss = 6.7712455e-07
epoch 93: mean loss = 6.568076e-07  learning rate = 6.302493e-05
============================
Start of epoch 94
step 0: mean loss = 9.1193826e-08
step 100: mean loss = 1.7720944e-07
step 200: mean loss = 1.6702629e-07
step 300: mean loss = 2.1066124e-07
step 400: mean loss = 2.600736e-07
step 500: mean loss = 3.205217e-07
step 600: mean loss = 3.1489364e-07
step 700: mean loss = 2.9612943e-07
step 800: mean loss = 6.4157115e-07
step 900: mean loss = 6.1144254e-07
step 1000: mean loss = 5.631953e-07
step 1100: mean loss = 5.250865e-07
step 1200: mean loss = 5.7887894e-07
epoch 94: mean loss = 6.1443814e-07  learning rate = 6.302493e-05
============================
Start of epoch 95
step 0: mean loss = 1.3833376e-06
step 100: mean loss = 2.0230397e-07
step 200: mean loss = 2.1779185e-07
step 300: mean loss = 2.1554536e-07
step 400: mean loss = 2.2212201e-07
step 500: mean loss = 3.927133e-07
step 600: mean loss = 4.2063863e-07
step 700: mean loss = 4.0110277e-07
step 800: mean loss = 3.7294362e-07
step 900: mean loss = 3.4592605e-07
step 1000: mean loss = 3.6164536e-07
step 1100: mean loss = 3.4119813e-07
step 1200: mean loss = 4.0450556e-07
epoch 95: mean loss = 4.0481245e-07  learning rate = 6.302493e-05
============================
Start of epoch 96
step 0: mean loss = 5.37652e-07
step 100: mean loss = 4.56041e-07
step 200: mean loss = 5.054102e-07
step 300: mean loss = 4.601588e-07
step 400: mean loss = 5.078403e-07
step 500: mean loss = 5.435665e-07
step 600: mean loss = 4.9981537e-07
step 700: mean loss = 7.3436297e-07
step 800: mean loss = 7.134362e-07
step 900: mean loss = 6.457329e-07
step 1000: mean loss = 6.018414e-07
step 1100: mean loss = 5.560471e-07
step 1200: mean loss = 5.21894e-07
epoch 96: mean loss = 5.098118e-07  learning rate = 6.302493e-05
============================
Start of epoch 97
step 0: mean loss = 7.6509735e-08
step 100: mean loss = 2.829169e-06
step 200: mean loss = 1.8389709e-06
step 300: mean loss = 1.2818347e-06
step 400: mean loss = 1.022805e-06
step 500: mean loss = 8.464175e-07
step 600: mean loss = 7.310961e-07
step 700: mean loss = 6.5754153e-07
step 800: mean loss = 6.268099e-07
step 900: mean loss = 7.134514e-07
step 1000: mean loss = 6.6704314e-07
step 1100: mean loss = 6.739159e-07
step 1200: mean loss = 6.389311e-07
epoch 97: mean loss = 6.368118e-07  learning rate = 6.302493e-05
============================
Start of epoch 98
step 0: mean loss = 3.919637e-07
step 100: mean loss = 5.0236144e-07
step 200: mean loss = 5.538547e-07
step 300: mean loss = 4.886292e-07
step 400: mean loss = 3.958912e-07
step 500: mean loss = 4.3784675e-07
step 600: mean loss = 3.8863615e-07
step 700: mean loss = 4.6663442e-07
step 800: mean loss = 4.252866e-07
step 900: mean loss = 4.0269617e-07
step 1000: mean loss = 3.8983453e-07
step 1100: mean loss = 3.835418e-07
step 1200: mean loss = 3.6427753e-07
epoch 98: mean loss = 3.6285863e-07  learning rate = 6.302493e-05
============================
Start of epoch 99
step 0: mean loss = 7.51989e-07
step 100: mean loss = 1.2776495e-06
step 200: mean loss = 7.748773e-07
step 300: mean loss = 5.712484e-07
step 400: mean loss = 5.125748e-07
step 500: mean loss = 4.3656274e-07
step 600: mean loss = 9.3341254e-07
step 700: mean loss = 8.7897985e-07
step 800: mean loss = 7.8591e-07
step 900: mean loss = 7.112043e-07
step 1000: mean loss = 6.511161e-07
step 1100: mean loss = 6.0978334e-07
step 1200: mean loss = 5.7022476e-07
epoch 99: mean loss = 5.5397464e-07  learning rate = 5.987368e-05
============================
Start of epoch 100
step 0: mean loss = 4.6133027e-07
step 100: mean loss = 3.6151536e-07
step 200: mean loss = 2.631075e-07
step 300: mean loss = 2.4604404e-07
step 400: mean loss = 3.0456334e-07
step 500: mean loss = 3.7989662e-07
step 600: mean loss = 8.4386204e-07
step 700: mean loss = 9.188238e-07
step 800: mean loss = 8.202352e-07
step 900: mean loss = 7.4466806e-07
step 1000: mean loss = 6.8553834e-07
step 1100: mean loss = 6.3030905e-07
step 1200: mean loss = 5.890847e-07
epoch 100: mean loss = 5.728454e-07  learning rate = 5.987368e-05
============================
Start of epoch 101
step 0: mean loss = 9.7004246e-08
step 100: mean loss = 3.885363e-07
step 200: mean loss = 2.6295848e-07
step 300: mean loss = 2.2110001e-07
step 400: mean loss = 2.1172471e-07
step 500: mean loss = 2.3071689e-07
step 600: mean loss = 3.6857347e-07
step 700: mean loss = 3.874918e-07
step 800: mean loss = 3.5556923e-07
step 900: mean loss = 3.8600396e-07
step 1000: mean loss = 3.931286e-07
step 1100: mean loss = 4.1440651e-07
step 1200: mean loss = 4.03987e-07
epoch 101: mean loss = 4.1992854e-07  learning rate = 5.987368e-05
============================
Start of epoch 102
step 0: mean loss = 1.3903671e-06
step 100: mean loss = 6.5840646e-07
step 200: mean loss = 4.448006e-07
step 300: mean loss = 5.891578e-07
step 400: mean loss = 5.0389366e-07
step 500: mean loss = 4.917166e-07
step 600: mean loss = 4.4235676e-07
step 700: mean loss = 4.0349957e-07
step 800: mean loss = 5.692323e-07
step 900: mean loss = 5.2232116e-07
step 1000: mean loss = 4.945146e-07
step 1100: mean loss = 4.7350426e-07
step 1200: mean loss = 4.799101e-07
epoch 102: mean loss = 4.7459508e-07  learning rate = 5.987368e-05
============================
Start of epoch 103
step 0: mean loss = 4.2377533e-07
step 100: mean loss = 1.3982456e-07
step 200: mean loss = 2.8707996e-07
step 300: mean loss = 4.8511936e-07
step 400: mean loss = 4.2606777e-07
step 500: mean loss = 4.0491523e-07
step 600: mean loss = 3.9629955e-07
step 700: mean loss = 4.3283765e-07
step 800: mean loss = 4.158621e-07
step 900: mean loss = 4.2703536e-07
step 1000: mean loss = 4.118721e-07
step 1100: mean loss = 3.8633075e-07
step 1200: mean loss = 3.7671998e-07
epoch 103: mean loss = 3.7428808e-07  learning rate = 5.987368e-05
============================
Start of epoch 104
step 0: mean loss = 9.0507064e-07
step 100: mean loss = 1.1882438e-06
step 200: mean loss = 7.221345e-07
step 300: mean loss = 5.2219616e-07
step 400: mean loss = 4.1662997e-07
step 500: mean loss = 3.6019895e-07
step 600: mean loss = 1.2742958e-06
step 700: mean loss = 1.1338069e-06
step 800: mean loss = 1.005549e-06
step 900: mean loss = 9.0389796e-07
step 1000: mean loss = 8.2491107e-07
step 1100: mean loss = 7.687552e-07
step 1200: mean loss = 7.1617103e-07
epoch 104: mean loss = 6.9998487e-07  learning rate = 5.987368e-05
============================
Start of epoch 105
step 0: mean loss = 3.8173295e-07
step 100: mean loss = 8.3673183e-07
step 200: mean loss = 5.5993263e-07
step 300: mean loss = 4.342669e-07
step 400: mean loss = 3.5471473e-07
step 500: mean loss = 5.7035425e-07
step 600: mean loss = 5.290143e-07
step 700: mean loss = 4.6691363e-07
step 800: mean loss = 4.2401305e-07
step 900: mean loss = 4.4979078e-07
step 1000: mean loss = 4.3999137e-07
step 1100: mean loss = 4.7117118e-07
step 1200: mean loss = 4.574626e-07
epoch 105: mean loss = 4.524127e-07  learning rate = 5.987368e-05
============================
Start of epoch 106
step 0: mean loss = 4.459674e-07
step 100: mean loss = 2.927814e-07
step 200: mean loss = 2.679551e-07
step 300: mean loss = 2.9855926e-07
step 400: mean loss = 2.6592718e-07
step 500: mean loss = 2.3177363e-07
step 600: mean loss = 2.3722748e-07
step 700: mean loss = 2.7352638e-07
step 800: mean loss = 2.8737398e-07
step 900: mean loss = 2.9885683e-07
step 1000: mean loss = 3.9662507e-07
step 1100: mean loss = 3.7808252e-07
step 1200: mean loss = 3.694541e-07
epoch 106: mean loss = 3.6118746e-07  learning rate = 5.987368e-05
============================
Start of epoch 107
step 0: mean loss = 1.6084256e-07
step 100: mean loss = 3.8236757e-07
step 200: mean loss = 8.4115464e-07
step 300: mean loss = 6.521036e-07
step 400: mean loss = 5.120022e-07
step 500: mean loss = 4.3579146e-07
step 600: mean loss = 4.123163e-07
step 700: mean loss = 3.8467687e-07
step 800: mean loss = 3.669874e-07
step 900: mean loss = 3.8440686e-07
step 1000: mean loss = 3.942805e-07
step 1100: mean loss = 3.761391e-07
step 1200: mean loss = 3.5373822e-07
epoch 107: mean loss = 3.5001074e-07  learning rate = 5.987368e-05
============================
Start of epoch 108
step 0: mean loss = 6.9642496e-08
step 100: mean loss = 2.7448768e-06
step 200: mean loss = 1.7430998e-06
step 300: mean loss = 1.2005158e-06
step 400: mean loss = 9.229873e-07
step 500: mean loss = 8.4040505e-07
step 600: mean loss = 7.3528236e-07
step 700: mean loss = 6.715893e-07
step 800: mean loss = 6.102891e-07
step 900: mean loss = 6.2909885e-07
step 1000: mean loss = 5.890402e-07
step 1100: mean loss = 5.9600836e-07
step 1200: mean loss = 6.6466595e-07
epoch 108: mean loss = 6.502567e-07  learning rate = 5.987368e-05
============================
Start of epoch 109
step 0: mean loss = 6.1874076e-08
step 100: mean loss = 1.4677511e-07
step 200: mean loss = 1.16916496e-07
step 300: mean loss = 2.7295016e-07
step 400: mean loss = 3.8257338e-07
step 500: mean loss = 3.2415696e-07
step 600: mean loss = 2.8937978e-07
step 700: mean loss = 2.823921e-07
step 800: mean loss = 2.712527e-07
step 900: mean loss = 2.5669823e-07
step 1000: mean loss = 2.4932862e-07
step 1100: mean loss = 2.855155e-07
step 1200: mean loss = 3.33109e-07
epoch 109: mean loss = 3.247813e-07  learning rate = 5.6879995e-05
============================
Start of epoch 110
step 0: mean loss = 5.3892496e-08
step 100: mean loss = 8.8110674e-08
step 200: mean loss = 1.041428e-07
step 300: mean loss = 2.4181782e-07
step 400: mean loss = 1.0993849e-06
step 500: mean loss = 8.945767e-07
step 600: mean loss = 7.6951306e-07
step 700: mean loss = 6.7271526e-07
step 800: mean loss = 6.0106623e-07
step 900: mean loss = 5.475554e-07
step 1000: mean loss = 5.035946e-07
step 1100: mean loss = 4.6952775e-07
step 1200: mean loss = 4.956989e-07
epoch 110: mean loss = 4.950623e-07  learning rate = 5.6879995e-05
============================
Start of epoch 111
step 0: mean loss = 6.424214e-08
step 100: mean loss = 4.6524033e-07
step 200: mean loss = 3.1093094e-07
step 300: mean loss = 2.420721e-07
step 400: mean loss = 2.9266795e-07
step 500: mean loss = 1.1866563e-06
step 600: mean loss = 1.0259861e-06
step 700: mean loss = 8.917031e-07
step 800: mean loss = 7.983928e-07
step 900: mean loss = 7.2523625e-07
step 1000: mean loss = 6.6416396e-07
step 1100: mean loss = 6.189264e-07
step 1200: mean loss = 5.8517924e-07
epoch 111: mean loss = 5.666225e-07  learning rate = 5.6879995e-05
============================
Start of epoch 112
step 0: mean loss = 3.7628018e-07
step 100: mean loss = 1.132079e-07
step 200: mean loss = 1.1174767e-07
step 300: mean loss = 1.1525305e-07
step 400: mean loss = 1.2289229e-07
step 500: mean loss = 1.5312746e-07
step 600: mean loss = 1.6633047e-07
step 700: mean loss = 1.625556e-07
step 800: mean loss = 1.8781661e-07
step 900: mean loss = 2.3679189e-07
step 1000: mean loss = 3.107701e-07
step 1100: mean loss = 2.903435e-07
step 1200: mean loss = 3.5033398e-07
epoch 112: mean loss = 4.7393058e-07  learning rate = 5.6879995e-05
============================
Start of epoch 113
step 0: mean loss = 1.6577933e-06
step 100: mean loss = 1.9426024e-07
step 200: mean loss = 1.7315398e-07
step 300: mean loss = 1.5207345e-07
step 400: mean loss = 1.3530712e-07
step 500: mean loss = 1.3129771e-07
step 600: mean loss = 2.7602232e-07
step 700: mean loss = 3.3507104e-07
step 800: mean loss = 3.1549058e-07
step 900: mean loss = 2.984261e-07
step 1000: mean loss = 2.846439e-07
step 1100: mean loss = 2.7529046e-07
step 1200: mean loss = 2.6323838e-07
epoch 113: mean loss = 2.57826e-07  learning rate = 5.6879995e-05
============================
Start of epoch 114
step 0: mean loss = 1.2302789e-07
step 100: mean loss = 1.0560736e-07
step 200: mean loss = 1.7871055e-07
step 300: mean loss = 4.7871595e-07
step 400: mean loss = 5.390425e-07
step 500: mean loss = 5.0746553e-07
step 600: mean loss = 4.8216884e-07
step 700: mean loss = 4.2919407e-07
step 800: mean loss = 4.103936e-07
step 900: mean loss = 3.9330862e-07
step 1000: mean loss = 3.7089663e-07
step 1100: mean loss = 3.8773427e-07
step 1200: mean loss = 3.7229086e-07
epoch 114: mean loss = 3.6067365e-07  learning rate = 5.6879995e-05
============================
Start of epoch 115
step 0: mean loss = 6.964624e-08
step 100: mean loss = 1.5973126e-07
step 200: mean loss = 2.1377539e-06
step 300: mean loss = 1.5201181e-06
step 400: mean loss = 1.1714343e-06
step 500: mean loss = 9.693673e-07
step 600: mean loss = 8.451063e-07
step 700: mean loss = 7.409462e-07
step 800: mean loss = 6.637834e-07
step 900: mean loss = 5.97576e-07
step 1000: mean loss = 5.527251e-07
step 1100: mean loss = 5.143824e-07
step 1200: mean loss = 4.929533e-07
epoch 115: mean loss = 4.8005285e-07  learning rate = 5.6879995e-05
============================
Start of epoch 116
step 0: mean loss = 1.3640843e-07
step 100: mean loss = 1.9610586e-07
step 200: mean loss = 1.5920115e-07
step 300: mean loss = 2.0300357e-07
step 400: mean loss = 2.4868072e-07
step 500: mean loss = 2.2799232e-07
step 600: mean loss = 2.1485769e-07
step 700: mean loss = 2.1072259e-07
step 800: mean loss = 2.3294419e-07
step 900: mean loss = 6.157362e-07
step 1000: mean loss = 6.826849e-07
step 1100: mean loss = 6.2648166e-07
step 1200: mean loss = 5.807062e-07
epoch 116: mean loss = 5.60749e-07  learning rate = 5.6879995e-05
============================
Start of epoch 117
step 0: mean loss = 1.4103712e-07
step 100: mean loss = 1.3340559e-07
step 200: mean loss = 1.0800299e-07
step 300: mean loss = 2.928215e-07
step 400: mean loss = 2.4754397e-07
step 500: mean loss = 2.1958805e-07
step 600: mean loss = 2.2930881e-07
step 700: mean loss = 3.621648e-07
step 800: mean loss = 3.319281e-07
step 900: mean loss = 3.067576e-07
step 1000: mean loss = 2.8688717e-07
step 1100: mean loss = 2.7070513e-07
step 1200: mean loss = 2.8518386e-07
epoch 117: mean loss = 2.7979868e-07  learning rate = 5.6879995e-05
============================
Start of epoch 118
step 0: mean loss = 7.435756e-08
step 100: mean loss = 2.505489e-07
step 200: mean loss = 3.0598483e-07
step 300: mean loss = 1.0958196e-06
step 400: mean loss = 8.5142e-07
step 500: mean loss = 7.045533e-07
step 600: mean loss = 6.0369297e-07
step 700: mean loss = 5.28951e-07
step 800: mean loss = 4.7898016e-07
step 900: mean loss = 4.4885704e-07
step 1000: mean loss = 4.212485e-07
step 1100: mean loss = 3.9616847e-07
step 1200: mean loss = 3.707838e-07
epoch 118: mean loss = 3.7053346e-07  learning rate = 5.6879995e-05
============================
Start of epoch 119
step 0: mean loss = 5.469138e-07
step 100: mean loss = 3.921198e-07
step 200: mean loss = 3.8056473e-07
step 300: mean loss = 4.3091828e-07
step 400: mean loss = 3.6405143e-07
step 500: mean loss = 3.3066908e-07
step 600: mean loss = 3.0749572e-07
step 700: mean loss = 2.8349808e-07
step 800: mean loss = 2.7134027e-07
step 900: mean loss = 2.8662873e-07
step 1000: mean loss = 2.7624432e-07
step 1100: mean loss = 2.7117306e-07
step 1200: mean loss = 2.7016418e-07
epoch 119: mean loss = 2.632594e-07  learning rate = 5.4036e-05
============================
Start of epoch 120
step 0: mean loss = 7.2959935e-08
step 100: mean loss = 4.4458645e-07
step 200: mean loss = 3.5658712e-07
step 300: mean loss = 5.744103e-07
step 400: mean loss = 5.299929e-07
step 500: mean loss = 7.118376e-07
step 600: mean loss = 6.925439e-07
step 700: mean loss = 6.043659e-07
step 800: mean loss = 5.393368e-07
step 900: mean loss = 4.9408897e-07
step 1000: mean loss = 4.529483e-07
step 1100: mean loss = 4.3414136e-07
step 1200: mean loss = 4.6007204e-07
epoch 120: mean loss = 4.494967e-07  learning rate = 5.4036e-05
============================
Start of epoch 121
step 0: mean loss = 1.14831536e-07
step 100: mean loss = 4.1271403e-07
step 200: mean loss = 3.0812905e-07
step 300: mean loss = 2.4640826e-07
step 400: mean loss = 1.9941498e-07
step 500: mean loss = 2.506849e-07
step 600: mean loss = 2.7928033e-07
step 700: mean loss = 2.5592922e-07
step 800: mean loss = 2.3669064e-07
step 900: mean loss = 2.1857454e-07
step 1000: mean loss = 2.4007312e-07
step 1100: mean loss = 4.0721883e-07
step 1200: mean loss = 4.0646225e-07
epoch 121: mean loss = 3.9653574e-07  learning rate = 5.4036e-05
============================
Start of epoch 122
step 0: mean loss = 8.655035e-08
step 100: mean loss = 8.548447e-08
step 200: mean loss = 2.1576673e-07
step 300: mean loss = 2.42531e-07
step 400: mean loss = 1.9799978e-07
step 500: mean loss = 1.7937892e-07
step 600: mean loss = 2.0057718e-07
step 700: mean loss = 3.2729238e-07
step 800: mean loss = 3.154702e-07
step 900: mean loss = 3.6007617e-07
step 1000: mean loss = 3.3573897e-07
step 1100: mean loss = 3.199127e-07
step 1200: mean loss = 3.0577846e-07
epoch 122: mean loss = 3.1349893e-07  learning rate = 5.4036e-05
============================
Start of epoch 123
step 0: mean loss = 1.1438636e-06
step 100: mean loss = 6.952123e-07
step 200: mean loss = 4.039535e-07
step 300: mean loss = 3.0771707e-07
step 400: mean loss = 2.8099822e-07
step 500: mean loss = 2.4240313e-07
step 600: mean loss = 2.3406707e-07
step 700: mean loss = 2.1754168e-07
step 800: mean loss = 2.5141776e-07
step 900: mean loss = 2.9254372e-07
step 1000: mean loss = 2.7234827e-07
step 1100: mean loss = 2.7057428e-07
step 1200: mean loss = 2.6524827e-07
epoch 123: mean loss = 3.139864e-07  learning rate = 5.4036e-05
============================
Start of epoch 124
step 0: mean loss = 1.3302522e-06
step 100: mean loss = 5.6046395e-07
step 200: mean loss = 3.352932e-07
step 300: mean loss = 2.5308918e-07
step 400: mean loss = 2.1835714e-07
step 500: mean loss = 2.0029456e-07
step 600: mean loss = 1.8120292e-07
step 700: mean loss = 1.7203814e-07
step 800: mean loss = 1.6251226e-07
step 900: mean loss = 1.8341375e-07
step 1000: mean loss = 2.4116216e-07
step 1100: mean loss = 2.4686614e-07
step 1200: mean loss = 2.4598094e-07
epoch 124: mean loss = 2.392396e-07  learning rate = 5.4036e-05
============================
Start of epoch 125
step 0: mean loss = 2.3320217e-07
step 100: mean loss = 2.2995954e-07
step 200: mean loss = 2.64807e-07
step 300: mean loss = 5.235852e-07
step 400: mean loss = 4.2903855e-07
step 500: mean loss = 4.0894412e-07
step 600: mean loss = 3.7564928e-07
step 700: mean loss = 3.5066856e-07
step 800: mean loss = 3.1375487e-07
step 900: mean loss = 3.0077624e-07
step 1000: mean loss = 3.4619524e-07
step 1100: mean loss = 3.7469303e-07
step 1200: mean loss = 3.8723428e-07
epoch 125: mean loss = 3.7674553e-07  learning rate = 5.4036e-05
============================
Start of epoch 126
step 0: mean loss = 7.44703e-08
step 100: mean loss = 1.3447507e-07
step 200: mean loss = 1.4651044e-07
step 300: mean loss = 2.4737741e-07
step 400: mean loss = 3.069612e-07
step 500: mean loss = 2.7528384e-07
step 600: mean loss = 2.4340545e-07
step 700: mean loss = 2.6656562e-07
step 800: mean loss = 6.670425e-07
step 900: mean loss = 6.0251847e-07
step 1000: mean loss = 5.500824e-07
step 1100: mean loss = 5.065377e-07
step 1200: mean loss = 4.7028476e-07
epoch 126: mean loss = 4.5421825e-07  learning rate = 5.4036e-05
============================
Start of epoch 127
step 0: mean loss = 1.5237993e-07
step 100: mean loss = 7.20373e-08
step 200: mean loss = 7.362848e-08
step 300: mean loss = 8.053655e-08
step 400: mean loss = 9.0859345e-08
step 500: mean loss = 9.240611e-08
step 600: mean loss = 1.04922854e-07
step 700: mean loss = 1.0765672e-07
step 800: mean loss = 1.2139522e-07
step 900: mean loss = 2.4003097e-07
step 1000: mean loss = 2.2618583e-07
step 1100: mean loss = 2.2163313e-07
step 1200: mean loss = 2.2625198e-07
epoch 127: mean loss = 2.584799e-07  learning rate = 5.4036e-05
============================
Start of epoch 128
step 0: mean loss = 4.8724075e-07
step 100: mean loss = 2.3049694e-07
step 200: mean loss = 2.810766e-07
step 300: mean loss = 2.5102267e-07
step 400: mean loss = 2.153875e-07
step 500: mean loss = 1.8909792e-07
step 600: mean loss = 1.7494567e-07
step 700: mean loss = 1.5978601e-07
step 800: mean loss = 1.5326282e-07
step 900: mean loss = 1.6077088e-07
step 1000: mean loss = 1.8731106e-07
step 1100: mean loss = 2.4556337e-07
step 1200: mean loss = 2.4273538e-07
epoch 128: mean loss = 2.4015975e-07  learning rate = 5.4036e-05
============================
Start of epoch 129
step 0: mean loss = 5.2011904e-07
step 100: mean loss = 1.4425078e-07
step 200: mean loss = 2.4900322e-07
step 300: mean loss = 2.6913995e-07
step 400: mean loss = 2.46516e-07
step 500: mean loss = 2.1305698e-07
step 600: mean loss = 1.9869844e-07
step 700: mean loss = 3.9675908e-07
step 800: mean loss = 3.8941025e-07
step 900: mean loss = 3.7342062e-07
step 1000: mean loss = 3.4712068e-07
step 1100: mean loss = 5.0473227e-07
step 1200: mean loss = 5.017322e-07
epoch 129: mean loss = 4.8514363e-07  learning rate = 5.1334195e-05
============================
Start of epoch 130
step 0: mean loss = 4.596317e-08
step 100: mean loss = 5.9420056e-08
step 200: mean loss = 5.473102e-08
step 300: mean loss = 6.072352e-08
step 400: mean loss = 7.764549e-08
step 500: mean loss = 7.854879e-08
step 600: mean loss = 7.4723424e-08
step 700: mean loss = 1.6342999e-07
step 800: mean loss = 2.3561469e-07
step 900: mean loss = 2.1978732e-07
step 1000: mean loss = 2.067297e-07
step 1100: mean loss = 2.0514187e-07
step 1200: mean loss = 1.9461288e-07
epoch 130: mean loss = 1.8938579e-07  learning rate = 5.1334195e-05
============================
Start of epoch 131
step 0: mean loss = 5.930397e-08
step 100: mean loss = 6.44103e-08
step 200: mean loss = 1.5164206e-07
step 300: mean loss = 1.6252524e-07
step 400: mean loss = 1.5037226e-07
step 500: mean loss = 1.5440484e-07
step 600: mean loss = 1.5135873e-07
step 700: mean loss = 1.5294681e-07
step 800: mean loss = 1.5317137e-07
step 900: mean loss = 1.9693852e-07
step 1000: mean loss = 1.9700322e-07
step 1100: mean loss = 1.9234956e-07
step 1200: mean loss = 1.9548817e-07
epoch 131: mean loss = 1.9108846e-07  learning rate = 5.1334195e-05
============================
Start of epoch 132
step 0: mean loss = 5.1291494e-08
step 100: mean loss = 5.011884e-07
step 200: mean loss = 7.355515e-07
step 300: mean loss = 5.11728e-07
step 400: mean loss = 4.0905448e-07
step 500: mean loss = 3.7841548e-07
step 600: mean loss = 3.4783727e-07
step 700: mean loss = 3.465854e-07
step 800: mean loss = 6.3589243e-07
step 900: mean loss = 5.752561e-07
step 1000: mean loss = 5.2636335e-07
step 1100: mean loss = 4.8946845e-07
step 1200: mean loss = 4.6449156e-07
epoch 132: mean loss = 4.4798944e-07  learning rate = 5.1334195e-05
============================
Start of epoch 133
step 0: mean loss = 5.747027e-08
step 100: mean loss = 2.2024629e-07
step 200: mean loss = 1.4698507e-07
step 300: mean loss = 3.5448377e-07
step 400: mean loss = 3.391606e-07
step 500: mean loss = 3.4213457e-07
step 600: mean loss = 3.07877e-07
step 700: mean loss = 2.7202253e-07
step 800: mean loss = 2.573768e-07
step 900: mean loss = 2.3722257e-07
step 1000: mean loss = 2.202458e-07
step 1100: mean loss = 2.0665789e-07
step 1200: mean loss = 2.3218423e-07
epoch 133: mean loss = 2.289133e-07  learning rate = 5.1334195e-05
============================
Start of epoch 134
step 0: mean loss = 6.2910466e-08
step 100: mean loss = 1.1363834e-07
step 200: mean loss = 3.146547e-07
step 300: mean loss = 3.3955527e-07
step 400: mean loss = 4.3182263e-07
step 500: mean loss = 3.6026847e-07
step 600: mean loss = 3.242066e-07
step 700: mean loss = 2.8506707e-07
step 800: mean loss = 2.5863153e-07
step 900: mean loss = 2.4465209e-07
step 1000: mean loss = 2.7780905e-07
step 1100: mean loss = 2.7255842e-07
step 1200: mean loss = 2.6655385e-07
epoch 134: mean loss = 2.608771e-07  learning rate = 5.1334195e-05
============================
Start of epoch 135
step 0: mean loss = 9.8978e-08
step 100: mean loss = 1.7010022e-07
step 200: mean loss = 1.9459925e-07
step 300: mean loss = 1.8123295e-07
step 400: mean loss = 1.6421747e-07
step 500: mean loss = 1.7194093e-07
step 600: mean loss = 1.9235748e-07
step 700: mean loss = 1.7804486e-07
step 800: mean loss = 1.6541813e-07
step 900: mean loss = 1.939541e-07
step 1000: mean loss = 2.2460151e-07
step 1100: mean loss = 2.6414594e-07
step 1200: mean loss = 2.8830013e-07
epoch 135: mean loss = 2.7935695e-07  learning rate = 5.1334195e-05
============================
Start of epoch 136
step 0: mean loss = 8.060865e-08
step 100: mean loss = 8.90678e-08
step 200: mean loss = 2.8924197e-07
step 300: mean loss = 3.480799e-07
step 400: mean loss = 2.826325e-07
step 500: mean loss = 2.448037e-07
step 600: mean loss = 2.5905024e-07
step 700: mean loss = 2.5497198e-07
step 800: mean loss = 2.3713245e-07
step 900: mean loss = 2.6029193e-07
step 1000: mean loss = 2.4545204e-07
step 1100: mean loss = 2.2956438e-07
step 1200: mean loss = 2.4533614e-07
epoch 136: mean loss = 3.472294e-07  learning rate = 5.1334195e-05
============================
Start of epoch 137
step 0: mean loss = 7.7270005e-07
step 100: mean loss = 1.3012847e-07
step 200: mean loss = 1.0390617e-07
step 300: mean loss = 8.400417e-08
step 400: mean loss = 5.2651296e-07
step 500: mean loss = 4.337198e-07
step 600: mean loss = 3.7765346e-07
step 700: mean loss = 3.3998322e-07
step 800: mean loss = 3.148571e-07
step 900: mean loss = 3.005502e-07
step 1000: mean loss = 2.7502335e-07
step 1100: mean loss = 2.5578498e-07
step 1200: mean loss = 2.442901e-07
epoch 137: mean loss = 2.383143e-07  learning rate = 5.1334195e-05
============================
Start of epoch 138
step 0: mean loss = 7.621052e-08
step 100: mean loss = 3.1367645e-07
step 200: mean loss = 2.0265352e-07
step 300: mean loss = 2.5800804e-07
step 400: mean loss = 2.2519968e-07
step 500: mean loss = 2.2008516e-07
step 600: mean loss = 1.9572295e-07
step 700: mean loss = 3.0616e-07
step 800: mean loss = 3.7464562e-07
step 900: mean loss = 3.4475403e-07
step 1000: mean loss = 3.16212e-07
step 1100: mean loss = 2.951078e-07
step 1200: mean loss = 2.7843174e-07
epoch 138: mean loss = 2.7377206e-07  learning rate = 5.1334195e-05
============================
Start of epoch 139
step 0: mean loss = 5.677291e-08
step 100: mean loss = 1.6256334e-07
step 200: mean loss = 1.8840862e-07
step 300: mean loss = 1.4096838e-07
step 400: mean loss = 1.1662455e-07
step 500: mean loss = 1.265077e-07
step 600: mean loss = 1.2399434e-07
step 700: mean loss = 1.234712e-07
step 800: mean loss = 1.3824828e-07
step 900: mean loss = 1.4604007e-07
step 1000: mean loss = 1.4649991e-07
step 1100: mean loss = 3.011277e-07
step 1200: mean loss = 2.996598e-07
epoch 139: mean loss = 2.906167e-07  learning rate = 4.876749e-05
============================
Start of epoch 140
step 0: mean loss = 1.668628e-07
step 100: mean loss = 1.1224125e-07
step 200: mean loss = 9.609897e-08
step 300: mean loss = 8.107709e-08
step 400: mean loss = 8.952152e-08
step 500: mean loss = 8.03898e-08
step 600: mean loss = 9.480034e-08
step 700: mean loss = 1.09285494e-07
step 800: mean loss = 1.1424992e-07
step 900: mean loss = 1.2184435e-07
step 1000: mean loss = 1.4301425e-07
step 1100: mean loss = 1.3871863e-07
step 1200: mean loss = 1.3320471e-07
epoch 140: mean loss = 1.3260275e-07  learning rate = 4.876749e-05
============================
Start of epoch 141
step 0: mean loss = 2.2681414e-08
step 100: mean loss = 2.9570828e-07
step 200: mean loss = 2.7027295e-07
step 300: mean loss = 2.7821005e-07
step 400: mean loss = 2.2852696e-07
step 500: mean loss = 2.558521e-07
step 600: mean loss = 3.2756105e-07
step 700: mean loss = 3.2523465e-07
step 800: mean loss = 2.931279e-07
step 900: mean loss = 2.698737e-07
step 1000: mean loss = 2.5543747e-07
step 1100: mean loss = 2.3715353e-07
step 1200: mean loss = 2.2954532e-07
epoch 141: mean loss = 2.224861e-07  learning rate = 4.876749e-05
============================
Start of epoch 142
step 0: mean loss = 5.0235343e-08
step 100: mean loss = 6.6504435e-07
step 200: mean loss = 4.5490964e-07
step 300: mean loss = 3.4873656e-07
step 400: mean loss = 2.7173033e-07
step 500: mean loss = 2.3137808e-07
step 600: mean loss = 2.3855844e-07
step 700: mean loss = 2.6431925e-07
step 800: mean loss = 2.4600956e-07
step 900: mean loss = 2.5186588e-07
step 1000: mean loss = 2.5830926e-07
step 1100: mean loss = 2.6791318e-07
step 1200: mean loss = 2.6894855e-07
epoch 142: mean loss = 2.6269024e-07  learning rate = 4.876749e-05
============================
Start of epoch 143
step 0: mean loss = 6.06232e-07
step 100: mean loss = 4.3686927e-07
step 200: mean loss = 2.8699557e-07
step 300: mean loss = 2.2149736e-07
step 400: mean loss = 2.56237e-07
step 500: mean loss = 2.2729553e-07
step 600: mean loss = 2.0786665e-07
step 700: mean loss = 1.9081666e-07
step 800: mean loss = 2.457322e-07
step 900: mean loss = 2.4807505e-07
step 1000: mean loss = 2.3475215e-07
step 1100: mean loss = 2.2201277e-07
step 1200: mean loss = 2.0863295e-07
epoch 143: mean loss = 2.0607949e-07  learning rate = 4.876749e-05
============================
Start of epoch 144
step 0: mean loss = 1.3162926e-07
step 100: mean loss = 7.3626296e-08
step 200: mean loss = 8.616525e-08
step 300: mean loss = 1.9505843e-07
step 400: mean loss = 3.2169982e-07
step 500: mean loss = 4.0955658e-07
step 600: mean loss = 3.4981582e-07
step 700: mean loss = 3.1547924e-07
step 800: mean loss = 2.8824593e-07
step 900: mean loss = 3.2907465e-07
step 1000: mean loss = 3.1067657e-07
step 1100: mean loss = 2.9272186e-07
step 1200: mean loss = 2.7761132e-07
epoch 144: mean loss = 2.7176017e-07  learning rate = 4.876749e-05
============================
Start of epoch 145
step 0: mean loss = 1.2668957e-07
step 100: mean loss = 1.4554922e-07
step 200: mean loss = 1.3139477e-07
step 300: mean loss = 1.2949279e-07
step 400: mean loss = 1.1738708e-07
step 500: mean loss = 1.18378686e-07
step 600: mean loss = 1.4604049e-07
step 700: mean loss = 1.4044086e-07
step 800: mean loss = 2.0475922e-07
step 900: mean loss = 2.6259409e-07
step 1000: mean loss = 2.4266353e-07
step 1100: mean loss = 2.2468686e-07
step 1200: mean loss = 2.1199456e-07
epoch 145: mean loss = 2.0758982e-07  learning rate = 4.876749e-05
============================
Start of epoch 146
step 0: mean loss = 8.309977e-08
step 100: mean loss = 8.356142e-08
step 200: mean loss = 1.06597035e-07
step 300: mean loss = 1.213471e-07
step 400: mean loss = 1.0579416e-07
step 500: mean loss = 1.8683846e-07
step 600: mean loss = 2.3989523e-07
step 700: mean loss = 2.2909967e-07
step 800: mean loss = 2.17556e-07
step 900: mean loss = 2.0253073e-07
step 1000: mean loss = 2.0074106e-07
step 1100: mean loss = 1.94117e-07
step 1200: mean loss = 1.9239106e-07
epoch 146: mean loss = 2.0074972e-07  learning rate = 4.876749e-05
============================
Start of epoch 147
step 0: mean loss = 6.176182e-07
step 100: mean loss = 7.80914e-07
step 200: mean loss = 4.5382777e-07
step 300: mean loss = 3.3535719e-07
step 400: mean loss = 2.7940075e-07
step 500: mean loss = 2.37915e-07
step 600: mean loss = 2.1488074e-07
step 700: mean loss = 2.2439124e-07
step 800: mean loss = 2.0755802e-07
step 900: mean loss = 2.0337244e-07
step 1000: mean loss = 1.9119021e-07
step 1100: mean loss = 2.6802547e-07
step 1200: mean loss = 3.9139152e-07
epoch 147: mean loss = 3.7962076e-07  learning rate = 4.876749e-05
============================
Start of epoch 148
step 0: mean loss = 3.693659e-08
step 100: mean loss = 5.041443e-08
step 200: mean loss = 7.617738e-08
step 300: mean loss = 6.7966916e-08
step 400: mean loss = 6.54252e-08
step 500: mean loss = 6.4958556e-08
step 600: mean loss = 6.102751e-08
step 700: mean loss = 6.2866484e-08
step 800: mean loss = 8.955218e-08
step 900: mean loss = 1.2890943e-07
step 1000: mean loss = 1.354873e-07
step 1100: mean loss = 1.3104187e-07
step 1200: mean loss = 1.3710515e-07
epoch 148: mean loss = 1.3368468e-07  learning rate = 4.876749e-05
============================
Start of epoch 149
step 0: mean loss = 3.5057717e-08
step 100: mean loss = 7.828337e-08
step 200: mean loss = 6.492179e-08
step 300: mean loss = 1.0930887e-07
step 400: mean loss = 1.6768495e-07
step 500: mean loss = 1.4861779e-07
step 600: mean loss = 2.4792422e-07
step 700: mean loss = 2.4285086e-07
step 800: mean loss = 2.2090354e-07
step 900: mean loss = 2.0138523e-07
step 1000: mean loss = 1.9418204e-07
step 1100: mean loss = 2.2589936e-07
step 1200: mean loss = 2.405995e-07
epoch 149: mean loss = 2.337864e-07  learning rate = 4.6329114e-05
============================
Start of epoch 150
step 0: mean loss = 3.1723754e-08
step 100: mean loss = 9.4006765e-08
step 200: mean loss = 1.2003343e-07
step 300: mean loss = 1.0258614e-07
step 400: mean loss = 1.2728978e-07
step 500: mean loss = 1.1983026e-07
step 600: mean loss = 2.9046996e-07
step 700: mean loss = 3.5688885e-07
step 800: mean loss = 3.1956893e-07
step 900: mean loss = 2.8943043e-07
step 1000: mean loss = 2.6983614e-07
step 1100: mean loss = 2.4964572e-07
step 1200: mean loss = 2.3450681e-07
epoch 150: mean loss = 2.3122224e-07  learning rate = 4.6329114e-05
============================
Start of epoch 151
step 0: mean loss = 6.076236e-08
step 100: mean loss = 3.1997266e-07
step 200: mean loss = 2.1010518e-07
step 300: mean loss = 1.5523798e-07
step 400: mean loss = 1.8848249e-07
step 500: mean loss = 1.7739202e-07
step 600: mean loss = 1.6594237e-07
step 700: mean loss = 1.7644277e-07
step 800: mean loss = 1.6508122e-07
step 900: mean loss = 1.5413917e-07
step 1000: mean loss = 1.6587207e-07
step 1100: mean loss = 1.6566388e-07
step 1200: mean loss = 1.6883381e-07
epoch 151: mean loss = 1.6699381e-07  learning rate = 4.6329114e-05
============================
Start of epoch 152
step 0: mean loss = 3.0363218e-08
step 100: mean loss = 4.880897e-08
step 200: mean loss = 5.8416754e-07
step 300: mean loss = 4.1777488e-07
step 400: mean loss = 3.6891217e-07
step 500: mean loss = 3.0427384e-07
step 600: mean loss = 2.6059715e-07
step 700: mean loss = 2.4261738e-07
step 800: mean loss = 2.2577997e-07
step 900: mean loss = 2.1675042e-07
step 1000: mean loss = 2.2399381e-07
step 1100: mean loss = 2.1871595e-07
step 1200: mean loss = 2.3604045e-07
epoch 152: mean loss = 2.2843085e-07  learning rate = 4.6329114e-05
============================
Start of epoch 153
step 0: mean loss = 1.5593182e-07
step 100: mean loss = 3.0246093e-07
step 200: mean loss = 1.75583e-07
step 300: mean loss = 1.559828e-07
step 400: mean loss = 1.475253e-07
step 500: mean loss = 1.3337622e-07
step 600: mean loss = 1.8055361e-07
step 700: mean loss = 1.8130514e-07
step 800: mean loss = 1.8108437e-07
step 900: mean loss = 1.7190153e-07
step 1000: mean loss = 1.882222e-07
step 1100: mean loss = 2.1970563e-07
step 1200: mean loss = 2.0684071e-07
epoch 153: mean loss = 2.0058123e-07  learning rate = 4.6329114e-05
============================
Start of epoch 154
step 0: mean loss = 5.0789094e-08
step 100: mean loss = 8.431118e-08
step 200: mean loss = 1.468268e-07
step 300: mean loss = 3.5408704e-07
step 400: mean loss = 1.4854888e-06
step 500: mean loss = 1.202651e-06
step 600: mean loss = 1.00869e-06
step 700: mean loss = 8.7038313e-07
step 800: mean loss = 7.6628095e-07
step 900: mean loss = 6.864795e-07
step 1000: mean loss = 6.2590266e-07
step 1100: mean loss = 5.721678e-07
step 1200: mean loss = 5.2721197e-07
epoch 154: mean loss = 5.078251e-07  learning rate = 4.6329114e-05
============================
Start of epoch 155
step 0: mean loss = 2.129005e-08
step 100: mean loss = 3.9371464e-08
step 200: mean loss = 5.41104e-08
step 300: mean loss = 5.8323543e-08
step 400: mean loss = 5.967535e-08
step 500: mean loss = 5.667475e-08
step 600: mean loss = 5.818973e-08
step 700: mean loss = 6.556282e-08
step 800: mean loss = 1.8845616e-07
step 900: mean loss = 1.7956985e-07
step 1000: mean loss = 1.6581836e-07
step 1100: mean loss = 1.5818037e-07
step 1200: mean loss = 1.4848156e-07
epoch 155: mean loss = 1.510214e-07  learning rate = 4.6329114e-05
============================
Start of epoch 156
step 0: mean loss = 1.0089691e-06
step 100: mean loss = 2.6273196e-07
step 200: mean loss = 1.5659103e-07
step 300: mean loss = 1.1995985e-07
step 400: mean loss = 1.64525e-07
step 500: mean loss = 1.4528258e-07
step 600: mean loss = 1.278609e-07
step 700: mean loss = 1.4848635e-07
step 800: mean loss = 1.9850185e-07
step 900: mean loss = 1.9003406e-07
step 1000: mean loss = 1.7840736e-07
step 1100: mean loss = 1.8536252e-07
step 1200: mean loss = 1.7521826e-07
epoch 156: mean loss = 1.8236693e-07  learning rate = 4.6329114e-05
============================
Start of epoch 157
step 0: mean loss = 2.9152488e-07
step 100: mean loss = 1.2993722e-07
step 200: mean loss = 1.9327835e-07
step 300: mean loss = 1.8672851e-07
step 400: mean loss = 1.5757082e-07
step 500: mean loss = 1.3604476e-07
step 600: mean loss = 1.3882466e-07
step 700: mean loss = 2.7771617e-07
step 800: mean loss = 3.2141736e-07
step 900: mean loss = 2.9012435e-07
step 1000: mean loss = 2.646094e-07
step 1100: mean loss = 2.4467803e-07
step 1200: mean loss = 2.2714272e-07
epoch 157: mean loss = 2.2073786e-07  learning rate = 4.6329114e-05
============================
Start of epoch 158
step 0: mean loss = 4.5378567e-08
step 100: mean loss = 1.5265375e-07
step 200: mean loss = 1.2212409e-07
step 300: mean loss = 1.0457839e-07
step 400: mean loss = 1.2141999e-07
step 500: mean loss = 2.6040624e-07
step 600: mean loss = 2.251203e-07
step 700: mean loss = 2.0211122e-07
step 800: mean loss = 1.9617208e-07
step 900: mean loss = 1.807691e-07
step 1000: mean loss = 1.7502099e-07
step 1100: mean loss = 1.6749493e-07
step 1200: mean loss = 1.5847911e-07
epoch 158: mean loss = 1.5472835e-07  learning rate = 4.6329114e-05
============================
Start of epoch 159
step 0: mean loss = 4.7224535e-07
step 100: mean loss = 1.2764283e-06
step 200: mean loss = 1.1646814e-06
step 300: mean loss = 8.163954e-07
step 400: mean loss = 6.242171e-07
step 500: mean loss = 5.0521203e-07
step 600: mean loss = 4.2597117e-07
step 700: mean loss = 3.7018341e-07
step 800: mean loss = 3.3874318e-07
step 900: mean loss = 3.264136e-07
step 1000: mean loss = 3.047928e-07
step 1100: mean loss = 2.9713956e-07
step 1200: mean loss = 2.8301955e-07
epoch 159: mean loss = 2.7506505e-07  learning rate = 4.4012657e-05
============================
Start of epoch 160
step 0: mean loss = 4.5280284e-08
step 100: mean loss = 1.12236165e-07
step 200: mean loss = 1.6771062e-07
step 300: mean loss = 2.4860412e-07
step 400: mean loss = 1.9841941e-07
step 500: mean loss = 1.6607719e-07
step 600: mean loss = 1.6533255e-07
step 700: mean loss = 1.4755005e-07
step 800: mean loss = 1.4234875e-07
step 900: mean loss = 1.3169965e-07
step 1000: mean loss = 1.2253587e-07
step 1100: mean loss = 1.2370639e-07
step 1200: mean loss = 1.2157217e-07
epoch 160: mean loss = 1.2234158e-07  learning rate = 4.4012657e-05
============================
Start of epoch 161
step 0: mean loss = 1.5510508e-07
step 100: mean loss = 9.380404e-08
step 200: mean loss = 1.2806743e-07
step 300: mean loss = 4.647231e-07
step 400: mean loss = 3.725531e-07
step 500: mean loss = 3.097935e-07
step 600: mean loss = 2.7846727e-07
step 700: mean loss = 2.5811553e-07
step 800: mean loss = 2.3168161e-07
step 900: mean loss = 2.1319812e-07
step 1000: mean loss = 1.9684126e-07
step 1100: mean loss = 2.81871e-07
step 1200: mean loss = 3.5061953e-07
epoch 161: mean loss = 3.3877404e-07  learning rate = 4.4012657e-05
============================
Start of epoch 162
step 0: mean loss = 1.8124707e-08
step 100: mean loss = 2.7608184e-08
step 200: mean loss = 3.1703212e-08
step 300: mean loss = 1.12766976e-07
step 400: mean loss = 1.2343735e-07
step 500: mean loss = 1.0510457e-07
step 600: mean loss = 9.7648e-08
step 700: mean loss = 9.312139e-08
step 800: mean loss = 9.991176e-08
step 900: mean loss = 9.416916e-08
step 1000: mean loss = 8.834596e-08
step 1100: mean loss = 1.2488151e-07
step 1200: mean loss = 1.2796828e-07
epoch 162: mean loss = 1.2474426e-07  learning rate = 4.4012657e-05
============================
Start of epoch 163
step 0: mean loss = 6.484959e-08
step 100: mean loss = 5.4358424e-08
step 200: mean loss = 1.8388918e-07
step 300: mean loss = 1.7073442e-07
step 400: mean loss = 1.4100951e-07
step 500: mean loss = 1.2096773e-07
step 600: mean loss = 1.1206865e-07
step 700: mean loss = 5.968203e-07
step 800: mean loss = 5.4336977e-07
step 900: mean loss = 4.870962e-07
step 1000: mean loss = 4.4067195e-07
step 1100: mean loss = 4.035905e-07
step 1200: mean loss = 3.7234497e-07
epoch 163: mean loss = 3.5905705e-07  learning rate = 4.4012657e-05
============================
Start of epoch 164
step 0: mean loss = 1.9548207e-08
step 100: mean loss = 4.190174e-08
step 200: mean loss = 6.002708e-08
step 300: mean loss = 5.1438874e-08
step 400: mean loss = 4.6198608e-08
step 500: mean loss = 4.782622e-08
step 600: mean loss = 4.996371e-08
step 700: mean loss = 6.0317824e-08
step 800: mean loss = 6.5812856e-08
step 900: mean loss = 6.738197e-08
step 1000: mean loss = 6.692234e-08
step 1100: mean loss = 6.761565e-08
step 1200: mean loss = 7.3202756e-08
epoch 164: mean loss = 1.07804276e-07  learning rate = 4.4012657e-05
============================
Start of epoch 165
step 0: mean loss = 5.547072e-07
step 100: mean loss = 9.500702e-07
step 200: mean loss = 5.451621e-07
step 300: mean loss = 3.88045e-07
step 400: mean loss = 3.0397723e-07
step 500: mean loss = 2.5285902e-07
step 600: mean loss = 2.374381e-07
step 700: mean loss = 2.1135122e-07
step 800: mean loss = 1.9275612e-07
step 900: mean loss = 1.8261467e-07
step 1000: mean loss = 1.8020245e-07
step 1100: mean loss = 1.7515683e-07
step 1200: mean loss = 1.6580663e-07
epoch 165: mean loss = 1.8573536e-07  learning rate = 4.4012657e-05
============================
Start of epoch 166
step 0: mean loss = 8.761999e-07
step 100: mean loss = 2.794653e-07
step 200: mean loss = 1.7082361e-07
step 300: mean loss = 1.9239089e-07
step 400: mean loss = 1.6497394e-07
step 500: mean loss = 1.5762818e-07
step 600: mean loss = 1.381892e-07
step 700: mean loss = 1.7129788e-07
step 800: mean loss = 1.5646586e-07
step 900: mean loss = 1.458354e-07
step 1000: mean loss = 1.3914732e-07
step 1100: mean loss = 1.9655945e-07
step 1200: mean loss = 1.9220056e-07
epoch 166: mean loss = 1.8861294e-07  learning rate = 4.4012657e-05
============================
Start of epoch 167
step 0: mean loss = 5.451103e-08
step 100: mean loss = 4.6098695e-08
step 200: mean loss = 3.8243886e-08
step 300: mean loss = 4.9002693e-08
step 400: mean loss = 5.5444154e-08
step 500: mean loss = 5.274862e-08
step 600: mean loss = 6.7584196e-08
step 700: mean loss = 8.935392e-08
step 800: mean loss = 1.2093557e-07
step 900: mean loss = 1.7489052e-07
step 1000: mean loss = 1.7988344e-07
step 1100: mean loss = 1.6670694e-07
step 1200: mean loss = 1.6115163e-07
epoch 167: mean loss = 1.7478773e-07  learning rate = 4.4012657e-05
============================
Start of epoch 168
step 0: mean loss = 8.638866e-07
step 100: mean loss = 2.3504646e-07
step 200: mean loss = 2.089653e-07
step 300: mean loss = 1.6054179e-07
step 400: mean loss = 1.5766672e-07
step 500: mean loss = 1.4877098e-07
step 600: mean loss = 1.4556554e-07
step 700: mean loss = 1.3579418e-07
step 800: mean loss = 1.4726471e-07
step 900: mean loss = 1.3478265e-07
step 1000: mean loss = 1.2657046e-07
step 1100: mean loss = 1.553888e-07
step 1200: mean loss = 3.100861e-07
epoch 168: mean loss = 3.0020894e-07  learning rate = 4.4012657e-05
============================
Start of epoch 169
step 0: mean loss = 4.0703412e-08
step 100: mean loss = 2.2172397e-08
step 200: mean loss = 2.1982792e-08
step 300: mean loss = 2.355112e-08
step 400: mean loss = 2.433007e-08
step 500: mean loss = 3.2623714e-08
step 600: mean loss = 3.6927215e-08
step 700: mean loss = 3.8002256e-08
step 800: mean loss = 4.6295046e-08
step 900: mean loss = 4.4276163e-08
step 1000: mean loss = 4.7768914e-08
step 1100: mean loss = 5.889031e-08
step 1200: mean loss = 8.2839875e-08
epoch 169: mean loss = 8.4993616e-08  learning rate = 4.181202e-05
============================
Start of epoch 170
step 0: mean loss = 7.834508e-08
step 100: mean loss = 5.383969e-08
step 200: mean loss = 1.13297794e-07
step 300: mean loss = 1.5578443e-07
step 400: mean loss = 1.730605e-07
step 500: mean loss = 1.5111414e-07
step 600: mean loss = 1.5565892e-07
step 700: mean loss = 1.4310727e-07
step 800: mean loss = 1.3131056e-07
step 900: mean loss = 1.2070686e-07
step 1000: mean loss = 1.1406733e-07
step 1100: mean loss = 1.15339645e-07
step 1200: mean loss = 1.12515664e-07
epoch 170: mean loss = 1.267731e-07  learning rate = 4.181202e-05
============================
Start of epoch 171
step 0: mean loss = 8.6536477e-07
step 100: mean loss = 6.9204674e-07
step 200: mean loss = 4.1000442e-07
step 300: mean loss = 2.8993068e-07
step 400: mean loss = 2.2823474e-07
step 500: mean loss = 1.9097814e-07
step 600: mean loss = 1.96562e-07
step 700: mean loss = 1.8159791e-07
step 800: mean loss = 1.7042272e-07
step 900: mean loss = 1.6755865e-07
step 1000: mean loss = 1.5800221e-07
step 1100: mean loss = 1.5933112e-07
step 1200: mean loss = 1.5748513e-07
epoch 171: mean loss = 1.5472824e-07  learning rate = 4.181202e-05
============================
Start of epoch 172
step 0: mean loss = 8.006879e-08
step 100: mean loss = 7.481816e-08
step 200: mean loss = 6.502031e-08
step 300: mean loss = 1.6685446e-07
step 400: mean loss = 1.5155345e-07
step 500: mean loss = 1.3023678e-07
step 600: mean loss = 1.16930295e-07
step 700: mean loss = 1.1035589e-07
step 800: mean loss = 1.1364784e-07
step 900: mean loss = 2.0338312e-07
step 1000: mean loss = 2.7076214e-07
step 1100: mean loss = 2.4910477e-07
step 1200: mean loss = 2.3096236e-07
epoch 172: mean loss = 2.233734e-07  learning rate = 4.181202e-05
============================
Start of epoch 173
step 0: mean loss = 4.8151765e-08
step 100: mean loss = 3.4633867e-08
step 200: mean loss = 3.8879314e-08
step 300: mean loss = 3.6883048e-08
step 400: mean loss = 4.830838e-08
step 500: mean loss = 6.366452e-08
step 600: mean loss = 6.2912044e-08
step 700: mean loss = 6.711771e-08
step 800: mean loss = 7.038735e-08
step 900: mean loss = 7.040498e-08
step 1000: mean loss = 7.800915e-08
step 1100: mean loss = 8.798628e-08
step 1200: mean loss = 8.436627e-08
epoch 173: mean loss = 8.600389e-08  learning rate = 4.181202e-05
============================
Start of epoch 174
step 0: mean loss = 6.346233e-08
step 100: mean loss = 9.653198e-08
step 200: mean loss = 1.6568586e-07
step 300: mean loss = 3.4225e-07
step 400: mean loss = 2.654913e-07
step 500: mean loss = 2.2726935e-07
step 600: mean loss = 1.956475e-07
step 700: mean loss = 1.7686529e-07
step 800: mean loss = 1.6683997e-07
step 900: mean loss = 1.5427848e-07
step 1000: mean loss = 1.4384406e-07
step 1100: mean loss = 1.4845311e-07
step 1200: mean loss = 1.4784177e-07
epoch 174: mean loss = 1.4450151e-07  learning rate = 4.181202e-05
============================
Start of epoch 175
step 0: mean loss = 3.0834997e-08
step 100: mean loss = 6.336807e-08
step 200: mean loss = 6.164726e-08
step 300: mean loss = 2.0636557e-07
step 400: mean loss = 2.4556942e-07
step 500: mean loss = 2.1617925e-07
step 600: mean loss = 2.0106778e-07
step 700: mean loss = 1.9501134e-07
step 800: mean loss = 1.7872217e-07
step 900: mean loss = 1.660446e-07
step 1000: mean loss = 1.6232278e-07
step 1100: mean loss = 1.5721396e-07
step 1200: mean loss = 1.6358915e-07
epoch 175: mean loss = 1.9389427e-07  learning rate = 4.181202e-05
============================
Start of epoch 176
step 0: mean loss = 4.1374815e-07
step 100: mean loss = 1.3823967e-07
step 200: mean loss = 1.05591255e-07
step 300: mean loss = 9.027947e-08
step 400: mean loss = 7.875746e-08
step 500: mean loss = 6.990474e-08
step 600: mean loss = 6.9011605e-08
step 700: mean loss = 8.816749e-08
step 800: mean loss = 9.082109e-08
step 900: mean loss = 1.06840744e-07
step 1000: mean loss = 9.8973295e-08
step 1100: mean loss = 1.0036558e-07
step 1200: mean loss = 9.866219e-08
epoch 176: mean loss = 1.0940706e-07  learning rate = 4.181202e-05
============================
Start of epoch 177
step 0: mean loss = 1.4135733e-07
step 100: mean loss = 1.2681036e-07
step 200: mean loss = 8.1767546e-08
step 300: mean loss = 9.303448e-08
step 400: mean loss = 1.8191471e-07
step 500: mean loss = 1.6519154e-07
step 600: mean loss = 1.491744e-07
step 700: mean loss = 1.3819478e-07
step 800: mean loss = 1.3174991e-07
step 900: mean loss = 1.2042655e-07
step 1000: mean loss = 1.2031995e-07
step 1100: mean loss = 1.3498574e-07
step 1200: mean loss = 1.3842444e-07
epoch 177: mean loss = 1.400149e-07  learning rate = 4.181202e-05
============================
Start of epoch 178
step 0: mean loss = 1.4102915e-07
step 100: mean loss = 6.042534e-08
step 200: mean loss = 1.4801029e-07
step 300: mean loss = 1.4009804e-07
step 400: mean loss = 1.2701011e-07
step 500: mean loss = 1.0830326e-07
step 600: mean loss = 1.02304234e-07
step 700: mean loss = 9.8765334e-08
step 800: mean loss = 1.5059005e-07
step 900: mean loss = 1.5131994e-07
step 1000: mean loss = 1.6123934e-07
step 1100: mean loss = 1.4912199e-07
step 1200: mean loss = 1.4228789e-07
epoch 178: mean loss = 1.3883006e-07  learning rate = 4.181202e-05
============================
Start of epoch 179
step 0: mean loss = 2.8161864e-08
step 100: mean loss = 3.671953e-08
step 200: mean loss = 2.7081606e-07
step 300: mean loss = 2.3428395e-07
step 400: mean loss = 1.9872166e-07
step 500: mean loss = 2.4498783e-07
step 600: mean loss = 2.1822314e-07
step 700: mean loss = 1.9477936e-07
step 800: mean loss = 1.7677309e-07
step 900: mean loss = 1.6340226e-07
step 1000: mean loss = 1.576568e-07
step 1100: mean loss = 1.4823232e-07
step 1200: mean loss = 1.53111e-07
epoch 179: mean loss = 1.5566992e-07  learning rate = 3.972142e-05
============================
Start of epoch 180
step 0: mean loss = 2.2819716e-08
step 100: mean loss = 2.1349052e-07
step 200: mean loss = 1.5712364e-07
step 300: mean loss = 1.3540436e-07
step 400: mean loss = 1.4660459e-07
step 500: mean loss = 1.4673367e-07
step 600: mean loss = 1.2815995e-07
step 700: mean loss = 1.26942e-07
step 800: mean loss = 1.2191505e-07
step 900: mean loss = 1.1219658e-07
step 1000: mean loss = 1.1310919e-07
step 1100: mean loss = 1.064281e-07
step 1200: mean loss = 1.0570379e-07
epoch 180: mean loss = 1.0762918e-07  learning rate = 3.972142e-05
============================
Start of epoch 181
step 0: mean loss = 1.6256043e-07
step 100: mean loss = 2.4819312e-07
step 200: mean loss = 1.5379133e-07
step 300: mean loss = 1.2452182e-07
step 400: mean loss = 1.065478e-07
step 500: mean loss = 1.10645125e-07
step 600: mean loss = 2.5735645e-07
step 700: mean loss = 2.3347427e-07
step 800: mean loss = 2.0876702e-07
step 900: mean loss = 1.89242e-07
step 1000: mean loss = 1.7515237e-07
step 1100: mean loss = 1.6418377e-07
step 1200: mean loss = 1.5323657e-07
epoch 181: mean loss = 1.5003981e-07  learning rate = 3.972142e-05
============================
Start of epoch 182
step 0: mean loss = 5.072323e-08
step 100: mean loss = 9.145304e-08
step 200: mean loss = 1.8496317e-07
step 300: mean loss = 1.5006842e-07
step 400: mean loss = 1.1958748e-07
step 500: mean loss = 1.2389035e-07
step 600: mean loss = 1.3386014e-07
step 700: mean loss = 1.2903661e-07
step 800: mean loss = 1.2057666e-07
step 900: mean loss = 1.4133593e-07
step 1000: mean loss = 1.3504152e-07
step 1100: mean loss = 1.2917711e-07
step 1200: mean loss = 1.4257937e-07
epoch 182: mean loss = 1.4457389e-07  learning rate = 3.972142e-05
============================
Start of epoch 183
step 0: mean loss = 1.7453235e-08
step 100: mean loss = 4.862278e-08
step 200: mean loss = 1.2381234e-07
step 300: mean loss = 1.13533055e-07
step 400: mean loss = 9.459935e-08
step 500: mean loss = 8.3886164e-08
step 600: mean loss = 1.1981476e-07
step 700: mean loss = 1.2697537e-07
step 800: mean loss = 1.2814293e-07
step 900: mean loss = 1.218977e-07
step 1000: mean loss = 1.1245067e-07
step 1100: mean loss = 1.10865436e-07
step 1200: mean loss = 1.0751545e-07
epoch 183: mean loss = 1.04727526e-07  learning rate = 3.972142e-05
============================
Start of epoch 184
step 0: mean loss = 1.6461971e-08
step 100: mean loss = 3.9523822e-08
step 200: mean loss = 5.563818e-08
step 300: mean loss = 2.8813403e-07
step 400: mean loss = 2.377501e-07
step 500: mean loss = 1.961733e-07
step 600: mean loss = 1.7632358e-07
step 700: mean loss = 3.3484756e-07
step 800: mean loss = 3.2407328e-07
step 900: mean loss = 2.9046282e-07
step 1000: mean loss = 2.6393414e-07
step 1100: mean loss = 2.4214143e-07
step 1200: mean loss = 2.2500241e-07
epoch 184: mean loss = 2.173717e-07  learning rate = 3.972142e-05
============================
Start of epoch 185
step 0: mean loss = 1.2944045e-08
step 100: mean loss = 3.2862662e-08
step 200: mean loss = 4.950477e-08
step 300: mean loss = 4.5884835e-08
step 400: mean loss = 4.754981e-08
step 500: mean loss = 4.8585648e-08
step 600: mean loss = 5.4764875e-08
step 700: mean loss = 5.841602e-08
step 800: mean loss = 5.995441e-08
step 900: mean loss = 5.8181218e-08
step 1000: mean loss = 7.095752e-08
step 1100: mean loss = 8.452076e-08
step 1200: mean loss = 9.686433e-08
epoch 185: mean loss = 9.7267765e-08  learning rate = 3.972142e-05
============================
Start of epoch 186
step 0: mean loss = 4.581714e-08
step 100: mean loss = 2.0114531e-07
step 200: mean loss = 1.2014885e-07
step 300: mean loss = 1.2741766e-07
step 400: mean loss = 1.17247104e-07
step 500: mean loss = 1.1385647e-07
step 600: mean loss = 1.1143093e-07
step 700: mean loss = 1.3687466e-07
step 800: mean loss = 1.3074076e-07
step 900: mean loss = 1.2003537e-07
step 1000: mean loss = 1.109679e-07
step 1100: mean loss = 1.0662358e-07
step 1200: mean loss = 1.0970161e-07
epoch 186: mean loss = 1.2920171e-07  learning rate = 3.972142e-05
============================
Start of epoch 187
step 0: mean loss = 3.4245102e-07
step 100: mean loss = 9.092685e-08
step 200: mean loss = 7.136544e-08
step 300: mean loss = 7.762671e-08
step 400: mean loss = 8.2647034e-08
step 500: mean loss = 7.5860605e-08
step 600: mean loss = 8.9243855e-08
step 700: mean loss = 2.040233e-07
step 800: mean loss = 2.1702408e-07
step 900: mean loss = 1.9635408e-07
step 1000: mean loss = 1.7897968e-07
step 1100: mean loss = 1.6621753e-07
step 1200: mean loss = 1.6088302e-07
epoch 187: mean loss = 1.5636778e-07  learning rate = 3.972142e-05
============================
Start of epoch 188
step 0: mean loss = 4.402391e-08
step 100: mean loss = 5.6780106e-08
step 200: mean loss = 6.245686e-08
step 300: mean loss = 5.4635407e-08
step 400: mean loss = 5.775912e-08
step 500: mean loss = 7.7349846e-08
step 600: mean loss = 1.1528284e-07
step 700: mean loss = 1.2767308e-07
step 800: mean loss = 1.2612438e-07
step 900: mean loss = 1.2724355e-07
step 1000: mean loss = 1.5467232e-07
step 1100: mean loss = 1.4728298e-07
step 1200: mean loss = 1.3696827e-07
epoch 188: mean loss = 1.3242632e-07  learning rate = 3.972142e-05
============================
Start of epoch 189
step 0: mean loss = 1.013232e-08
step 100: mean loss = 6.485271e-08
step 200: mean loss = 6.4110786e-08
step 300: mean loss = 6.172575e-08
step 400: mean loss = 6.9225e-08
step 500: mean loss = 7.2024775e-08
step 600: mean loss = 6.8983084e-08
step 700: mean loss = 1.0835927e-07
step 800: mean loss = 1.3408417e-07
step 900: mean loss = 1.2726184e-07
step 1000: mean loss = 1.17979816e-07
step 1100: mean loss = 1.1856146e-07
step 1200: mean loss = 1.1737845e-07
epoch 189: mean loss = 1.18328515e-07  learning rate = 3.773535e-05
============================
Start of epoch 190
step 0: mean loss = 1.8200135e-08
step 100: mean loss = 5.9407476e-08
step 200: mean loss = 1.2318546e-07
step 300: mean loss = 9.857999e-08
step 400: mean loss = 9.178686e-08
step 500: mean loss = 8.067038e-08
step 600: mean loss = 1.14692206e-07
step 700: mean loss = 1.1047657e-07
step 800: mean loss = 1.0501136e-07
step 900: mean loss = 1.0124106e-07
step 1000: mean loss = 1.0280909e-07
step 1100: mean loss = 9.997877e-08
step 1200: mean loss = 1.2788549e-07
epoch 190: mean loss = 1.3841924e-07  learning rate = 3.773535e-05
============================
Start of epoch 191
step 0: mean loss = 6.7169125e-08
step 100: mean loss = 9.243233e-08
step 200: mean loss = 8.682397e-08
step 300: mean loss = 8.168533e-08
step 400: mean loss = 8.425759e-08
step 500: mean loss = 8.561116e-08
step 600: mean loss = 8.0944886e-08
step 700: mean loss = 7.772481e-08
step 800: mean loss = 7.9875115e-08
step 900: mean loss = 8.3563464e-08
step 1000: mean loss = 7.910641e-08
step 1100: mean loss = 7.38874e-08
step 1200: mean loss = 7.341244e-08
epoch 191: mean loss = 7.3104e-08  learning rate = 3.773535e-05
============================
Start of epoch 192
step 0: mean loss = 2.4030555e-08
step 100: mean loss = 1.3722861e-07
step 200: mean loss = 2.9321134e-07
step 300: mean loss = 2.1671403e-07
step 400: mean loss = 1.726464e-07
step 500: mean loss = 1.6942973e-07
step 600: mean loss = 1.6039758e-07
step 700: mean loss = 1.445075e-07
step 800: mean loss = 1.2927264e-07
step 900: mean loss = 1.2145439e-07
step 1000: mean loss = 1.16488486e-07
step 1100: mean loss = 1.1438873e-07
step 1200: mean loss = 1.5568646e-07
epoch 192: mean loss = 1.5800717e-07  learning rate = 3.773535e-05
============================
Start of epoch 193
step 0: mean loss = 1.03407444e-07
step 100: mean loss = 3.487915e-08
step 200: mean loss = 4.6358682e-08
step 300: mean loss = 4.7162544e-08
step 400: mean loss = 5.6284076e-08
step 500: mean loss = 5.256617e-08
step 600: mean loss = 5.2886556e-08
step 700: mean loss = 4.9789286e-08
step 800: mean loss = 6.973592e-08
step 900: mean loss = 6.789461e-08
step 1000: mean loss = 6.766466e-08
step 1100: mean loss = 7.5146765e-08
step 1200: mean loss = 7.177611e-08
epoch 193: mean loss = 7.265472e-08  learning rate = 3.773535e-05
============================
Start of epoch 194
step 0: mean loss = 2.2423224e-07
step 100: mean loss = 1.005582e-07
step 200: mean loss = 3.9385475e-07
step 300: mean loss = 2.7999482e-07
step 400: mean loss = 2.1926067e-07
step 500: mean loss = 1.8457447e-07
step 600: mean loss = 1.6043317e-07
step 700: mean loss = 1.4258259e-07
step 800: mean loss = 1.4146606e-07
step 900: mean loss = 1.5220063e-07
step 1000: mean loss = 1.4110323e-07
step 1100: mean loss = 1.3577339e-07
step 1200: mean loss = 1.2806034e-07
epoch 194: mean loss = 1.2499677e-07  learning rate = 3.773535e-05
============================
Start of epoch 195
step 0: mean loss = 5.067131e-08
step 100: mean loss = 3.1924518e-08
step 200: mean loss = 3.6187217e-08
step 300: mean loss = 5.551607e-08
step 400: mean loss = 6.627241e-08
step 500: mean loss = 1.5774457e-07
step 600: mean loss = 1.4348355e-07
step 700: mean loss = 1.6494135e-07
step 800: mean loss = 1.471353e-07
step 900: mean loss = 1.3643222e-07
step 1000: mean loss = 1.2848973e-07
step 1100: mean loss = 1.2279307e-07
step 1200: mean loss = 1.2116021e-07
epoch 195: mean loss = 1.3308834e-07  learning rate = 3.773535e-05
============================
Start of epoch 196
step 0: mean loss = 3.9096967e-08
step 100: mean loss = 4.927678e-08
step 200: mean loss = 3.743412e-08
step 300: mean loss = 5.4825883e-08
step 400: mean loss = 1.9440712e-07
step 500: mean loss = 2.0175048e-07
step 600: mean loss = 1.7599382e-07
step 700: mean loss = 1.5435948e-07
step 800: mean loss = 1.4081424e-07
step 900: mean loss = 1.3742059e-07
step 1000: mean loss = 1.272033e-07
step 1100: mean loss = 1.2182161e-07
step 1200: mean loss = 1.15972874e-07
epoch 196: mean loss = 1.1287093e-07  learning rate = 3.773535e-05
============================
Start of epoch 197
step 0: mean loss = 6.1117944e-08
step 100: mean loss = 1.4375411e-07
step 200: mean loss = 8.8343675e-08
step 300: mean loss = 6.6270935e-08
step 400: mean loss = 6.3072115e-08
step 500: mean loss = 1.3448226e-07
step 600: mean loss = 1.3108189e-07
step 700: mean loss = 1.1837762e-07
step 800: mean loss = 1.14085445e-07
step 900: mean loss = 1.07350786e-07
step 1000: mean loss = 1.6662148e-07
step 1100: mean loss = 1.8260472e-07
step 1200: mean loss = 1.7291681e-07
epoch 197: mean loss = 1.6738409e-07  learning rate = 3.773535e-05
============================
Start of epoch 198
step 0: mean loss = 5.5834754e-08
step 100: mean loss = 2.7467301e-08
step 200: mean loss = 3.0213602e-08
step 300: mean loss = 3.2647595e-08
step 400: mean loss = 4.0876515e-08
step 500: mean loss = 4.9481628e-08
step 600: mean loss = 4.5672486e-08
step 700: mean loss = 4.6259416e-08
step 800: mean loss = 5.3334862e-08
step 900: mean loss = 5.3508636e-08
step 1000: mean loss = 7.937685e-08
step 1100: mean loss = 7.852719e-08
step 1200: mean loss = 7.447587e-08
epoch 198: mean loss = 7.2888724e-08  learning rate = 3.773535e-05
============================
Start of epoch 199
step 0: mean loss = 1.2450575e-08
step 100: mean loss = 4.1580982e-08
step 200: mean loss = 3.786373e-08
step 300: mean loss = 3.811995e-08
step 400: mean loss = 8.068299e-08
step 500: mean loss = 3.9152633e-07
step 600: mean loss = 4.130168e-07
step 700: mean loss = 3.5734817e-07
step 800: mean loss = 3.1653474e-07
step 900: mean loss = 2.8333974e-07
step 1000: mean loss = 2.577691e-07
step 1100: mean loss = 2.36583e-07
step 1200: mean loss = 2.1934822e-07
epoch 199: mean loss = 2.1188066e-07  learning rate = 3.5848585e-05
saving the weights
++++++++++++++++++++++++++++++
Start of cycle 1
Total number of epochs in this cycle: 400
Batch size in this cycle: 16
============================
Start of epoch 0
step 0: mean loss = 1.10044276e-07
step 100: mean loss = 2.5383043e-08
step 200: mean loss = 2.1677218e-08
step 300: mean loss = 2.0233564e-08
step 400: mean loss = 1.9160758e-08
step 500: mean loss = 1.8901341e-08
step 600: mean loss = 1.8638326e-08
epoch 0: mean loss = 1.8778675e-08  learning rate = 3.5848585e-05
============================
Start of epoch 1
step 0: mean loss = 8.000423e-08
step 100: mean loss = 2.2051468e-08
step 200: mean loss = 1.9909109e-08
step 300: mean loss = 2.2743016e-08
step 400: mean loss = 6.651382e-08
step 500: mean loss = 6.453388e-08
step 600: mean loss = 5.7908824e-08
epoch 1: mean loss = 5.6388263e-08  learning rate = 3.5848585e-05
============================
Start of epoch 2
step 0: mean loss = 2.7819414e-08
step 100: mean loss = 6.6791316e-08
step 200: mean loss = 4.8267303e-08
step 300: mean loss = 4.0302872e-08
step 400: mean loss = 3.9242487e-08
step 500: mean loss = 4.878803e-08
step 600: mean loss = 1.5958166e-07
epoch 2: mean loss = 2.4288602e-07  learning rate = 3.5848585e-05
============================
Start of epoch 3
step 0: mean loss = 1.0234544e-06
step 100: mean loss = 1.9041298e-07
step 200: mean loss = 1.0496075e-07
step 300: mean loss = 7.5168956e-08
step 400: mean loss = 5.9889e-08
step 500: mean loss = 5.1337015e-08
step 600: mean loss = 4.6523645e-08
epoch 3: mean loss = 4.5301555e-08  learning rate = 3.5848585e-05
============================
Start of epoch 4
step 0: mean loss = 1.07336104e-08
step 100: mean loss = 1.8273598e-08
step 200: mean loss = 1.597841e-08
step 300: mean loss = 1.6207089e-08
step 400: mean loss = 1.5817914e-08
step 500: mean loss = 1.875245e-08
step 600: mean loss = 1.9719074e-08
epoch 4: mean loss = 2.0328288e-08  learning rate = 3.5848585e-05
============================
Start of epoch 5
step 0: mean loss = 1.5745382e-08
step 100: mean loss = 4.6875673e-08
step 200: mean loss = 4.3313126e-08
step 300: mean loss = 3.680681e-08
step 400: mean loss = 3.4203815e-08
step 500: mean loss = 4.1394312e-08
step 600: mean loss = 5.013555e-08
epoch 5: mean loss = 4.9787452e-08  learning rate = 3.5848585e-05
============================
Start of epoch 6
step 0: mean loss = 1.8254212e-08
step 100: mean loss = 3.9653262e-08
step 200: mean loss = 6.9703894e-08
step 300: mean loss = 1.1969658e-07
step 400: mean loss = 9.50309e-08
step 500: mean loss = 8.052545e-08
step 600: mean loss = 7.408877e-08
epoch 6: mean loss = 7.203515e-08  learning rate = 3.5848585e-05
============================
Start of epoch 7
step 0: mean loss = 2.3706772e-08
step 100: mean loss = 2.1082212e-08
step 200: mean loss = 3.1971677e-08
step 300: mean loss = 7.14365e-08
step 400: mean loss = 7.311766e-08
step 500: mean loss = 6.446975e-08
step 600: mean loss = 5.8578426e-08
epoch 7: mean loss = 5.7792214e-08  learning rate = 3.5848585e-05
============================
Start of epoch 8
step 0: mean loss = 3.8077214e-08
step 100: mean loss = 5.7373153e-08
step 200: mean loss = 3.8838692e-08
step 300: mean loss = 3.519223e-08
step 400: mean loss = 3.5796624e-08
step 500: mean loss = 3.643555e-08
step 600: mean loss = 4.6649227e-08
epoch 8: mean loss = 4.8372588e-08  learning rate = 3.5848585e-05
============================
Start of epoch 9
step 0: mean loss = 4.343395e-08
step 100: mean loss = 5.1712735e-08
step 200: mean loss = 6.4535854e-08
step 300: mean loss = 5.660672e-08
step 400: mean loss = 5.0981328e-08
step 500: mean loss = 5.1823864e-08
step 600: mean loss = 6.959704e-08
epoch 9: mean loss = 6.779353e-08  learning rate = 3.5848585e-05
============================
Start of epoch 10
step 0: mean loss = 1.5687002e-08
step 100: mean loss = 4.2519634e-08
step 200: mean loss = 3.7535603e-08
step 300: mean loss = 3.8776673e-08
step 400: mean loss = 4.6178016e-08
step 500: mean loss = 4.313668e-08
step 600: mean loss = 4.1150713e-08
epoch 10: mean loss = 4.838032e-08  learning rate = 3.5848585e-05
============================
Start of epoch 11
step 0: mean loss = 1.0902895e-06
step 100: mean loss = 1.1047935e-07
step 200: mean loss = 7.001882e-08
step 300: mean loss = 7.914009e-08
step 400: mean loss = 6.891227e-08
step 500: mean loss = 6.537644e-08
step 600: mean loss = 6.0616884e-08
epoch 11: mean loss = 5.8911596e-08  learning rate = 3.5848585e-05
============================
Start of epoch 12
step 0: mean loss = 4.8132414e-08
step 100: mean loss = 1.199046e-07
step 200: mean loss = 2.8051556e-07
step 300: mean loss = 1.9416186e-07
step 400: mean loss = 1.504013e-07
step 500: mean loss = 1.2445435e-07
step 600: mean loss = 1.0781014e-07
epoch 12: mean loss = 1.0432532e-07  learning rate = 3.5848585e-05
============================
Start of epoch 13
step 0: mean loss = 2.376488e-08
step 100: mean loss = 3.246527e-08
step 200: mean loss = 3.732013e-08
step 300: mean loss = 3.849436e-08
step 400: mean loss = 3.8463185e-08
step 500: mean loss = 3.8867302e-08
step 600: mean loss = 3.77284e-08
epoch 13: mean loss = 3.7112688e-08  learning rate = 3.5848585e-05
============================
Start of epoch 14
step 0: mean loss = 1.628319e-08
step 100: mean loss = 1.2315489e-07
step 200: mean loss = 8.6147516e-08
step 300: mean loss = 8.086229e-08
step 400: mean loss = 6.823967e-08
step 500: mean loss = 6.467034e-08
step 600: mean loss = 6.766563e-08
epoch 14: mean loss = 6.7281455e-08  learning rate = 3.5848585e-05
============================
Start of epoch 15
step 0: mean loss = 4.855542e-08
step 100: mean loss = 3.384019e-08
step 200: mean loss = 4.8769344e-08
step 300: mean loss = 4.2442178e-08
step 400: mean loss = 5.689415e-08
step 500: mean loss = 5.1102486e-08
step 600: mean loss = 4.896509e-08
epoch 15: mean loss = 4.9167564e-08  learning rate = 3.5848585e-05
============================
Start of epoch 16
step 0: mean loss = 2.4694803e-08
step 100: mean loss = 2.4078957e-08
step 200: mean loss = 1.9369573e-07
step 300: mean loss = 1.7770688e-07
step 400: mean loss = 1.3817586e-07
step 500: mean loss = 1.17300125e-07
step 600: mean loss = 1.0118787e-07
epoch 16: mean loss = 9.815551e-08  learning rate = 3.5848585e-05
============================
Start of epoch 17
step 0: mean loss = 2.1290868e-08
step 100: mean loss = 3.4155324e-08
step 200: mean loss = 2.9493963e-08
step 300: mean loss = 2.6574146e-08
step 400: mean loss = 5.714318e-08
step 500: mean loss = 5.644783e-08
step 600: mean loss = 5.077714e-08
epoch 17: mean loss = 5.1893295e-08  learning rate = 3.5848585e-05
============================
Start of epoch 18
step 0: mean loss = 2.920828e-08
step 100: mean loss = 1.6831253e-08
step 200: mean loss = 3.5348585e-08
step 300: mean loss = 9.595702e-08
step 400: mean loss = 8.122525e-08
step 500: mean loss = 7.593515e-08
step 600: mean loss = 6.603524e-08
epoch 18: mean loss = 6.4588754e-08  learning rate = 3.5848585e-05
============================
Start of epoch 19
step 0: mean loss = 2.4089228e-08
step 100: mean loss = 2.3056995e-08
step 200: mean loss = 4.7857185e-08
step 300: mean loss = 5.0104536e-08
step 400: mean loss = 5.0707854e-08
step 500: mean loss = 4.4668194e-08
step 600: mean loss = 5.2343015e-08
epoch 19: mean loss = 6.284671e-08  learning rate = 3.4056153e-05
============================
Start of epoch 20
step 0: mean loss = 1.2705057e-07
step 100: mean loss = 1.5298069e-07
step 200: mean loss = 8.603218e-08
step 300: mean loss = 6.724278e-08
step 400: mean loss = 5.4953773e-08
step 500: mean loss = 4.854688e-08
step 600: mean loss = 4.3395254e-08
epoch 20: mean loss = 4.555158e-08  learning rate = 3.4056153e-05
============================
Start of epoch 21
step 0: mean loss = 1.430233e-07
step 100: mean loss = 4.0255262e-08
step 200: mean loss = 6.941306e-08
step 300: mean loss = 8.597678e-08
step 400: mean loss = 6.931398e-08
step 500: mean loss = 5.9305894e-08
step 600: mean loss = 6.2697765e-08
epoch 21: mean loss = 6.093024e-08  learning rate = 3.4056153e-05
============================
Start of epoch 22
step 0: mean loss = 1.8959323e-08
step 100: mean loss = 5.3805568e-08
step 200: mean loss = 4.4164405e-08
step 300: mean loss = 3.810557e-08
step 400: mean loss = 3.7763492e-08
step 500: mean loss = 4.1280714e-08
step 600: mean loss = 4.119387e-08
epoch 22: mean loss = 4.2837584e-08  learning rate = 3.4056153e-05
============================
Start of epoch 23
step 0: mean loss = 4.297197e-08
step 100: mean loss = 1.8404369e-07
step 200: mean loss = 1.2473058e-07
step 300: mean loss = 9.343639e-08
step 400: mean loss = 7.474127e-08
step 500: mean loss = 7.091571e-08
step 600: mean loss = 6.2113436e-08
epoch 23: mean loss = 6.045039e-08  learning rate = 3.4056153e-05
============================
Start of epoch 24
step 0: mean loss = 8.71047e-09
step 100: mean loss = 2.8376198e-07
step 200: mean loss = 2.1207764e-07
step 300: mean loss = 1.4640226e-07
step 400: mean loss = 1.1492892e-07
step 500: mean loss = 9.5529316e-08
step 600: mean loss = 8.544542e-08
epoch 24: mean loss = 8.289384e-08  learning rate = 3.4056153e-05
============================
Start of epoch 25
step 0: mean loss = 1.41909435e-08
step 100: mean loss = 3.750876e-08
step 200: mean loss = 2.9870215e-08
step 300: mean loss = 4.6673062e-08
step 400: mean loss = 4.297844e-08
step 500: mean loss = 4.3365162e-08
step 600: mean loss = 7.5453464e-08
epoch 25: mean loss = 7.325949e-08  learning rate = 3.4056153e-05
============================
Start of epoch 26
step 0: mean loss = 1.7969423e-08
step 100: mean loss = 2.5812302e-08
step 200: mean loss = 2.8663893e-08
step 300: mean loss = 2.4864105e-08
step 400: mean loss = 2.5789072e-08
step 500: mean loss = 3.043539e-08
step 600: mean loss = 2.806598e-08
epoch 26: mean loss = 2.795643e-08  learning rate = 3.4056153e-05
============================
Start of epoch 27
step 0: mean loss = 7.399187e-08
step 100: mean loss = 4.4547764e-07
step 200: mean loss = 2.3231907e-07
step 300: mean loss = 1.6186782e-07
step 400: mean loss = 1.2837832e-07
step 500: mean loss = 1.0643531e-07
step 600: mean loss = 9.286926e-08
epoch 27: mean loss = 9.054701e-08  learning rate = 3.4056153e-05
============================
Start of epoch 28
step 0: mean loss = 1.1809904e-08
step 100: mean loss = 1.7649356e-08
step 200: mean loss = 1.5760033e-08
step 300: mean loss = 2.2262222e-08
step 400: mean loss = 2.7293222e-08
step 500: mean loss = 3.7471384e-08
step 600: mean loss = 3.724138e-08
epoch 28: mean loss = 3.6718372e-08  learning rate = 3.4056153e-05
============================
Start of epoch 29
step 0: mean loss = 3.14412e-08
step 100: mean loss = 5.0976286e-08
step 200: mean loss = 5.1050908e-08
step 300: mean loss = 4.629995e-08
step 400: mean loss = 4.582995e-08
step 500: mean loss = 4.2540663e-08
step 600: mean loss = 4.366198e-08
epoch 29: mean loss = 4.287518e-08  learning rate = 3.4056153e-05
============================
Start of epoch 30
step 0: mean loss = 2.5807555e-08
step 100: mean loss = 6.641867e-08
step 200: mean loss = 4.812687e-08
step 300: mean loss = 9.777173e-08
step 400: mean loss = 8.901875e-08
step 500: mean loss = 7.607692e-08
step 600: mean loss = 6.6285416e-08
epoch 30: mean loss = 6.438742e-08  learning rate = 3.4056153e-05
============================
Start of epoch 31
step 0: mean loss = 1.1716048e-08
step 100: mean loss = 2.3967983e-08
step 200: mean loss = 7.0500164e-08
step 300: mean loss = 6.45249e-08
step 400: mean loss = 5.6172127e-08
step 500: mean loss = 4.8061924e-08
step 600: mean loss = 5.438495e-08
epoch 31: mean loss = 5.3349726e-08  learning rate = 3.4056153e-05
============================
Start of epoch 32
step 0: mean loss = 2.2491783e-08
step 100: mean loss = 5.6354494e-08
step 200: mean loss = 6.54141e-08
step 300: mean loss = 6.12902e-08
step 400: mean loss = 5.2976787e-08
step 500: mean loss = 5.0961166e-08
step 600: mean loss = 4.8031147e-08
epoch 32: mean loss = 5.5166737e-08  learning rate = 3.4056153e-05
============================
Start of epoch 33
step 0: mean loss = 1.2803918e-07
step 100: mean loss = 6.9196346e-08
step 200: mean loss = 5.7612922e-08
step 300: mean loss = 4.6272486e-08
step 400: mean loss = 6.2419645e-08
step 500: mean loss = 5.5202687e-08
step 600: mean loss = 5.7849427e-08
epoch 33: mean loss = 5.670262e-08  learning rate = 3.4056153e-05
============================
Start of epoch 34
step 0: mean loss = 1.718183e-08
step 100: mean loss = 6.4657804e-08
step 200: mean loss = 7.740209e-08
step 300: mean loss = 5.8073184e-08
step 400: mean loss = 4.892745e-08
step 500: mean loss = 4.509862e-08
step 600: mean loss = 4.4749697e-08
epoch 34: mean loss = 4.458932e-08  learning rate = 3.4056153e-05
============================
Start of epoch 35
step 0: mean loss = 1.3809236e-08
step 100: mean loss = 1.0160122e-07
step 200: mean loss = 2.559529e-07
step 300: mean loss = 1.7652594e-07
step 400: mean loss = 1.360227e-07
step 500: mean loss = 1.1247038e-07
step 600: mean loss = 9.5808524e-08
epoch 35: mean loss = 9.316853e-08  learning rate = 3.4056153e-05
============================
Start of epoch 36
step 0: mean loss = 1.0073056e-07
step 100: mean loss = 6.404072e-08
step 200: mean loss = 8.179474e-08
step 300: mean loss = 5.969148e-08
step 400: mean loss = 5.2401695e-08
step 500: mean loss = 4.8037872e-08
step 600: mean loss = 4.2749765e-08
epoch 36: mean loss = 4.294909e-08  learning rate = 3.4056153e-05
============================
Start of epoch 37
step 0: mean loss = 5.0411018e-08
step 100: mean loss = 4.305631e-08
step 200: mean loss = 3.3346996e-08
step 300: mean loss = 3.3500484e-08
step 400: mean loss = 2.9454847e-08
step 500: mean loss = 5.805539e-08
step 600: mean loss = 6.067628e-08
epoch 37: mean loss = 5.927324e-08  learning rate = 3.4056153e-05
============================
Start of epoch 38
step 0: mean loss = 5.998895e-08
step 100: mean loss = 6.035749e-08
step 200: mean loss = 4.0229533e-08
step 300: mean loss = 5.899474e-08
step 400: mean loss = 7.310909e-08
step 500: mean loss = 6.444602e-08
step 600: mean loss = 5.8564535e-08
epoch 38: mean loss = 5.7622714e-08  learning rate = 3.4056153e-05
============================
Start of epoch 39
step 0: mean loss = 2.8875334e-08
step 100: mean loss = 3.3441083e-08
step 200: mean loss = 9.73968e-08
step 300: mean loss = 7.6102744e-08
step 400: mean loss = 7.214823e-08
step 500: mean loss = 6.651237e-08
step 600: mean loss = 5.8302128e-08
epoch 39: mean loss = 5.6621328e-08  learning rate = 3.2353342e-05
============================
Start of epoch 40
step 0: mean loss = 1.617623e-08
step 100: mean loss = 3.096264e-08
step 200: mean loss = 3.194294e-08
step 300: mean loss = 3.676122e-08
step 400: mean loss = 6.862518e-08
step 500: mean loss = 6.0043966e-08
step 600: mean loss = 5.3773626e-08
epoch 40: mean loss = 5.3278818e-08  learning rate = 3.2353342e-05
============================
Start of epoch 41
step 0: mean loss = 7.3438436e-08
step 100: mean loss = 8.3327095e-08
step 200: mean loss = 6.097549e-08
step 300: mean loss = 5.5675965e-08
step 400: mean loss = 4.501659e-08
step 500: mean loss = 3.98412e-08
step 600: mean loss = 3.974265e-08
epoch 41: mean loss = 3.9553147e-08  learning rate = 3.2353342e-05
============================
Start of epoch 42
step 0: mean loss = 3.5293787e-08
step 100: mean loss = 8.3064936e-07
step 200: mean loss = 5.224185e-07
step 300: mean loss = 3.5269252e-07
step 400: mean loss = 2.6769052e-07
step 500: mean loss = 2.1659844e-07
step 600: mean loss = 1.8245689e-07
epoch 42: mean loss = 1.7586997e-07  learning rate = 3.2353342e-05
============================
Start of epoch 43
step 0: mean loss = 8.449502e-09
step 100: mean loss = 1.7661526e-08
step 200: mean loss = 1.7065446e-08
step 300: mean loss = 1.5045288e-08
step 400: mean loss = 1.4525474e-08
step 500: mean loss = 1.8357136e-08
step 600: mean loss = 2.4125423e-08
epoch 43: mean loss = 2.4031307e-08  learning rate = 3.2353342e-05
============================
Start of epoch 44
step 0: mean loss = 1.0435922e-08
step 100: mean loss = 1.6478655e-08
step 200: mean loss = 2.016786e-08
step 300: mean loss = 1.9501964e-08
step 400: mean loss = 2.0154335e-08
step 500: mean loss = 2.0393642e-08
step 600: mean loss = 3.3790847e-08
epoch 44: mean loss = 3.417494e-08  learning rate = 3.2353342e-05
============================
Start of epoch 45
step 0: mean loss = 4.1999492e-08
step 100: mean loss = 4.5028294e-08
step 200: mean loss = 4.2181863e-08
step 300: mean loss = 5.0571312e-08
step 400: mean loss = 4.320941e-08
step 500: mean loss = 3.936466e-08
step 600: mean loss = 3.898561e-08
epoch 45: mean loss = 4.0591825e-08  learning rate = 3.2353342e-05
============================
Start of epoch 46
step 0: mean loss = 2.4557545e-08
step 100: mean loss = 4.5204786e-08
step 200: mean loss = 4.4665892e-08
step 300: mean loss = 4.780413e-08
step 400: mean loss = 5.898976e-08
step 500: mean loss = 5.2937317e-08
step 600: mean loss = 4.724315e-08
epoch 46: mean loss = 4.6027818e-08  learning rate = 3.2353342e-05
============================
Start of epoch 47
step 0: mean loss = 1.27835715e-08
step 100: mean loss = 2.2232532e-08
step 200: mean loss = 3.5632628e-08
step 300: mean loss = 2.0269967e-07
step 400: mean loss = 1.6044366e-07
step 500: mean loss = 1.308789e-07
step 600: mean loss = 1.1146205e-07
epoch 47: mean loss = 1.07814316e-07  learning rate = 3.2353342e-05
============================
Start of epoch 48
step 0: mean loss = 9.75856e-09
step 100: mean loss = 1.13766685e-08
step 200: mean loss = 1.9440963e-08
step 300: mean loss = 1.8292805e-08
step 400: mean loss = 1.7709677e-08
step 500: mean loss = 2.127209e-08
step 600: mean loss = 2.1761732e-08
epoch 48: mean loss = 2.281854e-08  learning rate = 3.2353342e-05
============================
Start of epoch 49
step 0: mean loss = 3.461771e-08
step 100: mean loss = 8.334161e-08
step 200: mean loss = 5.6925987e-08
step 300: mean loss = 4.6568776e-08
step 400: mean loss = 4.3352642e-08
step 500: mean loss = 4.2249763e-08
step 600: mean loss = 3.866881e-08
epoch 49: mean loss = 3.9499316e-08  learning rate = 3.2353342e-05
============================
Start of epoch 50
step 0: mean loss = 6.367774e-08
step 100: mean loss = 3.1854356e-08
step 200: mean loss = 8.2709356e-08
step 300: mean loss = 6.100738e-08
step 400: mean loss = 4.9668145e-08
step 500: mean loss = 5.753721e-08
step 600: mean loss = 6.384248e-08
epoch 50: mean loss = 6.280784e-08  learning rate = 3.2353342e-05
============================
Start of epoch 51
step 0: mean loss = 1.7300366e-08
step 100: mean loss = 1.00404876e-07
step 200: mean loss = 6.073263e-08
step 300: mean loss = 4.866489e-08
step 400: mean loss = 4.0928768e-08
step 500: mean loss = 4.377519e-08
step 600: mean loss = 4.1555992e-08
epoch 51: mean loss = 4.1490868e-08  learning rate = 3.2353342e-05
============================
Start of epoch 52
step 0: mean loss = 3.9891507e-08
step 100: mean loss = 4.5058176e-08
step 200: mean loss = 3.929076e-08
step 300: mean loss = 1.6065727e-07
step 400: mean loss = 1.252982e-07
step 500: mean loss = 1.0391959e-07
step 600: mean loss = 9.100635e-08
epoch 52: mean loss = 8.8274e-08  learning rate = 3.2353342e-05
============================
Start of epoch 53
step 0: mean loss = 1.9781275e-08
step 100: mean loss = 2.3939549e-08
step 200: mean loss = 3.8424673e-08
step 300: mean loss = 3.1484728e-08
step 400: mean loss = 3.7053475e-08
step 500: mean loss = 3.2936473e-08
step 600: mean loss = 3.0780495e-08
epoch 53: mean loss = 3.0411364e-08  learning rate = 3.2353342e-05
============================
Start of epoch 54
step 0: mean loss = 8.691946e-08
step 100: mean loss = 1.6206801e-08
step 200: mean loss = 3.3113345e-08
step 300: mean loss = 4.6172854e-08
step 400: mean loss = 4.9623672e-08
step 500: mean loss = 4.6581583e-08
step 600: mean loss = 4.3647702e-08
epoch 54: mean loss = 4.3165432e-08  learning rate = 3.2353342e-05
============================
Start of epoch 55
step 0: mean loss = 2.2136568e-08
step 100: mean loss = 6.1179314e-08
step 200: mean loss = 1.09131356e-07
step 300: mean loss = 8.040989e-08
step 400: mean loss = 6.6218945e-08
step 500: mean loss = 5.7507915e-08
step 600: mean loss = 5.2495036e-08
epoch 55: mean loss = 5.3679994e-08  learning rate = 3.2353342e-05
============================
Start of epoch 56
step 0: mean loss = 4.8749064e-07
step 100: mean loss = 2.9479133e-07
step 200: mean loss = 1.647841e-07
step 300: mean loss = 1.216811e-07
step 400: mean loss = 9.521637e-08
step 500: mean loss = 7.991985e-08
step 600: mean loss = 7.926942e-08
epoch 56: mean loss = 7.671537e-08  learning rate = 3.2353342e-05
============================
Start of epoch 57
step 0: mean loss = 1.1269938e-08
step 100: mean loss = 2.4549587e-08
step 200: mean loss = 6.130574e-08
step 300: mean loss = 5.7937278e-08
step 400: mean loss = 4.888945e-08
step 500: mean loss = 4.315226e-08
step 600: mean loss = 4.3848548e-08
epoch 57: mean loss = 4.300367e-08  learning rate = 3.2353342e-05
============================
Start of epoch 58
step 0: mean loss = 1.2746275e-08
step 100: mean loss = 3.2362873e-08
step 200: mean loss = 7.121256e-08
step 300: mean loss = 1.7354068e-07
step 400: mean loss = 1.3433366e-07
step 500: mean loss = 1.0986653e-07
step 600: mean loss = 9.349779e-08
epoch 58: mean loss = 9.034366e-08  learning rate = 3.2353342e-05
============================
Start of epoch 59
step 0: mean loss = 1.4979785e-08
step 100: mean loss = 3.4758433e-08
step 200: mean loss = 2.565071e-08
step 300: mean loss = 2.28898e-08
step 400: mean loss = 3.679094e-08
step 500: mean loss = 5.9178486e-08
step 600: mean loss = 5.1461697e-08
epoch 59: mean loss = 4.9891497e-08  learning rate = 3.0735675e-05
============================
Start of epoch 60
step 0: mean loss = 8.329656e-09
step 100: mean loss = 2.2227495e-08
step 200: mean loss = 3.0133357e-08
step 300: mean loss = 2.7803107e-08
step 400: mean loss = 2.8445063e-08
step 500: mean loss = 3.149449e-08
step 600: mean loss = 3.0050302e-08
epoch 60: mean loss = 2.9790511e-08  learning rate = 3.0735675e-05
============================
Start of epoch 61
step 0: mean loss = 1.6753797e-08
step 100: mean loss = 3.5574665e-08
step 200: mean loss = 2.6206894e-08
step 300: mean loss = 3.091522e-08
step 400: mean loss = 3.029942e-08
step 500: mean loss = 3.4403723e-08
step 600: mean loss = 3.4569137e-08
epoch 61: mean loss = 3.3817734e-08  learning rate = 3.0735675e-05
============================
Start of epoch 62
step 0: mean loss = 7.9437825e-09
step 100: mean loss = 1.256202e-07
step 200: mean loss = 7.906245e-08
step 300: mean loss = 6.3434534e-08
step 400: mean loss = 5.352843e-08
step 500: mean loss = 5.0278718e-08
step 600: mean loss = 7.8643076e-08
epoch 62: mean loss = 7.6287165e-08  learning rate = 3.0735675e-05
============================
Start of epoch 63
step 0: mean loss = 1.7412223e-08
step 100: mean loss = 1.221528e-08
step 200: mean loss = 1.413575e-08
step 300: mean loss = 1.7169265e-08
step 400: mean loss = 2.3535813e-08
step 500: mean loss = 3.054868e-08
step 600: mean loss = 2.8657457e-08
epoch 63: mean loss = 2.8693732e-08  learning rate = 3.0735675e-05
============================
Start of epoch 64
step 0: mean loss = 2.5265388e-08
step 100: mean loss = 1.9127645e-08
step 200: mean loss = 2.61981e-08
step 300: mean loss = 3.5327435e-08
step 400: mean loss = 4.6920782e-08
step 500: mean loss = 4.5569323e-08
step 600: mean loss = 4.2694644e-08
epoch 64: mean loss = 4.269794e-08  learning rate = 3.0735675e-05
============================
Start of epoch 65
step 0: mean loss = 4.4261157e-08
step 100: mean loss = 4.4535266e-08
step 200: mean loss = 4.615823e-08
step 300: mean loss = 4.7827147e-08
step 400: mean loss = 7.774062e-08
step 500: mean loss = 8.0797804e-08
step 600: mean loss = 6.959524e-08
epoch 65: mean loss = 6.756391e-08  learning rate = 3.0735675e-05
============================
Start of epoch 66
step 0: mean loss = 1.1558305e-08
step 100: mean loss = 1.9974435e-08
step 200: mean loss = 1.7228434e-08
step 300: mean loss = 1.7693708e-08
step 400: mean loss = 2.6217265e-08
step 500: mean loss = 2.4396282e-08
step 600: mean loss = 2.6089332e-08
epoch 66: mean loss = 2.576997e-08  learning rate = 3.0735675e-05
============================
Start of epoch 67
step 0: mean loss = 2.3475225e-08
step 100: mean loss = 2.0260428e-07
step 200: mean loss = 1.0940068e-07
step 300: mean loss = 7.860157e-08
step 400: mean loss = 6.3047096e-08
step 500: mean loss = 5.787104e-08
step 600: mean loss = 5.476899e-08
epoch 67: mean loss = 5.3257548e-08  learning rate = 3.0735675e-05
============================
Start of epoch 68
step 0: mean loss = 9.007271e-09
step 100: mean loss = 4.1039197e-08
step 200: mean loss = 2.915933e-08
step 300: mean loss = 2.7381622e-08
step 400: mean loss = 2.9506177e-08
step 500: mean loss = 3.9023494e-08
step 600: mean loss = 5.4926815e-08
epoch 68: mean loss = 5.3222816e-08  learning rate = 3.0735675e-05
============================
Start of epoch 69
step 0: mean loss = 2.1862695e-08
step 100: mean loss = 2.5273314e-08
step 200: mean loss = 3.3111846e-08
step 300: mean loss = 3.9186187e-08
step 400: mean loss = 3.6776356e-08
step 500: mean loss = 3.65131e-08
step 600: mean loss = 3.53662e-08
epoch 69: mean loss = 3.4641893e-08  learning rate = 3.0735675e-05
============================
Start of epoch 70
step 0: mean loss = 1.7110457e-08
step 100: mean loss = 1.22747e-08
step 200: mean loss = 1.8000671e-08
step 300: mean loss = 7.734241e-08
step 400: mean loss = 1.4161263e-07
step 500: mean loss = 1.16222544e-07
step 600: mean loss = 9.935728e-08
epoch 70: mean loss = 9.593244e-08  learning rate = 3.0735675e-05
============================
Start of epoch 71
step 0: mean loss = 8.367765e-09
step 100: mean loss = 1.576642e-08
step 200: mean loss = 1.4728277e-08
step 300: mean loss = 1.5100749e-08
step 400: mean loss = 2.255069e-08
step 500: mean loss = 2.0782176e-08
step 600: mean loss = 1.9346654e-08
epoch 71: mean loss = 1.9057426e-08  learning rate = 3.0735675e-05
============================
Start of epoch 72
step 0: mean loss = 9.187914e-09
step 100: mean loss = 3.9282455e-08
step 200: mean loss = 3.3216402e-08
step 300: mean loss = 3.3736463e-08
step 400: mean loss = 3.0822832e-08
step 500: mean loss = 2.8584408e-08
step 600: mean loss = 5.258368e-08
epoch 72: mean loss = 5.3068298e-08  learning rate = 3.0735675e-05
============================
Start of epoch 73
step 0: mean loss = 5.0465133e-08
step 100: mean loss = 4.4457135e-08
step 200: mean loss = 3.5688082e-08
step 300: mean loss = 5.343071e-08
step 400: mean loss = 5.1536038e-08
step 500: mean loss = 4.374794e-08
step 600: mean loss = 4.0037698e-08
epoch 73: mean loss = 4.15651e-08  learning rate = 3.0735675e-05
============================
Start of epoch 74
step 0: mean loss = 2.4847324e-08
step 100: mean loss = 3.226843e-07
step 200: mean loss = 1.6811796e-07
step 300: mean loss = 1.2585213e-07
step 400: mean loss = 9.8962076e-08
step 500: mean loss = 8.206631e-08
step 600: mean loss = 7.028746e-08
epoch 74: mean loss = 6.813563e-08  learning rate = 3.0735675e-05
============================
Start of epoch 75
step 0: mean loss = 2.7072483e-08
step 100: mean loss = 1.6016656e-08
step 200: mean loss = 6.300557e-08
step 300: mean loss = 6.1466196e-08
step 400: mean loss = 5.1284626e-08
step 500: mean loss = 4.5866095e-08
step 600: mean loss = 4.0421593e-08
epoch 75: mean loss = 3.9308613e-08  learning rate = 3.0735675e-05
============================
Start of epoch 76
step 0: mean loss = 1.3111543e-08
step 100: mean loss = 2.0712658e-08
step 200: mean loss = 4.261651e-08
step 300: mean loss = 3.671879e-08
step 400: mean loss = 3.517141e-08
step 500: mean loss = 3.1658793e-08
step 600: mean loss = 4.2356103e-08
epoch 76: mean loss = 5.5544014e-08  learning rate = 3.0735675e-05
============================
Start of epoch 77
step 0: mean loss = 8.625948e-08
step 100: mean loss = 4.844189e-08
step 200: mean loss = 3.4181785e-08
step 300: mean loss = 3.9061796e-08
step 400: mean loss = 4.058937e-08
step 500: mean loss = 3.500482e-08
step 600: mean loss = 4.647274e-08
epoch 77: mean loss = 4.5760974e-08  learning rate = 3.0735675e-05
============================
Start of epoch 78
step 0: mean loss = 9.251062e-09
step 100: mean loss = 2.0034822e-08
step 200: mean loss = 1.7360087e-08
step 300: mean loss = 1.7784666e-08
step 400: mean loss = 1.8312896e-08
step 500: mean loss = 2.299565e-08
step 600: mean loss = 4.084585e-08
epoch 78: mean loss = 4.2443634e-08  learning rate = 3.0735675e-05
============================
Start of epoch 79
step 0: mean loss = 3.2840354e-08
step 100: mean loss = 3.5046234e-08
step 200: mean loss = 2.8925419e-08
step 300: mean loss = 2.8767813e-08
step 400: mean loss = 3.2555164e-08
step 500: mean loss = 6.572933e-08
step 600: mean loss = 5.8175623e-08
epoch 79: mean loss = 5.6887405e-08  learning rate = 2.919889e-05
============================
Start of epoch 80
step 0: mean loss = 1.46048595e-08
step 100: mean loss = 1.1098063e-08
step 200: mean loss = 1.1697204e-08
step 300: mean loss = 1.5525174e-08
step 400: mean loss = 1.5571588e-08
step 500: mean loss = 1.6527313e-08
step 600: mean loss = 1.9937302e-08
epoch 80: mean loss = 2.0500844e-08  learning rate = 2.919889e-05
============================
Start of epoch 81
step 0: mean loss = 1.9610583e-08
step 100: mean loss = 3.300188e-08
step 200: mean loss = 3.048926e-08
step 300: mean loss = 3.2087105e-08
step 400: mean loss = 3.949776e-08
step 500: mean loss = 4.034906e-08
step 600: mean loss = 3.5774914e-08
epoch 81: mean loss = 3.5201573e-08  learning rate = 2.919889e-05
============================
Start of epoch 82
step 0: mean loss = 1.0107729e-08
step 100: mean loss = 1.5944938e-08
step 200: mean loss = 3.1766803e-08
step 300: mean loss = 5.661514e-08
step 400: mean loss = 4.8971536e-08
step 500: mean loss = 4.427082e-08
step 600: mean loss = 9.300887e-08
epoch 82: mean loss = 9.7274636e-08  learning rate = 2.919889e-05
============================
Start of epoch 83
step 0: mean loss = 3.8702446e-08
step 100: mean loss = 1.878502e-08
step 200: mean loss = 2.3922706e-08
step 300: mean loss = 2.1152461e-08
step 400: mean loss = 1.8975253e-08
step 500: mean loss = 1.8497893e-08
step 600: mean loss = 1.8348278e-08
epoch 83: mean loss = 1.8052788e-08  learning rate = 2.919889e-05
============================
Start of epoch 84
step 0: mean loss = 1.41705385e-08
step 100: mean loss = 1.657887e-08
step 200: mean loss = 1.5077184e-08
step 300: mean loss = 1.4935342e-08
step 400: mean loss = 1.6208697e-08
step 500: mean loss = 5.2613725e-08
step 600: mean loss = 7.806601e-08
epoch 84: mean loss = 7.5417766e-08  learning rate = 2.919889e-05
============================
Start of epoch 85
step 0: mean loss = 7.1850907e-09
step 100: mean loss = 1.3292476e-08
step 200: mean loss = 1.2408933e-08
step 300: mean loss = 1.3685341e-08
step 400: mean loss = 1.3361084e-08
step 500: mean loss = 1.5649347e-08
step 600: mean loss = 1.7753248e-08
epoch 85: mean loss = 1.7796108e-08  learning rate = 2.919889e-05
============================
Start of epoch 86
step 0: mean loss = 3.074851e-08
step 100: mean loss = 2.1352664e-08
step 200: mean loss = 2.3864487e-08
step 300: mean loss = 8.1264986e-08
step 400: mean loss = 6.56791e-08
step 500: mean loss = 5.5281117e-08
step 600: mean loss = 4.8217967e-08
epoch 86: mean loss = 4.684268e-08  learning rate = 2.919889e-05
============================
Start of epoch 87
step 0: mean loss = 1.5593711e-08
step 100: mean loss = 1.2914733e-08
step 200: mean loss = 1.5464455e-08
step 300: mean loss = 1.5360374e-08
step 400: mean loss = 1.6339303e-08
step 500: mean loss = 1.841654e-08
step 600: mean loss = 1.9379133e-08
epoch 87: mean loss = 2.0129722e-08  learning rate = 2.919889e-05
============================
Start of epoch 88
step 0: mean loss = 1.8539435e-08
step 100: mean loss = 3.1201388e-08
step 200: mean loss = 4.4270262e-08
step 300: mean loss = 1.5532653e-07
step 400: mean loss = 1.1931597e-07
step 500: mean loss = 9.7326925e-08
step 600: mean loss = 8.38656e-08
epoch 88: mean loss = 8.124281e-08  learning rate = 2.919889e-05
============================
Start of epoch 89
step 0: mean loss = 1.595906e-08
step 100: mean loss = 2.036646e-08
step 200: mean loss = 2.8071925e-08
step 300: mean loss = 2.2436947e-08
step 400: mean loss = 2.0946857e-08
step 500: mean loss = 2.014052e-08
step 600: mean loss = 2.2995138e-08
epoch 89: mean loss = 2.2877616e-08  learning rate = 2.919889e-05
============================
Start of epoch 90
step 0: mean loss = 1.1997328e-08
step 100: mean loss = 1.5622208e-08
step 200: mean loss = 1.6508565e-08
step 300: mean loss = 3.7452043e-08
step 400: mean loss = 5.160557e-08
step 500: mean loss = 4.3560377e-08
step 600: mean loss = 4.7399226e-08
epoch 90: mean loss = 4.6724885e-08  learning rate = 2.919889e-05
============================
Start of epoch 91
step 0: mean loss = 1.6490507e-08
step 100: mean loss = 1.066268e-08
step 200: mean loss = 1.8631747e-08
step 300: mean loss = 2.754957e-08
step 400: mean loss = 2.645518e-08
step 500: mean loss = 2.4469344e-08
step 600: mean loss = 2.9051755e-08
epoch 91: mean loss = 2.855488e-08  learning rate = 2.919889e-05
============================
Start of epoch 92
step 0: mean loss = 1.4129718e-08
step 100: mean loss = 3.9403503e-08
step 200: mean loss = 8.2732164e-08
step 300: mean loss = 6.4344526e-08
step 400: mean loss = 5.1853352e-08
step 500: mean loss = 4.861022e-08
step 600: mean loss = 5.147181e-08
epoch 92: mean loss = 5.3439283e-08  learning rate = 2.919889e-05
============================
Start of epoch 93
step 0: mean loss = 7.2349394e-08
step 100: mean loss = 2.9226356e-08
step 200: mean loss = 3.067263e-08
step 300: mean loss = 2.6824086e-08
step 400: mean loss = 2.7446639e-08
step 500: mean loss = 2.4594735e-08
step 600: mean loss = 2.3114694e-08
epoch 93: mean loss = 2.6139066e-08  learning rate = 2.919889e-05
============================
Start of epoch 94
step 0: mean loss = 6.217475e-08
step 100: mean loss = 5.173213e-08
step 200: mean loss = 4.1906357e-08
step 300: mean loss = 4.613338e-08
step 400: mean loss = 3.9054903e-08
step 500: mean loss = 3.437655e-08
step 600: mean loss = 3.304413e-08
epoch 94: mean loss = 3.3285808e-08  learning rate = 2.919889e-05
============================
Start of epoch 95
step 0: mean loss = 2.0516358e-08
step 100: mean loss = 2.0437964e-08
step 200: mean loss = 1.4791846e-07
step 300: mean loss = 1.17741216e-07
step 400: mean loss = 9.192315e-08
step 500: mean loss = 7.838683e-08
step 600: mean loss = 6.771031e-08
epoch 95: mean loss = 6.59014e-08  learning rate = 2.919889e-05
============================
Start of epoch 96
step 0: mean loss = 7.381825e-09
step 100: mean loss = 1.6506625e-08
step 200: mean loss = 1.8466668e-08
step 300: mean loss = 1.739149e-08
step 400: mean loss = 1.7412171e-08
step 500: mean loss = 1.842508e-08
step 600: mean loss = 1.860528e-08
epoch 96: mean loss = 1.9563611e-08  learning rate = 2.919889e-05
============================
Start of epoch 97
step 0: mean loss = 7.468394e-08
step 100: mean loss = 2.800626e-07
step 200: mean loss = 1.5155761e-07
step 300: mean loss = 1.1099553e-07
step 400: mean loss = 9.385206e-08
step 500: mean loss = 7.824847e-08
step 600: mean loss = 6.7840105e-08
epoch 97: mean loss = 6.6155955e-08  learning rate = 2.919889e-05
============================
Start of epoch 98
step 0: mean loss = 1.0876721e-08
step 100: mean loss = 2.1173552e-08
step 200: mean loss = 4.6361116e-08
step 300: mean loss = 3.840195e-08
step 400: mean loss = 3.261823e-08
step 500: mean loss = 2.8716169e-08
step 600: mean loss = 3.6258566e-08
epoch 98: mean loss = 3.7275644e-08  learning rate = 2.919889e-05
============================
Start of epoch 99
step 0: mean loss = 2.0827637e-08
step 100: mean loss = 3.3200955e-08
step 200: mean loss = 3.2735894e-08
step 300: mean loss = 2.6264168e-08
step 400: mean loss = 2.3411841e-08
step 500: mean loss = 2.6265296e-08
step 600: mean loss = 2.6609467e-08
epoch 99: mean loss = 2.6835414e-08  learning rate = 2.7738948e-05
============================
Start of epoch 100
step 0: mean loss = 3.0823834e-08
step 100: mean loss = 1.7553667e-07
step 200: mean loss = 9.757527e-08
step 300: mean loss = 6.8661656e-08
step 400: mean loss = 6.015038e-08
step 500: mean loss = 5.1464177e-08
step 600: mean loss = 5.2685735e-08
epoch 100: mean loss = 5.1261363e-08  learning rate = 2.7738948e-05
============================
Start of epoch 101
step 0: mean loss = 8.631661e-09
step 100: mean loss = 1.2019617e-08
step 200: mean loss = 3.5172885e-08
step 300: mean loss = 3.497893e-08
step 400: mean loss = 2.8527648e-08
step 500: mean loss = 3.4040905e-08
step 600: mean loss = 3.0988673e-08
epoch 101: mean loss = 3.023222e-08  learning rate = 2.7738948e-05
============================
Start of epoch 102
step 0: mean loss = 1.809072e-08
step 100: mean loss = 2.0674241e-08
step 200: mean loss = 3.3418043e-08
step 300: mean loss = 2.8643834e-08
step 400: mean loss = 2.613311e-08
step 500: mean loss = 2.7039091e-08
step 600: mean loss = 2.7775139e-08
epoch 102: mean loss = 2.89408e-08  learning rate = 2.7738948e-05
============================
Start of epoch 103
step 0: mean loss = 1.1571264e-07
step 100: mean loss = 3.7162597e-08
step 200: mean loss = 2.9360177e-08
step 300: mean loss = 3.8768277e-08
step 400: mean loss = 5.6131036e-08
step 500: mean loss = 4.7776595e-08
step 600: mean loss = 4.4525276e-08
epoch 103: mean loss = 4.3453557e-08  learning rate = 2.7738948e-05
============================
Start of epoch 104
step 0: mean loss = 3.5075846e-08
step 100: mean loss = 1.2851434e-08
step 200: mean loss = 1.5945407e-08
step 300: mean loss = 2.1701043e-08
step 400: mean loss = 2.479513e-08
step 500: mean loss = 2.4754035e-08
step 600: mean loss = 2.3017588e-08
epoch 104: mean loss = 2.3442169e-08  learning rate = 2.7738948e-05
============================
Start of epoch 105
step 0: mean loss = 2.4160112e-08
step 100: mean loss = 1.346223e-07
step 200: mean loss = 8.59608e-08
step 300: mean loss = 6.2878236e-08
step 400: mean loss = 5.2463715e-08
step 500: mean loss = 4.794297e-08
step 600: mean loss = 4.3345977e-08
epoch 105: mean loss = 4.2258307e-08  learning rate = 2.7738948e-05
============================
Start of epoch 106
step 0: mean loss = 9.210931e-09
step 100: mean loss = 3.659338e-08
step 200: mean loss = 4.34697e-08
step 300: mean loss = 3.6862783e-08
step 400: mean loss = 3.1074595e-08
step 500: mean loss = 3.5218797e-08
step 600: mean loss = 3.2055873e-08
epoch 106: mean loss = 3.3777066e-08  learning rate = 2.7738948e-05
============================
Start of epoch 107
step 0: mean loss = 2.7618535e-08
step 100: mean loss = 3.7079825e-08
step 200: mean loss = 2.6782509e-08
step 300: mean loss = 4.14075e-08
step 400: mean loss = 4.0483364e-08
step 500: mean loss = 3.4551434e-08
step 600: mean loss = 3.3962156e-08
epoch 107: mean loss = 3.513351e-08  learning rate = 2.7738948e-05
============================
Start of epoch 108
step 0: mean loss = 1.2032798e-08
step 100: mean loss = 1.7007055e-08
step 200: mean loss = 1.8833521e-08
step 300: mean loss = 3.9717523e-08
step 400: mean loss = 3.8680763e-08
step 500: mean loss = 3.399265e-08
step 600: mean loss = 3.19275e-08
epoch 108: mean loss = 3.100285e-08  learning rate = 2.7738948e-05
============================
Start of epoch 109
step 0: mean loss = 5.0951754e-09
step 100: mean loss = 3.096971e-08
step 200: mean loss = 3.194511e-08
step 300: mean loss = 2.806698e-08
step 400: mean loss = 2.5788047e-08
step 500: mean loss = 5.8238818e-08
step 600: mean loss = 5.199866e-08
epoch 109: mean loss = 5.0510238e-08  learning rate = 2.7738948e-05
============================
Start of epoch 110
step 0: mean loss = 8.050819e-09
step 100: mean loss = 1.8783565e-08
step 200: mean loss = 2.0835484e-08
step 300: mean loss = 1.9247844e-08
step 400: mean loss = 1.693515e-08
step 500: mean loss = 1.9050576e-08
step 600: mean loss = 2.326527e-08
epoch 110: mean loss = 2.2773484e-08  learning rate = 2.7738948e-05
============================
Start of epoch 111
step 0: mean loss = 8.325779e-09
step 100: mean loss = 5.3810062e-08
step 200: mean loss = 5.1513403e-08
step 300: mean loss = 3.889745e-08
step 400: mean loss = 3.6943927e-08
step 500: mean loss = 3.4249418e-08
step 600: mean loss = 5.067596e-08
epoch 111: mean loss = 4.926704e-08  learning rate = 2.7738948e-05
============================
Start of epoch 112
step 0: mean loss = 1.6318596e-08
step 100: mean loss = 1.6943112e-08
step 200: mean loss = 2.148311e-08
step 300: mean loss = 2.0939023e-08
step 400: mean loss = 4.5971813e-08
step 500: mean loss = 4.478578e-08
step 600: mean loss = 3.9379074e-08
epoch 112: mean loss = 3.818879e-08  learning rate = 2.7738948e-05
============================
Start of epoch 113
step 0: mean loss = 7.87633e-09
step 100: mean loss = 1.3046965e-08
step 200: mean loss = 1.3658565e-08
step 300: mean loss = 1.5944606e-08
step 400: mean loss = 3.551824e-08
step 500: mean loss = 3.3342e-08
step 600: mean loss = 3.049633e-08
epoch 113: mean loss = 2.9763216e-08  learning rate = 2.7738948e-05
============================
Start of epoch 114
step 0: mean loss = 8.381881e-09
step 100: mean loss = 3.159757e-08
step 200: mean loss = 6.364729e-08
step 300: mean loss = 4.5898773e-08
step 400: mean loss = 3.868989e-08
step 500: mean loss = 3.697181e-08
step 600: mean loss = 3.6215667e-08
epoch 114: mean loss = 3.596732e-08  learning rate = 2.7738948e-05
============================
Start of epoch 115
step 0: mean loss = 1.5508311e-08
step 100: mean loss = 6.328894e-08
step 200: mean loss = 4.2108947e-08
step 300: mean loss = 3.192513e-08
step 400: mean loss = 2.8192126e-08
step 500: mean loss = 2.4786432e-08
step 600: mean loss = 3.5001666e-08
epoch 115: mean loss = 3.768679e-08  learning rate = 2.7738948e-05
============================
Start of epoch 116
step 0: mean loss = 7.716524e-08
step 100: mean loss = 4.7243336e-08
step 200: mean loss = 3.018891e-08
step 300: mean loss = 2.4011168e-08
step 400: mean loss = 2.9043978e-08
step 500: mean loss = 2.6998189e-08
step 600: mean loss = 2.53919e-08
epoch 116: mean loss = 2.4840885e-08  learning rate = 2.7738948e-05
============================
Start of epoch 117
step 0: mean loss = 7.667992e-09
step 100: mean loss = 3.3000372e-08
step 200: mean loss = 2.7961905e-08
step 300: mean loss = 2.5021603e-08
step 400: mean loss = 3.500705e-08
step 500: mean loss = 3.1438066e-08
step 600: mean loss = 3.9102822e-08
epoch 117: mean loss = 3.8971137e-08  learning rate = 2.7738948e-05
============================
Start of epoch 118
step 0: mean loss = 4.138456e-08
step 100: mean loss = 6.5319746e-08
step 200: mean loss = 3.7517545e-08
step 300: mean loss = 4.126516e-08
step 400: mean loss = 3.7208697e-08
step 500: mean loss = 3.5966362e-08
step 600: mean loss = 6.006988e-08
epoch 118: mean loss = 5.96517e-08  learning rate = 2.7738948e-05
============================
Start of epoch 119
step 0: mean loss = 1.6151542e-08
step 100: mean loss = 1.0552644e-08
step 200: mean loss = 1.0678816e-08
step 300: mean loss = 1.062637e-08
step 400: mean loss = 1.1889379e-08
step 500: mean loss = 1.2026732e-08
step 600: mean loss = 1.7699543e-08
epoch 119: mean loss = 1.7503693e-08  learning rate = 2.6352e-05
============================
Start of epoch 120
step 0: mean loss = 9.494991e-09
step 100: mean loss = 4.8348657e-08
step 200: mean loss = 4.636399e-08
step 300: mean loss = 3.880629e-08
step 400: mean loss = 3.3229487e-08
step 500: mean loss = 3.046373e-08
step 600: mean loss = 4.9271332e-08
epoch 120: mean loss = 4.792682e-08  learning rate = 2.6352e-05
============================
Start of epoch 121
step 0: mean loss = 1.4839381e-08
step 100: mean loss = 1.7456301e-08
step 200: mean loss = 1.4741281e-08
step 300: mean loss = 1.7987059e-08
step 400: mean loss = 1.6130558e-08
step 500: mean loss = 1.5252867e-08
step 600: mean loss = 2.0375694e-08
epoch 121: mean loss = 2.097795e-08  learning rate = 2.6352e-05
============================
Start of epoch 122
step 0: mean loss = 1.1817012e-08
step 100: mean loss = 4.48346e-08
step 200: mean loss = 2.919527e-08
step 300: mean loss = 2.7292824e-08
step 400: mean loss = 3.815607e-08
step 500: mean loss = 3.535924e-08
step 600: mean loss = 3.2167556e-08
epoch 122: mean loss = 3.1524806e-08  learning rate = 2.6352e-05
============================
Start of epoch 123
step 0: mean loss = 1.6555816e-08
step 100: mean loss = 2.245437e-08
step 200: mean loss = 1.723075e-08
step 300: mean loss = 1.907115e-08
step 400: mean loss = 1.8492399e-08
step 500: mean loss = 5.9318936e-08
step 600: mean loss = 5.4933086e-08
epoch 123: mean loss = 5.361868e-08  learning rate = 2.6352e-05
============================
Start of epoch 124
step 0: mean loss = 1.998122e-08
step 100: mean loss = 2.620942e-08
step 200: mean loss = 1.7428441e-08
step 300: mean loss = 1.8233994e-08
step 400: mean loss = 1.8211827e-08
step 500: mean loss = 1.6807787e-08
step 600: mean loss = 1.6300868e-08
epoch 124: mean loss = 1.6377518e-08  learning rate = 2.6352e-05
============================
Start of epoch 125
step 0: mean loss = 4.3282476e-08
step 100: mean loss = 2.4155625e-08
step 200: mean loss = 1.8401625e-08
step 300: mean loss = 2.0883029e-08
step 400: mean loss = 2.5654671e-08
step 500: mean loss = 3.3917406e-08
step 600: mean loss = 2.991409e-08
epoch 125: mean loss = 2.9341791e-08  learning rate = 2.6352e-05
============================
Start of epoch 126
step 0: mean loss = 1.1359012e-08
step 100: mean loss = 7.965514e-08
step 200: mean loss = 5.0061946e-08
step 300: mean loss = 3.702432e-08
step 400: mean loss = 3.187818e-08
step 500: mean loss = 3.0458825e-08
step 600: mean loss = 3.7266346e-08
epoch 126: mean loss = 3.61474e-08  learning rate = 2.6352e-05
============================
Start of epoch 127
step 0: mean loss = 9.658662e-09
step 100: mean loss = 1.2787158e-08
step 200: mean loss = 1.7414305e-08
step 300: mean loss = 2.3894811e-08
step 400: mean loss = 2.3439107e-08
step 500: mean loss = 2.1545597e-08
step 600: mean loss = 2.0592834e-08
epoch 127: mean loss = 2.02845e-08  learning rate = 2.6352e-05
============================
Start of epoch 128
step 0: mean loss = 1.0212366e-08
step 100: mean loss = 1.6752479e-08
step 200: mean loss = 1.4553446e-07
step 300: mean loss = 1.0284435e-07
step 400: mean loss = 8.166567e-08
step 500: mean loss = 6.7253275e-08
step 600: mean loss = 5.9776916e-08
epoch 128: mean loss = 5.8702938e-08  learning rate = 2.6352e-05
============================
Start of epoch 129
step 0: mean loss = 1.5067897e-08
step 100: mean loss = 1.497991e-08
step 200: mean loss = 1.4121099e-08
step 300: mean loss = 1.9242902e-08
step 400: mean loss = 1.913227e-08
step 500: mean loss = 2.831182e-08
step 600: mean loss = 2.6477634e-08
epoch 129: mean loss = 2.5894412e-08  learning rate = 2.6352e-05
============================
Start of epoch 130
step 0: mean loss = 1.20125545e-08
step 100: mean loss = 1.2101825e-08
step 200: mean loss = 1.5769231e-08
step 300: mean loss = 1.9326722e-08
step 400: mean loss = 3.0111178e-08
step 500: mean loss = 2.6713915e-08
step 600: mean loss = 2.879759e-08
epoch 130: mean loss = 2.8204754e-08  learning rate = 2.6352e-05
============================
Start of epoch 131
step 0: mean loss = 1.3978268e-08
step 100: mean loss = 1.6837864e-08
step 200: mean loss = 9.4003575e-08
step 300: mean loss = 6.8156744e-08
step 400: mean loss = 5.4736276e-08
step 500: mean loss = 4.778788e-08
step 600: mean loss = 4.1752497e-08
epoch 131: mean loss = 4.0511736e-08  learning rate = 2.6352e-05
============================
Start of epoch 132
step 0: mean loss = 5.8119973e-08
step 100: mean loss = 3.663769e-08
step 200: mean loss = 2.3438702e-08
step 300: mean loss = 1.9934289e-08
step 400: mean loss = 2.0593948e-08
step 500: mean loss = 1.9584153e-08
step 600: mean loss = 2.7971263e-08
epoch 132: mean loss = 3.8268197e-08  learning rate = 2.6352e-05
============================
Start of epoch 133
step 0: mean loss = 2.8327495e-06
step 100: mean loss = 1.8839764e-07
step 200: mean loss = 9.960703e-08
step 300: mean loss = 6.9351984e-08
step 400: mean loss = 5.584386e-08
step 500: mean loss = 5.025359e-08
step 600: mean loss = 4.3187356e-08
epoch 133: mean loss = 4.190262e-08  learning rate = 2.6352e-05
============================
Start of epoch 134
step 0: mean loss = 7.460953e-09
step 100: mean loss = 2.4042466e-08
step 200: mean loss = 2.5728566e-08
step 300: mean loss = 2.1406622e-08
step 400: mean loss = 2.2609491e-08
step 500: mean loss = 2.7159084e-08
step 600: mean loss = 4.1563265e-08
epoch 134: mean loss = 4.2931177e-08  learning rate = 2.6352e-05
============================
Start of epoch 135
step 0: mean loss = 1.1781445e-08
step 100: mean loss = 1.7950805e-08
step 200: mean loss = 1.8871061e-08
step 300: mean loss = 1.6417994e-08
step 400: mean loss = 1.557509e-08
step 500: mean loss = 1.4245453e-08
step 600: mean loss = 1.5954425e-08
epoch 135: mean loss = 1.6106723e-08  learning rate = 2.6352e-05
============================
Start of epoch 136
step 0: mean loss = 1.6681529e-08
step 100: mean loss = 2.8958851e-08
step 200: mean loss = 2.7554417e-08
step 300: mean loss = 5.390305e-08
step 400: mean loss = 5.0669183e-08
step 500: mean loss = 4.3075353e-08
step 600: mean loss = 3.8753218e-08
epoch 136: mean loss = 3.7806736e-08  learning rate = 2.6352e-05
============================
Start of epoch 137
step 0: mean loss = 7.587145e-09
step 100: mean loss = 1.3536615e-08
step 200: mean loss = 1.35726745e-08
step 300: mean loss = 1.4524304e-08
step 400: mean loss = 2.0205414e-08
step 500: mean loss = 2.9473968e-08
step 600: mean loss = 2.6647816e-08
epoch 137: mean loss = 2.5911545e-08  learning rate = 2.6352e-05
============================
Start of epoch 138
step 0: mean loss = 7.062771e-09
step 100: mean loss = 2.3007289e-08
step 200: mean loss = 2.4715908e-08
step 300: mean loss = 3.121118e-08
step 400: mean loss = 2.6996316e-08
step 500: mean loss = 2.5990676e-08
step 600: mean loss = 3.673119e-08
epoch 138: mean loss = 5.0732954e-08  learning rate = 2.6352e-05
============================
Start of epoch 139
step 0: mean loss = 3.2780673e-07
step 100: mean loss = 1.4399262e-07
step 200: mean loss = 7.682828e-08
step 300: mean loss = 5.6204296e-08
step 400: mean loss = 4.4873698e-08
step 500: mean loss = 3.8469697e-08
step 600: mean loss = 3.394319e-08
epoch 139: mean loss = 3.304458e-08  learning rate = 2.50344e-05
============================
Start of epoch 140
step 0: mean loss = 1.3483738e-08
step 100: mean loss = 1.216802e-08
step 200: mean loss = 1.0090514e-08
step 300: mean loss = 1.9021615e-08
step 400: mean loss = 2.0702238e-08
step 500: mean loss = 1.8864228e-08
step 600: mean loss = 1.7657266e-08
epoch 140: mean loss = 2.2871582e-08  learning rate = 2.50344e-05
============================
Start of epoch 141
step 0: mean loss = 2.0594614e-08
step 100: mean loss = 1.6837337e-08
step 200: mean loss = 3.228625e-08
step 300: mean loss = 3.4871697e-08
step 400: mean loss = 2.9884653e-08
step 500: mean loss = 2.8599366e-08
step 600: mean loss = 2.6950564e-08
epoch 141: mean loss = 2.634553e-08  learning rate = 2.50344e-05
============================
Start of epoch 142
step 0: mean loss = 1.8202746e-08
step 100: mean loss = 2.16407e-08
step 200: mean loss = 2.7157487e-08
step 300: mean loss = 4.90167e-08
step 400: mean loss = 4.433462e-08
step 500: mean loss = 3.7974104e-08
step 600: mean loss = 3.4164117e-08
epoch 142: mean loss = 3.337167e-08  learning rate = 2.50344e-05
============================
Start of epoch 143
step 0: mean loss = 2.3284683e-08
step 100: mean loss = 1.4501956e-08
step 200: mean loss = 2.1416952e-08
step 300: mean loss = 2.085041e-08
step 400: mean loss = 2.9637764e-08
step 500: mean loss = 2.6501157e-08
step 600: mean loss = 2.3934701e-08
epoch 143: mean loss = 2.4804871e-08  learning rate = 2.50344e-05
============================
Start of epoch 144
step 0: mean loss = 2.053227e-08
step 100: mean loss = 2.1471976e-08
step 200: mean loss = 4.652776e-08
step 300: mean loss = 3.605932e-08
step 400: mean loss = 4.4375618e-08
step 500: mean loss = 3.8854132e-08
step 600: mean loss = 3.43993e-08
epoch 144: mean loss = 3.3410615e-08  learning rate = 2.50344e-05
============================
Start of epoch 145
step 0: mean loss = 7.3903053e-09
step 100: mean loss = 1.0646166e-08
step 200: mean loss = 2.947063e-08
step 300: mean loss = 3.0765353e-08
step 400: mean loss = 3.65275e-08
step 500: mean loss = 3.5764355e-08
step 600: mean loss = 3.3777052e-08
epoch 145: mean loss = 3.5157836e-08  learning rate = 2.50344e-05
============================
Start of epoch 146
step 0: mean loss = 1.7915664e-08
step 100: mean loss = 1.424182e-08
step 200: mean loss = 2.194309e-08
step 300: mean loss = 1.9315593e-08
step 400: mean loss = 1.7882192e-08
step 500: mean loss = 1.712325e-08
step 600: mean loss = 2.296925e-08
epoch 146: mean loss = 2.2433264e-08  learning rate = 2.50344e-05
============================
Start of epoch 147
step 0: mean loss = 1.5374738e-08
step 100: mean loss = 2.1359977e-08
step 200: mean loss = 3.877518e-08
step 300: mean loss = 4.5060617e-08
step 400: mean loss = 3.754648e-08
step 500: mean loss = 3.3703685e-08
step 600: mean loss = 3.0577933e-08
epoch 147: mean loss = 3.6315882e-08  learning rate = 2.50344e-05
============================
Start of epoch 148
step 0: mean loss = 1.539922e-07
step 100: mean loss = 4.672703e-08
step 200: mean loss = 3.657132e-08
step 300: mean loss = 3.592891e-08
step 400: mean loss = 2.987087e-08
step 500: mean loss = 2.7518222e-08
step 600: mean loss = 2.8797423e-08
epoch 148: mean loss = 3.6706627e-08  learning rate = 2.50344e-05
============================
Start of epoch 149
step 0: mean loss = 3.6600245e-08
step 100: mean loss = 2.33386e-08
step 200: mean loss = 6.629167e-08
step 300: mean loss = 4.9413924e-08
step 400: mean loss = 4.0128416e-08
step 500: mean loss = 3.5286078e-08
step 600: mean loss = 3.2076578e-08
epoch 149: mean loss = 3.1172267e-08  learning rate = 2.50344e-05
============================
Start of epoch 150
step 0: mean loss = 4.412485e-09
step 100: mean loss = 1.6432642e-08
step 200: mean loss = 1.6597426e-08
step 300: mean loss = 1.97119e-08
step 400: mean loss = 1.9672626e-08
step 500: mean loss = 3.4713135e-08
step 600: mean loss = 3.1290153e-08
epoch 150: mean loss = 3.048912e-08  learning rate = 2.50344e-05
============================
Start of epoch 151
step 0: mean loss = 9.919667e-09
step 100: mean loss = 1.5818992e-08
step 200: mean loss = 1.2840948e-08
step 300: mean loss = 1.3145436e-08
step 400: mean loss = 1.8332207e-08
step 500: mean loss = 1.7736351e-08
step 600: mean loss = 2.6721436e-08
epoch 151: mean loss = 3.040367e-08  learning rate = 2.50344e-05
============================
Start of epoch 152
step 0: mean loss = 1.5956012e-08
step 100: mean loss = 2.3142407e-08
step 200: mean loss = 1.9524693e-08
step 300: mean loss = 1.7829743e-08
step 400: mean loss = 3.264274e-08
step 500: mean loss = 2.909821e-08
step 600: mean loss = 2.9586829e-08
epoch 152: mean loss = 2.9286296e-08  learning rate = 2.50344e-05
============================
Start of epoch 153
step 0: mean loss = 1.4160375e-08
step 100: mean loss = 1.9609548e-08
step 200: mean loss = 2.1068248e-08
step 300: mean loss = 1.7313589e-08
step 400: mean loss = 1.7353369e-08
step 500: mean loss = 1.7507729e-08
step 600: mean loss = 1.997994e-08
epoch 153: mean loss = 1.9711571e-08  learning rate = 2.50344e-05
============================
Start of epoch 154
step 0: mean loss = 4.155656e-08
step 100: mean loss = 2.584093e-07
step 200: mean loss = 1.349809e-07
step 300: mean loss = 9.325785e-08
step 400: mean loss = 7.426138e-08
step 500: mean loss = 7.122134e-08
step 600: mean loss = 6.3964805e-08
epoch 154: mean loss = 6.180222e-08  learning rate = 2.50344e-05
============================
Start of epoch 155
step 0: mean loss = 9.3558326e-09
step 100: mean loss = 1.0517174e-08
step 200: mean loss = 9.041814e-09
step 300: mean loss = 1.1061465e-08
step 400: mean loss = 1.3014704e-08
step 500: mean loss = 2.3437405e-08
step 600: mean loss = 2.100541e-08
epoch 155: mean loss = 2.0574804e-08  learning rate = 2.50344e-05
============================
Start of epoch 156
step 0: mean loss = 1.0219326e-08
step 100: mean loss = 1.3286153e-08
step 200: mean loss = 1.1371558e-08
step 300: mean loss = 1.9090127e-08
step 400: mean loss = 1.784975e-08
step 500: mean loss = 2.0095571e-08
step 600: mean loss = 2.3064084e-08
epoch 156: mean loss = 2.3007766e-08  learning rate = 2.50344e-05
============================
Start of epoch 157
step 0: mean loss = 4.747265e-09
step 100: mean loss = 1.1216169e-08
step 200: mean loss = 2.1445166e-08
step 300: mean loss = 5.2445973e-08
step 400: mean loss = 4.2584016e-08
step 500: mean loss = 3.7331258e-08
step 600: mean loss = 3.4267117e-08
epoch 157: mean loss = 3.330586e-08  learning rate = 2.50344e-05
============================
Start of epoch 158
step 0: mean loss = 8.965155e-09
step 100: mean loss = 1.4193348e-08
step 200: mean loss = 2.57591e-08
step 300: mean loss = 2.164498e-08
step 400: mean loss = 2.1693273e-08
step 500: mean loss = 2.6755163e-08
step 600: mean loss = 2.7800272e-08
epoch 158: mean loss = 3.1488216e-08  learning rate = 2.50344e-05
============================
Start of epoch 159
step 0: mean loss = 3.5086344e-08
step 100: mean loss = 9.7437336e-08
step 200: mean loss = 5.470797e-08
step 300: mean loss = 4.0058556e-08
step 400: mean loss = 3.2705366e-08
step 500: mean loss = 2.8579029e-08
step 600: mean loss = 3.0346428e-08
epoch 159: mean loss = 3.0978622e-08  learning rate = 2.3782679e-05
============================
Start of epoch 160
step 0: mean loss = 9.739317e-08
step 100: mean loss = 2.0784208e-08
step 200: mean loss = 1.9768617e-08
step 300: mean loss = 2.5556327e-08
step 400: mean loss = 2.1067166e-08
step 500: mean loss = 1.865786e-08
step 600: mean loss = 1.6956648e-08
epoch 160: mean loss = 1.6761229e-08  learning rate = 2.3782679e-05
============================
Start of epoch 161
step 0: mean loss = 9.321806e-09
step 100: mean loss = 2.5899512e-08
step 200: mean loss = 2.7732726e-08
step 300: mean loss = 2.2094763e-08
step 400: mean loss = 2.490317e-08
step 500: mean loss = 8.350718e-08
step 600: mean loss = 7.090836e-08
epoch 161: mean loss = 6.859679e-08  learning rate = 2.3782679e-05
============================
Start of epoch 162
step 0: mean loss = 6.1680168e-09
step 100: mean loss = 9.734485e-09
step 200: mean loss = 8.292255e-09
step 300: mean loss = 8.782069e-09
step 400: mean loss = 9.634978e-09
step 500: mean loss = 9.580591e-09
step 600: mean loss = 9.5819805e-09
epoch 162: mean loss = 9.610298e-09  learning rate = 2.3782679e-05
============================
Start of epoch 163
step 0: mean loss = 6.394744e-09
step 100: mean loss = 9.359298e-09
step 200: mean loss = 1.9180426e-08
step 300: mean loss = 1.948698e-08
step 400: mean loss = 2.941246e-08
step 500: mean loss = 2.7790838e-08
step 600: mean loss = 2.8526161e-08
epoch 163: mean loss = 2.783501e-08  learning rate = 2.3782679e-05
============================
Start of epoch 164
step 0: mean loss = 1.816602e-08
step 100: mean loss = 9.040895e-09
step 200: mean loss = 3.6749304e-07
step 300: mean loss = 2.4996768e-07
step 400: mean loss = 1.8932508e-07
step 500: mean loss = 1.5272906e-07
step 600: mean loss = 1.285797e-07
epoch 164: mean loss = 1.238769e-07  learning rate = 2.3782679e-05
============================
Start of epoch 165
step 0: mean loss = 4.341551e-09
step 100: mean loss = 7.748247e-09
step 200: mean loss = 7.343302e-09
step 300: mean loss = 7.275231e-09
step 400: mean loss = 7.3513786e-09
step 500: mean loss = 7.3322513e-09
step 600: mean loss = 7.282728e-09
epoch 165: mean loss = 7.46605e-09  learning rate = 2.3782679e-05
============================
Start of epoch 166
step 0: mean loss = 3.6772092e-09
step 100: mean loss = 9.765898e-09
step 200: mean loss = 9.9253326e-09
step 300: mean loss = 9.6428945e-09
step 400: mean loss = 1.3339211e-08
step 500: mean loss = 1.3556607e-08
step 600: mean loss = 1.2801389e-08
epoch 166: mean loss = 1.3661422e-08  learning rate = 2.3782679e-05
============================
Start of epoch 167
step 0: mean loss = 7.825863e-09
step 100: mean loss = 1.7893699e-08
step 200: mean loss = 5.1460514e-08
step 300: mean loss = 3.9265988e-08
step 400: mean loss = 3.2005943e-08
step 500: mean loss = 2.7539759e-08
step 600: mean loss = 2.5235684e-08
epoch 167: mean loss = 2.465728e-08  learning rate = 2.3782679e-05
============================
Start of epoch 168
step 0: mean loss = 3.860012e-09
step 100: mean loss = 1.4824428e-08
step 200: mean loss = 1.7937136e-08
step 300: mean loss = 2.5687491e-08
step 400: mean loss = 3.236307e-08
step 500: mean loss = 2.888409e-08
step 600: mean loss = 4.0555012e-08
epoch 168: mean loss = 3.977344e-08  learning rate = 2.3782679e-05
============================
Start of epoch 169
step 0: mean loss = 9.490269e-09
step 100: mean loss = 9.619234e-09
step 200: mean loss = 1.14644605e-08
step 300: mean loss = 1.08565e-08
step 400: mean loss = 1.1309657e-08
step 500: mean loss = 1.3422196e-08
step 600: mean loss = 2.1819135e-08
epoch 169: mean loss = 2.125422e-08  learning rate = 2.3782679e-05
============================
Start of epoch 170
step 0: mean loss = 6.154137e-09
step 100: mean loss = 1.7173907e-08
step 200: mean loss = 1.5612317e-08
step 300: mean loss = 1.4331076e-08
step 400: mean loss = 3.8409365e-08
step 500: mean loss = 3.49791e-08
step 600: mean loss = 3.2471235e-08
epoch 170: mean loss = 3.2096825e-08  learning rate = 2.3782679e-05
============================
Start of epoch 171
step 0: mean loss = 1.4535837e-08
step 100: mean loss = 1.5941424e-08
step 200: mean loss = 1.25422694e-08
step 300: mean loss = 1.1428575e-08
step 400: mean loss = 1.1773054e-08
step 500: mean loss = 1.2343403e-08
step 600: mean loss = 1.2473285e-08
epoch 171: mean loss = 1.2274695e-08  learning rate = 2.3782679e-05
============================
Start of epoch 172
step 0: mean loss = 2.0991772e-08
step 100: mean loss = 1.7800943e-08
step 200: mean loss = 3.419592e-08
step 300: mean loss = 2.9242068e-08
step 400: mean loss = 2.4372136e-08
step 500: mean loss = 2.3714566e-08
step 600: mean loss = 2.396775e-08
epoch 172: mean loss = 3.035992e-08  learning rate = 2.3782679e-05
============================
Start of epoch 173
step 0: mean loss = 1.9071288e-07
step 100: mean loss = 2.521973e-07
step 200: mean loss = 1.3106612e-07
step 300: mean loss = 9.120949e-08
step 400: mean loss = 7.0247545e-08
step 500: mean loss = 5.803892e-08
step 600: mean loss = 5.0346227e-08
epoch 173: mean loss = 4.8652566e-08  learning rate = 2.3782679e-05
============================
Start of epoch 174
step 0: mean loss = 5.71736e-09
step 100: mean loss = 6.590843e-09
step 200: mean loss = 9.349877e-09
step 300: mean loss = 1.3165916e-08
step 400: mean loss = 1.4713573e-08
step 500: mean loss = 1.4547912e-08
step 600: mean loss = 1.65674e-08
epoch 174: mean loss = 1.649915e-08  learning rate = 2.3782679e-05
============================
Start of epoch 175
step 0: mean loss = 2.7130318e-08
step 100: mean loss = 4.463423e-08
step 200: mean loss = 2.8884285e-08
step 300: mean loss = 2.4599379e-08
step 400: mean loss = 2.3133467e-08
step 500: mean loss = 2.5895236e-08
step 600: mean loss = 3.281658e-08
epoch 175: mean loss = 3.2082244e-08  learning rate = 2.3782679e-05
============================
Start of epoch 176
step 0: mean loss = 8.723254e-09
step 100: mean loss = 2.961815e-08
step 200: mean loss = 4.3247496e-08
step 300: mean loss = 3.2596798e-08
step 400: mean loss = 2.7487648e-08
step 500: mean loss = 2.3681755e-08
step 600: mean loss = 2.3107628e-08
epoch 176: mean loss = 2.2725857e-08  learning rate = 2.3782679e-05
============================
Start of epoch 177
step 0: mean loss = 6.7008514e-09
step 100: mean loss = 3.5488437e-08
step 200: mean loss = 2.3316272e-08
step 300: mean loss = 3.1953224e-08
step 400: mean loss = 4.818968e-08
step 500: mean loss = 4.2477996e-08
step 600: mean loss = 3.6922206e-08
epoch 177: mean loss = 3.5853354e-08  learning rate = 2.3782679e-05
============================
Start of epoch 178
step 0: mean loss = 3.980751e-09
step 100: mean loss = 9.9032125e-09
step 200: mean loss = 9.228788e-09
step 300: mean loss = 1.0259003e-08
step 400: mean loss = 1.833689e-08
step 500: mean loss = 1.8686713e-08
step 600: mean loss = 1.942225e-08
epoch 178: mean loss = 1.9188258e-08  learning rate = 2.3782679e-05
============================
Start of epoch 179
step 0: mean loss = 4.550291e-09
step 100: mean loss = 9.622563e-09
step 200: mean loss = 3.8943103e-08
step 300: mean loss = 2.9688593e-08
step 400: mean loss = 2.721881e-08
step 500: mean loss = 2.4689033e-08
step 600: mean loss = 2.4805367e-08
epoch 179: mean loss = 2.484698e-08  learning rate = 2.2593546e-05
============================
Start of epoch 180
step 0: mean loss = 1.1675833e-08
step 100: mean loss = 2.0186615e-08
step 200: mean loss = 1.9803458e-08
step 300: mean loss = 2.4806152e-08
step 400: mean loss = 2.2364153e-08
step 500: mean loss = 1.9665578e-08
step 600: mean loss = 2.1535906e-08
epoch 180: mean loss = 2.3821123e-08  learning rate = 2.2593546e-05
============================
Start of epoch 181
step 0: mean loss = 5.6475113e-08
step 100: mean loss = 1.3860377e-07
step 200: mean loss = 7.590211e-08
step 300: mean loss = 5.4292073e-08
step 400: mean loss = 4.25339e-08
step 500: mean loss = 3.7078273e-08
step 600: mean loss = 3.51958e-08
epoch 181: mean loss = 3.4158596e-08  learning rate = 2.2593546e-05
============================
Start of epoch 182
step 0: mean loss = 8.993538e-09
step 100: mean loss = 9.826985e-09
step 200: mean loss = 1.27866056e-08
step 300: mean loss = 1.2746793e-08
step 400: mean loss = 1.3908381e-08
step 500: mean loss = 1.46698715e-08
step 600: mean loss = 1.4528251e-08
epoch 182: mean loss = 1.4528577e-08  learning rate = 2.2593546e-05
============================
Start of epoch 183
step 0: mean loss = 6.349974e-08
step 100: mean loss = 3.798471e-08
step 200: mean loss = 2.469016e-08
step 300: mean loss = 2.4385596e-08
step 400: mean loss = 3.5139198e-08
step 500: mean loss = 3.178458e-08
step 600: mean loss = 2.902499e-08
epoch 183: mean loss = 2.819941e-08  learning rate = 2.2593546e-05
============================
Start of epoch 184
step 0: mean loss = 1.21326185e-08
step 100: mean loss = 9.818922e-09
step 200: mean loss = 4.2469512e-08
step 300: mean loss = 3.7325005e-08
step 400: mean loss = 3.0192805e-08
step 500: mean loss = 2.632031e-08
step 600: mean loss = 2.6434583e-08
epoch 184: mean loss = 2.5782766e-08  learning rate = 2.2593546e-05
============================
Start of epoch 185
step 0: mean loss = 5.5980096e-09
step 100: mean loss = 1.2674975e-08
step 200: mean loss = 1.9440202e-08
step 300: mean loss = 1.7100438e-08
step 400: mean loss = 1.7033907e-08
step 500: mean loss = 2.023797e-08
step 600: mean loss = 3.3131816e-08
epoch 185: mean loss = 3.538942e-08  learning rate = 2.2593546e-05
============================
Start of epoch 186
step 0: mean loss = 1.1519345e-07
step 100: mean loss = 1.3446766e-08
step 200: mean loss = 1.6619227e-08
step 300: mean loss = 1.5133287e-08
step 400: mean loss = 1.485904e-08
step 500: mean loss = 1.42812615e-08
step 600: mean loss = 1.8962998e-08
epoch 186: mean loss = 1.869686e-08  learning rate = 2.2593546e-05
============================
Start of epoch 187
step 0: mean loss = 7.2559345e-09
step 100: mean loss = 4.389838e-08
step 200: mean loss = 3.3159182e-08
step 300: mean loss = 2.6638801e-08
step 400: mean loss = 2.3176712e-08
step 500: mean loss = 2.0125954e-08
step 600: mean loss = 1.8134656e-08
epoch 187: mean loss = 1.7727114e-08  learning rate = 2.2593546e-05
============================
Start of epoch 188
step 0: mean loss = 7.738917e-09
step 100: mean loss = 1.5154795e-08
step 200: mean loss = 1.6515708e-08
step 300: mean loss = 4.3823984e-08
step 400: mean loss = 4.0768338e-08
step 500: mean loss = 3.4556646e-08
step 600: mean loss = 3.197108e-08
epoch 188: mean loss = 3.1187234e-08  learning rate = 2.2593546e-05
============================
Start of epoch 189
step 0: mean loss = 2.3164688e-08
step 100: mean loss = 1.5681959e-08
step 200: mean loss = 1.4837128e-08
step 300: mean loss = 1.2650381e-08
step 400: mean loss = 1.2413846e-08
step 500: mean loss = 1.1523217e-08
step 600: mean loss = 1.7488839e-08
epoch 189: mean loss = 1.7351597e-08  learning rate = 2.2593546e-05
============================
Start of epoch 190
step 0: mean loss = 3.0555483e-08
step 100: mean loss = 2.8131131e-08
step 200: mean loss = 2.4350461e-08
step 300: mean loss = 3.6523357e-08
step 400: mean loss = 3.3778296e-08
step 500: mean loss = 2.8903852e-08
step 600: mean loss = 2.5840999e-08
epoch 190: mean loss = 2.6202667e-08  learning rate = 2.2593546e-05
============================
Start of epoch 191
step 0: mean loss = 4.2531468e-08
step 100: mean loss = 3.746402e-08
step 200: mean loss = 2.4681931e-08
step 300: mean loss = 1.9784476e-08
step 400: mean loss = 2.5977293e-08
step 500: mean loss = 2.6166376e-08
step 600: mean loss = 2.7430124e-08
epoch 191: mean loss = 2.7489895e-08  learning rate = 2.2593546e-05
============================
Start of epoch 192
step 0: mean loss = 1.9027343e-08
step 100: mean loss = 1.1241839e-08
step 200: mean loss = 1.3933646e-08
step 300: mean loss = 2.94394e-08
step 400: mean loss = 2.8675235e-08
step 500: mean loss = 2.4599117e-08
step 600: mean loss = 2.3150422e-08
epoch 192: mean loss = 2.2561494e-08  learning rate = 2.2593546e-05
============================
Start of epoch 193
step 0: mean loss = 3.1836422e-09
step 100: mean loss = 1.8544062e-08
step 200: mean loss = 1.6173699e-08
step 300: mean loss = 2.7167077e-08
step 400: mean loss = 2.6241636e-08
step 500: mean loss = 2.3838194e-08
step 600: mean loss = 2.1543162e-08
epoch 193: mean loss = 2.1171866e-08  learning rate = 2.2593546e-05
============================
Start of epoch 194
step 0: mean loss = 2.4509006e-08
step 100: mean loss = 8.9940535e-09
step 200: mean loss = 1.5640396e-08
step 300: mean loss = 2.424828e-08
step 400: mean loss = 2.0903357e-08
step 500: mean loss = 2.062072e-08
step 600: mean loss = 4.1653113e-08
epoch 194: mean loss = 4.2390813e-08  learning rate = 2.2593546e-05
============================
Start of epoch 195
step 0: mean loss = 9.012836e-09
step 100: mean loss = 1.4562963e-08
step 200: mean loss = 1.1596938e-08
step 300: mean loss = 1.29556765e-08
step 400: mean loss = 1.3740298e-08
step 500: mean loss = 1.3303615e-08
step 600: mean loss = 1.3933875e-08
epoch 195: mean loss = 1.3712996e-08  learning rate = 2.2593546e-05
============================
Start of epoch 196
step 0: mean loss = 1.0669903e-08
step 100: mean loss = 1.00815845e-08
step 200: mean loss = 1.7236548e-08
step 300: mean loss = 2.4302292e-08
step 400: mean loss = 2.1668008e-08
step 500: mean loss = 2.1768741e-08
step 600: mean loss = 2.0404864e-08
epoch 196: mean loss = 1.9919248e-08  learning rate = 2.2593546e-05
============================
Start of epoch 197
step 0: mean loss = 9.806646e-09
step 100: mean loss = 1.4239727e-08
step 200: mean loss = 1.6178191e-08
step 300: mean loss = 2.5885518e-08
step 400: mean loss = 3.291456e-08
step 500: mean loss = 2.8177165e-08
step 600: mean loss = 2.6862974e-08
epoch 197: mean loss = 2.6220759e-08  learning rate = 2.2593546e-05
============================
Start of epoch 198
step 0: mean loss = 4.970405e-09
step 100: mean loss = 1.1893085e-08
step 200: mean loss = 1.8721208e-08
step 300: mean loss = 3.7871974e-08
step 400: mean loss = 3.052865e-08
step 500: mean loss = 2.9267907e-08
step 600: mean loss = 2.611561e-08
epoch 198: mean loss = 2.5887434e-08  learning rate = 2.2593546e-05
============================
Start of epoch 199
step 0: mean loss = 7.619419e-09
step 100: mean loss = 1.7335363e-08
step 200: mean loss = 2.3895808e-08
step 300: mean loss = 2.3217307e-08
step 400: mean loss = 2.4441071e-08
step 500: mean loss = 2.1208376e-08
step 600: mean loss = 2.0340874e-08
epoch 199: mean loss = 2.0937023e-08  learning rate = 2.1463866e-05
============================
Start of epoch 200
step 0: mean loss = 2.3849271e-08
step 100: mean loss = 1.845688e-08
step 200: mean loss = 1.832086e-08
step 300: mean loss = 1.9928834e-08
step 400: mean loss = 1.9946292e-08
step 500: mean loss = 2.0522107e-08
step 600: mean loss = 2.312052e-08
epoch 200: mean loss = 2.2761947e-08  learning rate = 2.1463866e-05
============================
Start of epoch 201
step 0: mean loss = 6.227663e-09
step 100: mean loss = 3.8561705e-08
step 200: mean loss = 2.6400947e-08
step 300: mean loss = 2.4073344e-08
step 400: mean loss = 2.0405535e-08
step 500: mean loss = 2.0273708e-08
step 600: mean loss = 1.9138747e-08
epoch 201: mean loss = 1.8894523e-08  learning rate = 2.1463866e-05
============================
Start of epoch 202
step 0: mean loss = 8.511411e-09
step 100: mean loss = 1.9505212e-08
step 200: mean loss = 1.5905048e-08
step 300: mean loss = 1.9442263e-08
step 400: mean loss = 2.0479021e-08
step 500: mean loss = 1.8107457e-08
step 600: mean loss = 2.150538e-08
epoch 202: mean loss = 2.7121844e-08  learning rate = 2.1463866e-05
============================
Start of epoch 203
step 0: mean loss = 5.9181524e-08
step 100: mean loss = 5.3264962e-08
step 200: mean loss = 3.2226808e-08
step 300: mean loss = 2.4565782e-08
step 400: mean loss = 2.067501e-08
step 500: mean loss = 1.8171303e-08
step 600: mean loss = 2.2286695e-08
epoch 203: mean loss = 2.2427477e-08  learning rate = 2.1463866e-05
============================
Start of epoch 204
step 0: mean loss = 5.9704583e-09
step 100: mean loss = 2.960283e-08
step 200: mean loss = 2.0003185e-08
step 300: mean loss = 2.5957217e-08
step 400: mean loss = 2.6034112e-08
step 500: mean loss = 2.244916e-08
step 600: mean loss = 2.6505896e-08
epoch 204: mean loss = 2.8527644e-08  learning rate = 2.1463866e-05
============================
Start of epoch 205
step 0: mean loss = 5.7952545e-09
step 100: mean loss = 1.6079044e-08
step 200: mean loss = 1.3489857e-08
step 300: mean loss = 1.1866024e-08
step 400: mean loss = 1.2800193e-08
step 500: mean loss = 1.9892774e-08
step 600: mean loss = 1.853035e-08
epoch 205: mean loss = 1.8284197e-08  learning rate = 2.1463866e-05
============================
Start of epoch 206
step 0: mean loss = 6.817217e-09
step 100: mean loss = 6.4762293e-09
step 200: mean loss = 1.3966779e-08
step 300: mean loss = 2.5814728e-08
step 400: mean loss = 2.2189466e-08
step 500: mean loss = 2.3738416e-08
step 600: mean loss = 2.4743642e-08
epoch 206: mean loss = 2.3996435e-08  learning rate = 2.1463866e-05
============================
Start of epoch 207
step 0: mean loss = 3.875362e-09
step 100: mean loss = 8.5483435e-08
step 200: mean loss = 1.0235856e-07
step 300: mean loss = 7.032578e-08
step 400: mean loss = 5.4552284e-08
step 500: mean loss = 4.598246e-08
step 600: mean loss = 3.9979234e-08
epoch 207: mean loss = 3.8855614e-08  learning rate = 2.1463866e-05
============================
Start of epoch 208
step 0: mean loss = 7.279239e-09
step 100: mean loss = 6.741208e-09
step 200: mean loss = 1.05415845e-08
step 300: mean loss = 2.0917588e-08
step 400: mean loss = 2.0661554e-08
step 500: mean loss = 1.9512122e-08
step 600: mean loss = 1.8080916e-08
epoch 208: mean loss = 1.7997458e-08  learning rate = 2.1463866e-05
============================
Start of epoch 209
step 0: mean loss = 4.9824935e-09
step 100: mean loss = 5.5955855e-08
step 200: mean loss = 3.7725393e-08
step 300: mean loss = 2.9743157e-08
step 400: mean loss = 2.620061e-08
step 500: mean loss = 2.4458332e-08
step 600: mean loss = 2.232284e-08
epoch 209: mean loss = 2.2018817e-08  learning rate = 2.1463866e-05
============================
Start of epoch 210
step 0: mean loss = 2.145246e-08
step 100: mean loss = 9.743026e-09
step 200: mean loss = 1.1754028e-08
step 300: mean loss = 1.1445513e-08
step 400: mean loss = 1.1020032e-08
step 500: mean loss = 3.2489183e-08
step 600: mean loss = 2.8992632e-08
epoch 210: mean loss = 2.817348e-08  learning rate = 2.1463866e-05
============================
Start of epoch 211
step 0: mean loss = 1.857171e-08
step 100: mean loss = 8.2841245e-09
step 200: mean loss = 7.771672e-09
step 300: mean loss = 9.32778e-09
step 400: mean loss = 1.3083681e-08
step 500: mean loss = 1.7380078e-08
step 600: mean loss = 2.688789e-08
epoch 211: mean loss = 2.7719365e-08  learning rate = 2.1463866e-05
============================
Start of epoch 212
step 0: mean loss = 1.7750203e-08
step 100: mean loss = 1.241298e-08
step 200: mean loss = 1.3156834e-08
step 300: mean loss = 1.2318719e-08
step 400: mean loss = 1.7649166e-08
step 500: mean loss = 1.591178e-08
step 600: mean loss = 1.508474e-08
epoch 212: mean loss = 1.5425702e-08  learning rate = 2.1463866e-05
============================
Start of epoch 213
step 0: mean loss = 1.5942934e-08
step 100: mean loss = 9.861234e-08
step 200: mean loss = 6.8665614e-08
step 300: mean loss = 5.0054897e-08
step 400: mean loss = 4.0208292e-08
step 500: mean loss = 3.4520014e-08
step 600: mean loss = 3.042721e-08
epoch 213: mean loss = 2.9511229e-08  learning rate = 2.1463866e-05
============================
Start of epoch 214
step 0: mean loss = 6.4926673e-09
step 100: mean loss = 7.454338e-09
step 200: mean loss = 2.0518451e-08
step 300: mean loss = 1.7397415e-08
step 400: mean loss = 1.6420467e-08
step 500: mean loss = 1.9550667e-08
step 600: mean loss = 1.834172e-08
epoch 214: mean loss = 1.8316952e-08  learning rate = 2.1463866e-05
============================
Start of epoch 215
step 0: mean loss = 1.1533105e-08
step 100: mean loss = 1.9322991e-08
step 200: mean loss = 2.3443137e-08
step 300: mean loss = 5.6003234e-08
step 400: mean loss = 4.490416e-08
step 500: mean loss = 3.7482604e-08
step 600: mean loss = 3.7456104e-08
epoch 215: mean loss = 3.6248878e-08  learning rate = 2.1463866e-05
============================
Start of epoch 216
step 0: mean loss = 1.4340531e-08
step 100: mean loss = 7.94182e-09
step 200: mean loss = 9.266748e-09
step 300: mean loss = 1.1600785e-08
step 400: mean loss = 1.12125225e-08
step 500: mean loss = 1.13514975e-08
step 600: mean loss = 1.2219097e-08
epoch 216: mean loss = 1.2760156e-08  learning rate = 2.1463866e-05
============================
Start of epoch 217
step 0: mean loss = 1.12493215e-08
step 100: mean loss = 1.1963405e-08
step 200: mean loss = 1.5145035e-08
step 300: mean loss = 1.4216812e-08
step 400: mean loss = 1.4436872e-08
step 500: mean loss = 1.5359054e-08
step 600: mean loss = 1.591499e-08
epoch 217: mean loss = 1.6278696e-08  learning rate = 2.1463866e-05
============================
Start of epoch 218
step 0: mean loss = 1.6316038e-08
step 100: mean loss = 1.6499559e-08
step 200: mean loss = 3.5077207e-08
step 300: mean loss = 2.6931982e-08
step 400: mean loss = 2.7926248e-08
step 500: mean loss = 2.4048635e-08
step 600: mean loss = 2.1299078e-08
epoch 218: mean loss = 2.0733419e-08  learning rate = 2.1463866e-05
============================
Start of epoch 219
step 0: mean loss = 6.7775354e-09
step 100: mean loss = 1.0976628e-08
step 200: mean loss = 1.6638039e-08
step 300: mean loss = 1.797118e-08
step 400: mean loss = 3.52124e-08
step 500: mean loss = 3.019535e-08
step 600: mean loss = 2.6796837e-08
epoch 219: mean loss = 2.6391955e-08  learning rate = 2.0390673e-05
============================
Start of epoch 220
step 0: mean loss = 1.27111095e-08
step 100: mean loss = 2.1607187e-08
step 200: mean loss = 1.6206384e-08
step 300: mean loss = 1.5233878e-08
step 400: mean loss = 1.4125362e-08
step 500: mean loss = 1.3388257e-08
step 600: mean loss = 1.3559743e-08
epoch 220: mean loss = 1.3753345e-08  learning rate = 2.0390673e-05
============================
Start of epoch 221
step 0: mean loss = 8.214324e-09
step 100: mean loss = 6.9231e-08
step 200: mean loss = 4.057344e-08
step 300: mean loss = 3.014105e-08
step 400: mean loss = 2.4734014e-08
step 500: mean loss = 2.8384754e-08
step 600: mean loss = 2.4973325e-08
epoch 221: mean loss = 2.4272286e-08  learning rate = 2.0390673e-05
============================
Start of epoch 222
step 0: mean loss = 7.813254e-09
step 100: mean loss = 1.5139145e-08
step 200: mean loss = 1.8365482e-08
step 300: mean loss = 2.2592104e-08
step 400: mean loss = 2.0863096e-08
step 500: mean loss = 1.931251e-08
step 600: mean loss = 1.7362838e-08
epoch 222: mean loss = 1.725882e-08  learning rate = 2.0390673e-05
============================
Start of epoch 223
step 0: mean loss = 1.0186915e-08
step 100: mean loss = 7.705952e-09
step 200: mean loss = 9.729212e-09
step 300: mean loss = 1.744973e-08
step 400: mean loss = 3.503707e-08
step 500: mean loss = 3.2869757e-08
step 600: mean loss = 3.217116e-08
epoch 223: mean loss = 3.141508e-08  learning rate = 2.0390673e-05
============================
Start of epoch 224
step 0: mean loss = 8.009096e-09
step 100: mean loss = 1.0379462e-08
step 200: mean loss = 1.0211147e-08
step 300: mean loss = 1.135945e-08
step 400: mean loss = 1.1351835e-08
step 500: mean loss = 1.315053e-08
step 600: mean loss = 1.4326574e-08
epoch 224: mean loss = 1.42062735e-08  learning rate = 2.0390673e-05
============================
Start of epoch 225
step 0: mean loss = 1.035867e-08
step 100: mean loss = 1.4383865e-08
step 200: mean loss = 1.600176e-08
step 300: mean loss = 1.576047e-08
step 400: mean loss = 1.4209635e-08
step 500: mean loss = 2.5040782e-08
step 600: mean loss = 2.21799e-08
epoch 225: mean loss = 2.2168948e-08  learning rate = 2.0390673e-05
============================
Start of epoch 226
step 0: mean loss = 2.7355815e-08
step 100: mean loss = 5.5962047e-08
step 200: mean loss = 3.8214342e-08
step 300: mean loss = 2.8646602e-08
step 400: mean loss = 2.7326008e-08
step 500: mean loss = 2.6817379e-08
step 600: mean loss = 2.4011404e-08
epoch 226: mean loss = 2.3615861e-08  learning rate = 2.0390673e-05
============================
Start of epoch 227
step 0: mean loss = 1.0422255e-08
step 100: mean loss = 9.684618e-09
step 200: mean loss = 1.1238212e-08
step 300: mean loss = 1.4524949e-08
step 400: mean loss = 1.3668255e-08
step 500: mean loss = 2.077033e-08
step 600: mean loss = 1.9137651e-08
epoch 227: mean loss = 1.8626455e-08  learning rate = 2.0390673e-05
============================
Start of epoch 228
step 0: mean loss = 4.870858e-09
step 100: mean loss = 9.552617e-09
step 200: mean loss = 2.9241875e-08
step 300: mean loss = 3.1011044e-08
step 400: mean loss = 2.6127458e-08
step 500: mean loss = 2.2254223e-08
step 600: mean loss = 2.1426894e-08
epoch 228: mean loss = 2.499384e-08  learning rate = 2.0390673e-05
============================
Start of epoch 229
step 0: mean loss = 2.9190656e-07
step 100: mean loss = 5.951813e-08
step 200: mean loss = 3.5018157e-08
step 300: mean loss = 2.9200525e-08
step 400: mean loss = 2.7613405e-08
step 500: mean loss = 2.3760633e-08
step 600: mean loss = 2.0971255e-08
epoch 229: mean loss = 2.050581e-08  learning rate = 2.0390673e-05
============================
Start of epoch 230
step 0: mean loss = 9.925918e-09
step 100: mean loss = 1.1607098e-08
step 200: mean loss = 1.0799386e-08
step 300: mean loss = 1.0232353e-08
step 400: mean loss = 2.1896087e-08
step 500: mean loss = 2.5028383e-08
step 600: mean loss = 2.2391658e-08
epoch 230: mean loss = 2.1912255e-08  learning rate = 2.0390673e-05
============================
Start of epoch 231
step 0: mean loss = 7.555749e-09
step 100: mean loss = 9.511652e-09
step 200: mean loss = 9.612631e-09
step 300: mean loss = 1.2646015e-08
step 400: mean loss = 1.2267348e-08
step 500: mean loss = 1.6198902e-08
step 600: mean loss = 1.823622e-08
epoch 231: mean loss = 1.8147885e-08  learning rate = 2.0390673e-05
============================
Start of epoch 232
step 0: mean loss = 1.4978975e-08
step 100: mean loss = 2.2876776e-08
step 200: mean loss = 1.736613e-08
step 300: mean loss = 1.6742367e-08
step 400: mean loss = 1.6460577e-08
step 500: mean loss = 1.626515e-08
step 600: mean loss = 1.6221271e-08
epoch 232: mean loss = 1.6211406e-08  learning rate = 2.0390673e-05
============================
Start of epoch 233
step 0: mean loss = 1.7575951e-08
step 100: mean loss = 9.973717e-09
step 200: mean loss = 1.1674885e-08
step 300: mean loss = 1.4629608e-08
step 400: mean loss = 1.6146975e-08
step 500: mean loss = 2.587054e-08
step 600: mean loss = 2.5282127e-08
epoch 233: mean loss = 2.4970632e-08  learning rate = 2.0390673e-05
============================
Start of epoch 234
step 0: mean loss = 7.0130284e-09
step 100: mean loss = 1.0031113e-08
step 200: mean loss = 1.7627771e-08
step 300: mean loss = 1.8062169e-08
step 400: mean loss = 1.5505039e-08
step 500: mean loss = 1.8032413e-08
step 600: mean loss = 2.0285725e-08
epoch 234: mean loss = 1.9831147e-08  learning rate = 2.0390673e-05
============================
Start of epoch 235
step 0: mean loss = 6.1105125e-09
step 100: mean loss = 1.0082621e-08
step 200: mean loss = 1.07675895e-08
step 300: mean loss = 1.9569674e-08
step 400: mean loss = 1.7518586e-08
step 500: mean loss = 2.2951044e-08
step 600: mean loss = 2.0808672e-08
epoch 235: mean loss = 2.0249816e-08  learning rate = 2.0390673e-05
============================
Start of epoch 236
step 0: mean loss = 1.05184235e-08
step 100: mean loss = 1.7044625e-08
step 200: mean loss = 1.5041019e-08
step 300: mean loss = 1.4620414e-08
step 400: mean loss = 1.9781037e-08
step 500: mean loss = 1.81126e-08
step 600: mean loss = 1.7380849e-08
epoch 236: mean loss = 1.7031917e-08  learning rate = 2.0390673e-05
============================
Start of epoch 237
step 0: mean loss = 1.5012418e-08
step 100: mean loss = 3.0825163e-08
step 200: mean loss = 2.1740885e-08
step 300: mean loss = 2.0942519e-08
step 400: mean loss = 1.8006956e-08
step 500: mean loss = 1.6144396e-08
step 600: mean loss = 1.6167109e-08
epoch 237: mean loss = 1.5843186e-08  learning rate = 2.0390673e-05
============================
Start of epoch 238
step 0: mean loss = 2.4271056e-08
step 100: mean loss = 4.8903214e-08
step 200: mean loss = 3.005562e-08
step 300: mean loss = 2.6726303e-08
step 400: mean loss = 3.4118592e-08
step 500: mean loss = 2.8812675e-08
step 600: mean loss = 2.5604328e-08
epoch 238: mean loss = 2.6097865e-08  learning rate = 2.0390673e-05
============================
Start of epoch 239
step 0: mean loss = 6.003953e-08
step 100: mean loss = 2.5468317e-08
step 200: mean loss = 2.16778e-08
step 300: mean loss = 1.7436244e-08
step 400: mean loss = 1.5705181e-08
step 500: mean loss = 1.592293e-08
step 600: mean loss = 1.8021163e-08
epoch 239: mean loss = 1.85482e-08  learning rate = 1.937114e-05
============================
Start of epoch 240
step 0: mean loss = 1.3052154e-08
step 100: mean loss = 4.619245e-08
step 200: mean loss = 2.7099205e-08
step 300: mean loss = 2.8399002e-08
step 400: mean loss = 2.5674256e-08
step 500: mean loss = 2.4470129e-08
step 600: mean loss = 2.144693e-08
epoch 240: mean loss = 2.0879062e-08  learning rate = 1.937114e-05
============================
Start of epoch 241
step 0: mean loss = 2.809236e-09
step 100: mean loss = 7.879467e-09
step 200: mean loss = 1.286665e-08
step 300: mean loss = 1.3189903e-08
step 400: mean loss = 1.2169296e-08
step 500: mean loss = 1.1609758e-08
step 600: mean loss = 1.6914651e-08
epoch 241: mean loss = 1.707252e-08  learning rate = 1.937114e-05
============================
Start of epoch 242
step 0: mean loss = 2.2763032e-08
step 100: mean loss = 1.3920936e-08
step 200: mean loss = 1.1058129e-08
step 300: mean loss = 1.176816e-08
step 400: mean loss = 1.697859e-08
step 500: mean loss = 1.5028299e-08
step 600: mean loss = 1.512809e-08
epoch 242: mean loss = 1.5225254e-08  learning rate = 1.937114e-05
============================
Start of epoch 243
step 0: mean loss = 1.2552144e-08
step 100: mean loss = 1.1140666e-08
step 200: mean loss = 1.2916809e-08
step 300: mean loss = 2.1513385e-08
step 400: mean loss = 1.9803878e-08
step 500: mean loss = 1.9781547e-08
step 600: mean loss = 1.9372212e-08
epoch 243: mean loss = 2.1913012e-08  learning rate = 1.937114e-05
============================
Start of epoch 244
step 0: mean loss = 1.7856594e-08
step 100: mean loss = 1.3126987e-08
step 200: mean loss = 1.0640215e-08
step 300: mean loss = 1.7460277e-08
step 400: mean loss = 1.962199e-08
step 500: mean loss = 4.0480618e-08
step 600: mean loss = 3.47545e-08
epoch 244: mean loss = 3.3624225e-08  learning rate = 1.937114e-05
============================
Start of epoch 245
step 0: mean loss = 6.5395866e-09
step 100: mean loss = 7.301678e-09
step 200: mean loss = 8.255221e-09
step 300: mean loss = 8.598169e-09
step 400: mean loss = 8.280113e-09
step 500: mean loss = 7.859974e-09
step 600: mean loss = 8.521877e-09
epoch 245: mean loss = 8.621098e-09  learning rate = 1.937114e-05
============================
Start of epoch 246
step 0: mean loss = 8.7836005e-09
step 100: mean loss = 1.2948172e-08
step 200: mean loss = 1.1487883e-08
step 300: mean loss = 1.0558525e-08
step 400: mean loss = 1.0294309e-08
step 500: mean loss = 1.3736801e-08
step 600: mean loss = 1.5947307e-08
epoch 246: mean loss = 1.5640868e-08  learning rate = 1.937114e-05
============================
Start of epoch 247
step 0: mean loss = 3.8434975e-09
step 100: mean loss = 8.295545e-09
step 200: mean loss = 1.2186688e-08
step 300: mean loss = 1.1440208e-08
step 400: mean loss = 2.054075e-08
step 500: mean loss = 1.7758554e-08
step 600: mean loss = 1.8075072e-08
epoch 247: mean loss = 1.8119882e-08  learning rate = 1.937114e-05
============================
Start of epoch 248
step 0: mean loss = 1.4921133e-08
step 100: mean loss = 1.390067e-08
step 200: mean loss = 1.4720594e-08
step 300: mean loss = 1.4763285e-08
step 400: mean loss = 1.5116356e-08
step 500: mean loss = 1.5085549e-08
step 600: mean loss = 1.6357635e-08
epoch 248: mean loss = 1.7529375e-08  learning rate = 1.937114e-05
============================
Start of epoch 249
step 0: mean loss = 1.9842517e-07
step 100: mean loss = 2.4181816e-08
step 200: mean loss = 1.6583803e-08
step 300: mean loss = 1.565656e-08
step 400: mean loss = 1.4973486e-08
step 500: mean loss = 1.4352255e-08
step 600: mean loss = 1.7286151e-08
epoch 249: mean loss = 1.8230724e-08  learning rate = 1.937114e-05
============================
Start of epoch 250
step 0: mean loss = 9.938335e-09
step 100: mean loss = 1.17690515e-08
step 200: mean loss = 1.208881e-08
step 300: mean loss = 1.2080462e-08
step 400: mean loss = 2.5005017e-08
step 500: mean loss = 2.2288164e-08
step 600: mean loss = 1.9971514e-08
epoch 250: mean loss = 1.9583663e-08  learning rate = 1.937114e-05
============================
Start of epoch 251
step 0: mean loss = 3.4894295e-08
step 100: mean loss = 3.5592272e-08
step 200: mean loss = 2.4622612e-08
step 300: mean loss = 2.5479519e-08
step 400: mean loss = 2.138299e-08
step 500: mean loss = 1.8831221e-08
step 600: mean loss = 1.6842945e-08
epoch 251: mean loss = 1.6440952e-08  learning rate = 1.937114e-05
============================
Start of epoch 252
step 0: mean loss = 7.908875e-09
step 100: mean loss = 3.8779916e-08
step 200: mean loss = 5.5373835e-08
step 300: mean loss = 3.9401787e-08
step 400: mean loss = 3.224141e-08
step 500: mean loss = 2.8165184e-08
step 600: mean loss = 2.6071191e-08
epoch 252: mean loss = 2.5622553e-08  learning rate = 1.937114e-05
============================
Start of epoch 253
step 0: mean loss = 2.267075e-08
step 100: mean loss = 1.0975528e-08
step 200: mean loss = 1.6344034e-08
step 300: mean loss = 1.4522381e-08
step 400: mean loss = 1.3090026e-08
step 500: mean loss = 1.2216449e-08
step 600: mean loss = 1.1528711e-08
epoch 253: mean loss = 1.1474743e-08  learning rate = 1.937114e-05
============================
Start of epoch 254
step 0: mean loss = 1.6773438e-08
step 100: mean loss = 8.6510944e-08
step 200: mean loss = 4.7831254e-08
step 300: mean loss = 3.5872482e-08
step 400: mean loss = 2.9116523e-08
step 500: mean loss = 2.5077714e-08
step 600: mean loss = 2.225816e-08
epoch 254: mean loss = 2.192106e-08  learning rate = 1.937114e-05
============================
Start of epoch 255
step 0: mean loss = 1.5463765e-08
step 100: mean loss = 1.6948945e-08
step 200: mean loss = 1.2041832e-08
step 300: mean loss = 1.0313683e-08
step 400: mean loss = 1.1651958e-08
step 500: mean loss = 1.7610155e-08
step 600: mean loss = 2.3112191e-08
epoch 255: mean loss = 2.2724658e-08  learning rate = 1.937114e-05
============================
Start of epoch 256
step 0: mean loss = 6.230225e-08
step 100: mean loss = 3.905601e-08
step 200: mean loss = 4.1491308e-08
step 300: mean loss = 3.3934008e-08
step 400: mean loss = 2.7509175e-08
step 500: mean loss = 2.533184e-08
step 600: mean loss = 2.3295321e-08
epoch 256: mean loss = 2.268176e-08  learning rate = 1.937114e-05
============================
Start of epoch 257
step 0: mean loss = 9.054365e-09
step 100: mean loss = 1.0694319e-08
step 200: mean loss = 1.2496259e-08
step 300: mean loss = 1.3612817e-08
step 400: mean loss = 1.6235752e-08
step 500: mean loss = 1.439942e-08
step 600: mean loss = 1.3137731e-08
epoch 257: mean loss = 1.3005319e-08  learning rate = 1.937114e-05
============================
Start of epoch 258
step 0: mean loss = 4.9840425e-09
step 100: mean loss = 2.327595e-08
step 200: mean loss = 2.4942096e-08
step 300: mean loss = 2.3775128e-08
step 400: mean loss = 2.0286958e-08
step 500: mean loss = 1.8005249e-08
step 600: mean loss = 2.0074383e-08
epoch 258: mean loss = 1.973524e-08  learning rate = 1.937114e-05
============================
Start of epoch 259
step 0: mean loss = 7.1575266e-09
step 100: mean loss = 7.7109386e-09
step 200: mean loss = 1.0559721e-08
step 300: mean loss = 1.9504595e-08
step 400: mean loss = 2.6219658e-08
step 500: mean loss = 2.3426336e-08
step 600: mean loss = 2.1081327e-08
epoch 259: mean loss = 2.0522876e-08  learning rate = 1.8402581e-05
============================
Start of epoch 260
step 0: mean loss = 1.1395448e-08
step 100: mean loss = 1.1070386e-08
step 200: mean loss = 9.484582e-09
step 300: mean loss = 1.7656525e-08
step 400: mean loss = 2.0072534e-08
step 500: mean loss = 1.8048746e-08
step 600: mean loss = 1.692395e-08
epoch 260: mean loss = 1.6608652e-08  learning rate = 1.8402581e-05
============================
Start of epoch 261
step 0: mean loss = 1.31408555e-08
step 100: mean loss = 1.7026576e-08
step 200: mean loss = 1.1729224e-08
step 300: mean loss = 1.1872314e-08
step 400: mean loss = 1.0799377e-08
step 500: mean loss = 1.0552709e-08
step 600: mean loss = 1.4128901e-08
epoch 261: mean loss = 1.4980392e-08  learning rate = 1.8402581e-05
============================
Start of epoch 262
step 0: mean loss = 6.4598e-08
step 100: mean loss = 1.519555e-08
step 200: mean loss = 1.3833087e-08
step 300: mean loss = 1.523135e-08
step 400: mean loss = 1.7189828e-08
step 500: mean loss = 1.4968853e-08
step 600: mean loss = 1.421595e-08
epoch 262: mean loss = 1.3868767e-08  learning rate = 1.8402581e-05
============================
Start of epoch 263
step 0: mean loss = 4.6610977e-09
step 100: mean loss = 1.0332242e-08
step 200: mean loss = 1.17903625e-08
step 300: mean loss = 2.1531807e-08
step 400: mean loss = 2.8566788e-08
step 500: mean loss = 2.4745134e-08
step 600: mean loss = 2.2356048e-08
epoch 263: mean loss = 2.177891e-08  learning rate = 1.8402581e-05
============================
Start of epoch 264
step 0: mean loss = 5.083955e-09
step 100: mean loss = 2.7757231e-08
step 200: mean loss = 2.8664898e-08
step 300: mean loss = 2.1676906e-08
step 400: mean loss = 1.8225874e-08
step 500: mean loss = 1.6311404e-08
step 600: mean loss = 1.5299248e-08
epoch 264: mean loss = 1.5004295e-08  learning rate = 1.8402581e-05
============================
Start of epoch 265
step 0: mean loss = 6.0586856e-09
step 100: mean loss = 9.037049e-09
step 200: mean loss = 1.2639409e-08
step 300: mean loss = 1.1488612e-08
step 400: mean loss = 1.9523675e-08
step 500: mean loss = 1.7914207e-08
step 600: mean loss = 1.6706082e-08
epoch 265: mean loss = 1.644896e-08  learning rate = 1.8402581e-05
============================
Start of epoch 266
step 0: mean loss = 6.2851497e-09
step 100: mean loss = 9.164617e-09
step 200: mean loss = 8.3314955e-09
step 300: mean loss = 8.784816e-09
step 400: mean loss = 9.092454e-09
step 500: mean loss = 1.373554e-08
step 600: mean loss = 1.6466473e-08
epoch 266: mean loss = 1.6312983e-08  learning rate = 1.8402581e-05
============================
Start of epoch 267
step 0: mean loss = 1.5912184e-08
step 100: mean loss = 2.045813e-08
step 200: mean loss = 1.5889912e-08
step 300: mean loss = 2.0891086e-08
step 400: mean loss = 1.7475372e-08
step 500: mean loss = 1.5974287e-08
step 600: mean loss = 1.468327e-08
epoch 267: mean loss = 1.4518439e-08  learning rate = 1.8402581e-05
============================
Start of epoch 268
step 0: mean loss = 1.0365324e-08
step 100: mean loss = 1.5294756e-08
step 200: mean loss = 1.711723e-08
step 300: mean loss = 1.589818e-08
step 400: mean loss = 1.5115537e-08
step 500: mean loss = 1.3847681e-08
step 600: mean loss = 1.4658975e-08
epoch 268: mean loss = 1.4338485e-08  learning rate = 1.8402581e-05
============================
Start of epoch 269
step 0: mean loss = 1.0849741e-08
step 100: mean loss = 3.1291414e-08
step 200: mean loss = 2.3417474e-08
step 300: mean loss = 2.0660645e-08
step 400: mean loss = 1.7578378e-08
step 500: mean loss = 1.6662337e-08
step 600: mean loss = 1.9352163e-08
epoch 269: mean loss = 1.9326489e-08  learning rate = 1.8402581e-05
============================
Start of epoch 270
step 0: mean loss = 8.2541625e-08
step 100: mean loss = 4.8373323e-08
step 200: mean loss = 2.9418997e-08
step 300: mean loss = 2.2567884e-08
step 400: mean loss = 2.177523e-08
step 500: mean loss = 1.990183e-08
step 600: mean loss = 2.1551715e-08
epoch 270: mean loss = 2.112505e-08  learning rate = 1.8402581e-05
============================
Start of epoch 271
step 0: mean loss = 9.544348e-09
step 100: mean loss = 9.6308135e-09
step 200: mean loss = 1.1752599e-08
step 300: mean loss = 1.040306e-08
step 400: mean loss = 1.2902918e-08
step 500: mean loss = 1.180489e-08
step 600: mean loss = 1.11121405e-08
epoch 271: mean loss = 1.10445955e-08  learning rate = 1.8402581e-05
============================
Start of epoch 272
step 0: mean loss = 5.074602e-09
step 100: mean loss = 1.4369347e-08
step 200: mean loss = 7.089894e-08
step 300: mean loss = 5.409588e-08
step 400: mean loss = 4.231124e-08
step 500: mean loss = 3.5066705e-08
step 600: mean loss = 3.0158656e-08
epoch 272: mean loss = 2.9275794e-08  learning rate = 1.8402581e-05
============================
Start of epoch 273
step 0: mean loss = 1.0762619e-08
step 100: mean loss = 1.3387737e-08
step 200: mean loss = 1.2286291e-08
step 300: mean loss = 1.0379172e-08
step 400: mean loss = 1.0128667e-08
step 500: mean loss = 1.2324223e-08
step 600: mean loss = 1.6781579e-08
epoch 273: mean loss = 1.6488686e-08  learning rate = 1.8402581e-05
============================
Start of epoch 274
step 0: mean loss = 2.132846e-08
step 100: mean loss = 7.237885e-09
step 200: mean loss = 7.559023e-09
step 300: mean loss = 7.916757e-09
step 400: mean loss = 8.964831e-09
step 500: mean loss = 8.575405e-09
step 600: mean loss = 1.0764899e-08
epoch 274: mean loss = 1.0747211e-08  learning rate = 1.8402581e-05
============================
Start of epoch 275
step 0: mean loss = 6.5241026e-09
step 100: mean loss = 2.5789799e-08
step 200: mean loss = 1.6496386e-08
step 300: mean loss = 1.5743561e-08
step 400: mean loss = 3.293977e-08
step 500: mean loss = 3.0575116e-08
step 600: mean loss = 2.6521214e-08
epoch 275: mean loss = 2.5793188e-08  learning rate = 1.8402581e-05
============================
Start of epoch 276
step 0: mean loss = 1.0599075e-08
step 100: mean loss = 8.244953e-09
step 200: mean loss = 8.567253e-09
step 300: mean loss = 8.798501e-09
step 400: mean loss = 9.723505e-09
step 500: mean loss = 1.1252576e-08
step 600: mean loss = 2.249912e-08
epoch 276: mean loss = 2.1842602e-08  learning rate = 1.8402581e-05
============================
Start of epoch 277
step 0: mean loss = 4.0231134e-09
step 100: mean loss = 6.7324004e-09
step 200: mean loss = 9.019672e-09
step 300: mean loss = 8.3352445e-09
step 400: mean loss = 8.798979e-09
step 500: mean loss = 1.0120179e-08
step 600: mean loss = 1.1316937e-08
epoch 277: mean loss = 1.1241361e-08  learning rate = 1.8402581e-05
============================
Start of epoch 278
step 0: mean loss = 1.9766503e-08
step 100: mean loss = 1.20745325e-08
step 200: mean loss = 2.6620702e-08
step 300: mean loss = 2.1686535e-08
step 400: mean loss = 1.8822087e-08
step 500: mean loss = 3.1568984e-08
step 600: mean loss = 2.8090975e-08
epoch 278: mean loss = 2.7170943e-08  learning rate = 1.8402581e-05
============================
Start of epoch 279
step 0: mean loss = 5.6082916e-09
step 100: mean loss = 5.397142e-09
step 200: mean loss = 6.739099e-09
step 300: mean loss = 1.0364834e-08
step 400: mean loss = 1.1250016e-08
step 500: mean loss = 1.03781606e-08
step 600: mean loss = 9.643201e-09
epoch 279: mean loss = 1.0247641e-08  learning rate = 1.7482453e-05
============================
Start of epoch 280
step 0: mean loss = 7.024577e-08
step 100: mean loss = 1.7235916e-08
step 200: mean loss = 1.31623965e-08
step 300: mean loss = 1.1841055e-08
step 400: mean loss = 1.0558341e-08
step 500: mean loss = 1.1290742e-08
step 600: mean loss = 1.1295421e-08
epoch 280: mean loss = 1.1063744e-08  learning rate = 1.7482453e-05
============================
Start of epoch 281
step 0: mean loss = 1.4674464e-08
step 100: mean loss = 1.0162745e-08
step 200: mean loss = 1.3106812e-08
step 300: mean loss = 1.9935754e-08
step 400: mean loss = 1.7202007e-08
step 500: mean loss = 1.541676e-08
step 600: mean loss = 1.4180095e-08
epoch 281: mean loss = 1.4408752e-08  learning rate = 1.7482453e-05
============================
Start of epoch 282
step 0: mean loss = 2.0868509e-08
step 100: mean loss = 1.7296852e-08
step 200: mean loss = 1.5646911e-08
step 300: mean loss = 2.632054e-08
step 400: mean loss = 2.1533967e-08
step 500: mean loss = 1.9137419e-08
step 600: mean loss = 1.9132031e-08
epoch 282: mean loss = 1.894461e-08  learning rate = 1.7482453e-05
============================
Start of epoch 283
step 0: mean loss = 8.572508e-09
step 100: mean loss = 8.948907e-09
step 200: mean loss = 7.2795774e-09
step 300: mean loss = 1.3576094e-08
step 400: mean loss = 1.19811645e-08
step 500: mean loss = 1.2751283e-08
step 600: mean loss = 1.7370704e-08
epoch 283: mean loss = 1.6967713e-08  learning rate = 1.7482453e-05
============================
Start of epoch 284
step 0: mean loss = 1.5592267e-08
step 100: mean loss = 1.5191262e-08
step 200: mean loss = 1.172661e-08
step 300: mean loss = 1.0810633e-08
step 400: mean loss = 9.594895e-09
step 500: mean loss = 1.08043725e-08
step 600: mean loss = 1.1037844e-08
epoch 284: mean loss = 1.1407669e-08  learning rate = 1.7482453e-05
============================
Start of epoch 285
step 0: mean loss = 5.2483107e-09
step 100: mean loss = 9.053812e-09
step 200: mean loss = 2.581119e-08
step 300: mean loss = 2.8815473e-08
step 400: mean loss = 2.4716847e-08
step 500: mean loss = 2.1286047e-08
step 600: mean loss = 1.964516e-08
epoch 285: mean loss = 1.9291285e-08  learning rate = 1.7482453e-05
============================
Start of epoch 286
step 0: mean loss = 6.3725913e-09
step 100: mean loss = 6.2200622e-09
step 200: mean loss = 1.9471278e-08
step 300: mean loss = 1.6625936e-08
step 400: mean loss = 1.4628365e-08
step 500: mean loss = 1.3241905e-08
step 600: mean loss = 1.2926995e-08
epoch 286: mean loss = 1.2733894e-08  learning rate = 1.7482453e-05
============================
Start of epoch 287
step 0: mean loss = 3.5490246e-09
step 100: mean loss = 5.983683e-08
step 200: mean loss = 3.314199e-08
step 300: mean loss = 2.4513623e-08
step 400: mean loss = 2.01577e-08
step 500: mean loss = 1.8163579e-08
step 600: mean loss = 1.6715596e-08
epoch 287: mean loss = 1.6298504e-08  learning rate = 1.7482453e-05
============================
Start of epoch 288
step 0: mean loss = 6.770727e-09
step 100: mean loss = 3.6019692e-08
step 200: mean loss = 2.1377401e-08
step 300: mean loss = 2.0389498e-08
step 400: mean loss = 1.6994587e-08
step 500: mean loss = 1.6832322e-08
step 600: mean loss = 1.6601552e-08
epoch 288: mean loss = 1.671399e-08  learning rate = 1.7482453e-05
============================
Start of epoch 289
step 0: mean loss = 8.524806e-09
step 100: mean loss = 1.322236e-08
step 200: mean loss = 2.5257037e-08
step 300: mean loss = 2.4327003e-08
step 400: mean loss = 2.1197865e-08
step 500: mean loss = 1.8509438e-08
step 600: mean loss = 1.6758799e-08
epoch 289: mean loss = 1.7472706e-08  learning rate = 1.7482453e-05
============================
Start of epoch 290
step 0: mean loss = 6.406253e-08
step 100: mean loss = 1.3412891e-08
step 200: mean loss = 1.0469903e-08
step 300: mean loss = 1.1247601e-08
step 400: mean loss = 1.2139895e-08
step 500: mean loss = 1.4877264e-08
step 600: mean loss = 1.5153557e-08
epoch 290: mean loss = 1.4855298e-08  learning rate = 1.7482453e-05
============================
Start of epoch 291
step 0: mean loss = 6.52704e-09
step 100: mean loss = 1.1057856e-08
step 200: mean loss = 1.3117538e-08
step 300: mean loss = 1.4601309e-08
step 400: mean loss = 1.7229045e-08
step 500: mean loss = 1.504227e-08
step 600: mean loss = 1.3715103e-08
epoch 291: mean loss = 1.3577347e-08  learning rate = 1.7482453e-05
============================
Start of epoch 292
step 0: mean loss = 6.4806756e-09
step 100: mean loss = 2.353022e-08
step 200: mean loss = 1.896832e-08
step 300: mean loss = 2.0036007e-08
step 400: mean loss = 1.8824379e-08
step 500: mean loss = 1.7300561e-08
step 600: mean loss = 1.6295134e-08
epoch 292: mean loss = 1.6142739e-08  learning rate = 1.7482453e-05
============================
Start of epoch 293
step 0: mean loss = 5.304357e-09
step 100: mean loss = 1.3533683e-08
step 200: mean loss = 1.3831803e-08
step 300: mean loss = 1.3599969e-08
step 400: mean loss = 1.4545962e-08
step 500: mean loss = 1.8120637e-08
step 600: mean loss = 1.8946729e-08
epoch 293: mean loss = 1.8709532e-08  learning rate = 1.7482453e-05
============================
Start of epoch 294
step 0: mean loss = 5.2043205e-09
step 100: mean loss = 8.051501e-09
step 200: mean loss = 7.829434e-09
step 300: mean loss = 2.0184144e-08
step 400: mean loss = 1.6740323e-08
step 500: mean loss = 1.5199825e-08
step 600: mean loss = 1.5371604e-08
epoch 294: mean loss = 1.5034754e-08  learning rate = 1.7482453e-05
============================
Start of epoch 295
step 0: mean loss = 3.9090513e-09
step 100: mean loss = 1.5857827e-08
step 200: mean loss = 2.1040574e-08
step 300: mean loss = 1.6986911e-08
step 400: mean loss = 1.4925151e-08
step 500: mean loss = 1.3673847e-08
step 600: mean loss = 1.3070964e-08
epoch 295: mean loss = 1.28891955e-08  learning rate = 1.7482453e-05
============================
Start of epoch 296
step 0: mean loss = 4.893366e-09
step 100: mean loss = 2.3331177e-08
step 200: mean loss = 3.704031e-08
step 300: mean loss = 2.7893362e-08
step 400: mean loss = 2.259802e-08
step 500: mean loss = 2.032688e-08
step 600: mean loss = 1.8769315e-08
epoch 296: mean loss = 1.827376e-08  learning rate = 1.7482453e-05
============================
Start of epoch 297
step 0: mean loss = 4.5893986e-09
step 100: mean loss = 8.806597e-09
step 200: mean loss = 1.1066357e-08
step 300: mean loss = 1.8765508e-08
step 400: mean loss = 1.6622366e-08
step 500: mean loss = 1.5252075e-08
step 600: mean loss = 1.4932207e-08
epoch 297: mean loss = 1.48834545e-08  learning rate = 1.7482453e-05
============================
Start of epoch 298
step 0: mean loss = 8.831167e-09
step 100: mean loss = 1.3308896e-08
step 200: mean loss = 1.5503348e-08
step 300: mean loss = 1.3955515e-08
step 400: mean loss = 1.3974796e-08
step 500: mean loss = 1.470346e-08
step 600: mean loss = 1.4934091e-08
epoch 298: mean loss = 1.4864058e-08  learning rate = 1.7482453e-05
============================
Start of epoch 299
step 0: mean loss = 1.9382245e-08
step 100: mean loss = 2.0249338e-08
step 200: mean loss = 1.5059461e-08
step 300: mean loss = 1.3208667e-08
step 400: mean loss = 1.2013256e-08
step 500: mean loss = 1.2205027e-08
step 600: mean loss = 1.7281344e-08
epoch 299: mean loss = 1.686988e-08  learning rate = 1.660833e-05
============================
Start of epoch 300
step 0: mean loss = 6.0564425e-09
step 100: mean loss = 8.900438e-09
step 200: mean loss = 1.1732966e-08
step 300: mean loss = 1.5084154e-08
step 400: mean loss = 1.3777555e-08
step 500: mean loss = 1.2381746e-08
step 600: mean loss = 1.1395129e-08
epoch 300: mean loss = 1.1214919e-08  learning rate = 1.660833e-05
============================
Start of epoch 301
step 0: mean loss = 1.2174164e-08
step 100: mean loss = 6.8781234e-09
step 200: mean loss = 1.5955171e-08
step 300: mean loss = 3.2969712e-08
step 400: mean loss = 2.7163125e-08
step 500: mean loss = 2.3209166e-08
step 600: mean loss = 2.0412275e-08
epoch 301: mean loss = 1.9806174e-08  learning rate = 1.660833e-05
============================
Start of epoch 302
step 0: mean loss = 4.3927533e-09
step 100: mean loss = 9.404575e-09
step 200: mean loss = 7.1516566e-09
step 300: mean loss = 7.0780444e-09
step 400: mean loss = 7.2289255e-09
step 500: mean loss = 1.1058998e-08
step 600: mean loss = 1.3395975e-08
epoch 302: mean loss = 1.3243496e-08  learning rate = 1.660833e-05
============================
Start of epoch 303
step 0: mean loss = 3.2068386e-09
step 100: mean loss = 1.489925e-08
step 200: mean loss = 1.3563629e-08
step 300: mean loss = 1.173621e-08
step 400: mean loss = 1.1079361e-08
step 500: mean loss = 1.1042736e-08
step 600: mean loss = 1.018178e-08
epoch 303: mean loss = 1.0084787e-08  learning rate = 1.660833e-05
============================
Start of epoch 304
step 0: mean loss = 7.80152e-09
step 100: mean loss = 1.6129622e-08
step 200: mean loss = 1.1985148e-08
step 300: mean loss = 1.531492e-08
step 400: mean loss = 1.40703404e-08
step 500: mean loss = 1.2808248e-08
step 600: mean loss = 1.1794e-08
epoch 304: mean loss = 1.2958417e-08  learning rate = 1.660833e-05
============================
Start of epoch 305
step 0: mean loss = 1.3336541e-08
step 100: mean loss = 1.3646063e-08
step 200: mean loss = 1.2583641e-08
step 300: mean loss = 1.0731546e-08
step 400: mean loss = 1.3130699e-08
step 500: mean loss = 1.7016303e-08
step 600: mean loss = 1.6173269e-08
epoch 305: mean loss = 1.5763995e-08  learning rate = 1.660833e-05
============================
Start of epoch 306
step 0: mean loss = 4.681557e-09
step 100: mean loss = 1.1078962e-08
step 200: mean loss = 1.4801924e-08
step 300: mean loss = 1.4217805e-08
step 400: mean loss = 1.2138472e-08
step 500: mean loss = 1.1364836e-08
step 600: mean loss = 2.2092847e-08
epoch 306: mean loss = 2.1614436e-08  learning rate = 1.660833e-05
============================
Start of epoch 307
step 0: mean loss = 2.1470635e-08
step 100: mean loss = 5.334952e-09
step 200: mean loss = 5.282975e-09
step 300: mean loss = 5.6187903e-09
step 400: mean loss = 6.136383e-09
step 500: mean loss = 7.50956e-09
step 600: mean loss = 1.9121323e-08
epoch 307: mean loss = 2.0415953e-08  learning rate = 1.660833e-05
============================
Start of epoch 308
step 0: mean loss = 1.9996659e-08
step 100: mean loss = 9.756324e-09
step 200: mean loss = 8.301201e-09
step 300: mean loss = 7.3080195e-09
step 400: mean loss = 7.166619e-09
step 500: mean loss = 6.7913e-09
step 600: mean loss = 7.044744e-09
epoch 308: mean loss = 7.165761e-09  learning rate = 1.660833e-05
============================
Start of epoch 309
step 0: mean loss = 2.7502841e-08
step 100: mean loss = 1.15713075e-08
step 200: mean loss = 9.083309e-09
step 300: mean loss = 9.200684e-09
step 400: mean loss = 8.737016e-09
step 500: mean loss = 9.141129e-09
step 600: mean loss = 8.964152e-09
epoch 309: mean loss = 1.0426196e-08  learning rate = 1.660833e-05
============================
Start of epoch 310
step 0: mean loss = 1.6307553e-07
step 100: mean loss = 2.890892e-08
step 200: mean loss = 1.8846977e-08
step 300: mean loss = 1.7209413e-08
step 400: mean loss = 1.9548633e-08
step 500: mean loss = 1.854457e-08
step 600: mean loss = 1.6712004e-08
epoch 310: mean loss = 1.6378555e-08  learning rate = 1.660833e-05
============================
Start of epoch 311
step 0: mean loss = 4.9124877e-09
step 100: mean loss = 9.302528e-09
step 200: mean loss = 8.249401e-09
step 300: mean loss = 1.2021623e-08
step 400: mean loss = 1.2302662e-08
step 500: mean loss = 1.1476932e-08
step 600: mean loss = 1.1774975e-08
epoch 311: mean loss = 1.151181e-08  learning rate = 1.660833e-05
============================
Start of epoch 312
step 0: mean loss = 1.1454252e-08
step 100: mean loss = 4.2276653e-08
step 200: mean loss = 2.4702983e-08
step 300: mean loss = 1.840038e-08
step 400: mean loss = 1.5919344e-08
step 500: mean loss = 1.5468705e-08
step 600: mean loss = 1.375595e-08
epoch 312: mean loss = 1.3534197e-08  learning rate = 1.660833e-05
============================
Start of epoch 313
step 0: mean loss = 1.2733155e-08
step 100: mean loss = 1.8266112e-08
step 200: mean loss = 2.7083447e-08
step 300: mean loss = 2.0340178e-08
step 400: mean loss = 2.7313074e-08
step 500: mean loss = 2.3123382e-08
step 600: mean loss = 2.0108565e-08
epoch 313: mean loss = 1.9674133e-08  learning rate = 1.660833e-05
============================
Start of epoch 314
step 0: mean loss = 1.0644903e-08
step 100: mean loss = 7.03675e-09
step 200: mean loss = 7.5862925e-09
step 300: mean loss = 7.2216824e-09
step 400: mean loss = 8.999977e-09
step 500: mean loss = 8.70618e-09
step 600: mean loss = 8.337042e-09
epoch 314: mean loss = 8.328059e-09  learning rate = 1.660833e-05
============================
Start of epoch 315
step 0: mean loss = 1.7812345e-08
step 100: mean loss = 1.1031574e-08
step 200: mean loss = 1.1175763e-08
step 300: mean loss = 1.3149728e-08
step 400: mean loss = 1.3419012e-08
step 500: mean loss = 1.815772e-08
step 600: mean loss = 1.646097e-08
epoch 315: mean loss = 1.6086124e-08  learning rate = 1.660833e-05
============================
Start of epoch 316
step 0: mean loss = 4.7510547e-09
step 100: mean loss = 5.954157e-09
step 200: mean loss = 5.827029e-09
step 300: mean loss = 9.543953e-09
step 400: mean loss = 1.7221423e-08
step 500: mean loss = 1.6192532e-08
step 600: mean loss = 1.4795755e-08
epoch 316: mean loss = 1.453078e-08  learning rate = 1.660833e-05
============================
Start of epoch 317
step 0: mean loss = 5.521131e-09
step 100: mean loss = 2.0116968e-08
step 200: mean loss = 1.3328848e-08
step 300: mean loss = 1.1508944e-08
step 400: mean loss = 1.1047513e-08
step 500: mean loss = 1.1310833e-08
step 600: mean loss = 1.2121401e-08
epoch 317: mean loss = 1.1913189e-08  learning rate = 1.660833e-05
============================
Start of epoch 318
step 0: mean loss = 9.805261e-09
step 100: mean loss = 1.7430148e-08
step 200: mean loss = 1.3462968e-08
step 300: mean loss = 2.18851e-08
step 400: mean loss = 1.9655632e-08
step 500: mean loss = 1.7015594e-08
step 600: mean loss = 1.583473e-08
epoch 318: mean loss = 1.5400735e-08  learning rate = 1.660833e-05
============================
Start of epoch 319
step 0: mean loss = 3.4132388e-09
step 100: mean loss = 2.4439249e-08
step 200: mean loss = 1.5291043e-08
step 300: mean loss = 1.3205223e-08
step 400: mean loss = 1.1793254e-08
step 500: mean loss = 1.5671452e-08
step 600: mean loss = 1.574382e-08
epoch 319: mean loss = 1.5394148e-08  learning rate = 1.5777914e-05
============================
Start of epoch 320
step 0: mean loss = 1.102949e-08
step 100: mean loss = 1.29631825e-08
step 200: mean loss = 1.0716228e-08
step 300: mean loss = 9.472129e-09
step 400: mean loss = 8.890016e-09
step 500: mean loss = 8.473403e-09
step 600: mean loss = 8.331891e-09
epoch 320: mean loss = 8.2685325e-09  learning rate = 1.5777914e-05
============================
Start of epoch 321
step 0: mean loss = 4.684561e-09
step 100: mean loss = 2.082692e-08
step 200: mean loss = 1.8833111e-08
step 300: mean loss = 1.7372287e-08
step 400: mean loss = 1.4971082e-08
step 500: mean loss = 1.6176395e-08
step 600: mean loss = 1.5662211e-08
epoch 321: mean loss = 1.560496e-08  learning rate = 1.5777914e-05
============================
Start of epoch 322
step 0: mean loss = 9.968856e-09
step 100: mean loss = 8.727226e-09
step 200: mean loss = 1.006475e-08
step 300: mean loss = 1.5990711e-08
step 400: mean loss = 2.3165528e-08
step 500: mean loss = 2.006408e-08
step 600: mean loss = 1.7753505e-08
epoch 322: mean loss = 1.7290875e-08  learning rate = 1.5777914e-05
============================
Start of epoch 323
step 0: mean loss = 6.9641253e-09
step 100: mean loss = 4.6875375e-09
step 200: mean loss = 5.929257e-09
step 300: mean loss = 9.701305e-09
step 400: mean loss = 1.1107426e-08
step 500: mean loss = 1.4007321e-08
step 600: mean loss = 1.3217061e-08
epoch 323: mean loss = 1.2996707e-08  learning rate = 1.5777914e-05
============================
Start of epoch 324
step 0: mean loss = 4.6391606e-09
step 100: mean loss = 5.772235e-09
step 200: mean loss = 6.42915e-09
step 300: mean loss = 7.2243407e-09
step 400: mean loss = 1.4008731e-08
step 500: mean loss = 1.30005064e-08
step 600: mean loss = 1.2449638e-08
epoch 324: mean loss = 1.2316414e-08  learning rate = 1.5777914e-05
============================
Start of epoch 325
step 0: mean loss = 4.940163e-09
step 100: mean loss = 6.479944e-09
step 200: mean loss = 7.877859e-09
step 300: mean loss = 7.658638e-09
step 400: mean loss = 8.435373e-09
step 500: mean loss = 8.434483e-09
step 600: mean loss = 1.40198715e-08
epoch 325: mean loss = 1.3779166e-08  learning rate = 1.5777914e-05
============================
Start of epoch 326
step 0: mean loss = 4.110037e-09
step 100: mean loss = 5.145603e-09
step 200: mean loss = 9.137672e-09
step 300: mean loss = 8.838853e-09
step 400: mean loss = 7.768325e-09
step 500: mean loss = 9.916652e-09
step 600: mean loss = 1.12636425e-08
epoch 326: mean loss = 1.1099475e-08  learning rate = 1.5777914e-05
============================
Start of epoch 327
step 0: mean loss = 4.4029163e-09
step 100: mean loss = 1.2634318e-08
step 200: mean loss = 1.5635482e-08
step 300: mean loss = 1.4792173e-08
step 400: mean loss = 1.26989415e-08
step 500: mean loss = 1.1878126e-08
step 600: mean loss = 1.9382126e-08
epoch 327: mean loss = 1.9136618e-08  learning rate = 1.5777914e-05
============================
Start of epoch 328
step 0: mean loss = 1.848575e-08
step 100: mean loss = 1.0965217e-08
step 200: mean loss = 1.6199289e-08
step 300: mean loss = 1.39038825e-08
step 400: mean loss = 1.1758295e-08
step 500: mean loss = 1.0985906e-08
step 600: mean loss = 1.1151703e-08
epoch 328: mean loss = 1.1074169e-08  learning rate = 1.5777914e-05
============================
Start of epoch 329
step 0: mean loss = 4.7289372e-09
step 100: mean loss = 1.8542723e-08
step 200: mean loss = 1.200106e-08
step 300: mean loss = 1.10097895e-08
step 400: mean loss = 1.0671277e-08
step 500: mean loss = 1.0369574e-08
step 600: mean loss = 1.098594e-08
epoch 329: mean loss = 1.1004964e-08  learning rate = 1.5777914e-05
============================
Start of epoch 330
step 0: mean loss = 5.8514837e-09
step 100: mean loss = 1.7199463e-08
step 200: mean loss = 1.5433503e-08
step 300: mean loss = 1.956912e-08
step 400: mean loss = 2.4708383e-08
step 500: mean loss = 2.1008372e-08
step 600: mean loss = 1.8296928e-08
epoch 330: mean loss = 1.7771606e-08  learning rate = 1.5777914e-05
============================
Start of epoch 331
step 0: mean loss = 3.6666745e-09
step 100: mean loss = 7.997768e-09
step 200: mean loss = 1.0683891e-08
step 300: mean loss = 1.0774202e-08
step 400: mean loss = 2.0790132e-08
step 500: mean loss = 1.7807396e-08
step 600: mean loss = 1.5686162e-08
epoch 331: mean loss = 1.5283552e-08  learning rate = 1.5777914e-05
============================
Start of epoch 332
step 0: mean loss = 4.1701242e-09
step 100: mean loss = 6.3634706e-09
step 200: mean loss = 9.9933475e-09
step 300: mean loss = 8.648132e-09
step 400: mean loss = 8.057606e-09
step 500: mean loss = 2.1300758e-08
step 600: mean loss = 1.9311173e-08
epoch 332: mean loss = 1.8937131e-08  learning rate = 1.5777914e-05
============================
Start of epoch 333
step 0: mean loss = 1.7418756e-08
step 100: mean loss = 4.8986326e-09
step 200: mean loss = 6.76768e-09
step 300: mean loss = 6.834397e-09
step 400: mean loss = 7.844791e-09
step 500: mean loss = 7.778801e-09
step 600: mean loss = 8.124326e-09
epoch 333: mean loss = 8.02088e-09  learning rate = 1.5777914e-05
============================
Start of epoch 334
step 0: mean loss = 3.2919119e-09
step 100: mean loss = 9.727388e-09
step 200: mean loss = 8.504396e-09
step 300: mean loss = 8.254757e-09
step 400: mean loss = 8.640564e-09
step 500: mean loss = 8.837769e-09
step 600: mean loss = 1.3429882e-08
epoch 334: mean loss = 1.3524051e-08  learning rate = 1.5777914e-05
============================
Start of epoch 335
step 0: mean loss = 5.239837e-09
step 100: mean loss = 1.0030535e-08
step 200: mean loss = 7.259446e-09
step 300: mean loss = 6.8423485e-09
step 400: mean loss = 6.996603e-09
step 500: mean loss = 7.49347e-09
step 600: mean loss = 9.300429e-09
epoch 335: mean loss = 9.289927e-09  learning rate = 1.5777914e-05
============================
Start of epoch 336
step 0: mean loss = 4.163423e-09
step 100: mean loss = 1.6445304e-08
step 200: mean loss = 1.3103479e-08
step 300: mean loss = 1.1300884e-08
step 400: mean loss = 1.2868514e-08
step 500: mean loss = 1.4369855e-08
step 600: mean loss = 1.6675417e-08
epoch 336: mean loss = 1.6251557e-08  learning rate = 1.5777914e-05
============================
Start of epoch 337
step 0: mean loss = 5.9798175e-09
step 100: mean loss = 8.619257e-09
step 200: mean loss = 7.417688e-09
step 300: mean loss = 8.134947e-09
step 400: mean loss = 1.0060687e-08
step 500: mean loss = 1.0260654e-08
step 600: mean loss = 9.794706e-09
epoch 337: mean loss = 1.0417918e-08  learning rate = 1.5777914e-05
============================
Start of epoch 338
step 0: mean loss = 5.467883e-08
step 100: mean loss = 1.7136347e-08
step 200: mean loss = 1.1568381e-08
step 300: mean loss = 1.0714243e-08
step 400: mean loss = 1.0137494e-08
step 500: mean loss = 1.0631698e-08
step 600: mean loss = 1.06349045e-08
epoch 338: mean loss = 1.0966284e-08  learning rate = 1.5777914e-05
============================
Start of epoch 339
step 0: mean loss = 2.8672847e-08
step 100: mean loss = 1.1060651e-08
step 200: mean loss = 1.0874638e-08
step 300: mean loss = 1.2460864e-08
step 400: mean loss = 1.1848065e-08
step 500: mean loss = 1.2608027e-08
step 600: mean loss = 1.1788635e-08
epoch 339: mean loss = 1.1618261e-08  learning rate = 1.4989017e-05
============================
Start of epoch 340
step 0: mean loss = 3.7785832e-09
step 100: mean loss = 9.339103e-09
step 200: mean loss = 9.288541e-09
step 300: mean loss = 1.2049297e-08
step 400: mean loss = 1.5045613e-08
step 500: mean loss = 1.5879285e-08
step 600: mean loss = 1.4495015e-08
epoch 340: mean loss = 1.409947e-08  learning rate = 1.4989017e-05
============================
Start of epoch 341
step 0: mean loss = 2.3292528e-09
step 100: mean loss = 7.913044e-09
step 200: mean loss = 1.0412839e-08
step 300: mean loss = 1.0741923e-08
step 400: mean loss = 1.0375127e-08
step 500: mean loss = 1.0464542e-08
step 600: mean loss = 1.0773967e-08
epoch 341: mean loss = 1.056759e-08  learning rate = 1.4989017e-05
============================
Start of epoch 342
step 0: mean loss = 4.107627e-09
step 100: mean loss = 5.6019278e-08
step 200: mean loss = 3.415359e-08
step 300: mean loss = 2.4715334e-08
step 400: mean loss = 2.1053276e-08
step 500: mean loss = 1.8136234e-08
step 600: mean loss = 1.7500911e-08
epoch 342: mean loss = 1.758135e-08  learning rate = 1.4989017e-05
============================
Start of epoch 343
step 0: mean loss = 1.1191224e-08
step 100: mean loss = 1.1119722e-08
step 200: mean loss = 8.533842e-09
step 300: mean loss = 1.0408594e-08
step 400: mean loss = 9.255347e-09
step 500: mean loss = 9.127719e-09
step 600: mean loss = 1.2002613e-08
epoch 343: mean loss = 1.1774631e-08  learning rate = 1.4989017e-05
============================
Start of epoch 344
step 0: mean loss = 3.82619e-09
step 100: mean loss = 8.572699e-09
step 200: mean loss = 6.648654e-09
step 300: mean loss = 7.629967e-09
step 400: mean loss = 8.239524e-09
step 500: mean loss = 8.291777e-09
step 600: mean loss = 8.350421e-09
epoch 344: mean loss = 9.387131e-09  learning rate = 1.4989017e-05
============================
Start of epoch 345
step 0: mean loss = 1.0903311e-08
step 100: mean loss = 2.5055437e-08
step 200: mean loss = 1.711036e-08
step 300: mean loss = 1.3197113e-08
step 400: mean loss = 1.2601865e-08
step 500: mean loss = 1.1425317e-08
step 600: mean loss = 1.08901235e-08
epoch 345: mean loss = 1.1003471e-08  learning rate = 1.4989017e-05
============================
Start of epoch 346
step 0: mean loss = 7.763075e-09
step 100: mean loss = 8.517586e-09
step 200: mean loss = 8.725734e-09
step 300: mean loss = 2.4626074e-08
step 400: mean loss = 2.171984e-08
step 500: mean loss = 1.8547977e-08
step 600: mean loss = 1.6283346e-08
epoch 346: mean loss = 1.587699e-08  learning rate = 1.4989017e-05
============================
Start of epoch 347
step 0: mean loss = 4.068928e-09
step 100: mean loss = 8.417213e-09
step 200: mean loss = 7.775605e-09
step 300: mean loss = 1.0677741e-08
step 400: mean loss = 1.2079618e-08
step 500: mean loss = 1.1096342e-08
step 600: mean loss = 1.0532644e-08
epoch 347: mean loss = 1.03724815e-08  learning rate = 1.4989017e-05
============================
Start of epoch 348
step 0: mean loss = 9.752126e-09
step 100: mean loss = 8.018026e-09
step 200: mean loss = 8.2595975e-09
step 300: mean loss = 1.0220518e-08
step 400: mean loss = 9.806849e-09
step 500: mean loss = 1.3278701e-08
step 600: mean loss = 1.6790732e-08
epoch 348: mean loss = 1.6370398e-08  learning rate = 1.4989017e-05
============================
Start of epoch 349
step 0: mean loss = 4.5403468e-09
step 100: mean loss = 1.7046197e-08
step 200: mean loss = 2.5988635e-08
step 300: mean loss = 2.0221007e-08
step 400: mean loss = 1.6634656e-08
step 500: mean loss = 1.43786165e-08
step 600: mean loss = 1.28591795e-08
epoch 349: mean loss = 1.2568358e-08  learning rate = 1.4989017e-05
============================
Start of epoch 350
step 0: mean loss = 1.3275743e-08
step 100: mean loss = 1.5721785e-08
step 200: mean loss = 1.1757535e-08
step 300: mean loss = 1.0519049e-08
step 400: mean loss = 9.173898e-09
step 500: mean loss = 9.012625e-09
step 600: mean loss = 9.341918e-09
epoch 350: mean loss = 9.292027e-09  learning rate = 1.4989017e-05
============================
Start of epoch 351
step 0: mean loss = 9.128375e-09
step 100: mean loss = 1.824151e-08
step 200: mean loss = 5.3921877e-08
step 300: mean loss = 3.7596926e-08
step 400: mean loss = 3.0099205e-08
step 500: mean loss = 2.4899109e-08
step 600: mean loss = 2.1931374e-08
epoch 351: mean loss = 2.137899e-08  learning rate = 1.4989017e-05
============================
Start of epoch 352
step 0: mean loss = 5.7828915e-09
step 100: mean loss = 5.12195e-09
step 200: mean loss = 5.4449583e-09
step 300: mean loss = 1.0588811e-08
step 400: mean loss = 9.1990096e-09
step 500: mean loss = 9.041105e-09
step 600: mean loss = 8.717934e-09
epoch 352: mean loss = 8.592755e-09  learning rate = 1.4989017e-05
============================
Start of epoch 353
step 0: mean loss = 1.572133e-08
step 100: mean loss = 7.985817e-09
step 200: mean loss = 8.79299e-09
step 300: mean loss = 7.976465e-09
step 400: mean loss = 8.740832e-09
step 500: mean loss = 9.552711e-09
step 600: mean loss = 1.0484911e-08
epoch 353: mean loss = 1.08933165e-08  learning rate = 1.4989017e-05
============================
Start of epoch 354
step 0: mean loss = 7.2567543e-09
step 100: mean loss = 8.394092e-09
step 200: mean loss = 1.721542e-08
step 300: mean loss = 1.340895e-08
step 400: mean loss = 1.8542769e-08
step 500: mean loss = 1.602212e-08
step 600: mean loss = 1.4726194e-08
epoch 354: mean loss = 1.43401335e-08  learning rate = 1.4989017e-05
============================
Start of epoch 355
step 0: mean loss = 4.9842654e-09
step 100: mean loss = 5.218317e-09
step 200: mean loss = 8.703381e-09
step 300: mean loss = 7.3255757e-09
step 400: mean loss = 7.862396e-09
step 500: mean loss = 1.02337445e-08
step 600: mean loss = 9.949846e-09
epoch 355: mean loss = 9.85158e-09  learning rate = 1.4989017e-05
============================
Start of epoch 356
step 0: mean loss = 1.3564126e-08
step 100: mean loss = 1.1390847e-08
step 200: mean loss = 1.32215465e-08
step 300: mean loss = 1.4327654e-08
step 400: mean loss = 1.317483e-08
step 500: mean loss = 1.1748618e-08
step 600: mean loss = 1.1564154e-08
epoch 356: mean loss = 1.1353999e-08  learning rate = 1.4989017e-05
============================
Start of epoch 357
step 0: mean loss = 1.2034138e-08
step 100: mean loss = 8.562761e-09
step 200: mean loss = 9.864899e-09
step 300: mean loss = 1.0207031e-08
step 400: mean loss = 1.6836998e-08
step 500: mean loss = 1.7599145e-08
step 600: mean loss = 1.5947506e-08
epoch 357: mean loss = 1.5514216e-08  learning rate = 1.4989017e-05
============================
Start of epoch 358
step 0: mean loss = 3.6871461e-09
step 100: mean loss = 5.8373026e-09
step 200: mean loss = 7.905149e-09
step 300: mean loss = 8.908081e-09
step 400: mean loss = 8.266543e-09
step 500: mean loss = 1.3263086e-08
step 600: mean loss = 1.4458487e-08
epoch 358: mean loss = 1.4082948e-08  learning rate = 1.4989017e-05
============================
Start of epoch 359
step 0: mean loss = 5.5237535e-09
step 100: mean loss = 4.9672173e-09
step 200: mean loss = 6.1159464e-09
step 300: mean loss = 7.3233837e-09
step 400: mean loss = 8.89662e-09
step 500: mean loss = 9.087994e-09
step 600: mean loss = 9.9354525e-09
epoch 359: mean loss = 1.00677156e-08  learning rate = 1.4239566e-05
============================
Start of epoch 360
step 0: mean loss = 8.834064e-09
step 100: mean loss = 5.369457e-09
step 200: mean loss = 4.7407744e-09
step 300: mean loss = 5.6142806e-09
step 400: mean loss = 5.661817e-09
step 500: mean loss = 5.8791603e-09
step 600: mean loss = 5.906435e-09
epoch 360: mean loss = 6.822031e-09  learning rate = 1.4239566e-05
============================
Start of epoch 361
step 0: mean loss = 2.3332655e-08
step 100: mean loss = 6.2006467e-09
step 200: mean loss = 1.6060598e-08
step 300: mean loss = 1.384024e-08
step 400: mean loss = 1.1713506e-08
step 500: mean loss = 1.197917e-08
step 600: mean loss = 1.2985924e-08
epoch 361: mean loss = 1.4319702e-08  learning rate = 1.4239566e-05
============================
Start of epoch 362
step 0: mean loss = 2.3658252e-08
step 100: mean loss = 7.139381e-09
step 200: mean loss = 6.346727e-09
step 300: mean loss = 7.593418e-09
step 400: mean loss = 9.264692e-09
step 500: mean loss = 1.0379717e-08
step 600: mean loss = 1.0095658e-08
epoch 362: mean loss = 1.0011198e-08  learning rate = 1.4239566e-05
============================
Start of epoch 363
step 0: mean loss = 2.7792626e-09
step 100: mean loss = 8.218418e-09
step 200: mean loss = 1.0479844e-08
step 300: mean loss = 9.1294545e-09
step 400: mean loss = 1.0391514e-08
step 500: mean loss = 9.667724e-09
step 600: mean loss = 1.0110285e-08
epoch 363: mean loss = 1.0116188e-08  learning rate = 1.4239566e-05
============================
Start of epoch 364
step 0: mean loss = 2.0812678e-08
step 100: mean loss = 1.2368285e-08
step 200: mean loss = 1.2167858e-08
step 300: mean loss = 1.3162725e-08
step 400: mean loss = 1.926628e-08
step 500: mean loss = 2.0901695e-08
step 600: mean loss = 1.8056141e-08
epoch 364: mean loss = 1.752499e-08  learning rate = 1.4239566e-05
============================
Start of epoch 365
step 0: mean loss = 3.5397805e-09
step 100: mean loss = 5.1051745e-09
step 200: mean loss = 5.4669616e-09
step 300: mean loss = 5.4789933e-09
step 400: mean loss = 5.8606466e-09
step 500: mean loss = 5.580388e-09
step 600: mean loss = 6.606893e-09
epoch 365: mean loss = 6.669859e-09  learning rate = 1.4239566e-05
============================
Start of epoch 366
step 0: mean loss = 6.517412e-09
step 100: mean loss = 8.0908995e-09
step 200: mean loss = 7.466539e-09
step 300: mean loss = 1.4959111e-08
step 400: mean loss = 1.4809869e-08
step 500: mean loss = 1.46719605e-08
step 600: mean loss = 1.3328705e-08
epoch 366: mean loss = 1.31009275e-08  learning rate = 1.4239566e-05
============================
Start of epoch 367
step 0: mean loss = 3.9682146e-09
step 100: mean loss = 8.714049e-09
step 200: mean loss = 8.123184e-09
step 300: mean loss = 7.832665e-09
step 400: mean loss = 1.217582e-08
step 500: mean loss = 1.1540712e-08
step 600: mean loss = 1.1662541e-08
epoch 367: mean loss = 1.1519041e-08  learning rate = 1.4239566e-05
============================
Start of epoch 368
step 0: mean loss = 7.154523e-09
step 100: mean loss = 6.1448415e-09
step 200: mean loss = 6.056267e-09
step 300: mean loss = 6.951972e-09
step 400: mean loss = 6.7744734e-09
step 500: mean loss = 1.2005016e-08
step 600: mean loss = 2.1283778e-08
epoch 368: mean loss = 2.0624478e-08  learning rate = 1.4239566e-05
============================
Start of epoch 369
step 0: mean loss = 3.8631867e-09
step 100: mean loss = 5.9109664e-09
step 200: mean loss = 5.8185785e-09
step 300: mean loss = 5.983901e-09
step 400: mean loss = 8.781395e-09
step 500: mean loss = 8.703462e-09
step 600: mean loss = 7.938236e-09
epoch 369: mean loss = 7.786873e-09  learning rate = 1.4239566e-05
============================
Start of epoch 370
step 0: mean loss = 4.8442446e-09
step 100: mean loss = 4.4395723e-09
step 200: mean loss = 5.166251e-09
step 300: mean loss = 7.52788e-09
step 400: mean loss = 7.1199504e-09
step 500: mean loss = 9.401775e-09
step 600: mean loss = 1.1279818e-08
epoch 370: mean loss = 1.1301118e-08  learning rate = 1.4239566e-05
============================
Start of epoch 371
step 0: mean loss = 4.400154e-09
step 100: mean loss = 4.8317554e-09
step 200: mean loss = 6.870093e-09
step 300: mean loss = 6.748261e-09
step 400: mean loss = 6.231335e-09
step 500: mean loss = 6.3712107e-09
step 600: mean loss = 7.0675874e-09
epoch 371: mean loss = 8.331575e-09  learning rate = 1.4239566e-05
============================
Start of epoch 372
step 0: mean loss = 4.2408328e-08
step 100: mean loss = 8.841951e-09
step 200: mean loss = 9.454519e-09
step 300: mean loss = 8.722842e-09
step 400: mean loss = 9.974617e-09
step 500: mean loss = 1.0107852e-08
step 600: mean loss = 1.0009497e-08
epoch 372: mean loss = 9.770173e-09  learning rate = 1.4239566e-05
============================
Start of epoch 373
step 0: mean loss = 5.8171827e-09
step 100: mean loss = 5.7208243e-09
step 200: mean loss = 8.199966e-09
step 300: mean loss = 7.752188e-09
step 400: mean loss = 9.025457e-09
step 500: mean loss = 8.631924e-09
step 600: mean loss = 8.556856e-09
epoch 373: mean loss = 8.817844e-09  learning rate = 1.4239566e-05
============================
Start of epoch 374
step 0: mean loss = 3.3362553e-09
step 100: mean loss = 9.414474e-09
step 200: mean loss = 2.0181192e-08
step 300: mean loss = 2.430808e-08
step 400: mean loss = 1.9637149e-08
step 500: mean loss = 1.6812718e-08
step 600: mean loss = 1.5600241e-08
epoch 374: mean loss = 1.5273612e-08  learning rate = 1.4239566e-05
============================
Start of epoch 375
step 0: mean loss = 4.415951e-09
step 100: mean loss = 7.069089e-09
step 200: mean loss = 8.815814e-09
step 300: mean loss = 8.765899e-09
step 400: mean loss = 9.434614e-09
step 500: mean loss = 9.330322e-09
step 600: mean loss = 1.01422595e-08
epoch 375: mean loss = 1.0276088e-08  learning rate = 1.4239566e-05
============================
Start of epoch 376
step 0: mean loss = 3.5534906e-09
step 100: mean loss = 6.5126957e-09
step 200: mean loss = 1.1399407e-08
step 300: mean loss = 1.1074546e-08
step 400: mean loss = 1.2013987e-08
step 500: mean loss = 1.1232136e-08
step 600: mean loss = 1.2008734e-08
epoch 376: mean loss = 1.1867693e-08  learning rate = 1.4239566e-05
============================
Start of epoch 377
step 0: mean loss = 1.0965953e-08
step 100: mean loss = 6.5175336e-09
step 200: mean loss = 7.3307347e-09
step 300: mean loss = 8.952704e-09
step 400: mean loss = 1.0601888e-08
step 500: mean loss = 1.1306076e-08
step 600: mean loss = 1.0563094e-08
epoch 377: mean loss = 1.038562e-08  learning rate = 1.4239566e-05
============================
Start of epoch 378
step 0: mean loss = 2.0705042e-09
step 100: mean loss = 7.558679e-09
step 200: mean loss = 7.4443465e-09
step 300: mean loss = 1.027607e-08
step 400: mean loss = 1.2474715e-08
step 500: mean loss = 1.2162092e-08
step 600: mean loss = 1.1789021e-08
epoch 378: mean loss = 1.1550153e-08  learning rate = 1.4239566e-05
============================
Start of epoch 379
step 0: mean loss = 4.882258e-09
step 100: mean loss = 6.796707e-09
step 200: mean loss = 6.3758563e-09
step 300: mean loss = 8.871593e-09
step 400: mean loss = 8.514252e-09
step 500: mean loss = 8.062388e-09
step 600: mean loss = 8.0071745e-09
epoch 379: mean loss = 7.929549e-09  learning rate = 1.35275895e-05
============================
Start of epoch 380
step 0: mean loss = 4.54535e-09
step 100: mean loss = 9.101833e-09
step 200: mean loss = 7.971767e-09
step 300: mean loss = 1.1802656e-08
step 400: mean loss = 9.9514725e-09
step 500: mean loss = 9.475908e-09
step 600: mean loss = 1.2450382e-08
epoch 380: mean loss = 1.24104975e-08  learning rate = 1.35275895e-05
============================
Start of epoch 381
step 0: mean loss = 1.219656e-08
step 100: mean loss = 6.850581e-09
step 200: mean loss = 7.3113666e-09
step 300: mean loss = 6.617043e-09
step 400: mean loss = 6.4641803e-09
step 500: mean loss = 6.676917e-09
step 600: mean loss = 6.6228307e-09
epoch 381: mean loss = 6.820415e-09  learning rate = 1.35275895e-05
============================
Start of epoch 382
step 0: mean loss = 1.7010276e-08
step 100: mean loss = 2.8926578e-08
step 200: mean loss = 1.7286578e-08
step 300: mean loss = 1.863124e-08
step 400: mean loss = 1.5304597e-08
step 500: mean loss = 1.3058293e-08
step 600: mean loss = 1.37559875e-08
epoch 382: mean loss = 1.3423501e-08  learning rate = 1.35275895e-05
============================
Start of epoch 383
step 0: mean loss = 5.717335e-09
step 100: mean loss = 1.37640095e-08
step 200: mean loss = 1.331547e-08
step 300: mean loss = 1.0991277e-08
step 400: mean loss = 1.105824e-08
step 500: mean loss = 1.1845356e-08
step 600: mean loss = 1.0783186e-08
epoch 383: mean loss = 1.0529013e-08  learning rate = 1.35275895e-05
============================
Start of epoch 384
step 0: mean loss = 3.9381094e-09
step 100: mean loss = 6.7487407e-09
step 200: mean loss = 8.49793e-09
step 300: mean loss = 8.820377e-09
step 400: mean loss = 7.739512e-09
step 500: mean loss = 1.4477328e-08
step 600: mean loss = 1.3264201e-08
epoch 384: mean loss = 1.292857e-08  learning rate = 1.35275895e-05
============================
Start of epoch 385
step 0: mean loss = 2.5002194e-09
step 100: mean loss = 4.426374e-09
step 200: mean loss = 5.644745e-09
step 300: mean loss = 5.3833693e-09
step 400: mean loss = 5.132211e-09
step 500: mean loss = 5.1547686e-09
step 600: mean loss = 8.818891e-09
epoch 385: mean loss = 8.763056e-09  learning rate = 1.35275895e-05
============================
Start of epoch 386
step 0: mean loss = 5.647732e-09
step 100: mean loss = 6.4152785e-09
step 200: mean loss = 1.3088543e-08
step 300: mean loss = 1.00579385e-08
step 400: mean loss = 8.753201e-09
step 500: mean loss = 8.455219e-09
step 600: mean loss = 9.032098e-09
epoch 386: mean loss = 9.2287475e-09  learning rate = 1.35275895e-05
============================
Start of epoch 387
step 0: mean loss = 1.11156995e-08
step 100: mean loss = 1.6588533e-08
step 200: mean loss = 1.0593753e-08
step 300: mean loss = 9.545625e-09
step 400: mean loss = 9.167388e-09
step 500: mean loss = 8.509162e-09
step 600: mean loss = 8.046279e-09
epoch 387: mean loss = 8.019403e-09  learning rate = 1.35275895e-05
============================
Start of epoch 388
step 0: mean loss = 4.594716e-09
step 100: mean loss = 2.0433287e-08
step 200: mean loss = 1.362276e-08
step 300: mean loss = 1.3082006e-08
step 400: mean loss = 1.3519754e-08
step 500: mean loss = 1.2092864e-08
step 600: mean loss = 1.085899e-08
epoch 388: mean loss = 1.0827172e-08  learning rate = 1.35275895e-05
============================
Start of epoch 389
step 0: mean loss = 1.649823e-08
step 100: mean loss = 1.2639401e-08
step 200: mean loss = 1.23542065e-08
step 300: mean loss = 1.439798e-08
step 400: mean loss = 1.7356172e-08
step 500: mean loss = 1.5000762e-08
step 600: mean loss = 1.3152899e-08
epoch 389: mean loss = 1.2776532e-08  learning rate = 1.35275895e-05
============================
Start of epoch 390
step 0: mean loss = 3.022437e-09
step 100: mean loss = 1.4890952e-08
step 200: mean loss = 1.770936e-08
step 300: mean loss = 1.4654972e-08
step 400: mean loss = 1.5078875e-08
step 500: mean loss = 1.39112775e-08
step 600: mean loss = 1.34536675e-08
epoch 390: mean loss = 1.31684805e-08  learning rate = 1.35275895e-05
============================
Start of epoch 391
step 0: mean loss = 9.5823065e-09
step 100: mean loss = 4.7960715e-09
step 200: mean loss = 5.626146e-09
step 300: mean loss = 8.320237e-09
step 400: mean loss = 7.70906e-09
step 500: mean loss = 7.393958e-09
step 600: mean loss = 7.1084387e-09
epoch 391: mean loss = 7.399887e-09  learning rate = 1.35275895e-05
============================
Start of epoch 392
step 0: mean loss = 3.4144976e-09
step 100: mean loss = 1.2300605e-08
step 200: mean loss = 1.453386e-08
step 300: mean loss = 1.28626105e-08
step 400: mean loss = 1.2176573e-08
step 500: mean loss = 1.8553756e-08
step 600: mean loss = 1.8546467e-08
epoch 392: mean loss = 1.8022781e-08  learning rate = 1.35275895e-05
============================
Start of epoch 393
step 0: mean loss = 4.2392836e-09
step 100: mean loss = 6.362509e-09
step 200: mean loss = 5.502472e-09
step 300: mean loss = 5.3838294e-09
step 400: mean loss = 5.631696e-09
step 500: mean loss = 5.728858e-09
step 600: mean loss = 5.9060916e-09
epoch 393: mean loss = 5.891907e-09  learning rate = 1.35275895e-05
============================
Start of epoch 394
step 0: mean loss = 4.873777e-09
step 100: mean loss = 7.3988273e-09
step 200: mean loss = 7.4283193e-09
step 300: mean loss = 7.570164e-09
step 400: mean loss = 7.0363178e-09
step 500: mean loss = 8.469089e-09
step 600: mean loss = 9.018329e-09
epoch 394: mean loss = 9.4268024e-09  learning rate = 1.35275895e-05
============================
Start of epoch 395
step 0: mean loss = 1.1541802e-08
step 100: mean loss = 1.0443901e-08
step 200: mean loss = 9.347382e-09
step 300: mean loss = 8.291421e-09
step 400: mean loss = 8.582806e-09
step 500: mean loss = 9.979528e-09
step 600: mean loss = 1.3017073e-08
epoch 395: mean loss = 1.2682656e-08  learning rate = 1.35275895e-05
============================
Start of epoch 396
step 0: mean loss = 4.2554014e-09
step 100: mean loss = 9.896354e-09
step 200: mean loss = 9.35175e-09
step 300: mean loss = 1.0306139e-08
step 400: mean loss = 9.214947e-09
step 500: mean loss = 9.390033e-09
step 600: mean loss = 8.646894e-09
epoch 396: mean loss = 8.529755e-09  learning rate = 1.35275895e-05
============================
Start of epoch 397
step 0: mean loss = 4.565634e-09
step 100: mean loss = 5.528304e-09
step 200: mean loss = 7.954076e-09
step 300: mean loss = 9.735704e-09
step 400: mean loss = 1.0187214e-08
step 500: mean loss = 9.7355795e-09
step 600: mean loss = 1.0286431e-08
epoch 397: mean loss = 1.057129e-08  learning rate = 1.35275895e-05
============================
Start of epoch 398
step 0: mean loss = 8.2324245e-09
step 100: mean loss = 6.529761e-09
step 200: mean loss = 6.394975e-09
step 300: mean loss = 7.404385e-09
step 400: mean loss = 2.5226425e-08
step 500: mean loss = 2.1202407e-08
step 600: mean loss = 1.8399751e-08
epoch 398: mean loss = 1.7819604e-08  learning rate = 1.35275895e-05
============================
Start of epoch 399
step 0: mean loss = 2.8423943e-09
step 100: mean loss = 6.096581e-09
step 200: mean loss = 8.263899e-09
step 300: mean loss = 8.867188e-09
step 400: mean loss = 8.733657e-09
step 500: mean loss = 8.964406e-09
step 600: mean loss = 8.278792e-09
epoch 399: mean loss = 8.4818215e-09  learning rate = 1.2851208e-05
saving the weights
++++++++++++++++++++++++++++++
Start of cycle 2
Total number of epochs in this cycle: 800
Batch size in this cycle: 32
============================
WARNING:tensorflow:5 out of the last 6 calls to <function genDistInvPerNlist at 0x7fdebe210b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/beta/tutorials/eager/tf_function#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Start of epoch 0
step 0: mean loss = 5.7763407e-09
step 100: mean loss = 4.1589483e-09
step 200: mean loss = 3.856535e-09
step 300: mean loss = 3.9000594e-09
epoch 0: mean loss = 3.8868095e-09  learning rate = 1.2851208e-05
============================
Start of epoch 1
step 0: mean loss = 2.1345763e-09
step 100: mean loss = 3.7000538e-09
step 200: mean loss = 4.1048054e-09
step 300: mean loss = 4.3267456e-09
epoch 1: mean loss = 4.325859e-09  learning rate = 1.2851208e-05
============================
Start of epoch 2
step 0: mean loss = 1.3639823e-08
step 100: mean loss = 4.583116e-09
step 200: mean loss = 6.16568e-09
step 300: mean loss = 6.0810494e-09
epoch 2: mean loss = 5.9975167e-09  learning rate = 1.2851208e-05
============================
Start of epoch 3
step 0: mean loss = 5.818909e-09
step 100: mean loss = 4.6483932e-09
step 200: mean loss = 6.0872374e-09
step 300: mean loss = 5.3216045e-09
epoch 3: mean loss = 5.274833e-09  learning rate = 1.2851208e-05
============================
Start of epoch 4
step 0: mean loss = 4.497666e-09
step 100: mean loss = 6.688799e-09
step 200: mean loss = 1.1662959e-08
step 300: mean loss = 1.0076092e-08
epoch 4: mean loss = 9.921121e-09  learning rate = 1.2851208e-05
============================
Start of epoch 5
step 0: mean loss = 5.8012586e-09
step 100: mean loss = 5.2602736e-09
step 200: mean loss = 6.310211e-09
step 300: mean loss = 5.884145e-09
epoch 5: mean loss = 5.83363e-09  learning rate = 1.2851208e-05
============================
Start of epoch 6
step 0: mean loss = 7.0879564e-09
step 100: mean loss = 1.1481353e-08
step 200: mean loss = 8.045878e-09
step 300: mean loss = 9.196856e-09
epoch 6: mean loss = 9.152794e-09  learning rate = 1.2851208e-05
============================
Start of epoch 7
step 0: mean loss = 7.671433e-09
step 100: mean loss = 6.9163058e-09
step 200: mean loss = 5.6153606e-09
step 300: mean loss = 5.3123723e-09
epoch 7: mean loss = 5.2840567e-09  learning rate = 1.2851208e-05
============================
Start of epoch 8
step 0: mean loss = 5.047589e-09
step 100: mean loss = 4.8654827e-09
step 200: mean loss = 5.4794906e-09
step 300: mean loss = 6.603231e-09
epoch 8: mean loss = 6.6482175e-09  learning rate = 1.2851208e-05
============================
Start of epoch 9
step 0: mean loss = 1.6462417e-08
step 100: mean loss = 8.890768e-09
step 200: mean loss = 8.055615e-09
step 300: mean loss = 9.474438e-09
epoch 9: mean loss = 9.292765e-09  learning rate = 1.2851208e-05
============================
Start of epoch 10
step 0: mean loss = 6.675357e-09
step 100: mean loss = 5.349169e-09
step 200: mean loss = 5.3858535e-09
step 300: mean loss = 5.3748814e-09
epoch 10: mean loss = 5.4833555e-09  learning rate = 1.2851208e-05
============================
Start of epoch 11
step 0: mean loss = 4.2627972e-09
step 100: mean loss = 7.862224e-09
step 200: mean loss = 7.8926305e-09
step 300: mean loss = 7.012559e-09
epoch 11: mean loss = 6.9686354e-09  learning rate = 1.2851208e-05
============================
Start of epoch 12
step 0: mean loss = 7.993447e-09
step 100: mean loss = 8.6216065e-09
step 200: mean loss = 8.399508e-09
step 300: mean loss = 9.525473e-09
epoch 12: mean loss = 9.821858e-09  learning rate = 1.2851208e-05
============================
Start of epoch 13
step 0: mean loss = 3.3534238e-09
step 100: mean loss = 5.754817e-09
step 200: mean loss = 5.2800235e-09
step 300: mean loss = 5.732563e-09
epoch 13: mean loss = 5.69651e-09  learning rate = 1.2851208e-05
============================
Start of epoch 14
step 0: mean loss = 3.9131196e-09
step 100: mean loss = 6.903974e-09
step 200: mean loss = 6.84439e-09
step 300: mean loss = 6.7218457e-09
epoch 14: mean loss = 6.728325e-09  learning rate = 1.2851208e-05
============================
Start of epoch 15
step 0: mean loss = 3.3152225e-09
step 100: mean loss = 7.3373028e-09
step 200: mean loss = 7.492449e-09
step 300: mean loss = 7.2151822e-09
epoch 15: mean loss = 7.2192514e-09  learning rate = 1.2851208e-05
============================
Start of epoch 16
step 0: mean loss = 5.768668e-09
step 100: mean loss = 5.734092e-09
step 200: mean loss = 7.7914795e-09
step 300: mean loss = 7.2406987e-09
epoch 16: mean loss = 7.1014465e-09  learning rate = 1.2851208e-05
============================
Start of epoch 17
step 0: mean loss = 8.4275955e-09
step 100: mean loss = 5.9630896e-09
step 200: mean loss = 7.365706e-09
step 300: mean loss = 6.197126e-09
epoch 17: mean loss = 6.1576118e-09  learning rate = 1.2851208e-05
============================
Start of epoch 18
step 0: mean loss = 5.821392e-09
step 100: mean loss = 1.3232326e-08
step 200: mean loss = 9.354269e-09
step 300: mean loss = 1.2789091e-08
epoch 18: mean loss = 1.2748293e-08  learning rate = 1.2851208e-05
============================
Start of epoch 19
step 0: mean loss = 4.276804e-09
step 100: mean loss = 4.7316626e-09
step 200: mean loss = 4.2544475e-09
step 300: mean loss = 4.430241e-09
epoch 19: mean loss = 4.3928083e-09  learning rate = 1.2851208e-05
============================
Start of epoch 20
step 0: mean loss = 4.5601705e-09
step 100: mean loss = 6.9837482e-09
step 200: mean loss = 7.807809e-09
step 300: mean loss = 8.052102e-09
epoch 20: mean loss = 8.404279e-09  learning rate = 1.2851208e-05
============================
Start of epoch 21
step 0: mean loss = 7.635757e-09
step 100: mean loss = 6.0748206e-09
step 200: mean loss = 5.6431206e-09
step 300: mean loss = 7.643296e-09
epoch 21: mean loss = 7.474363e-09  learning rate = 1.2851208e-05
============================
Start of epoch 22
step 0: mean loss = 2.7386584e-09
step 100: mean loss = 4.6902584e-09
step 200: mean loss = 4.4251767e-09
step 300: mean loss = 5.086927e-09
epoch 22: mean loss = 5.4230944e-09  learning rate = 1.2851208e-05
============================
Start of epoch 23
step 0: mean loss = 7.962551e-09
step 100: mean loss = 6.3378196e-09
step 200: mean loss = 5.2170543e-09
step 300: mean loss = 5.8386904e-09
epoch 23: mean loss = 5.843274e-09  learning rate = 1.2851208e-05
============================
Start of epoch 24
step 0: mean loss = 1.5241763e-08
step 100: mean loss = 9.986215e-09
step 200: mean loss = 7.549411e-09
step 300: mean loss = 1.4977505e-08
epoch 24: mean loss = 1.497283e-08  learning rate = 1.2851208e-05
============================
Start of epoch 25
step 0: mean loss = 1.7044371e-08
step 100: mean loss = 5.2486144e-09
step 200: mean loss = 4.561223e-09
step 300: mean loss = 4.3291704e-09
epoch 25: mean loss = 4.2748294e-09  learning rate = 1.2851208e-05
============================
Start of epoch 26
step 0: mean loss = 3.2073337e-09
step 100: mean loss = 4.475362e-09
step 200: mean loss = 4.7634288e-09
step 300: mean loss = 5.328239e-09
epoch 26: mean loss = 5.257029e-09  learning rate = 1.2851208e-05
============================
Start of epoch 27
step 0: mean loss = 3.3978877e-09
step 100: mean loss = 8.521244e-09
step 200: mean loss = 8.247604e-09
step 300: mean loss = 7.1164488e-09
epoch 27: mean loss = 7.044941e-09  learning rate = 1.2851208e-05
============================
Start of epoch 28
step 0: mean loss = 5.656386e-09
step 100: mean loss = 7.868721e-09
step 200: mean loss = 6.603031e-09
step 300: mean loss = 6.5191257e-09
epoch 28: mean loss = 6.402179e-09  learning rate = 1.2851208e-05
============================
Start of epoch 29
step 0: mean loss = 3.7567185e-09
step 100: mean loss = 1.0555685e-08
step 200: mean loss = 8.49107e-09
step 300: mean loss = 7.528135e-09
epoch 29: mean loss = 7.36584e-09  learning rate = 1.2851208e-05
============================
Start of epoch 30
step 0: mean loss = 4.733696e-09
step 100: mean loss = 9.691463e-09
step 200: mean loss = 8.638635e-09
step 300: mean loss = 7.480165e-09
epoch 30: mean loss = 7.716912e-09  learning rate = 1.2851208e-05
============================
Start of epoch 31
step 0: mean loss = 8.829041e-09
step 100: mean loss = 7.376568e-09
step 200: mean loss = 6.0630323e-09
step 300: mean loss = 6.585833e-09
epoch 31: mean loss = 6.5786367e-09  learning rate = 1.2851208e-05
============================
Start of epoch 32
step 0: mean loss = 3.7204564e-09
step 100: mean loss = 9.789282e-09
step 200: mean loss = 8.564942e-09
step 300: mean loss = 7.817508e-09
epoch 32: mean loss = 8.163821e-09  learning rate = 1.2851208e-05
============================
Start of epoch 33
step 0: mean loss = 6.357252e-09
step 100: mean loss = 9.256687e-09
step 200: mean loss = 7.527141e-09
step 300: mean loss = 6.9371016e-09
epoch 33: mean loss = 6.839098e-09  learning rate = 1.2851208e-05
============================
Start of epoch 34
step 0: mean loss = 3.5744e-09
step 100: mean loss = 7.081235e-09
step 200: mean loss = 9.266086e-09
step 300: mean loss = 7.8780875e-09
epoch 34: mean loss = 8.04441e-09  learning rate = 1.2851208e-05
============================
Start of epoch 35
step 0: mean loss = 1.7844632e-08
step 100: mean loss = 4.1119543e-09
step 200: mean loss = 5.195709e-09
step 300: mean loss = 5.4157447e-09
epoch 35: mean loss = 5.3626366e-09  learning rate = 1.2851208e-05
============================
Start of epoch 36
step 0: mean loss = 2.8029818e-09
step 100: mean loss = 5.458856e-09
step 200: mean loss = 6.5607315e-09
step 300: mean loss = 8.67129e-09
epoch 36: mean loss = 8.5950775e-09  learning rate = 1.2851208e-05
============================
Start of epoch 37
step 0: mean loss = 3.567429e-09
step 100: mean loss = 5.3186553e-09
step 200: mean loss = 1.0666537e-08
step 300: mean loss = 9.899204e-09
epoch 37: mean loss = 9.739278e-09  learning rate = 1.2851208e-05
============================
Start of epoch 38
step 0: mean loss = 3.927986e-09
step 100: mean loss = 4.328056e-09
step 200: mean loss = 5.897469e-09
step 300: mean loss = 9.01156e-09
epoch 38: mean loss = 8.802744e-09  learning rate = 1.2851208e-05
============================
Start of epoch 39
step 0: mean loss = 4.50415e-09
step 100: mean loss = 3.668946e-09
step 200: mean loss = 4.1348263e-09
step 300: mean loss = 4.099554e-09
epoch 39: mean loss = 4.0981787e-09  learning rate = 1.22086485e-05
============================
Start of epoch 40
step 0: mean loss = 3.2608003e-09
step 100: mean loss = 5.3958535e-09
step 200: mean loss = 5.243454e-09
step 300: mean loss = 5.6455036e-09
epoch 40: mean loss = 5.766435e-09  learning rate = 1.22086485e-05
============================
Start of epoch 41
step 0: mean loss = 1.2543059e-08
step 100: mean loss = 1.2701573e-08
step 200: mean loss = 8.387519e-09
step 300: mean loss = 7.1140245e-09
epoch 41: mean loss = 6.986086e-09  learning rate = 1.22086485e-05
============================
Start of epoch 42
step 0: mean loss = 3.501365e-09
step 100: mean loss = 4.1231956e-09
step 200: mean loss = 5.5517537e-09
step 300: mean loss = 7.483314e-09
epoch 42: mean loss = 7.365279e-09  learning rate = 1.22086485e-05
============================
Start of epoch 43
step 0: mean loss = 4.0569104e-09
step 100: mean loss = 4.9442095e-09
step 200: mean loss = 4.8369033e-09
step 300: mean loss = 5.9878156e-09
epoch 43: mean loss = 5.8862417e-09  learning rate = 1.22086485e-05
============================
Start of epoch 44
step 0: mean loss = 3.389546e-09
step 100: mean loss = 4.0296064e-09
step 200: mean loss = 5.98334e-09
step 300: mean loss = 5.4566316e-09
epoch 44: mean loss = 5.403586e-09  learning rate = 1.22086485e-05
============================
Start of epoch 45
step 0: mean loss = 4.82508e-09
step 100: mean loss = 4.945712e-09
step 200: mean loss = 5.34772e-09
step 300: mean loss = 5.660496e-09
epoch 45: mean loss = 5.6853557e-09  learning rate = 1.22086485e-05
============================
Start of epoch 46
step 0: mean loss = 8.685093e-09
step 100: mean loss = 1.3938577e-08
step 200: mean loss = 1.5891619e-08
step 300: mean loss = 1.1896423e-08
epoch 46: mean loss = 1.1589346e-08  learning rate = 1.22086485e-05
============================
Start of epoch 47
step 0: mean loss = 4.0743897e-09
step 100: mean loss = 5.0503126e-09
step 200: mean loss = 4.758208e-09
step 300: mean loss = 5.0480167e-09
epoch 47: mean loss = 5.1148543e-09  learning rate = 1.22086485e-05
============================
Start of epoch 48
step 0: mean loss = 4.4493627e-09
step 100: mean loss = 7.196539e-09
step 200: mean loss = 5.8310605e-09
step 300: mean loss = 7.392919e-09
epoch 48: mean loss = 7.455916e-09  learning rate = 1.22086485e-05
============================
Start of epoch 49
step 0: mean loss = 2.7673015e-09
step 100: mean loss = 4.30382e-09
step 200: mean loss = 8.197647e-09
step 300: mean loss = 7.2664736e-09
epoch 49: mean loss = 7.1439574e-09  learning rate = 1.22086485e-05
============================
Start of epoch 50
step 0: mean loss = 4.023364e-09
step 100: mean loss = 4.079137e-09
step 200: mean loss = 4.5034088e-09
step 300: mean loss = 4.189683e-09
epoch 50: mean loss = 4.1679566e-09  learning rate = 1.22086485e-05
============================
Start of epoch 51
step 0: mean loss = 4.990153e-09
step 100: mean loss = 6.466457e-09
step 200: mean loss = 7.041004e-09
step 300: mean loss = 8.403511e-09
epoch 51: mean loss = 8.2623615e-09  learning rate = 1.22086485e-05
============================
Start of epoch 52
step 0: mean loss = 6.8847514e-09
step 100: mean loss = 6.333323e-09
step 200: mean loss = 6.3880763e-09
step 300: mean loss = 5.9343304e-09
epoch 52: mean loss = 5.8583516e-09  learning rate = 1.22086485e-05
============================
Start of epoch 53
step 0: mean loss = 2.1708697e-09
step 100: mean loss = 6.054193e-09
step 200: mean loss = 5.1326934e-09
step 300: mean loss = 7.631613e-09
epoch 53: mean loss = 7.649519e-09  learning rate = 1.22086485e-05
============================
Start of epoch 54
step 0: mean loss = 4.5432262e-09
step 100: mean loss = 5.0485456e-09
step 200: mean loss = 4.6830175e-09
step 300: mean loss = 4.7193027e-09
epoch 54: mean loss = 4.763564e-09  learning rate = 1.22086485e-05
============================
Start of epoch 55
step 0: mean loss = 2.4642008e-09
step 100: mean loss = 3.6686552e-09
step 200: mean loss = 5.1138533e-09
step 300: mean loss = 5.489711e-09
epoch 55: mean loss = 5.3814606e-09  learning rate = 1.22086485e-05
============================
Start of epoch 56
step 0: mean loss = 3.6970778e-09
step 100: mean loss = 1.383721e-08
step 200: mean loss = 1.3538714e-08
step 300: mean loss = 1.1451141e-08
epoch 56: mean loss = 1.12267635e-08  learning rate = 1.22086485e-05
============================
Start of epoch 57
step 0: mean loss = 6.1034613e-09
step 100: mean loss = 3.3181344e-09
step 200: mean loss = 4.290092e-09
step 300: mean loss = 5.173106e-09
epoch 57: mean loss = 5.161711e-09  learning rate = 1.22086485e-05
============================
Start of epoch 58
step 0: mean loss = 4.3869015e-09
step 100: mean loss = 4.8632076e-09
step 200: mean loss = 4.95012e-09
step 300: mean loss = 6.2392083e-09
epoch 58: mean loss = 7.0269763e-09  learning rate = 1.22086485e-05
============================
Start of epoch 59
step 0: mean loss = 4.6525056e-08
step 100: mean loss = 4.7526214e-09
step 200: mean loss = 4.843619e-09
step 300: mean loss = 5.313499e-09
epoch 59: mean loss = 5.472837e-09  learning rate = 1.22086485e-05
============================
Start of epoch 60
step 0: mean loss = 4.9586215e-09
step 100: mean loss = 8.326333e-09
step 200: mean loss = 1.0466962e-08
step 300: mean loss = 8.570853e-09
epoch 60: mean loss = 8.462399e-09  learning rate = 1.22086485e-05
============================
Start of epoch 61
step 0: mean loss = 5.761867e-09
step 100: mean loss = 9.168579e-09
step 200: mean loss = 7.435276e-09
step 300: mean loss = 6.622365e-09
epoch 61: mean loss = 6.608899e-09  learning rate = 1.22086485e-05
============================
Start of epoch 62
step 0: mean loss = 5.562916e-09
step 100: mean loss = 8.674035e-09
step 200: mean loss = 7.46071e-09
step 300: mean loss = 7.0123445e-09
epoch 62: mean loss = 6.924868e-09  learning rate = 1.22086485e-05
============================
Start of epoch 63
step 0: mean loss = 3.737532e-09
step 100: mean loss = 4.0166284e-09
step 200: mean loss = 6.310409e-09
step 300: mean loss = 6.432353e-09
epoch 63: mean loss = 6.5904273e-09  learning rate = 1.22086485e-05
============================
Start of epoch 64
step 0: mean loss = 2.0163236e-08
step 100: mean loss = 7.728247e-09
step 200: mean loss = 9.567174e-09
step 300: mean loss = 8.438368e-09
epoch 64: mean loss = 8.291024e-09  learning rate = 1.22086485e-05
============================
Start of epoch 65
step 0: mean loss = 5.9701173e-09
step 100: mean loss = 3.611058e-09
step 200: mean loss = 4.0872297e-09
step 300: mean loss = 3.9975965e-09
epoch 65: mean loss = 4.01007e-09  learning rate = 1.22086485e-05
============================
Start of epoch 66
step 0: mean loss = 3.9204666e-09
step 100: mean loss = 5.352346e-09
step 200: mean loss = 5.32568e-09
step 300: mean loss = 6.2438885e-09
epoch 66: mean loss = 6.2472743e-09  learning rate = 1.22086485e-05
============================
Start of epoch 67
step 0: mean loss = 3.1765275e-09
step 100: mean loss = 3.6159267e-09
step 200: mean loss = 6.079307e-09
step 300: mean loss = 5.9984613e-09
epoch 67: mean loss = 5.944992e-09  learning rate = 1.22086485e-05
============================
Start of epoch 68
step 0: mean loss = 3.3197805e-09
step 100: mean loss = 5.193508e-09
step 200: mean loss = 6.6830412e-09
step 300: mean loss = 9.027361e-09
epoch 68: mean loss = 8.855086e-09  learning rate = 1.22086485e-05
============================
Start of epoch 69
step 0: mean loss = 3.7895007e-09
step 100: mean loss = 3.4452647e-09
step 200: mean loss = 3.7933727e-09
step 300: mean loss = 6.4621903e-09
epoch 69: mean loss = 6.5203998e-09  learning rate = 1.22086485e-05
============================
Start of epoch 70
step 0: mean loss = 9.176316e-09
step 100: mean loss = 1.8111322e-08
step 200: mean loss = 1.1367135e-08
step 300: mean loss = 8.795647e-09
epoch 70: mean loss = 8.796868e-09  learning rate = 1.22086485e-05
============================
Start of epoch 71
step 0: mean loss = 8.215769e-09
step 100: mean loss = 6.8335955e-09
step 200: mean loss = 5.954059e-09
step 300: mean loss = 5.63472e-09
epoch 71: mean loss = 5.6778218e-09  learning rate = 1.22086485e-05
============================
Start of epoch 72
step 0: mean loss = 4.481465e-09
step 100: mean loss = 1.1322996e-08
step 200: mean loss = 9.102611e-09
step 300: mean loss = 7.271386e-09
epoch 72: mean loss = 7.1651627e-09  learning rate = 1.22086485e-05
============================
Start of epoch 73
step 0: mean loss = 2.370712e-09
step 100: mean loss = 4.704458e-09
step 200: mean loss = 6.4512777e-09
step 300: mean loss = 6.450774e-09
epoch 73: mean loss = 6.501171e-09  learning rate = 1.22086485e-05
============================
Start of epoch 74
step 0: mean loss = 3.0254292e-09
step 100: mean loss = 4.531398e-09
step 200: mean loss = 7.2063147e-09
step 300: mean loss = 6.1549494e-09
epoch 74: mean loss = 6.1490537e-09  learning rate = 1.22086485e-05
============================
Start of epoch 75
step 0: mean loss = 3.7508756e-09
step 100: mean loss = 4.227974e-09
step 200: mean loss = 4.359864e-09
step 300: mean loss = 5.440849e-09
epoch 75: mean loss = 5.658343e-09  learning rate = 1.22086485e-05
============================
Start of epoch 76
step 0: mean loss = 1.0357573e-08
step 100: mean loss = 5.8089804e-09
step 200: mean loss = 5.395807e-09
step 300: mean loss = 5.911674e-09
epoch 76: mean loss = 5.938101e-09  learning rate = 1.22086485e-05
============================
Start of epoch 77
step 0: mean loss = 5.031808e-09
step 100: mean loss = 1.1261413e-08
step 200: mean loss = 8.662783e-09
step 300: mean loss = 7.799831e-09
epoch 77: mean loss = 7.639012e-09  learning rate = 1.22086485e-05
============================
Start of epoch 78
step 0: mean loss = 2.5788165e-09
step 100: mean loss = 3.867016e-09
step 200: mean loss = 5.385445e-09
step 300: mean loss = 7.0370527e-09
epoch 78: mean loss = 7.807503e-09  learning rate = 1.22086485e-05
============================
Start of epoch 79
step 0: mean loss = 3.3225888e-08
step 100: mean loss = 5.54961e-09
step 200: mean loss = 5.0888023e-09
step 300: mean loss = 5.0496864e-09
epoch 79: mean loss = 5.1828524e-09  learning rate = 1.1598217e-05
============================
Start of epoch 80
step 0: mean loss = 7.3575044e-09
step 100: mean loss = 4.774272e-09
step 200: mean loss = 8.246609e-09
step 300: mean loss = 8.112936e-09
epoch 80: mean loss = 7.98037e-09  learning rate = 1.1598217e-05
============================
Start of epoch 81
step 0: mean loss = 1.1964822e-08
step 100: mean loss = 6.3299566e-09
step 200: mean loss = 5.4858758e-09
step 300: mean loss = 5.2803593e-09
epoch 81: mean loss = 5.4412745e-09  learning rate = 1.1598217e-05
============================
Start of epoch 82
step 0: mean loss = 1.8362641e-08
step 100: mean loss = 4.759308e-09
step 200: mean loss = 4.166892e-09
step 300: mean loss = 5.2496434e-09
epoch 82: mean loss = 5.350329e-09  learning rate = 1.1598217e-05
============================
Start of epoch 83
step 0: mean loss = 4.241772e-09
step 100: mean loss = 6.177701e-09
step 200: mean loss = 5.083676e-09
step 300: mean loss = 6.37968e-09
epoch 83: mean loss = 6.486575e-09  learning rate = 1.1598217e-05
============================
Start of epoch 84
step 0: mean loss = 7.1200104e-09
step 100: mean loss = 7.701118e-09
step 200: mean loss = 5.818225e-09
step 300: mean loss = 5.371712e-09
epoch 84: mean loss = 5.34985e-09  learning rate = 1.1598217e-05
============================
Start of epoch 85
step 0: mean loss = 2.7654017e-09
step 100: mean loss = 3.9896637e-09
step 200: mean loss = 5.5274327e-09
step 300: mean loss = 7.708132e-09
epoch 85: mean loss = 7.669144e-09  learning rate = 1.1598217e-05
============================
Start of epoch 86
step 0: mean loss = 3.3889669e-09
step 100: mean loss = 6.009219e-09
step 200: mean loss = 4.830947e-09
step 300: mean loss = 5.0376623e-09
epoch 86: mean loss = 5.333314e-09  learning rate = 1.1598217e-05
============================
Start of epoch 87
step 0: mean loss = 1.0618711e-08
step 100: mean loss = 6.1156933e-09
step 200: mean loss = 5.973382e-09
step 300: mean loss = 5.5683946e-09
epoch 87: mean loss = 5.470526e-09  learning rate = 1.1598217e-05
============================
Start of epoch 88
step 0: mean loss = 2.3619886e-09
step 100: mean loss = 5.2596962e-09
step 200: mean loss = 6.078208e-09
step 300: mean loss = 6.130468e-09
epoch 88: mean loss = 6.1354206e-09  learning rate = 1.1598217e-05
============================
Start of epoch 89
step 0: mean loss = 3.6245553e-09
step 100: mean loss = 5.238803e-09
step 200: mean loss = 5.4233245e-09
step 300: mean loss = 6.9341e-09
epoch 89: mean loss = 7.0311676e-09  learning rate = 1.1598217e-05
============================
Start of epoch 90
step 0: mean loss = 1.8143918e-08
step 100: mean loss = 4.1350705e-09
step 200: mean loss = 5.1242486e-09
step 300: mean loss = 5.0726148e-09
epoch 90: mean loss = 5.0278812e-09  learning rate = 1.1598217e-05
============================
Start of epoch 91
step 0: mean loss = 4.5208366e-09
step 100: mean loss = 8.286657e-09
step 200: mean loss = 6.448591e-09
step 300: mean loss = 5.6188503e-09
epoch 91: mean loss = 5.617808e-09  learning rate = 1.1598217e-05
============================
Start of epoch 92
step 0: mean loss = 5.1452105e-09
step 100: mean loss = 4.074274e-09
step 200: mean loss = 4.818299e-09
step 300: mean loss = 5.569618e-09
epoch 92: mean loss = 5.501575e-09  learning rate = 1.1598217e-05
============================
Start of epoch 93
step 0: mean loss = 5.102496e-09
step 100: mean loss = 4.8818145e-09
step 200: mean loss = 4.4794435e-09
step 300: mean loss = 6.4918764e-09
epoch 93: mean loss = 6.5120416e-09  learning rate = 1.1598217e-05
============================
Start of epoch 94
step 0: mean loss = 8.885566e-09
step 100: mean loss = 8.502221e-09
step 200: mean loss = 7.568376e-09
step 300: mean loss = 7.154705e-09
epoch 94: mean loss = 7.1904043e-09  learning rate = 1.1598217e-05
============================
Start of epoch 95
step 0: mean loss = 6.269274e-09
step 100: mean loss = 3.8668855e-09
step 200: mean loss = 4.635283e-09
step 300: mean loss = 6.554914e-09
epoch 95: mean loss = 6.585112e-09  learning rate = 1.1598217e-05
============================
Start of epoch 96
step 0: mean loss = 4.3349986e-09
step 100: mean loss = 3.9495696e-09
step 200: mean loss = 4.697582e-09
step 300: mean loss = 4.696672e-09
epoch 96: mean loss = 4.684551e-09  learning rate = 1.1598217e-05
============================
Start of epoch 97
step 0: mean loss = 4.011832e-09
step 100: mean loss = 1.0206424e-08
step 200: mean loss = 8.084361e-09
step 300: mean loss = 6.475434e-09
epoch 97: mean loss = 6.7185995e-09  learning rate = 1.1598217e-05
============================
Start of epoch 98
step 0: mean loss = 3.9922583e-08
step 100: mean loss = 6.673175e-09
step 200: mean loss = 5.1418474e-09
step 300: mean loss = 6.971866e-09
epoch 98: mean loss = 6.83243e-09  learning rate = 1.1598217e-05
============================
Start of epoch 99
step 0: mean loss = 2.440599e-09
step 100: mean loss = 4.4538297e-09
step 200: mean loss = 5.639392e-09
step 300: mean loss = 5.994176e-09
epoch 99: mean loss = 5.978955e-09  learning rate = 1.1598217e-05
============================
Start of epoch 100
step 0: mean loss = 1.2134822e-08
step 100: mean loss = 7.1412414e-09
step 200: mean loss = 6.2672476e-09
step 300: mean loss = 7.449531e-09
epoch 100: mean loss = 7.327166e-09  learning rate = 1.1598217e-05
============================
Start of epoch 101
step 0: mean loss = 2.3348428e-09
step 100: mean loss = 3.632926e-09
step 200: mean loss = 3.692739e-09
step 300: mean loss = 4.5206145e-09
epoch 101: mean loss = 4.473278e-09  learning rate = 1.1598217e-05
============================
Start of epoch 102
step 0: mean loss = 3.1600542e-09
step 100: mean loss = 7.554763e-09
step 200: mean loss = 5.5885025e-09
step 300: mean loss = 6.777535e-09
epoch 102: mean loss = 7.1353976e-09  learning rate = 1.1598217e-05
============================
Start of epoch 103
step 0: mean loss = 6.5921206e-09
step 100: mean loss = 9.555029e-09
step 200: mean loss = 1.15768675e-08
step 300: mean loss = 9.154204e-09
epoch 103: mean loss = 8.9965475e-09  learning rate = 1.1598217e-05
============================
Start of epoch 104
step 0: mean loss = 5.2333715e-09
step 100: mean loss = 4.079065e-09
step 200: mean loss = 4.364865e-09
step 300: mean loss = 4.4315027e-09
epoch 104: mean loss = 4.406113e-09  learning rate = 1.1598217e-05
============================
Start of epoch 105
step 0: mean loss = 3.155381e-09
step 100: mean loss = 6.3638e-09
step 200: mean loss = 5.460943e-09
step 300: mean loss = 5.105315e-09
epoch 105: mean loss = 5.2444524e-09  learning rate = 1.1598217e-05
============================
Start of epoch 106
step 0: mean loss = 7.483048e-09
step 100: mean loss = 4.1847423e-09
step 200: mean loss = 4.307568e-09
step 300: mean loss = 6.0266467e-09
epoch 106: mean loss = 5.964149e-09  learning rate = 1.1598217e-05
============================
Start of epoch 107
step 0: mean loss = 8.29282e-09
step 100: mean loss = 7.2330772e-09
step 200: mean loss = 6.2021943e-09
step 300: mean loss = 6.5278747e-09
epoch 107: mean loss = 6.7331083e-09  learning rate = 1.1598217e-05
============================
Start of epoch 108
step 0: mean loss = 1.8916584e-08
step 100: mean loss = 4.499434e-09
step 200: mean loss = 4.333396e-09
step 300: mean loss = 4.4373953e-09
epoch 108: mean loss = 4.4906416e-09  learning rate = 1.1598217e-05
============================
Start of epoch 109
step 0: mean loss = 2.6637e-09
step 100: mean loss = 5.8035523e-09
step 200: mean loss = 7.818162e-09
step 300: mean loss = 7.517027e-09
epoch 109: mean loss = 7.646467e-09  learning rate = 1.1598217e-05
============================
Start of epoch 110
step 0: mean loss = 3.1646572e-09
step 100: mean loss = 4.512744e-09
step 200: mean loss = 4.5357544e-09
step 300: mean loss = 5.2735825e-09
epoch 110: mean loss = 7.3042985e-09  learning rate = 1.1598217e-05
============================
Start of epoch 111
step 0: mean loss = 2.7009161e-08
step 100: mean loss = 1.9637575e-08
step 200: mean loss = 1.1600033e-08
step 300: mean loss = 9.196972e-09
epoch 111: mean loss = 9.0153724e-09  learning rate = 1.1598217e-05
============================
Start of epoch 112
step 0: mean loss = 6.5399677e-09
step 100: mean loss = 3.8911727e-09
step 200: mean loss = 4.3842467e-09
step 300: mean loss = 5.1110285e-09
epoch 112: mean loss = 5.047794e-09  learning rate = 1.1598217e-05
============================
Start of epoch 113
step 0: mean loss = 3.1269463e-09
step 100: mean loss = 3.9970334e-09
step 200: mean loss = 6.1695635e-09
step 300: mean loss = 5.4413434e-09
epoch 113: mean loss = 5.375136e-09  learning rate = 1.1598217e-05
============================
Start of epoch 114
step 0: mean loss = 3.6501953e-09
step 100: mean loss = 8.861901e-09
step 200: mean loss = 6.6020176e-09
step 300: mean loss = 5.6403855e-09
epoch 114: mean loss = 5.5991314e-09  learning rate = 1.1598217e-05
============================
Start of epoch 115
step 0: mean loss = 3.03476e-09
step 100: mean loss = 5.080417e-09
step 200: mean loss = 7.505505e-09
step 300: mean loss = 6.6737504e-09
epoch 115: mean loss = 6.696736e-09  learning rate = 1.1598217e-05
============================
Start of epoch 116
step 0: mean loss = 4.9538413e-09
step 100: mean loss = 4.679952e-09
step 200: mean loss = 6.677884e-09
step 300: mean loss = 6.5511094e-09
epoch 116: mean loss = 6.423569e-09  learning rate = 1.1598217e-05
============================
Start of epoch 117
step 0: mean loss = 3.357293e-09
step 100: mean loss = 3.9567847e-09
step 200: mean loss = 4.347493e-09
step 300: mean loss = 4.607419e-09
epoch 117: mean loss = 5.511753e-09  learning rate = 1.1598217e-05
============================
Start of epoch 118
step 0: mean loss = 1.6879904e-08
step 100: mean loss = 4.421574e-08
step 200: mean loss = 2.3973286e-08
step 300: mean loss = 1.7250459e-08
epoch 118: mean loss = 1.6687059e-08  learning rate = 1.1598217e-05
============================
Start of epoch 119
step 0: mean loss = 2.6289584e-09
step 100: mean loss = 3.0458085e-09
step 200: mean loss = 3.108868e-09
step 300: mean loss = 3.3187277e-09
epoch 119: mean loss = 3.3363157e-09  learning rate = 1.1018305e-05
============================
Start of epoch 120
step 0: mean loss = 4.013029e-09
step 100: mean loss = 3.2138803e-09
step 200: mean loss = 3.5910264e-09
step 300: mean loss = 3.673366e-09
epoch 120: mean loss = 3.6432901e-09  learning rate = 1.1018305e-05
============================
Start of epoch 121
step 0: mean loss = 2.8999858e-09
step 100: mean loss = 4.9647415e-09
step 200: mean loss = 5.0752345e-09
step 300: mean loss = 6.4241252e-09
epoch 121: mean loss = 6.516004e-09  learning rate = 1.1018305e-05
============================
Start of epoch 122
step 0: mean loss = 5.3107194e-09
step 100: mean loss = 4.7376605e-09
step 200: mean loss = 4.4447557e-09
step 300: mean loss = 4.7408792e-09
epoch 122: mean loss = 4.7721187e-09  learning rate = 1.1018305e-05
============================
Start of epoch 123
step 0: mean loss = 2.1517494e-09
step 100: mean loss = 6.9299757e-09
step 200: mean loss = 6.0512635e-09
step 300: mean loss = 5.225182e-09
epoch 123: mean loss = 5.410275e-09  learning rate = 1.1018305e-05
============================
Start of epoch 124
step 0: mean loss = 3.983536e-09
step 100: mean loss = 6.897098e-09
step 200: mean loss = 5.7478178e-09
step 300: mean loss = 5.7002745e-09
epoch 124: mean loss = 5.5766303e-09  learning rate = 1.1018305e-05
============================
Start of epoch 125
step 0: mean loss = 3.680131e-09
step 100: mean loss = 3.8191543e-09
step 200: mean loss = 6.000286e-09
step 300: mean loss = 5.4682463e-09
epoch 125: mean loss = 5.468167e-09  learning rate = 1.1018305e-05
============================
Start of epoch 126
step 0: mean loss = 8.039902e-09
step 100: mean loss = 8.879722e-09
step 200: mean loss = 6.6826527e-09
step 300: mean loss = 6.286902e-09
epoch 126: mean loss = 6.2674967e-09  learning rate = 1.1018305e-05
============================
Start of epoch 127
step 0: mean loss = 1.665415e-08
step 100: mean loss = 4.9103868e-09
step 200: mean loss = 6.47348e-09
step 300: mean loss = 8.500826e-09
epoch 127: mean loss = 8.367238e-09  learning rate = 1.1018305e-05
============================
Start of epoch 128
step 0: mean loss = 3.941685e-09
step 100: mean loss = 4.283625e-09
step 200: mean loss = 3.9730907e-09
step 300: mean loss = 4.1548747e-09
epoch 128: mean loss = 4.2925627e-09  learning rate = 1.1018305e-05
============================
Start of epoch 129
step 0: mean loss = 7.091907e-09
step 100: mean loss = 4.3192534e-09
step 200: mean loss = 5.346562e-09
step 300: mean loss = 4.9291975e-09
epoch 129: mean loss = 5.1070113e-09  learning rate = 1.1018305e-05
============================
Start of epoch 130
step 0: mean loss = 2.599619e-08
step 100: mean loss = 6.8867343e-09
step 200: mean loss = 5.4110223e-09
step 300: mean loss = 5.2832934e-09
epoch 130: mean loss = 5.2464735e-09  learning rate = 1.1018305e-05
============================
Start of epoch 131
step 0: mean loss = 7.75999e-09
step 100: mean loss = 4.9952904e-09
step 200: mean loss = 5.973008e-09
step 300: mean loss = 5.254742e-09
epoch 131: mean loss = 5.152465e-09  learning rate = 1.1018305e-05
============================
Start of epoch 132
step 0: mean loss = 3.405995e-09
step 100: mean loss = 7.776734e-09
step 200: mean loss = 6.614927e-09
step 300: mean loss = 6.6313017e-09
epoch 132: mean loss = 6.577311e-09  learning rate = 1.1018305e-05
============================
Start of epoch 133
step 0: mean loss = 3.729657e-09
step 100: mean loss = 6.459635e-09
step 200: mean loss = 5.2148077e-09
step 300: mean loss = 5.2136566e-09
epoch 133: mean loss = 5.305954e-09  learning rate = 1.1018305e-05
============================
Start of epoch 134
step 0: mean loss = 2.1516072e-08
step 100: mean loss = 6.9133437e-09
step 200: mean loss = 6.058248e-09
step 300: mean loss = 5.8300076e-09
epoch 134: mean loss = 5.7587313e-09  learning rate = 1.1018305e-05
============================
Start of epoch 135
step 0: mean loss = 2.7241294e-09
step 100: mean loss = 5.2794333e-09
step 200: mean loss = 5.372701e-09
step 300: mean loss = 5.9623337e-09
epoch 135: mean loss = 6.0723506e-09  learning rate = 1.1018305e-05
============================
Start of epoch 136
step 0: mean loss = 2.9379487e-08
step 100: mean loss = 7.5836875e-09
step 200: mean loss = 5.990875e-09
step 300: mean loss = 7.462119e-09
epoch 136: mean loss = 7.3468147e-09  learning rate = 1.1018305e-05
============================
Start of epoch 137
step 0: mean loss = 4.460511e-09
step 100: mean loss = 3.1864391e-09
step 200: mean loss = 4.269289e-09
step 300: mean loss = 4.139274e-09
epoch 137: mean loss = 4.1629042e-09  learning rate = 1.1018305e-05
============================
Start of epoch 138
step 0: mean loss = 4.3982498e-09
step 100: mean loss = 3.9258237e-09
step 200: mean loss = 4.1459076e-09
step 300: mean loss = 4.384721e-09
epoch 138: mean loss = 4.432834e-09  learning rate = 1.1018305e-05
============================
Start of epoch 139
step 0: mean loss = 2.34077e-09
step 100: mean loss = 9.7873425e-09
step 200: mean loss = 8.033956e-09
step 300: mean loss = 6.852756e-09
epoch 139: mean loss = 6.8469044e-09  learning rate = 1.1018305e-05
============================
Start of epoch 140
step 0: mean loss = 4.472251e-09
step 100: mean loss = 4.3456896e-09
step 200: mean loss = 5.1228652e-09
step 300: mean loss = 5.4836495e-09
epoch 140: mean loss = 5.373801e-09  learning rate = 1.1018305e-05
============================
Start of epoch 141
step 0: mean loss = 3.7140233e-09
step 100: mean loss = 7.380701e-09
step 200: mean loss = 5.9816183e-09
step 300: mean loss = 6.4031194e-09
epoch 141: mean loss = 6.360197e-09  learning rate = 1.1018305e-05
============================
Start of epoch 142
step 0: mean loss = 3.563029e-09
step 100: mean loss = 3.5786365e-09
step 200: mean loss = 5.4748686e-09
step 300: mean loss = 4.817686e-09
epoch 142: mean loss = 4.729174e-09  learning rate = 1.1018305e-05
============================
Start of epoch 143
step 0: mean loss = 2.8735463e-09
step 100: mean loss = 4.766855e-09
step 200: mean loss = 5.646654e-09
step 300: mean loss = 5.0177555e-09
epoch 143: mean loss = 5.014821e-09  learning rate = 1.1018305e-05
============================
Start of epoch 144
step 0: mean loss = 4.556983e-09
step 100: mean loss = 4.124891e-09
step 200: mean loss = 5.735733e-09
step 300: mean loss = 7.1150836e-09
epoch 144: mean loss = 6.952352e-09  learning rate = 1.1018305e-05
============================
Start of epoch 145
step 0: mean loss = 4.846773e-09
step 100: mean loss = 8.58117e-09
step 200: mean loss = 7.050329e-09
step 300: mean loss = 6.6935653e-09
epoch 145: mean loss = 6.5767707e-09  learning rate = 1.1018305e-05
============================
Start of epoch 146
step 0: mean loss = 2.5987823e-09
step 100: mean loss = 4.1648933e-09
step 200: mean loss = 6.716797e-09
step 300: mean loss = 7.1835746e-09
epoch 146: mean loss = 7.0503114e-09  learning rate = 1.1018305e-05
============================
Start of epoch 147
step 0: mean loss = 2.3896045e-09
step 100: mean loss = 7.932786e-09
step 200: mean loss = 5.975031e-09
step 300: mean loss = 7.75407e-09
epoch 147: mean loss = 7.588698e-09  learning rate = 1.1018305e-05
============================
Start of epoch 148
step 0: mean loss = 4.692951e-09
step 100: mean loss = 4.239189e-09
step 200: mean loss = 3.7528936e-09
step 300: mean loss = 3.911345e-09
epoch 148: mean loss = 3.8610577e-09  learning rate = 1.1018305e-05
============================
Start of epoch 149
step 0: mean loss = 1.9468338e-09
step 100: mean loss = 3.785488e-09
step 200: mean loss = 4.5853876e-09
step 300: mean loss = 4.9217825e-09
epoch 149: mean loss = 4.8517155e-09  learning rate = 1.1018305e-05
============================
Start of epoch 150
step 0: mean loss = 2.4527818e-09
step 100: mean loss = 4.0639745e-09
step 200: mean loss = 5.1734332e-09
step 300: mean loss = 4.6882245e-09
epoch 150: mean loss = 4.6053032e-09  learning rate = 1.1018305e-05
============================
Start of epoch 151
step 0: mean loss = 3.1557725e-09
step 100: mean loss = 5.6608807e-09
step 200: mean loss = 5.6783325e-09
step 300: mean loss = 7.803142e-09
epoch 151: mean loss = 8.032332e-09  learning rate = 1.1018305e-05
============================
Start of epoch 152
step 0: mean loss = 1.2533216e-08
step 100: mean loss = 6.627612e-09
step 200: mean loss = 5.3642397e-09
step 300: mean loss = 5.3488476e-09
epoch 152: mean loss = 5.617154e-09  learning rate = 1.1018305e-05
============================
Start of epoch 153
step 0: mean loss = 9.302054e-09
step 100: mean loss = 4.6558455e-09
step 200: mean loss = 4.3767643e-09
step 300: mean loss = 4.4457837e-09
epoch 153: mean loss = 4.553315e-09  learning rate = 1.1018305e-05
============================
Start of epoch 154
step 0: mean loss = 1.8565899e-08
step 100: mean loss = 5.6830536e-09
step 200: mean loss = 4.8130726e-09
step 300: mean loss = 5.0396762e-09
epoch 154: mean loss = 5.0064783e-09  learning rate = 1.1018305e-05
============================
Start of epoch 155
step 0: mean loss = 7.3260393e-09
step 100: mean loss = 3.916721e-09
step 200: mean loss = 4.5292796e-09
step 300: mean loss = 5.3959393e-09
epoch 155: mean loss = 5.4040776e-09  learning rate = 1.1018305e-05
============================
Start of epoch 156
step 0: mean loss = 3.1379355e-09
step 100: mean loss = 2.232749e-08
step 200: mean loss = 1.3151721e-08
step 300: mean loss = 9.86958e-09
epoch 156: mean loss = 9.788839e-09  learning rate = 1.1018305e-05
============================
Start of epoch 157
step 0: mean loss = 2.8884088e-09
step 100: mean loss = 4.8041287e-09
step 200: mean loss = 4.4679553e-09
step 300: mean loss = 4.3199178e-09
epoch 157: mean loss = 4.2990087e-09  learning rate = 1.1018305e-05
============================
Start of epoch 158
step 0: mean loss = 3.2662846e-09
step 100: mean loss = 4.9476707e-09
step 200: mean loss = 4.865063e-09
step 300: mean loss = 4.708539e-09
epoch 158: mean loss = 4.7410094e-09  learning rate = 1.1018305e-05
============================
Start of epoch 159
step 0: mean loss = 8.964286e-09
step 100: mean loss = 4.662149e-09
step 200: mean loss = 5.405261e-09
step 300: mean loss = 5.2279723e-09
epoch 159: mean loss = 5.206565e-09  learning rate = 1.046739e-05
============================
Start of epoch 160
step 0: mean loss = 1.8209354e-08
step 100: mean loss = 6.4128836e-09
step 200: mean loss = 5.42928e-09
step 300: mean loss = 6.386237e-09
epoch 160: mean loss = 6.328265e-09  learning rate = 1.046739e-05
============================
Start of epoch 161
step 0: mean loss = 6.4498025e-09
step 100: mean loss = 5.580377e-09
step 200: mean loss = 4.991601e-09
step 300: mean loss = 4.462144e-09
epoch 161: mean loss = 4.4531325e-09  learning rate = 1.046739e-05
============================
Start of epoch 162
step 0: mean loss = 3.393587e-09
step 100: mean loss = 4.7577347e-09
step 200: mean loss = 5.7449947e-09
step 300: mean loss = 5.4554548e-09
epoch 162: mean loss = 5.3896323e-09  learning rate = 1.046739e-05
============================
Start of epoch 163
step 0: mean loss = 2.9946334e-09
step 100: mean loss = 4.077759e-09
step 200: mean loss = 6.2637477e-09
step 300: mean loss = 7.0652413e-09
epoch 163: mean loss = 6.9254127e-09  learning rate = 1.046739e-05
============================
Start of epoch 164
step 0: mean loss = 4.50186e-09
step 100: mean loss = 5.167294e-09
step 200: mean loss = 4.468647e-09
step 300: mean loss = 4.519789e-09
epoch 164: mean loss = 4.4613024e-09  learning rate = 1.046739e-05
============================
Start of epoch 165
step 0: mean loss = 3.0769538e-09
step 100: mean loss = 7.0508954e-09
step 200: mean loss = 6.1815624e-09
step 300: mean loss = 5.4988356e-09
epoch 165: mean loss = 5.401977e-09  learning rate = 1.046739e-05
============================
Start of epoch 166
step 0: mean loss = 3.1009084e-09
step 100: mean loss = 3.9066483e-09
step 200: mean loss = 5.122547e-09
step 300: mean loss = 4.6762767e-09
epoch 166: mean loss = 4.7373483e-09  learning rate = 1.046739e-05
============================
Start of epoch 167
step 0: mean loss = 3.6647385e-09
step 100: mean loss = 3.729036e-09
step 200: mean loss = 3.5423726e-09
step 300: mean loss = 4.7923043e-09
epoch 167: mean loss = 4.9312887e-09  learning rate = 1.046739e-05
============================
Start of epoch 168
step 0: mean loss = 1.5663229e-08
step 100: mean loss = 9.0286285e-09
step 200: mean loss = 6.527792e-09
step 300: mean loss = 6.1344605e-09
epoch 168: mean loss = 6.4447265e-09  learning rate = 1.046739e-05
============================
Start of epoch 169
step 0: mean loss = 2.0058913e-08
step 100: mean loss = 6.161805e-09
step 200: mean loss = 4.9757953e-09
step 300: mean loss = 4.405827e-09
epoch 169: mean loss = 4.4612425e-09  learning rate = 1.046739e-05
============================
Start of epoch 170
step 0: mean loss = 3.9574605e-08
step 100: mean loss = 5.7315708e-09
step 200: mean loss = 6.043418e-09
step 300: mean loss = 6.3130603e-09
epoch 170: mean loss = 6.1592593e-09  learning rate = 1.046739e-05
============================
Start of epoch 171
step 0: mean loss = 2.4959281e-09
step 100: mean loss = 3.67837e-09
step 200: mean loss = 4.4194604e-09
step 300: mean loss = 4.3115094e-09
epoch 171: mean loss = 4.272171e-09  learning rate = 1.046739e-05
============================
Start of epoch 172
step 0: mean loss = 3.364614e-09
step 100: mean loss = 7.4470865e-09
step 200: mean loss = 6.3798615e-09
step 300: mean loss = 5.9577347e-09
epoch 172: mean loss = 5.8569256e-09  learning rate = 1.046739e-05
============================
Start of epoch 173
step 0: mean loss = 2.6286853e-09
step 100: mean loss = 1.0362176e-08
step 200: mean loss = 7.304523e-09
step 300: mean loss = 6.0165823e-09
epoch 173: mean loss = 6.041519e-09  learning rate = 1.046739e-05
============================
Start of epoch 174
step 0: mean loss = 3.5389498e-09
step 100: mean loss = 6.6173844e-09
step 200: mean loss = 5.4715494e-09
step 300: mean loss = 5.4804463e-09
epoch 174: mean loss = 5.7494134e-09  learning rate = 1.046739e-05
============================
Start of epoch 175
step 0: mean loss = 4.817651e-08
step 100: mean loss = 5.2748037e-09
step 200: mean loss = 4.4244e-09
step 300: mean loss = 4.5165462e-09
epoch 175: mean loss = 4.4472857e-09  learning rate = 1.046739e-05
============================
Start of epoch 176
step 0: mean loss = 2.2522144e-09
step 100: mean loss = 4.28797e-09
step 200: mean loss = 4.9822932e-09
step 300: mean loss = 5.0948756e-09
epoch 176: mean loss = 5.0463123e-09  learning rate = 1.046739e-05
============================
Start of epoch 177
step 0: mean loss = 2.3748643e-09
step 100: mean loss = 6.6159234e-09
step 200: mean loss = 7.69005e-09
step 300: mean loss = 6.23413e-09
epoch 177: mean loss = 6.2836256e-09  learning rate = 1.046739e-05
============================
Start of epoch 178
step 0: mean loss = 1.0670853e-08
step 100: mean loss = 5.090068e-09
step 200: mean loss = 4.92429e-09
step 300: mean loss = 4.675539e-09
epoch 178: mean loss = 4.6175246e-09  learning rate = 1.046739e-05
============================
Start of epoch 179
step 0: mean loss = 6.7383903e-09
step 100: mean loss = 3.880222e-09
step 200: mean loss = 8.720437e-09
step 300: mean loss = 7.441796e-09
epoch 179: mean loss = 7.351824e-09  learning rate = 1.046739e-05
============================
Start of epoch 180
step 0: mean loss = 3.0833687e-09
step 100: mean loss = 3.6862087e-09
step 200: mean loss = 4.1301598e-09
step 300: mean loss = 3.8128505e-09
epoch 180: mean loss = 3.787555e-09  learning rate = 1.046739e-05
============================
Start of epoch 181
step 0: mean loss = 2.540779e-09
step 100: mean loss = 5.775902e-09
step 200: mean loss = 5.388002e-09
step 300: mean loss = 5.1012696e-09
epoch 181: mean loss = 5.029311e-09  learning rate = 1.046739e-05
============================
Start of epoch 182
step 0: mean loss = 7.31272e-09
step 100: mean loss = 1.2250901e-08
step 200: mean loss = 7.706253e-09
step 300: mean loss = 6.381294e-09
epoch 182: mean loss = 6.3145986e-09  learning rate = 1.046739e-05
============================
Start of epoch 183
step 0: mean loss = 3.853742e-09
step 100: mean loss = 7.4484463e-09
step 200: mean loss = 6.29015e-09
step 300: mean loss = 6.0410827e-09
epoch 183: mean loss = 5.942109e-09  learning rate = 1.046739e-05
============================
Start of epoch 184
step 0: mean loss = 2.67388e-09
step 100: mean loss = 3.7967767e-09
step 200: mean loss = 4.4630633e-09
step 300: mean loss = 7.4105952e-09
epoch 184: mean loss = 7.285168e-09  learning rate = 1.046739e-05
============================
Start of epoch 185
step 0: mean loss = 3.1808483e-09
step 100: mean loss = 3.9985455e-09
step 200: mean loss = 4.2515125e-09
step 300: mean loss = 3.8881045e-09
epoch 185: mean loss = 3.8388084e-09  learning rate = 1.046739e-05
============================
Start of epoch 186
step 0: mean loss = 2.4319724e-09
step 100: mean loss = 4.7621245e-09
step 200: mean loss = 4.28295e-09
step 300: mean loss = 4.8936513e-09
epoch 186: mean loss = 4.8080864e-09  learning rate = 1.046739e-05
============================
Start of epoch 187
step 0: mean loss = 2.8684841e-09
step 100: mean loss = 5.4765987e-09
step 200: mean loss = 5.745608e-09
step 300: mean loss = 5.086229e-09
epoch 187: mean loss = 5.118861e-09  learning rate = 1.046739e-05
============================
Start of epoch 188
step 0: mean loss = 3.6805161e-09
step 100: mean loss = 4.012852e-09
step 200: mean loss = 4.53962e-09
step 300: mean loss = 5.5591722e-09
epoch 188: mean loss = 5.4985176e-09  learning rate = 1.046739e-05
============================
Start of epoch 189
step 0: mean loss = 1.9677415e-08
step 100: mean loss = 1.2063033e-08
step 200: mean loss = 7.690777e-09
step 300: mean loss = 6.205795e-09
epoch 189: mean loss = 6.0662932e-09  learning rate = 1.046739e-05
============================
Start of epoch 190
step 0: mean loss = 2.527384e-09
step 100: mean loss = 3.2836356e-09
step 200: mean loss = 4.587404e-09
step 300: mean loss = 4.7648667e-09
epoch 190: mean loss = 4.6885513e-09  learning rate = 1.046739e-05
============================
Start of epoch 191
step 0: mean loss = 2.297983e-09
step 100: mean loss = 4.564151e-09
step 200: mean loss = 5.763993e-09
step 300: mean loss = 5.717886e-09
epoch 191: mean loss = 5.601992e-09  learning rate = 1.046739e-05
============================
Start of epoch 192
step 0: mean loss = 2.8492213e-09
step 100: mean loss = 3.578954e-09
step 200: mean loss = 3.5060563e-09
step 300: mean loss = 3.5271643e-09
epoch 192: mean loss = 3.5112082e-09  learning rate = 1.046739e-05
============================
Start of epoch 193
step 0: mean loss = 2.1575943e-09
step 100: mean loss = 1.3119205e-08
step 200: mean loss = 1.1575308e-08
step 300: mean loss = 8.908585e-09
epoch 193: mean loss = 8.724214e-09  learning rate = 1.046739e-05
============================
Start of epoch 194
step 0: mean loss = 3.1876362e-09
step 100: mean loss = 3.477109e-09
step 200: mean loss = 3.6927845e-09
step 300: mean loss = 3.949903e-09
epoch 194: mean loss = 3.9132546e-09  learning rate = 1.046739e-05
============================
Start of epoch 195
step 0: mean loss = 3.699644e-09
step 100: mean loss = 4.87102e-09
step 200: mean loss = 7.408888e-09
step 300: mean loss = 6.4042402e-09
epoch 195: mean loss = 6.390273e-09  learning rate = 1.046739e-05
============================
Start of epoch 196
step 0: mean loss = 4.6883026e-09
step 100: mean loss = 2.9059317e-09
step 200: mean loss = 3.0305694e-09
step 300: mean loss = 3.3969558e-09
epoch 196: mean loss = 3.5284287e-09  learning rate = 1.046739e-05
============================
Start of epoch 197
step 0: mean loss = 6.8064914e-09
step 100: mean loss = 9.439966e-09
step 200: mean loss = 6.253847e-09
step 300: mean loss = 6.303959e-09
epoch 197: mean loss = 6.38684e-09  learning rate = 1.046739e-05
============================
Start of epoch 198
step 0: mean loss = 6.5495023e-09
step 100: mean loss = 5.0995155e-09
step 200: mean loss = 4.65453e-09
step 300: mean loss = 4.9962163e-09
epoch 198: mean loss = 5.408825e-09  learning rate = 1.046739e-05
============================
Start of epoch 199
step 0: mean loss = 9.229007e-09
step 100: mean loss = 6.4560335e-09
step 200: mean loss = 5.45684e-09
step 300: mean loss = 4.7727102e-09
epoch 199: mean loss = 4.7164863e-09  learning rate = 9.94402e-06
============================
Start of epoch 200
step 0: mean loss = 3.6023038e-09
step 100: mean loss = 4.342975e-09
step 200: mean loss = 4.9310884e-09
step 300: mean loss = 4.978548e-09
epoch 200: mean loss = 5.1531512e-09  learning rate = 9.94402e-06
============================
Start of epoch 201
step 0: mean loss = 5.4350644e-09
step 100: mean loss = 5.7550955e-09
step 200: mean loss = 4.9676903e-09
step 300: mean loss = 5.6821405e-09
epoch 201: mean loss = 5.5661626e-09  learning rate = 9.94402e-06
============================
Start of epoch 202
step 0: mean loss = 7.2685267e-09
step 100: mean loss = 5.789637e-09
step 200: mean loss = 4.500092e-09
step 300: mean loss = 4.0702632e-09
epoch 202: mean loss = 4.035062e-09  learning rate = 9.94402e-06
============================
Start of epoch 203
step 0: mean loss = 2.5164977e-09
step 100: mean loss = 4.1228643e-09
step 200: mean loss = 4.1649315e-09
step 300: mean loss = 4.2711004e-09
epoch 203: mean loss = 4.299394e-09  learning rate = 9.94402e-06
============================
Start of epoch 204
step 0: mean loss = 2.7471607e-09
step 100: mean loss = 5.0123896e-09
step 200: mean loss = 4.9292357e-09
step 300: mean loss = 5.2358033e-09
epoch 204: mean loss = 5.5040412e-09  learning rate = 9.94402e-06
============================
Start of epoch 205
step 0: mean loss = 8.181948e-09
step 100: mean loss = 3.4762284e-09
step 200: mean loss = 5.5640093e-09
step 300: mean loss = 4.8511333e-09
epoch 205: mean loss = 4.890843e-09  learning rate = 9.94402e-06
============================
Start of epoch 206
step 0: mean loss = 6.1192638e-09
step 100: mean loss = 5.0851723e-09
step 200: mean loss = 4.422099e-09
step 300: mean loss = 4.8377866e-09
epoch 206: mean loss = 4.7863837e-09  learning rate = 9.94402e-06
============================
Start of epoch 207
step 0: mean loss = 2.4957596e-09
step 100: mean loss = 3.6707595e-09
step 200: mean loss = 4.8017395e-09
step 300: mean loss = 4.204399e-09
epoch 207: mean loss = 4.148868e-09  learning rate = 9.94402e-06
============================
Start of epoch 208
step 0: mean loss = 1.6071043e-09
step 100: mean loss = 1.9101874e-08
step 200: mean loss = 1.1528337e-08
step 300: mean loss = 8.9861105e-09
epoch 208: mean loss = 8.752496e-09  learning rate = 9.94402e-06
============================
Start of epoch 209
step 0: mean loss = 2.0701072e-09
step 100: mean loss = 3.0333847e-09
step 200: mean loss = 3.04075e-09
step 300: mean loss = 3.1990528e-09
epoch 209: mean loss = 3.1778646e-09  learning rate = 9.94402e-06
============================
Start of epoch 210
step 0: mean loss = 2.985653e-09
step 100: mean loss = 3.911991e-09
step 200: mean loss = 3.8916115e-09
step 300: mean loss = 4.237786e-09
epoch 210: mean loss = 4.3513966e-09  learning rate = 9.94402e-06
============================
Start of epoch 211
step 0: mean loss = 3.40741e-09
step 100: mean loss = 4.0804466e-09
step 200: mean loss = 8.291218e-09
step 300: mean loss = 6.7574963e-09
epoch 211: mean loss = 6.7106645e-09  learning rate = 9.94402e-06
============================
Start of epoch 212
step 0: mean loss = 3.5817056e-09
step 100: mean loss = 6.115287e-09
step 200: mean loss = 4.6142237e-09
step 300: mean loss = 4.304496e-09
epoch 212: mean loss = 4.2479447e-09  learning rate = 9.94402e-06
============================
Start of epoch 213
step 0: mean loss = 3.8617056e-09
step 100: mean loss = 2.9851057e-09
step 200: mean loss = 4.8284514e-09
step 300: mean loss = 5.0613527e-09
epoch 213: mean loss = 5.014872e-09  learning rate = 9.94402e-06
============================
Start of epoch 214
step 0: mean loss = 3.778861e-09
step 100: mean loss = 4.5354223e-09
step 200: mean loss = 5.0760014e-09
step 300: mean loss = 6.3970407e-09
epoch 214: mean loss = 6.281885e-09  learning rate = 9.94402e-06
============================
Start of epoch 215
step 0: mean loss = 2.569891e-09
step 100: mean loss = 5.695368e-09
step 200: mean loss = 4.9725566e-09
step 300: mean loss = 4.4613087e-09
epoch 215: mean loss = 4.4013446e-09  learning rate = 9.94402e-06
============================
Start of epoch 216
step 0: mean loss = 3.165523e-09
step 100: mean loss = 4.995444e-09
step 200: mean loss = 4.582918e-09
step 300: mean loss = 5.347055e-09
epoch 216: mean loss = 5.502506e-09  learning rate = 9.94402e-06
============================
Start of epoch 217
step 0: mean loss = 1.2462908e-08
step 100: mean loss = 4.0036774e-09
step 200: mean loss = 4.4939803e-09
step 300: mean loss = 5.342083e-09
epoch 217: mean loss = 5.419551e-09  learning rate = 9.94402e-06
============================
Start of epoch 218
step 0: mean loss = 9.921891e-09
step 100: mean loss = 3.2463774e-09
step 200: mean loss = 3.6739174e-09
step 300: mean loss = 5.235705e-09
epoch 218: mean loss = 5.3923825e-09  learning rate = 9.94402e-06
============================
Start of epoch 219
step 0: mean loss = 4.2050052e-09
step 100: mean loss = 4.310222e-09
step 200: mean loss = 4.3245976e-09
step 300: mean loss = 4.108214e-09
epoch 219: mean loss = 4.114545e-09  learning rate = 9.94402e-06
============================
Start of epoch 220
step 0: mean loss = 2.5886948e-09
step 100: mean loss = 3.9821746e-09
step 200: mean loss = 4.4550568e-09
step 300: mean loss = 5.2512967e-09
epoch 220: mean loss = 5.2088693e-09  learning rate = 9.94402e-06
============================
Start of epoch 221
step 0: mean loss = 8.863117e-09
step 100: mean loss = 9.0063486e-09
step 200: mean loss = 6.093344e-09
step 300: mean loss = 5.1046687e-09
epoch 221: mean loss = 5.031544e-09  learning rate = 9.94402e-06
============================
Start of epoch 222
step 0: mean loss = 3.1200158e-09
step 100: mean loss = 6.4574195e-09
step 200: mean loss = 5.6706706e-09
step 300: mean loss = 5.26028e-09
epoch 222: mean loss = 5.2709077e-09  learning rate = 9.94402e-06
============================
Start of epoch 223
step 0: mean loss = 1.2760094e-08
step 100: mean loss = 4.63807e-09
step 200: mean loss = 4.2574757e-09
step 300: mean loss = 3.9701864e-09
epoch 223: mean loss = 4.0572656e-09  learning rate = 9.94402e-06
============================
Start of epoch 224
step 0: mean loss = 4.2431743e-09
step 100: mean loss = 4.5861155e-09
step 200: mean loss = 5.1317115e-09
step 300: mean loss = 6.875437e-09
epoch 224: mean loss = 6.8180337e-09  learning rate = 9.94402e-06
============================
Start of epoch 225
step 0: mean loss = 3.5861034e-09
step 100: mean loss = 5.670825e-09
step 200: mean loss = 6.3914247e-09
step 300: mean loss = 5.496632e-09
epoch 225: mean loss = 5.3822453e-09  learning rate = 9.94402e-06
============================
Start of epoch 226
step 0: mean loss = 4.0065418e-09
step 100: mean loss = 4.2751496e-09
step 200: mean loss = 3.989384e-09
step 300: mean loss = 3.8407837e-09
epoch 226: mean loss = 3.8000447e-09  learning rate = 9.94402e-06
============================
Start of epoch 227
step 0: mean loss = 2.8868876e-09
step 100: mean loss = 8.603063e-09
step 200: mean loss = 8.1987706e-09
step 300: mean loss = 6.7329116e-09
epoch 227: mean loss = 6.5903194e-09  learning rate = 9.94402e-06
============================
Start of epoch 228
step 0: mean loss = 2.3309525e-09
step 100: mean loss = 4.519763e-09
step 200: mean loss = 5.436943e-09
step 300: mean loss = 5.1682014e-09
epoch 228: mean loss = 5.1170255e-09  learning rate = 9.94402e-06
============================
Start of epoch 229
step 0: mean loss = 5.824514e-09
step 100: mean loss = 3.516836e-09
step 200: mean loss = 3.147827e-09
step 300: mean loss = 3.6089542e-09
epoch 229: mean loss = 3.693066e-09  learning rate = 9.94402e-06
============================
Start of epoch 230
step 0: mean loss = 2.8186924e-09
step 100: mean loss = 5.2541154e-09
step 200: mean loss = 4.331095e-09
step 300: mean loss = 4.7494146e-09
epoch 230: mean loss = 4.6763513e-09  learning rate = 9.94402e-06
============================
Start of epoch 231
step 0: mean loss = 8.475679e-09
step 100: mean loss = 1.0472887e-08
step 200: mean loss = 6.839019e-09
step 300: mean loss = 5.661303e-09
epoch 231: mean loss = 5.6205094e-09  learning rate = 9.94402e-06
============================
Start of epoch 232
step 0: mean loss = 3.243794e-09
step 100: mean loss = 3.7819734e-09
step 200: mean loss = 3.5505898e-09
step 300: mean loss = 4.2006767e-09
epoch 232: mean loss = 4.232051e-09  learning rate = 9.94402e-06
============================
Start of epoch 233
step 0: mean loss = 3.3253453e-09
step 100: mean loss = 6.7200627e-09
step 200: mean loss = 7.251129e-09
step 300: mean loss = 6.638562e-09
epoch 233: mean loss = 6.5876997e-09  learning rate = 9.94402e-06
============================
Start of epoch 234
step 0: mean loss = 4.0060426e-09
step 100: mean loss = 3.7536165e-09
step 200: mean loss = 4.652741e-09
step 300: mean loss = 3.9815267e-09
epoch 234: mean loss = 3.914838e-09  learning rate = 9.94402e-06
============================
Start of epoch 235
step 0: mean loss = 4.250846e-09
step 100: mean loss = 5.4069194e-09
step 200: mean loss = 4.9740994e-09
step 300: mean loss = 5.371323e-09
epoch 235: mean loss = 5.281971e-09  learning rate = 9.94402e-06
============================
Start of epoch 236
step 0: mean loss = 2.0818103e-09
step 100: mean loss = 3.0541218e-09
step 200: mean loss = 2.9210672e-09
step 300: mean loss = 3.4611267e-09
epoch 236: mean loss = 3.4625052e-09  learning rate = 9.94402e-06
============================
Start of epoch 237
step 0: mean loss = 3.61648e-09
step 100: mean loss = 4.916008e-09
step 200: mean loss = 5.4090417e-09
step 300: mean loss = 4.6347393e-09
epoch 237: mean loss = 4.6082174e-09  learning rate = 9.94402e-06
============================
Start of epoch 238
step 0: mean loss = 3.286021e-09
step 100: mean loss = 4.9811124e-09
step 200: mean loss = 4.1745625e-09
step 300: mean loss = 4.1940185e-09
epoch 238: mean loss = 4.1737156e-09  learning rate = 9.94402e-06
============================
Start of epoch 239
step 0: mean loss = 6.084568e-09
step 100: mean loss = 5.649545e-09
step 200: mean loss = 6.035512e-09
step 300: mean loss = 5.2652567e-09
epoch 239: mean loss = 5.28616e-09  learning rate = 9.446818e-06
============================
Start of epoch 240
step 0: mean loss = 2.3649498e-09
step 100: mean loss = 4.4281965e-09
step 200: mean loss = 6.3399477e-09
step 300: mean loss = 5.6145977e-09
epoch 240: mean loss = 5.494785e-09  learning rate = 9.446818e-06
============================
Start of epoch 241
step 0: mean loss = 2.4159295e-09
step 100: mean loss = 3.4361438e-09
step 200: mean loss = 4.1528123e-09
step 300: mean loss = 4.200122e-09
epoch 241: mean loss = 4.1384642e-09  learning rate = 9.446818e-06
============================
Start of epoch 242
step 0: mean loss = 2.8618128e-09
step 100: mean loss = 6.788348e-09
step 200: mean loss = 5.4314597e-09
step 300: mean loss = 4.6669544e-09
epoch 242: mean loss = 4.6357407e-09  learning rate = 9.446818e-06
============================
Start of epoch 243
step 0: mean loss = 3.6406518e-09
step 100: mean loss = 3.4653138e-09
step 200: mean loss = 4.075299e-09
step 300: mean loss = 4.4834083e-09
epoch 243: mean loss = 4.562441e-09  learning rate = 9.446818e-06
============================
Start of epoch 244
step 0: mean loss = 4.58763e-09
step 100: mean loss = 5.049089e-09
step 200: mean loss = 6.143039e-09
step 300: mean loss = 5.1592712e-09
epoch 244: mean loss = 5.2430167e-09  learning rate = 9.446818e-06
============================
Start of epoch 245
step 0: mean loss = 8.662265e-09
step 100: mean loss = 3.7135888e-09
step 200: mean loss = 4.0010373e-09
step 300: mean loss = 4.3594115e-09
epoch 245: mean loss = 4.3971027e-09  learning rate = 9.446818e-06
============================
Start of epoch 246
step 0: mean loss = 1.49003085e-08
step 100: mean loss = 4.5049267e-09
step 200: mean loss = 4.9675664e-09
step 300: mean loss = 5.7169878e-09
epoch 246: mean loss = 5.7471587e-09  learning rate = 9.446818e-06
============================
Start of epoch 247
step 0: mean loss = 4.7542934e-09
step 100: mean loss = 3.387636e-09
step 200: mean loss = 3.339685e-09
step 300: mean loss = 3.7037675e-09
epoch 247: mean loss = 3.6769288e-09  learning rate = 9.446818e-06
============================
Start of epoch 248
step 0: mean loss = 2.4098141e-09
step 100: mean loss = 4.1442925e-09
step 200: mean loss = 4.8713926e-09
step 300: mean loss = 4.742906e-09
epoch 248: mean loss = 4.785752e-09  learning rate = 9.446818e-06
============================
Start of epoch 249
step 0: mean loss = 5.4632747e-09
step 100: mean loss = 4.407535e-09
step 200: mean loss = 3.97573e-09
step 300: mean loss = 3.830559e-09
epoch 249: mean loss = 3.8308605e-09  learning rate = 9.446818e-06
============================
Start of epoch 250
step 0: mean loss = 2.6815716e-09
step 100: mean loss = 4.2402655e-09
step 200: mean loss = 4.5450923e-09
step 300: mean loss = 4.7186433e-09
epoch 250: mean loss = 4.6262167e-09  learning rate = 9.446818e-06
============================
Start of epoch 251
step 0: mean loss = 2.687332e-09
step 100: mean loss = 2.986682e-09
step 200: mean loss = 3.1793084e-09
step 300: mean loss = 4.830539e-09
epoch 251: mean loss = 4.909992e-09  learning rate = 9.446818e-06
============================
Start of epoch 252
step 0: mean loss = 8.398049e-09
step 100: mean loss = 2.0368912e-08
step 200: mean loss = 1.2092398e-08
step 300: mean loss = 8.994146e-09
epoch 252: mean loss = 8.737671e-09  learning rate = 9.446818e-06
============================
Start of epoch 253
step 0: mean loss = 2.0072723e-09
step 100: mean loss = 3.0572116e-09
step 200: mean loss = 3.5929875e-09
step 300: mean loss = 3.2907381e-09
epoch 253: mean loss = 3.279278e-09  learning rate = 9.446818e-06
============================
Start of epoch 254
step 0: mean loss = 2.2854274e-09
step 100: mean loss = 4.375161e-09
step 200: mean loss = 4.0102863e-09
step 300: mean loss = 4.6491255e-09
epoch 254: mean loss = 4.6298534e-09  learning rate = 9.446818e-06
============================
Start of epoch 255
step 0: mean loss = 2.8853167e-09
step 100: mean loss = 4.6483417e-09
step 200: mean loss = 3.6843772e-09
step 300: mean loss = 3.728261e-09
epoch 255: mean loss = 3.671938e-09  learning rate = 9.446818e-06
============================
Start of epoch 256
step 0: mean loss = 2.471559e-09
step 100: mean loss = 8.027948e-09
step 200: mean loss = 6.4269625e-09
step 300: mean loss = 5.5676677e-09
epoch 256: mean loss = 5.5125744e-09  learning rate = 9.446818e-06
============================
Start of epoch 257
step 0: mean loss = 2.8447218e-09
step 100: mean loss = 2.900698e-09
step 200: mean loss = 4.362981e-09
step 300: mean loss = 4.647867e-09
epoch 257: mean loss = 4.5894675e-09  learning rate = 9.446818e-06
============================
Start of epoch 258
step 0: mean loss = 3.927744e-09
step 100: mean loss = 3.952385e-09
step 200: mean loss = 4.124575e-09
step 300: mean loss = 3.853707e-09
epoch 258: mean loss = 3.8456034e-09  learning rate = 9.446818e-06
============================
Start of epoch 259
step 0: mean loss = 4.695847e-09
step 100: mean loss = 3.6411085e-09
step 200: mean loss = 3.8248578e-09
step 300: mean loss = 4.057626e-09
epoch 259: mean loss = 4.0081343e-09  learning rate = 9.446818e-06
============================
Start of epoch 260
step 0: mean loss = 3.2813978e-09
step 100: mean loss = 3.6790482e-09
step 200: mean loss = 4.427614e-09
step 300: mean loss = 4.632981e-09
epoch 260: mean loss = 4.5763375e-09  learning rate = 9.446818e-06
============================
Start of epoch 261
step 0: mean loss = 2.628602e-09
step 100: mean loss = 3.818892e-09
step 200: mean loss = 4.231509e-09
step 300: mean loss = 5.347133e-09
epoch 261: mean loss = 5.262016e-09  learning rate = 9.446818e-06
============================
Start of epoch 262
step 0: mean loss = 7.3590316e-09
step 100: mean loss = 7.51812e-09
step 200: mean loss = 5.9954215e-09
step 300: mean loss = 5.125391e-09
epoch 262: mean loss = 5.2082103e-09  learning rate = 9.446818e-06
============================
Start of epoch 263
step 0: mean loss = 4.014539e-09
step 100: mean loss = 6.3547727e-09
step 200: mean loss = 6.068837e-09
step 300: mean loss = 5.0653686e-09
epoch 263: mean loss = 5.026963e-09  learning rate = 9.446818e-06
============================
Start of epoch 264
step 0: mean loss = 3.2313814e-09
step 100: mean loss = 2.8942317e-09
step 200: mean loss = 2.9476082e-09
step 300: mean loss = 5.281187e-09
epoch 264: mean loss = 6.272529e-09  learning rate = 9.446818e-06
============================
Start of epoch 265
step 0: mean loss = 4.7215458e-08
step 100: mean loss = 9.0145065e-09
step 200: mean loss = 6.6187376e-09
step 300: mean loss = 5.5980895e-09
epoch 265: mean loss = 5.514242e-09  learning rate = 9.446818e-06
============================
Start of epoch 266
step 0: mean loss = 4.080177e-09
step 100: mean loss = 3.276617e-09
step 200: mean loss = 3.2769838e-09
step 300: mean loss = 3.4464935e-09
epoch 266: mean loss = 3.6981014e-09  learning rate = 9.446818e-06
============================
Start of epoch 267
step 0: mean loss = 4.0908676e-09
step 100: mean loss = 4.0951043e-09
step 200: mean loss = 3.8204258e-09
step 300: mean loss = 4.2020822e-09
epoch 267: mean loss = 4.1401274e-09  learning rate = 9.446818e-06
============================
Start of epoch 268
step 0: mean loss = 3.1973393e-09
step 100: mean loss = 3.3653493e-09
step 200: mean loss = 4.1471115e-09
step 300: mean loss = 5.2602678e-09
epoch 268: mean loss = 5.1859512e-09  learning rate = 9.446818e-06
============================
Start of epoch 269
step 0: mean loss = 1.98166e-09
step 100: mean loss = 4.0972403e-09
step 200: mean loss = 3.85231e-09
step 300: mean loss = 4.31487e-09
epoch 269: mean loss = 4.4237494e-09  learning rate = 9.446818e-06
============================
Start of epoch 270
step 0: mean loss = 1.1077686e-08
step 100: mean loss = 4.0456656e-09
step 200: mean loss = 4.476569e-09
step 300: mean loss = 4.896534e-09
epoch 270: mean loss = 4.8414632e-09  learning rate = 9.446818e-06
============================
Start of epoch 271
step 0: mean loss = 2.6479825e-09
step 100: mean loss = 4.486643e-09
step 200: mean loss = 4.127579e-09
step 300: mean loss = 3.911585e-09
epoch 271: mean loss = 3.885502e-09  learning rate = 9.446818e-06
============================
Start of epoch 272
step 0: mean loss = 2.4058218e-09
step 100: mean loss = 4.7318394e-09
step 200: mean loss = 4.7140767e-09
step 300: mean loss = 4.0367403e-09
epoch 272: mean loss = 3.9827204e-09  learning rate = 9.446818e-06
============================
Start of epoch 273
step 0: mean loss = 1.4445105e-09
step 100: mean loss = 6.398341e-09
step 200: mean loss = 4.9673146e-09
step 300: mean loss = 4.503322e-09
epoch 273: mean loss = 4.4834367e-09  learning rate = 9.446818e-06
============================
Start of epoch 274
step 0: mean loss = 9.373117e-09
step 100: mean loss = 4.4877715e-09
step 200: mean loss = 5.3194387e-09
step 300: mean loss = 5.3814597e-09
epoch 274: mean loss = 6.0519523e-09  learning rate = 9.446818e-06
============================
Start of epoch 275
step 0: mean loss = 6.2567956e-08
step 100: mean loss = 1.0885287e-08
step 200: mean loss = 7.0194037e-09
step 300: mean loss = 5.6965876e-09
epoch 275: mean loss = 5.5693783e-09  learning rate = 9.446818e-06
============================
Start of epoch 276
step 0: mean loss = 1.7556117e-09
step 100: mean loss = 2.626525e-09
step 200: mean loss = 2.7427005e-09
step 300: mean loss = 3.5870578e-09
epoch 276: mean loss = 3.5510168e-09  learning rate = 9.446818e-06
============================
Start of epoch 277
step 0: mean loss = 2.0650628e-09
step 100: mean loss = 3.3888703e-09
step 200: mean loss = 7.052672e-09
step 300: mean loss = 5.6613465e-09
epoch 277: mean loss = 5.551776e-09  learning rate = 9.446818e-06
============================
Start of epoch 278
step 0: mean loss = 2.0595907e-09
step 100: mean loss = 7.070408e-09
step 200: mean loss = 5.880241e-09
step 300: mean loss = 5.3034754e-09
epoch 278: mean loss = 5.2174434e-09  learning rate = 9.446818e-06
============================
Start of epoch 279
step 0: mean loss = 3.4850065e-09
step 100: mean loss = 2.8651526e-09
step 200: mean loss = 3.698898e-09
step 300: mean loss = 3.972678e-09
epoch 279: mean loss = 3.9394354e-09  learning rate = 8.974477e-06
============================
Start of epoch 280
step 0: mean loss = 3.3539274e-09
step 100: mean loss = 5.0956332e-09
step 200: mean loss = 4.6081103e-09
step 300: mean loss = 4.1547468e-09
epoch 280: mean loss = 4.1267874e-09  learning rate = 8.974477e-06
============================
Start of epoch 281
step 0: mean loss = 2.3541509e-09
step 100: mean loss = 3.279787e-09
step 200: mean loss = 2.8386788e-09
step 300: mean loss = 3.0482827e-09
epoch 281: mean loss = 3.0902092e-09  learning rate = 8.974477e-06
============================
Start of epoch 282
step 0: mean loss = 2.6290075e-09
step 100: mean loss = 3.643525e-09
step 200: mean loss = 4.7727267e-09
step 300: mean loss = 4.9326587e-09
epoch 282: mean loss = 4.948921e-09  learning rate = 8.974477e-06
============================
Start of epoch 283
step 0: mean loss = 1.2675524e-08
step 100: mean loss = 4.5371884e-09
step 200: mean loss = 6.9795703e-09
step 300: mean loss = 5.9191763e-09
epoch 283: mean loss = 5.832716e-09  learning rate = 8.974477e-06
============================
Start of epoch 284
step 0: mean loss = 3.1991827e-09
step 100: mean loss = 3.595924e-09
step 200: mean loss = 3.3840708e-09
step 300: mean loss = 3.6944645e-09
epoch 284: mean loss = 3.8013384e-09  learning rate = 8.974477e-06
============================
Start of epoch 285
step 0: mean loss = 1.2821658e-08
step 100: mean loss = 4.9928635e-09
step 200: mean loss = 4.0522066e-09
step 300: mean loss = 3.7349364e-09
epoch 285: mean loss = 3.7202155e-09  learning rate = 8.974477e-06
============================
Start of epoch 286
step 0: mean loss = 2.3189946e-09
step 100: mean loss = 6.5540338e-09
step 200: mean loss = 5.7110445e-09
step 300: mean loss = 4.8701962e-09
epoch 286: mean loss = 4.905258e-09  learning rate = 8.974477e-06
============================
Start of epoch 287
step 0: mean loss = 4.3069392e-09
step 100: mean loss = 3.8291734e-09
step 200: mean loss = 3.6913632e-09
step 300: mean loss = 3.5707226e-09
epoch 287: mean loss = 3.6699201e-09  learning rate = 8.974477e-06
============================
Start of epoch 288
step 0: mean loss = 3.7796624e-09
step 100: mean loss = 4.2081596e-09
step 200: mean loss = 3.5576642e-09
step 300: mean loss = 4.2140034e-09
epoch 288: mean loss = 4.202123e-09  learning rate = 8.974477e-06
============================
Start of epoch 289
step 0: mean loss = 5.2158144e-09
step 100: mean loss = 4.206939e-09
step 200: mean loss = 4.0698565e-09
step 300: mean loss = 3.843339e-09
epoch 289: mean loss = 3.790855e-09  learning rate = 8.974477e-06
============================
Start of epoch 290
step 0: mean loss = 3.0880796e-09
step 100: mean loss = 4.930885e-09
step 200: mean loss = 4.7730055e-09
step 300: mean loss = 4.4704556e-09
epoch 290: mean loss = 4.634821e-09  learning rate = 8.974477e-06
============================
Start of epoch 291
step 0: mean loss = 7.3949322e-09
step 100: mean loss = 4.3108255e-09
step 200: mean loss = 4.2991872e-09
step 300: mean loss = 4.2409556e-09
epoch 291: mean loss = 4.2605723e-09  learning rate = 8.974477e-06
============================
Start of epoch 292
step 0: mean loss = 3.134253e-09
step 100: mean loss = 3.8637804e-09
step 200: mean loss = 4.0832453e-09
step 300: mean loss = 4.768802e-09
epoch 292: mean loss = 4.717465e-09  learning rate = 8.974477e-06
============================
Start of epoch 293
step 0: mean loss = 1.7452189e-09
step 100: mean loss = 3.7967527e-09
step 200: mean loss = 3.486521e-09
step 300: mean loss = 6.027737e-09
epoch 293: mean loss = 5.9288525e-09  learning rate = 8.974477e-06
============================
Start of epoch 294
step 0: mean loss = 3.6531265e-09
step 100: mean loss = 2.7482734e-09
step 200: mean loss = 4.6206523e-09
step 300: mean loss = 4.259938e-09
epoch 294: mean loss = 4.187998e-09  learning rate = 8.974477e-06
============================
Start of epoch 295
step 0: mean loss = 2.3645188e-09
step 100: mean loss = 2.7484288e-09
step 200: mean loss = 2.865895e-09
step 300: mean loss = 3.7445447e-09
epoch 295: mean loss = 4.161005e-09  learning rate = 8.974477e-06
============================
Start of epoch 296
step 0: mean loss = 2.6600737e-09
step 100: mean loss = 3.2702947e-09
step 200: mean loss = 3.9786787e-09
step 300: mean loss = 3.5793941e-09
epoch 296: mean loss = 3.5381762e-09  learning rate = 8.974477e-06
============================
Start of epoch 297
step 0: mean loss = 2.821077e-09
step 100: mean loss = 4.139136e-09
step 200: mean loss = 3.91478e-09
step 300: mean loss = 4.0613437e-09
epoch 297: mean loss = 4.0187786e-09  learning rate = 8.974477e-06
============================
Start of epoch 298
step 0: mean loss = 3.9708694e-09
step 100: mean loss = 5.86187e-09
step 200: mean loss = 4.6702486e-09
step 300: mean loss = 4.173345e-09
epoch 298: mean loss = 4.128459e-09  learning rate = 8.974477e-06
============================
Start of epoch 299
step 0: mean loss = 2.0604056e-09
step 100: mean loss = 4.497601e-09
step 200: mean loss = 5.461402e-09
step 300: mean loss = 4.9001883e-09
epoch 299: mean loss = 4.934217e-09  learning rate = 8.974477e-06
============================
Start of epoch 300
step 0: mean loss = 4.2917803e-09
step 100: mean loss = 3.9394306e-09
step 200: mean loss = 3.8203214e-09
step 300: mean loss = 4.107783e-09
epoch 300: mean loss = 4.0682684e-09  learning rate = 8.974477e-06
============================
Start of epoch 301
step 0: mean loss = 8.714656e-09
step 100: mean loss = 3.0763871e-09
step 200: mean loss = 4.166924e-09
step 300: mean loss = 4.1063375e-09
epoch 301: mean loss = 4.126507e-09  learning rate = 8.974477e-06
============================
Start of epoch 302
step 0: mean loss = 2.286594e-09
step 100: mean loss = 9.913899e-09
step 200: mean loss = 6.913545e-09
step 300: mean loss = 5.817045e-09
epoch 302: mean loss = 5.6857328e-09  learning rate = 8.974477e-06
============================
Start of epoch 303
step 0: mean loss = 2.5634068e-09
step 100: mean loss = 3.7627657e-09
step 200: mean loss = 4.071628e-09
step 300: mean loss = 4.5658766e-09
epoch 303: mean loss = 4.5157647e-09  learning rate = 8.974477e-06
============================
Start of epoch 304
step 0: mean loss = 2.3211637e-09
step 100: mean loss = 4.59829e-09
step 200: mean loss = 4.1855475e-09
step 300: mean loss = 4.054325e-09
epoch 304: mean loss = 4.0591366e-09  learning rate = 8.974477e-06
============================
Start of epoch 305
step 0: mean loss = 2.5503923e-09
step 100: mean loss = 3.561643e-09
step 200: mean loss = 4.3172563e-09
step 300: mean loss = 3.920993e-09
epoch 305: mean loss = 3.976398e-09  learning rate = 8.974477e-06
============================
Start of epoch 306
step 0: mean loss = 5.0605693e-09
step 100: mean loss = 5.6223928e-09
step 200: mean loss = 4.8900817e-09
step 300: mean loss = 4.2237804e-09
epoch 306: mean loss = 4.2050403e-09  learning rate = 8.974477e-06
============================
Start of epoch 307
step 0: mean loss = 3.0871217e-09
step 100: mean loss = 3.2735008e-09
step 200: mean loss = 4.7223128e-09
step 300: mean loss = 5.077207e-09
epoch 307: mean loss = 4.9771502e-09  learning rate = 8.974477e-06
============================
Start of epoch 308
step 0: mean loss = 2.2366005e-09
step 100: mean loss = 2.962078e-09
step 200: mean loss = 3.4858403e-09
step 300: mean loss = 3.6638987e-09
epoch 308: mean loss = 3.6354542e-09  learning rate = 8.974477e-06
============================
Start of epoch 309
step 0: mean loss = 2.512119e-09
step 100: mean loss = 5.008026e-09
step 200: mean loss = 4.8098863e-09
step 300: mean loss = 4.1030055e-09
epoch 309: mean loss = 4.0618846e-09  learning rate = 8.974477e-06
============================
Start of epoch 310
step 0: mean loss = 7.2736257e-09
step 100: mean loss = 4.2103685e-09
step 200: mean loss = 4.581132e-09
step 300: mean loss = 4.810516e-09
epoch 310: mean loss = 4.7201083e-09  learning rate = 8.974477e-06
============================
Start of epoch 311
step 0: mean loss = 2.045129e-09
step 100: mean loss = 5.536629e-09
step 200: mean loss = 4.677255e-09
step 300: mean loss = 3.9742885e-09
epoch 311: mean loss = 3.9339683e-09  learning rate = 8.974477e-06
============================
Start of epoch 312
step 0: mean loss = 2.0458877e-09
step 100: mean loss = 4.4724975e-09
step 200: mean loss = 4.4711514e-09
step 300: mean loss = 4.726196e-09
epoch 312: mean loss = 4.6751567e-09  learning rate = 8.974477e-06
============================
Start of epoch 313
step 0: mean loss = 6.2454943e-09
step 100: mean loss = 3.510959e-09
step 200: mean loss = 4.115162e-09
step 300: mean loss = 4.4697512e-09
epoch 313: mean loss = 4.3948587e-09  learning rate = 8.974477e-06
============================
Start of epoch 314
step 0: mean loss = 2.4332978e-09
step 100: mean loss = 2.9521012e-09
step 200: mean loss = 3.1098848e-09
step 300: mean loss = 3.9203885e-09
epoch 314: mean loss = 4.0853014e-09  learning rate = 8.974477e-06
============================
Start of epoch 315
step 0: mean loss = 2.404304e-09
step 100: mean loss = 8.327555e-09
step 200: mean loss = 5.5312506e-09
step 300: mean loss = 5.193856e-09
epoch 315: mean loss = 5.213454e-09  learning rate = 8.974477e-06
============================
Start of epoch 316
step 0: mean loss = 5.8612084e-09
step 100: mean loss = 5.396361e-09
step 200: mean loss = 4.7097983e-09
step 300: mean loss = 5.0264197e-09
epoch 316: mean loss = 4.96761e-09  learning rate = 8.974477e-06
============================
Start of epoch 317
step 0: mean loss = 8.672754e-09
step 100: mean loss = 3.851139e-09
step 200: mean loss = 3.5593786e-09
step 300: mean loss = 3.4465018e-09
epoch 317: mean loss = 3.4283894e-09  learning rate = 8.974477e-06
============================
Start of epoch 318
step 0: mean loss = 2.0661213e-09
step 100: mean loss = 3.643978e-09
step 200: mean loss = 3.579493e-09
step 300: mean loss = 3.483349e-09
epoch 318: mean loss = 3.7514996e-09  learning rate = 8.974477e-06
============================
Start of epoch 319
step 0: mean loss = 6.4744796e-09
step 100: mean loss = 3.544963e-09
step 200: mean loss = 4.2796775e-09
step 300: mean loss = 3.8988492e-09
epoch 319: mean loss = 3.843434e-09  learning rate = 8.525753e-06
============================
Start of epoch 320
step 0: mean loss = 2.1739992e-09
step 100: mean loss = 4.7694115e-09
step 200: mean loss = 3.953982e-09
step 300: mean loss = 4.214425e-09
epoch 320: mean loss = 4.1617545e-09  learning rate = 8.525753e-06
============================
Start of epoch 321
step 0: mean loss = 2.4170899e-09
step 100: mean loss = 3.6172343e-09
step 200: mean loss = 3.3208578e-09
step 300: mean loss = 4.08411e-09
epoch 321: mean loss = 4.824737e-09  learning rate = 8.525753e-06
============================
Start of epoch 322
step 0: mean loss = 1.7770764e-08
step 100: mean loss = 7.661378e-09
step 200: mean loss = 5.5108305e-09
step 300: mean loss = 5.200953e-09
epoch 322: mean loss = 5.0890288e-09  learning rate = 8.525753e-06
============================
Start of epoch 323
step 0: mean loss = 2.429394e-09
step 100: mean loss = 2.9901277e-09
step 200: mean loss = 3.0732537e-09
step 300: mean loss = 3.5038665e-09
epoch 323: mean loss = 3.4816423e-09  learning rate = 8.525753e-06
============================
Start of epoch 324
step 0: mean loss = 1.5193841e-09
step 100: mean loss = 3.5318692e-09
step 200: mean loss = 3.2790324e-09
step 300: mean loss = 3.197388e-09
epoch 324: mean loss = 3.2622791e-09  learning rate = 8.525753e-06
============================
Start of epoch 325
step 0: mean loss = 8.871821e-09
step 100: mean loss = 4.2658224e-09
step 200: mean loss = 4.1112145e-09
step 300: mean loss = 4.5781525e-09
epoch 325: mean loss = 4.5619544e-09  learning rate = 8.525753e-06
============================
Start of epoch 326
step 0: mean loss = 3.6393437e-09
step 100: mean loss = 4.0741046e-09
step 200: mean loss = 6.313075e-09
step 300: mean loss = 5.5232086e-09
epoch 326: mean loss = 5.4111817e-09  learning rate = 8.525753e-06
============================
Start of epoch 327
step 0: mean loss = 1.5604403e-09
step 100: mean loss = 3.675612e-09
step 200: mean loss = 3.7831045e-09
step 300: mean loss = 3.650217e-09
epoch 327: mean loss = 3.6896326e-09  learning rate = 8.525753e-06
============================
Start of epoch 328
step 0: mean loss = 1.9593582e-09
step 100: mean loss = 2.8941691e-09
step 200: mean loss = 3.0272087e-09
step 300: mean loss = 2.967082e-09
epoch 328: mean loss = 2.9770733e-09  learning rate = 8.525753e-06
============================
Start of epoch 329
step 0: mean loss = 4.3977977e-09
step 100: mean loss = 2.7225184e-09
step 200: mean loss = 7.4350877e-09
step 300: mean loss = 6.1687677e-09
epoch 329: mean loss = 6.0515246e-09  learning rate = 8.525753e-06
============================
Start of epoch 330
step 0: mean loss = 2.587584e-09
step 100: mean loss = 2.8843867e-09
step 200: mean loss = 2.9026286e-09
step 300: mean loss = 3.803513e-09
epoch 330: mean loss = 3.833025e-09  learning rate = 8.525753e-06
============================
Start of epoch 331
step 0: mean loss = 6.94603e-09
step 100: mean loss = 3.030808e-09
step 200: mean loss = 3.310692e-09
step 300: mean loss = 3.6452419e-09
epoch 331: mean loss = 3.631654e-09  learning rate = 8.525753e-06
============================
Start of epoch 332
step 0: mean loss = 6.772936e-09
step 100: mean loss = 5.7026392e-09
step 200: mean loss = 5.0364495e-09
step 300: mean loss = 4.4351824e-09
epoch 332: mean loss = 4.5089528e-09  learning rate = 8.525753e-06
============================
Start of epoch 333
step 0: mean loss = 6.691221e-09
step 100: mean loss = 4.3483483e-09
step 200: mean loss = 4.7955524e-09
step 300: mean loss = 4.2481143e-09
epoch 333: mean loss = 4.1849852e-09  learning rate = 8.525753e-06
============================
Start of epoch 334
step 0: mean loss = 2.291144e-09
step 100: mean loss = 3.367087e-09
step 200: mean loss = 3.6880592e-09
step 300: mean loss = 3.3748866e-09
epoch 334: mean loss = 3.3852439e-09  learning rate = 8.525753e-06
============================
Start of epoch 335
step 0: mean loss = 5.968073e-09
step 100: mean loss = 5.7553056e-09
step 200: mean loss = 4.655408e-09
step 300: mean loss = 4.369282e-09
epoch 335: mean loss = 4.396058e-09  learning rate = 8.525753e-06
============================
Start of epoch 336
step 0: mean loss = 3.3780485e-09
step 100: mean loss = 4.590014e-09
step 200: mean loss = 3.992721e-09
step 300: mean loss = 4.0707517e-09
epoch 336: mean loss = 4.0055363e-09  learning rate = 8.525753e-06
============================
Start of epoch 337
step 0: mean loss = 1.9940245e-09
step 100: mean loss = 4.4198845e-09
step 200: mean loss = 5.12553e-09
step 300: mean loss = 4.8823128e-09
epoch 337: mean loss = 4.8585074e-09  learning rate = 8.525753e-06
============================
Start of epoch 338
step 0: mean loss = 5.5191087e-09
step 100: mean loss = 3.723326e-09
step 200: mean loss = 4.8786473e-09
step 300: mean loss = 4.3063775e-09
epoch 338: mean loss = 4.221227e-09  learning rate = 8.525753e-06
============================
Start of epoch 339
step 0: mean loss = 3.2502776e-09
step 100: mean loss = 3.651733e-09
step 200: mean loss = 3.490811e-09
step 300: mean loss = 3.364338e-09
epoch 339: mean loss = 3.345578e-09  learning rate = 8.525753e-06
============================
Start of epoch 340
step 0: mean loss = 3.8582444e-09
step 100: mean loss = 3.8205745e-09
step 200: mean loss = 3.5032124e-09
step 300: mean loss = 5.007676e-09
epoch 340: mean loss = 4.9212394e-09  learning rate = 8.525753e-06
============================
Start of epoch 341
step 0: mean loss = 2.8503808e-09
step 100: mean loss = 4.2349413e-09
step 200: mean loss = 4.2281005e-09
step 300: mean loss = 3.7756775e-09
epoch 341: mean loss = 3.762369e-09  learning rate = 8.525753e-06
============================
Start of epoch 342
step 0: mean loss = 4.928904e-09
step 100: mean loss = 4.5448267e-09
step 200: mean loss = 4.424897e-09
step 300: mean loss = 3.923324e-09
epoch 342: mean loss = 3.9457e-09  learning rate = 8.525753e-06
============================
Start of epoch 343
step 0: mean loss = 1.971691e-09
step 100: mean loss = 5.804516e-09
step 200: mean loss = 5.1566635e-09
step 300: mean loss = 4.8186353e-09
epoch 343: mean loss = 4.7747375e-09  learning rate = 8.525753e-06
============================
Start of epoch 344
step 0: mean loss = 1.9469961e-09
step 100: mean loss = 2.9497513e-09
step 200: mean loss = 2.751762e-09
step 300: mean loss = 2.8092861e-09
epoch 344: mean loss = 2.8236464e-09  learning rate = 8.525753e-06
============================
Start of epoch 345
step 0: mean loss = 2.2394624e-09
step 100: mean loss = 6.8283015e-09
step 200: mean loss = 5.3525624e-09
step 300: mean loss = 4.4894573e-09
epoch 345: mean loss = 4.4645474e-09  learning rate = 8.525753e-06
============================
Start of epoch 346
step 0: mean loss = 1.8653001e-09
step 100: mean loss = 4.18717e-09
step 200: mean loss = 5.598613e-09
step 300: mean loss = 4.916089e-09
epoch 346: mean loss = 4.8233724e-09  learning rate = 8.525753e-06
============================
Start of epoch 347
step 0: mean loss = 2.6565812e-09
step 100: mean loss = 3.2575111e-09
step 200: mean loss = 3.0907883e-09
step 300: mean loss = 3.6857488e-09
epoch 347: mean loss = 3.7207912e-09  learning rate = 8.525753e-06
============================
Start of epoch 348
step 0: mean loss = 4.6138853e-09
step 100: mean loss = 4.2562074e-09
step 200: mean loss = 3.9428367e-09
step 300: mean loss = 3.801834e-09
epoch 348: mean loss = 3.7807406e-09  learning rate = 8.525753e-06
============================
Start of epoch 349
step 0: mean loss = 1.7571384e-09
step 100: mean loss = 4.4247312e-09
step 200: mean loss = 4.141996e-09
step 300: mean loss = 3.8616528e-09
epoch 349: mean loss = 3.896177e-09  learning rate = 8.525753e-06
============================
Start of epoch 350
step 0: mean loss = 2.2716886e-09
step 100: mean loss = 3.988937e-09
step 200: mean loss = 4.5910444e-09
step 300: mean loss = 4.2755057e-09
epoch 350: mean loss = 4.2240895e-09  learning rate = 8.525753e-06
============================
Start of epoch 351
step 0: mean loss = 1.8621252e-09
step 100: mean loss = 4.138955e-09
step 200: mean loss = 3.733419e-09
step 300: mean loss = 4.18392e-09
epoch 351: mean loss = 4.7975197e-09  learning rate = 8.525753e-06
============================
Start of epoch 352
step 0: mean loss = 6.138289e-09
step 100: mean loss = 5.0206914e-09
step 200: mean loss = 4.1611496e-09
step 300: mean loss = 3.9283514e-09
epoch 352: mean loss = 3.989084e-09  learning rate = 8.525753e-06
============================
Start of epoch 353
step 0: mean loss = 2.8662224e-09
step 100: mean loss = 3.0898475e-09
step 200: mean loss = 3.0838436e-09
step 300: mean loss = 4.843591e-09
epoch 353: mean loss = 4.8175623e-09  learning rate = 8.525753e-06
============================
Start of epoch 354
step 0: mean loss = 3.7559826e-09
step 100: mean loss = 3.6398107e-09
step 200: mean loss = 3.7024204e-09
step 300: mean loss = 3.5884582e-09
epoch 354: mean loss = 3.5329732e-09  learning rate = 8.525753e-06
============================
Start of epoch 355
step 0: mean loss = 2.2279e-09
step 100: mean loss = 2.9684508e-09
step 200: mean loss = 3.3175453e-09
step 300: mean loss = 3.711862e-09
epoch 355: mean loss = 3.6960912e-09  learning rate = 8.525753e-06
============================
Start of epoch 356
step 0: mean loss = 1.0504624e-08
step 100: mean loss = 5.157747e-09
step 200: mean loss = 4.1686197e-09
step 300: mean loss = 4.359987e-09
epoch 356: mean loss = 4.344537e-09  learning rate = 8.525753e-06
============================
Start of epoch 357
step 0: mean loss = 2.3993256e-09
step 100: mean loss = 3.0968073e-09
step 200: mean loss = 3.1830236e-09
step 300: mean loss = 3.5623522e-09
epoch 357: mean loss = 3.551483e-09  learning rate = 8.525753e-06
============================
Start of epoch 358
step 0: mean loss = 5.072826e-09
step 100: mean loss = 4.7934394e-09
step 200: mean loss = 5.636175e-09
step 300: mean loss = 5.445949e-09
epoch 358: mean loss = 5.4631575e-09  learning rate = 8.525753e-06
============================
Start of epoch 359
step 0: mean loss = 6.0788126e-09
step 100: mean loss = 2.6336422e-09
step 200: mean loss = 2.9746179e-09
step 300: mean loss = 2.8316922e-09
epoch 359: mean loss = 2.8506109e-09  learning rate = 8.099466e-06
============================
Start of epoch 360
step 0: mean loss = 6.549263e-09
step 100: mean loss = 6.5001418e-09
step 200: mean loss = 4.848651e-09
step 300: mean loss = 4.3563477e-09
epoch 360: mean loss = 4.3372874e-09  learning rate = 8.099466e-06
============================
Start of epoch 361
step 0: mean loss = 9.4016865e-09
step 100: mean loss = 4.5380744e-09
step 200: mean loss = 3.9590797e-09
step 300: mean loss = 3.922857e-09
epoch 361: mean loss = 3.8842782e-09  learning rate = 8.099466e-06
============================
Start of epoch 362
step 0: mean loss = 2.180182e-09
step 100: mean loss = 4.811894e-09
step 200: mean loss = 4.1366244e-09
step 300: mean loss = 3.5659764e-09
epoch 362: mean loss = 3.5324488e-09  learning rate = 8.099466e-06
============================
Start of epoch 363
step 0: mean loss = 1.914553e-09
step 100: mean loss = 4.2583874e-09
step 200: mean loss = 3.943632e-09
step 300: mean loss = 3.8786467e-09
epoch 363: mean loss = 3.9067816e-09  learning rate = 8.099466e-06
============================
Start of epoch 364
step 0: mean loss = 3.8256047e-09
step 100: mean loss = 4.568475e-09
step 200: mean loss = 3.7880254e-09
step 300: mean loss = 3.7351517e-09
epoch 364: mean loss = 3.842099e-09  learning rate = 8.099466e-06
============================
Start of epoch 365
step 0: mean loss = 4.1337895e-08
step 100: mean loss = 5.143268e-09
step 200: mean loss = 4.2103614e-09
step 300: mean loss = 3.9961217e-09
epoch 365: mean loss = 4.2656043e-09  learning rate = 8.099466e-06
============================
Start of epoch 366
step 0: mean loss = 2.7450917e-09
step 100: mean loss = 4.863836e-09
step 200: mean loss = 4.814635e-09
step 300: mean loss = 4.0863393e-09
epoch 366: mean loss = 4.0741104e-09  learning rate = 8.099466e-06
============================
Start of epoch 367
step 0: mean loss = 2.4446558e-09
step 100: mean loss = 3.4640566e-09
step 200: mean loss = 3.2729004e-09
step 300: mean loss = 3.4861987e-09
epoch 367: mean loss = 3.4690137e-09  learning rate = 8.099466e-06
============================
Start of epoch 368
step 0: mean loss = 2.6235116e-09
step 100: mean loss = 5.261096e-09
step 200: mean loss = 4.214266e-09
step 300: mean loss = 4.5981023e-09
epoch 368: mean loss = 4.540827e-09  learning rate = 8.099466e-06
============================
Start of epoch 369
step 0: mean loss = 2.5273819e-09
step 100: mean loss = 2.8826628e-09
step 200: mean loss = 2.8985638e-09
step 300: mean loss = 4.0627413e-09
epoch 369: mean loss = 3.9943284e-09  learning rate = 8.099466e-06
============================
Start of epoch 370
step 0: mean loss = 1.95791e-09
step 100: mean loss = 3.6006775e-09
step 200: mean loss = 3.6843053e-09
step 300: mean loss = 3.327076e-09
epoch 370: mean loss = 3.281884e-09  learning rate = 8.099466e-06
============================
Start of epoch 371
step 0: mean loss = 2.3019713e-09
step 100: mean loss = 2.9450824e-09
step 200: mean loss = 3.2495968e-09
step 300: mean loss = 3.42449e-09
epoch 371: mean loss = 3.5077155e-09  learning rate = 8.099466e-06
============================
Start of epoch 372
step 0: mean loss = 2.6073126e-09
step 100: mean loss = 4.111946e-09
step 200: mean loss = 4.9422146e-09
step 300: mean loss = 4.409244e-09
epoch 372: mean loss = 4.371276e-09  learning rate = 8.099466e-06
============================
Start of epoch 373
step 0: mean loss = 2.1623392e-09
step 100: mean loss = 3.4235188e-09
step 200: mean loss = 3.3111227e-09
step 300: mean loss = 3.1312555e-09
epoch 373: mean loss = 3.1268472e-09  learning rate = 8.099466e-06
============================
Start of epoch 374
step 0: mean loss = 2.152504e-09
step 100: mean loss = 3.0937588e-09
step 200: mean loss = 5.5754086e-09
step 300: mean loss = 5.0057687e-09
epoch 374: mean loss = 4.9125655e-09  learning rate = 8.099466e-06
============================
Start of epoch 375
step 0: mean loss = 4.496387e-09
step 100: mean loss = 3.7025278e-09
step 200: mean loss = 3.8445513e-09
step 300: mean loss = 3.7076215e-09
epoch 375: mean loss = 3.6678367e-09  learning rate = 8.099466e-06
============================
Start of epoch 376
step 0: mean loss = 7.5990325e-09
step 100: mean loss = 3.5192964e-09
step 200: mean loss = 3.1139618e-09
step 300: mean loss = 3.2879397e-09
epoch 376: mean loss = 3.2820733e-09  learning rate = 8.099466e-06
============================
Start of epoch 377
step 0: mean loss = 3.387775e-09
step 100: mean loss = 4.209511e-09
step 200: mean loss = 4.007586e-09
step 300: mean loss = 4.1034434e-09
epoch 377: mean loss = 4.1087853e-09  learning rate = 8.099466e-06
============================
Start of epoch 378
step 0: mean loss = 6.808243e-09
step 100: mean loss = 6.2358323e-09
step 200: mean loss = 5.2290474e-09
step 300: mean loss = 4.42488e-09
epoch 378: mean loss = 4.4763624e-09  learning rate = 8.099466e-06
============================
Start of epoch 379
step 0: mean loss = 5.294455e-09
step 100: mean loss = 4.5773434e-09
step 200: mean loss = 3.7137395e-09
step 300: mean loss = 3.5150354e-09
epoch 379: mean loss = 3.5062728e-09  learning rate = 8.099466e-06
============================
Start of epoch 380
step 0: mean loss = 3.0474587e-09
step 100: mean loss = 2.6925622e-09
step 200: mean loss = 3.4809413e-09
step 300: mean loss = 4.9980593e-09
epoch 380: mean loss = 4.9139617e-09  learning rate = 8.099466e-06
============================
Start of epoch 381
step 0: mean loss = 1.860925e-09
step 100: mean loss = 3.463406e-09
step 200: mean loss = 3.3572323e-09
step 300: mean loss = 3.2704013e-09
epoch 381: mean loss = 3.236973e-09  learning rate = 8.099466e-06
============================
Start of epoch 382
step 0: mean loss = 3.3758034e-09
step 100: mean loss = 2.9516074e-09
step 200: mean loss = 4.386431e-09
step 300: mean loss = 3.9526946e-09
epoch 382: mean loss = 4.001233e-09  learning rate = 8.099466e-06
============================
Start of epoch 383
step 0: mean loss = 5.193743e-09
step 100: mean loss = 2.8374958e-09
step 200: mean loss = 3.3419971e-09
step 300: mean loss = 3.2041363e-09
epoch 383: mean loss = 3.1696827e-09  learning rate = 8.099466e-06
============================
Start of epoch 384
step 0: mean loss = 1.95182e-09
step 100: mean loss = 2.917512e-09
step 200: mean loss = 4.9903175e-09
step 300: mean loss = 5.488903e-09
epoch 384: mean loss = 5.809608e-09  learning rate = 8.099466e-06
============================
Start of epoch 385
step 0: mean loss = 1.2630522e-08
step 100: mean loss = 4.0077386e-09
step 200: mean loss = 3.1599783e-09
step 300: mean loss = 3.0608025e-09
epoch 385: mean loss = 3.10811e-09  learning rate = 8.099466e-06
============================
Start of epoch 386
step 0: mean loss = 3.0004794e-09
step 100: mean loss = 3.0772083e-09
step 200: mean loss = 3.1217624e-09
step 300: mean loss = 3.259033e-09
epoch 386: mean loss = 3.2316496e-09  learning rate = 8.099466e-06
============================
Start of epoch 387
step 0: mean loss = 1.873349e-09
step 100: mean loss = 5.98174e-09
step 200: mean loss = 4.5712953e-09
step 300: mean loss = 3.972501e-09
epoch 387: mean loss = 3.902004e-09  learning rate = 8.099466e-06
============================
Start of epoch 388
step 0: mean loss = 2.0555935e-09
step 100: mean loss = 3.2142362e-09
step 200: mean loss = 2.9633993e-09
step 300: mean loss = 3.4040146e-09
epoch 388: mean loss = 3.4345233e-09  learning rate = 8.099466e-06
============================
Start of epoch 389
step 0: mean loss = 3.1610696e-09
step 100: mean loss = 3.2308645e-09
step 200: mean loss = 3.446217e-09
step 300: mean loss = 3.714066e-09
epoch 389: mean loss = 3.6873522e-09  learning rate = 8.099466e-06
============================
Start of epoch 390
step 0: mean loss = 2.3150715e-09
step 100: mean loss = 4.0254475e-09
step 200: mean loss = 3.5100407e-09
step 300: mean loss = 3.8455092e-09
epoch 390: mean loss = 3.788278e-09  learning rate = 8.099466e-06
============================
Start of epoch 391
step 0: mean loss = 2.24983e-09
step 100: mean loss = 2.747717e-09
step 200: mean loss = 6.737087e-09
step 300: mean loss = 5.6446776e-09
epoch 391: mean loss = 5.526714e-09  learning rate = 8.099466e-06
============================
Start of epoch 392
step 0: mean loss = 2.0041113e-09
step 100: mean loss = 2.2683424e-09
step 200: mean loss = 3.069832e-09
step 300: mean loss = 3.1991427e-09
epoch 392: mean loss = 3.178859e-09  learning rate = 8.099466e-06
============================
Start of epoch 393
step 0: mean loss = 2.1423834e-09
step 100: mean loss = 2.8505436e-09
step 200: mean loss = 3.2248781e-09
step 300: mean loss = 3.153815e-09
epoch 393: mean loss = 3.2920018e-09  learning rate = 8.099466e-06
============================
Start of epoch 394
step 0: mean loss = 2.6710905e-09
step 100: mean loss = 3.1683962e-09
step 200: mean loss = 3.649329e-09
step 300: mean loss = 3.5169057e-09
epoch 394: mean loss = 3.5884118e-09  learning rate = 8.099466e-06
============================
Start of epoch 395
step 0: mean loss = 3.4536118e-09
step 100: mean loss = 2.82548e-09
step 200: mean loss = 5.012174e-09
step 300: mean loss = 4.4864725e-09
epoch 395: mean loss = 4.405057e-09  learning rate = 8.099466e-06
============================
Start of epoch 396
step 0: mean loss = 2.2651665e-09
step 100: mean loss = 3.5114938e-09
step 200: mean loss = 3.2793381e-09
step 300: mean loss = 3.6725767e-09
epoch 396: mean loss = 3.7649426e-09  learning rate = 8.099466e-06
============================
Start of epoch 397
step 0: mean loss = 5.453761e-09
step 100: mean loss = 3.3561398e-09
step 200: mean loss = 3.923006e-09
step 300: mean loss = 3.8919077e-09
epoch 397: mean loss = 3.848523e-09  learning rate = 8.099466e-06
============================
Start of epoch 398
step 0: mean loss = 5.200513e-09
step 100: mean loss = 3.744634e-09
step 200: mean loss = 3.3676752e-09
step 300: mean loss = 3.0670209e-09
epoch 398: mean loss = 3.0662135e-09  learning rate = 8.099466e-06
============================
Start of epoch 399
step 0: mean loss = 6.5113497e-09
step 100: mean loss = 3.501707e-09
step 200: mean loss = 3.1444836e-09
step 300: mean loss = 4.2339394e-09
epoch 399: mean loss = 4.180215e-09  learning rate = 7.694493e-06
============================
Start of epoch 400
step 0: mean loss = 2.1993802e-09
step 100: mean loss = 3.5806293e-09
step 200: mean loss = 3.3028797e-09
step 300: mean loss = 3.1219745e-09
epoch 400: mean loss = 3.0824057e-09  learning rate = 7.694493e-06
============================
Start of epoch 401
step 0: mean loss = 1.6212136e-09
step 100: mean loss = 3.0906417e-09
step 200: mean loss = 3.2092957e-09
step 300: mean loss = 3.1667988e-09
epoch 401: mean loss = 3.3421053e-09  learning rate = 7.694493e-06
============================
Start of epoch 402
step 0: mean loss = 2.239597e-09
step 100: mean loss = 6.360964e-09
step 200: mean loss = 5.4636207e-09
step 300: mean loss = 4.6359006e-09
epoch 402: mean loss = 4.5472164e-09  learning rate = 7.694493e-06
============================
Start of epoch 403
step 0: mean loss = 2.9358158e-09
step 100: mean loss = 3.0148866e-09
step 200: mean loss = 3.0085452e-09
step 300: mean loss = 3.3174001e-09
epoch 403: mean loss = 3.363981e-09  learning rate = 7.694493e-06
============================
Start of epoch 404
step 0: mean loss = 6.881675e-09
step 100: mean loss = 3.2955692e-09
step 200: mean loss = 3.312632e-09
step 300: mean loss = 3.2393017e-09
epoch 404: mean loss = 3.2355238e-09  learning rate = 7.694493e-06
============================
Start of epoch 405
step 0: mean loss = 3.8953045e-09
step 100: mean loss = 4.424366e-09
step 200: mean loss = 4.4574087e-09
step 300: mean loss = 4.203819e-09
epoch 405: mean loss = 4.1435153e-09  learning rate = 7.694493e-06
============================
Start of epoch 406
step 0: mean loss = 1.9929973e-09
step 100: mean loss = 2.4825986e-09
step 200: mean loss = 5.057018e-09
step 300: mean loss = 4.153878e-09
epoch 406: mean loss = 4.0950945e-09  learning rate = 7.694493e-06
============================
Start of epoch 407
step 0: mean loss = 2.4829419e-09
step 100: mean loss = 2.9682128e-09
step 200: mean loss = 3.0258807e-09
step 300: mean loss = 2.8378255e-09
epoch 407: mean loss = 2.8866678e-09  learning rate = 7.694493e-06
============================
Start of epoch 408
step 0: mean loss = 3.108036e-09
step 100: mean loss = 3.5210004e-09
step 200: mean loss = 3.136265e-09
step 300: mean loss = 3.0855922e-09
epoch 408: mean loss = 3.105513e-09  learning rate = 7.694493e-06
============================
Start of epoch 409
step 0: mean loss = 9.904798e-09
step 100: mean loss = 3.7549848e-09
step 200: mean loss = 4.2666066e-09
step 300: mean loss = 3.9333616e-09
epoch 409: mean loss = 4.048346e-09  learning rate = 7.694493e-06
============================
Start of epoch 410
step 0: mean loss = 9.645293e-09
step 100: mean loss = 3.9146837e-09
step 200: mean loss = 4.337281e-09
step 300: mean loss = 3.9722905e-09
epoch 410: mean loss = 3.9412944e-09  learning rate = 7.694493e-06
============================
Start of epoch 411
step 0: mean loss = 2.0027475e-09
step 100: mean loss = 1.0220429e-08
step 200: mean loss = 7.221952e-09
step 300: mean loss = 5.893686e-09
epoch 411: mean loss = 5.9282588e-09  learning rate = 7.694493e-06
============================
Start of epoch 412
step 0: mean loss = 1.1434719e-08
step 100: mean loss = 4.5184194e-09
step 200: mean loss = 3.5912342e-09
step 300: mean loss = 3.4307057e-09
epoch 412: mean loss = 3.384641e-09  learning rate = 7.694493e-06
============================
Start of epoch 413
step 0: mean loss = 2.4523081e-09
step 100: mean loss = 3.2713532e-09
step 200: mean loss = 3.3011534e-09
step 300: mean loss = 3.2488154e-09
epoch 413: mean loss = 3.2311898e-09  learning rate = 7.694493e-06
============================
Start of epoch 414
step 0: mean loss = 2.239976e-09
step 100: mean loss = 3.491041e-09
step 200: mean loss = 3.0887968e-09
step 300: mean loss = 3.001841e-09
epoch 414: mean loss = 2.9946015e-09  learning rate = 7.694493e-06
============================
Start of epoch 415
step 0: mean loss = 2.1680684e-09
step 100: mean loss = 3.2929794e-09
step 200: mean loss = 5.0322937e-09
step 300: mean loss = 4.7133124e-09
epoch 415: mean loss = 4.608361e-09  learning rate = 7.694493e-06
============================
Start of epoch 416
step 0: mean loss = 2.1822935e-09
step 100: mean loss = 2.2839226e-09
step 200: mean loss = 2.8818277e-09
step 300: mean loss = 2.9365408e-09
epoch 416: mean loss = 2.9438447e-09  learning rate = 7.694493e-06
============================
Start of epoch 417
step 0: mean loss = 3.3499084e-09
step 100: mean loss = 3.9040042e-09
step 200: mean loss = 3.0973957e-09
step 300: mean loss = 4.340226e-09
epoch 417: mean loss = 4.3265453e-09  learning rate = 7.694493e-06
============================
Start of epoch 418
step 0: mean loss = 1.08840785e-08
step 100: mean loss = 3.077065e-09
step 200: mean loss = 3.6748662e-09
step 300: mean loss = 3.3632435e-09
epoch 418: mean loss = 3.3036531e-09  learning rate = 7.694493e-06
============================
Start of epoch 419
step 0: mean loss = 1.5256376e-09
step 100: mean loss = 2.8248526e-09
step 200: mean loss = 2.904921e-09
step 300: mean loss = 3.1523364e-09
epoch 419: mean loss = 3.129485e-09  learning rate = 7.694493e-06
============================
Start of epoch 420
step 0: mean loss = 4.4176005e-09
step 100: mean loss = 3.244704e-09
step 200: mean loss = 3.2804304e-09
step 300: mean loss = 3.7183732e-09
epoch 420: mean loss = 3.782575e-09  learning rate = 7.694493e-06
============================
Start of epoch 421
step 0: mean loss = 6.500123e-09
step 100: mean loss = 4.6927293e-09
step 200: mean loss = 4.0827035e-09
step 300: mean loss = 4.3897783e-09
epoch 421: mean loss = 4.6095874e-09  learning rate = 7.694493e-06
============================
Start of epoch 422
step 0: mean loss = 9.6791e-09
step 100: mean loss = 3.6826664e-09
step 200: mean loss = 3.8714765e-09
step 300: mean loss = 3.5980185e-09
epoch 422: mean loss = 3.6274082e-09  learning rate = 7.694493e-06
============================
Start of epoch 423
step 0: mean loss = 2.156495e-09
step 100: mean loss = 2.8639207e-09
step 200: mean loss = 2.7009825e-09
step 300: mean loss = 3.014775e-09
epoch 423: mean loss = 3.1217273e-09  learning rate = 7.694493e-06
============================
Start of epoch 424
step 0: mean loss = 5.533498e-09
step 100: mean loss = 3.8950807e-09
step 200: mean loss = 3.686778e-09
step 300: mean loss = 3.7113985e-09
epoch 424: mean loss = 3.7449173e-09  learning rate = 7.694493e-06
============================
Start of epoch 425
step 0: mean loss = 4.0888573e-09
step 100: mean loss = 6.96183e-09
step 200: mean loss = 4.8818016e-09
step 300: mean loss = 4.0953774e-09
epoch 425: mean loss = 4.035054e-09  learning rate = 7.694493e-06
============================
Start of epoch 426
step 0: mean loss = 2.0736661e-09
step 100: mean loss = 3.0252614e-09
step 200: mean loss = 2.72262e-09
step 300: mean loss = 3.675324e-09
epoch 426: mean loss = 3.6494285e-09  learning rate = 7.694493e-06
============================
Start of epoch 427
step 0: mean loss = 1.7352036e-09
step 100: mean loss = 2.448219e-09
step 200: mean loss = 3.3916039e-09
step 300: mean loss = 3.2671836e-09
epoch 427: mean loss = 3.3329708e-09  learning rate = 7.694493e-06
============================
Start of epoch 428
step 0: mean loss = 2.7913063e-09
step 100: mean loss = 2.9278173e-09
step 200: mean loss = 3.5362866e-09
step 300: mean loss = 4.1989088e-09
epoch 428: mean loss = 4.1381405e-09  learning rate = 7.694493e-06
============================
Start of epoch 429
step 0: mean loss = 2.4132585e-09
step 100: mean loss = 2.9106837e-09
step 200: mean loss = 3.479666e-09
step 300: mean loss = 3.3213134e-09
epoch 429: mean loss = 3.2864864e-09  learning rate = 7.694493e-06
============================
Start of epoch 430
step 0: mean loss = 3.4836318e-09
step 100: mean loss = 4.405635e-09
step 200: mean loss = 5.2511644e-09
step 300: mean loss = 4.3532014e-09
epoch 430: mean loss = 4.388074e-09  learning rate = 7.694493e-06
============================
Start of epoch 431
step 0: mean loss = 3.7085521e-09
step 100: mean loss = 6.1893024e-09
step 200: mean loss = 4.8670885e-09
step 300: mean loss = 3.9627728e-09
epoch 431: mean loss = 3.881078e-09  learning rate = 7.694493e-06
============================
Start of epoch 432
step 0: mean loss = 2.68994e-09
step 100: mean loss = 3.2148535e-09
step 200: mean loss = 2.9716891e-09
step 300: mean loss = 2.8083678e-09
epoch 432: mean loss = 2.8488725e-09  learning rate = 7.694493e-06
============================
Start of epoch 433
step 0: mean loss = 1.3134828e-08
step 100: mean loss = 3.740504e-09
step 200: mean loss = 3.1100185e-09
step 300: mean loss = 2.9912146e-09
epoch 433: mean loss = 2.978453e-09  learning rate = 7.694493e-06
============================
Start of epoch 434
step 0: mean loss = 2.6195661e-09
step 100: mean loss = 6.33957e-09
step 200: mean loss = 4.807287e-09
step 300: mean loss = 4.022901e-09
epoch 434: mean loss = 3.9727674e-09  learning rate = 7.694493e-06
============================
Start of epoch 435
step 0: mean loss = 1.9539215e-09
step 100: mean loss = 3.5532808e-09
step 200: mean loss = 3.3897964e-09
step 300: mean loss = 3.2220406e-09
epoch 435: mean loss = 3.255655e-09  learning rate = 7.694493e-06
============================
Start of epoch 436
step 0: mean loss = 1.0087671e-08
step 100: mean loss = 3.55784e-09
step 200: mean loss = 3.0889378e-09
step 300: mean loss = 3.155901e-09
epoch 436: mean loss = 3.125473e-09  learning rate = 7.694493e-06
============================
Start of epoch 437
step 0: mean loss = 2.2275546e-09
step 100: mean loss = 5.3872e-09
step 200: mean loss = 5.187682e-09
step 300: mean loss = 4.4031596e-09
epoch 437: mean loss = 4.3313584e-09  learning rate = 7.694493e-06
============================
Start of epoch 438
step 0: mean loss = 1.6745023e-09
step 100: mean loss = 2.3862186e-09
step 200: mean loss = 2.7341438e-09
step 300: mean loss = 3.0932634e-09
epoch 438: mean loss = 3.115254e-09  learning rate = 7.694493e-06
============================
Start of epoch 439
step 0: mean loss = 5.0088103e-09
step 100: mean loss = 3.8437316e-09
step 200: mean loss = 3.7336227e-09
step 300: mean loss = 3.6262993e-09
epoch 439: mean loss = 3.564775e-09  learning rate = 7.3097676e-06
============================
Start of epoch 440
step 0: mean loss = 1.3621847e-09
step 100: mean loss = 6.4528867e-09
step 200: mean loss = 4.3945705e-09
step 300: mean loss = 3.933576e-09
epoch 440: mean loss = 3.8883043e-09  learning rate = 7.3097676e-06
============================
Start of epoch 441
step 0: mean loss = 2.4536906e-09
step 100: mean loss = 2.6239615e-09
step 200: mean loss = 2.6564149e-09
step 300: mean loss = 2.799496e-09
epoch 441: mean loss = 2.8443514e-09  learning rate = 7.3097676e-06
============================
Start of epoch 442
step 0: mean loss = 1.619036e-08
step 100: mean loss = 4.5622124e-09
step 200: mean loss = 4.5072537e-09
step 300: mean loss = 4.2183403e-09
epoch 442: mean loss = 4.1364383e-09  learning rate = 7.3097676e-06
============================
Start of epoch 443
step 0: mean loss = 2.4272224e-09
step 100: mean loss = 2.714419e-09
step 200: mean loss = 2.796236e-09
step 300: mean loss = 2.9358407e-09
epoch 443: mean loss = 3.1509695e-09  learning rate = 7.3097676e-06
============================
Start of epoch 444
step 0: mean loss = 4.3721964e-09
step 100: mean loss = 8.240183e-09
step 200: mean loss = 5.6964997e-09
step 300: mean loss = 4.596201e-09
epoch 444: mean loss = 4.4941277e-09  learning rate = 7.3097676e-06
============================
Start of epoch 445
step 0: mean loss = 2.2404425e-09
step 100: mean loss = 2.5220475e-09
step 200: mean loss = 2.6536857e-09
step 300: mean loss = 2.5436233e-09
epoch 445: mean loss = 2.6602516e-09  learning rate = 7.3097676e-06
============================
Start of epoch 446
step 0: mean loss = 4.8530397e-09
step 100: mean loss = 4.389814e-09
step 200: mean loss = 4.4664863e-09
step 300: mean loss = 4.863488e-09
epoch 446: mean loss = 4.7842805e-09  learning rate = 7.3097676e-06
============================
Start of epoch 447
step 0: mean loss = 1.9607298e-09
step 100: mean loss = 2.7411844e-09
step 200: mean loss = 2.7295242e-09
step 300: mean loss = 2.704811e-09
epoch 447: mean loss = 2.6956466e-09  learning rate = 7.3097676e-06
============================
Start of epoch 448
step 0: mean loss = 3.0817155e-09
step 100: mean loss = 3.0615823e-09
step 200: mean loss = 5.148086e-09
step 300: mean loss = 4.698829e-09
epoch 448: mean loss = 4.6488804e-09  learning rate = 7.3097676e-06
============================
Start of epoch 449
step 0: mean loss = 2.708394e-09
step 100: mean loss = 2.4888682e-09
step 200: mean loss = 2.516789e-09
step 300: mean loss = 2.7335167e-09
epoch 449: mean loss = 2.7183493e-09  learning rate = 7.3097676e-06
============================
Start of epoch 450
step 0: mean loss = 1.4473729e-09
step 100: mean loss = 3.7873558e-09
step 200: mean loss = 3.4926795e-09
step 300: mean loss = 3.3271235e-09
epoch 450: mean loss = 3.2772898e-09  learning rate = 7.3097676e-06
============================
Start of epoch 451
step 0: mean loss = 1.9002533e-09
step 100: mean loss = 2.255558e-09
step 200: mean loss = 3.042379e-09
step 300: mean loss = 3.936193e-09
epoch 451: mean loss = 3.909601e-09  learning rate = 7.3097676e-06
============================
Start of epoch 452
step 0: mean loss = 5.128339e-09
step 100: mean loss = 5.740459e-09
step 200: mean loss = 4.1179407e-09
step 300: mean loss = 3.6162577e-09
epoch 452: mean loss = 3.5983232e-09  learning rate = 7.3097676e-06
============================
Start of epoch 453
step 0: mean loss = 2.2661466e-09
step 100: mean loss = 3.779828e-09
step 200: mean loss = 3.1114868e-09
step 300: mean loss = 3.586296e-09
epoch 453: mean loss = 3.7242889e-09  learning rate = 7.3097676e-06
============================
Start of epoch 454
step 0: mean loss = 1.0644417e-08
step 100: mean loss = 3.9913552e-09
step 200: mean loss = 3.3981165e-09
step 300: mean loss = 3.1780045e-09
epoch 454: mean loss = 3.134586e-09  learning rate = 7.3097676e-06
============================
Start of epoch 455
step 0: mean loss = 1.875869e-09
step 100: mean loss = 3.0490739e-09
step 200: mean loss = 3.1481122e-09
step 300: mean loss = 2.9733878e-09
epoch 455: mean loss = 2.9705487e-09  learning rate = 7.3097676e-06
============================
Start of epoch 456
step 0: mean loss = 1.7941699e-09
step 100: mean loss = 4.5750244e-09
step 200: mean loss = 5.2374056e-09
step 300: mean loss = 4.3702073e-09
epoch 456: mean loss = 4.3806305e-09  learning rate = 7.3097676e-06
============================
Start of epoch 457
step 0: mean loss = 7.384353e-09
step 100: mean loss = 3.891861e-09
step 200: mean loss = 3.808916e-09
step 300: mean loss = 3.3831544e-09
epoch 457: mean loss = 3.3313807e-09  learning rate = 7.3097676e-06
============================
Start of epoch 458
step 0: mean loss = 1.9238287e-09
step 100: mean loss = 4.0695873e-09
step 200: mean loss = 3.4568575e-09
step 300: mean loss = 3.0453315e-09
epoch 458: mean loss = 3.0103975e-09  learning rate = 7.3097676e-06
============================
Start of epoch 459
step 0: mean loss = 2.5826283e-09
step 100: mean loss = 3.926597e-09
step 200: mean loss = 3.4963505e-09
step 300: mean loss = 3.1757654e-09
epoch 459: mean loss = 3.141933e-09  learning rate = 7.3097676e-06
============================
Start of epoch 460
step 0: mean loss = 4.4702766e-09
step 100: mean loss = 4.162726e-09
step 200: mean loss = 3.854934e-09
step 300: mean loss = 3.7300567e-09
epoch 460: mean loss = 3.6794712e-09  learning rate = 7.3097676e-06
============================
Start of epoch 461
step 0: mean loss = 2.0798407e-09
step 100: mean loss = 3.8730037e-09
step 200: mean loss = 3.2714553e-09
step 300: mean loss = 3.1392309e-09
epoch 461: mean loss = 3.127797e-09  learning rate = 7.3097676e-06
============================
Start of epoch 462
step 0: mean loss = 5.874502e-09
step 100: mean loss = 5.2229203e-09
step 200: mean loss = 4.0922346e-09
step 300: mean loss = 3.5760859e-09
epoch 462: mean loss = 3.5217496e-09  learning rate = 7.3097676e-06
============================
Start of epoch 463
step 0: mean loss = 3.685048e-09
step 100: mean loss = 4.3801713e-09
step 200: mean loss = 3.6911405e-09
step 300: mean loss = 3.453797e-09
epoch 463: mean loss = 3.5417065e-09  learning rate = 7.3097676e-06
============================
Start of epoch 464
step 0: mean loss = 5.570636e-09
step 100: mean loss = 4.3213255e-09
step 200: mean loss = 4.0947676e-09
step 300: mean loss = 4.096472e-09
epoch 464: mean loss = 4.11382e-09  learning rate = 7.3097676e-06
============================
Start of epoch 465
step 0: mean loss = 4.614262e-09
step 100: mean loss = 3.2905232e-09
step 200: mean loss = 2.8850404e-09
step 300: mean loss = 3.1035032e-09
epoch 465: mean loss = 3.0833909e-09  learning rate = 7.3097676e-06
============================
Start of epoch 466
step 0: mean loss = 1.4705904e-09
step 100: mean loss = 2.4859972e-09
step 200: mean loss = 3.4498733e-09
step 300: mean loss = 3.3984433e-09
epoch 466: mean loss = 3.508138e-09  learning rate = 7.3097676e-06
============================
Start of epoch 467
step 0: mean loss = 1.7423327e-09
step 100: mean loss = 5.2131224e-09
step 200: mean loss = 4.080304e-09
step 300: mean loss = 3.652703e-09
epoch 467: mean loss = 3.6381897e-09  learning rate = 7.3097676e-06
============================
Start of epoch 468
step 0: mean loss = 2.8847977e-09
step 100: mean loss = 4.476991e-09
step 200: mean loss = 3.8050794e-09
step 300: mean loss = 4.0021493e-09
epoch 468: mean loss = 3.9500607e-09  learning rate = 7.3097676e-06
============================
Start of epoch 469
step 0: mean loss = 2.4548572e-09
step 100: mean loss = 3.7163501e-09
step 200: mean loss = 3.7228847e-09
step 300: mean loss = 3.2743475e-09
epoch 469: mean loss = 3.276402e-09  learning rate = 7.3097676e-06
============================
Start of epoch 470
step 0: mean loss = 5.096835e-09
step 100: mean loss = 3.1495209e-09
step 200: mean loss = 3.4761458e-09
step 300: mean loss = 3.1177882e-09
epoch 470: mean loss = 3.125903e-09  learning rate = 7.3097676e-06
============================
Start of epoch 471
step 0: mean loss = 1.8679351e-09
step 100: mean loss = 4.0148436e-09
step 200: mean loss = 3.5882988e-09
step 300: mean loss = 3.383552e-09
epoch 471: mean loss = 3.3834315e-09  learning rate = 7.3097676e-06
============================
Start of epoch 472
step 0: mean loss = 1.8099879e-09
step 100: mean loss = 2.697037e-09
step 200: mean loss = 2.7310205e-09
step 300: mean loss = 3.0354241e-09
epoch 472: mean loss = 3.081608e-09  learning rate = 7.3097676e-06
============================
Start of epoch 473
step 0: mean loss = 6.2090733e-09
step 100: mean loss = 3.9435903e-09
step 200: mean loss = 3.5447565e-09
step 300: mean loss = 3.164574e-09
epoch 473: mean loss = 3.236625e-09  learning rate = 7.3097676e-06
============================
Start of epoch 474
step 0: mean loss = 1.0559034e-08
step 100: mean loss = 4.0541384e-09
step 200: mean loss = 4.0881627e-09
step 300: mean loss = 3.7564534e-09
epoch 474: mean loss = 3.7069867e-09  learning rate = 7.3097676e-06
============================
Start of epoch 475
step 0: mean loss = 3.7291397e-09
step 100: mean loss = 2.5795273e-09
step 200: mean loss = 3.8539563e-09
step 300: mean loss = 3.4772667e-09
epoch 475: mean loss = 3.4758247e-09  learning rate = 7.3097676e-06
============================
Start of epoch 476
step 0: mean loss = 1.7870565e-09
step 100: mean loss = 2.9368545e-09
step 200: mean loss = 3.0889697e-09
step 300: mean loss = 3.6664123e-09
epoch 476: mean loss = 3.6280745e-09  learning rate = 7.3097676e-06
============================
Start of epoch 477
step 0: mean loss = 2.928982e-09
step 100: mean loss = 3.17697e-09
step 200: mean loss = 2.9836604e-09
step 300: mean loss = 3.2194956e-09
epoch 477: mean loss = 3.2731602e-09  learning rate = 7.3097676e-06
============================
Start of epoch 478
step 0: mean loss = 2.686182e-09
step 100: mean loss = 2.8371046e-09
step 200: mean loss = 2.957582e-09
step 300: mean loss = 2.906707e-09
epoch 478: mean loss = 2.879116e-09  learning rate = 7.3097676e-06
============================
Start of epoch 479
step 0: mean loss = 3.0359104e-09
step 100: mean loss = 4.259914e-09
step 200: mean loss = 3.8369476e-09
step 300: mean loss = 3.6726775e-09
epoch 479: mean loss = 3.6471253e-09  learning rate = 6.944279e-06
============================
Start of epoch 480
step 0: mean loss = 3.0678908e-09
step 100: mean loss = 2.655041e-09
step 200: mean loss = 3.0172425e-09
step 300: mean loss = 2.8119125e-09
epoch 480: mean loss = 2.783194e-09  learning rate = 6.944279e-06
============================
Start of epoch 481
step 0: mean loss = 2.4386182e-09
step 100: mean loss = 2.8971252e-09
step 200: mean loss = 3.0862466e-09
step 300: mean loss = 3.3513294e-09
epoch 481: mean loss = 3.3111531e-09  learning rate = 6.944279e-06
============================
Start of epoch 482
step 0: mean loss = 1.7367885e-09
step 100: mean loss = 3.364806e-09
step 200: mean loss = 3.238144e-09
step 300: mean loss = 3.102896e-09
epoch 482: mean loss = 3.1866587e-09  learning rate = 6.944279e-06
============================
Start of epoch 483
step 0: mean loss = 2.841856e-09
step 100: mean loss = 3.282998e-09
step 200: mean loss = 3.564286e-09
step 300: mean loss = 3.516167e-09
epoch 483: mean loss = 3.4647873e-09  learning rate = 6.944279e-06
============================
Start of epoch 484
step 0: mean loss = 2.190039e-09
step 100: mean loss = 3.1388618e-09
step 200: mean loss = 2.7546962e-09
step 300: mean loss = 2.7479627e-09
epoch 484: mean loss = 2.7491747e-09  learning rate = 6.944279e-06
============================
Start of epoch 485
step 0: mean loss = 5.30653e-09
step 100: mean loss = 3.0925442e-09
step 200: mean loss = 2.9774818e-09
step 300: mean loss = 2.803525e-09
epoch 485: mean loss = 2.7897875e-09  learning rate = 6.944279e-06
============================
Start of epoch 486
step 0: mean loss = 2.6388354e-09
step 100: mean loss = 3.3411078e-09
step 200: mean loss = 3.239574e-09
step 300: mean loss = 3.009628e-09
epoch 486: mean loss = 3.0360658e-09  learning rate = 6.944279e-06
============================
Start of epoch 487
step 0: mean loss = 2.5784062e-09
step 100: mean loss = 4.5676387e-09
step 200: mean loss = 4.200607e-09
step 300: mean loss = 3.6435732e-09
epoch 487: mean loss = 3.639126e-09  learning rate = 6.944279e-06
============================
Start of epoch 488
step 0: mean loss = 3.3375713e-09
step 100: mean loss = 5.090715e-09
step 200: mean loss = 4.0239914e-09
step 300: mean loss = 4.1325356e-09
epoch 488: mean loss = 4.0593995e-09  learning rate = 6.944279e-06
============================
Start of epoch 489
step 0: mean loss = 2.2902815e-09
step 100: mean loss = 2.5099955e-09
step 200: mean loss = 3.3135856e-09
step 300: mean loss = 3.3149632e-09
epoch 489: mean loss = 3.2650764e-09  learning rate = 6.944279e-06
============================
Start of epoch 490
step 0: mean loss = 2.8453613e-09
step 100: mean loss = 2.5816653e-09
step 200: mean loss = 2.7503129e-09
step 300: mean loss = 2.709258e-09
epoch 490: mean loss = 2.6862743e-09  learning rate = 6.944279e-06
============================
Start of epoch 491
step 0: mean loss = 1.8811928e-09
step 100: mean loss = 2.719726e-09
step 200: mean loss = 2.8927798e-09
step 300: mean loss = 3.1239014e-09
epoch 491: mean loss = 3.1034506e-09  learning rate = 6.944279e-06
============================
Start of epoch 492
step 0: mean loss = 1.785444e-09
step 100: mean loss = 4.6215307e-09
step 200: mean loss = 3.8282404e-09
step 300: mean loss = 3.3678773e-09
epoch 492: mean loss = 3.326962e-09  learning rate = 6.944279e-06
============================
Start of epoch 493
step 0: mean loss = 2.761126e-09
step 100: mean loss = 2.3992588e-09
step 200: mean loss = 2.652002e-09
step 300: mean loss = 2.6926745e-09
epoch 493: mean loss = 2.6986497e-09  learning rate = 6.944279e-06
============================
Start of epoch 494
step 0: mean loss = 2.5986495e-09
step 100: mean loss = 4.467121e-09
step 200: mean loss = 3.9307633e-09
step 300: mean loss = 3.8336427e-09
epoch 494: mean loss = 3.9279104e-09  learning rate = 6.944279e-06
============================
Start of epoch 495
step 0: mean loss = 6.203078e-09
step 100: mean loss = 2.8182843e-09
step 200: mean loss = 2.8026752e-09
step 300: mean loss = 2.7804017e-09
epoch 495: mean loss = 2.7594165e-09  learning rate = 6.944279e-06
============================
Start of epoch 496
step 0: mean loss = 1.5243964e-09
step 100: mean loss = 6.721298e-09
step 200: mean loss = 4.903425e-09
step 300: mean loss = 4.174505e-09
epoch 496: mean loss = 4.0995247e-09  learning rate = 6.944279e-06
============================
Start of epoch 497
step 0: mean loss = 1.6289743e-09
step 100: mean loss = 2.369161e-09
step 200: mean loss = 2.5611062e-09
step 300: mean loss = 2.7321545e-09
epoch 497: mean loss = 2.788303e-09  learning rate = 6.944279e-06
============================
Start of epoch 498
step 0: mean loss = 8.011197e-09
step 100: mean loss = 2.8137286e-09
step 200: mean loss = 3.2412915e-09
step 300: mean loss = 2.970264e-09
epoch 498: mean loss = 3.2095127e-09  learning rate = 6.944279e-06
============================
Start of epoch 499
step 0: mean loss = 3.3187875e-09
step 100: mean loss = 4.315917e-09
step 200: mean loss = 3.6341943e-09
step 300: mean loss = 3.2519243e-09
epoch 499: mean loss = 3.2325378e-09  learning rate = 6.944279e-06
============================
Start of epoch 500
step 0: mean loss = 2.2199582e-09
step 100: mean loss = 5.091553e-09
step 200: mean loss = 4.3454134e-09
step 300: mean loss = 3.799287e-09
epoch 500: mean loss = 3.764674e-09  learning rate = 6.944279e-06
============================
Start of epoch 501
step 0: mean loss = 3.5479648e-09
step 100: mean loss = 3.3050065e-09
step 200: mean loss = 2.8006852e-09
step 300: mean loss = 2.7210125e-09
epoch 501: mean loss = 2.746273e-09  learning rate = 6.944279e-06
============================
Start of epoch 502
step 0: mean loss = 3.2320089e-09
step 100: mean loss = 3.6865495e-09
step 200: mean loss = 3.5376948e-09
step 300: mean loss = 4.234891e-09
epoch 502: mean loss = 4.163059e-09  learning rate = 6.944279e-06
============================
Start of epoch 503
step 0: mean loss = 6.0564105e-09
step 100: mean loss = 2.9671245e-09
step 200: mean loss = 2.6689546e-09
step 300: mean loss = 2.6673077e-09
epoch 503: mean loss = 2.6605105e-09  learning rate = 6.944279e-06
============================
Start of epoch 504
step 0: mean loss = 2.105509e-09
step 100: mean loss = 2.2068791e-09
step 200: mean loss = 2.4734867e-09
step 300: mean loss = 2.5853149e-09
epoch 504: mean loss = 2.648265e-09  learning rate = 6.944279e-06
============================
Start of epoch 505
step 0: mean loss = 1.3454344e-08
step 100: mean loss = 3.2048666e-09
step 200: mean loss = 6.8329515e-09
step 300: mean loss = 5.3397207e-09
epoch 505: mean loss = 5.235694e-09  learning rate = 6.944279e-06
============================
Start of epoch 506
step 0: mean loss = 1.85846e-09
step 100: mean loss = 2.2262434e-09
step 200: mean loss = 2.214747e-09
step 300: mean loss = 2.3997577e-09
epoch 506: mean loss = 2.3851368e-09  learning rate = 6.944279e-06
============================
Start of epoch 507
step 0: mean loss = 2.408574e-09
step 100: mean loss = 2.3898057e-09
step 200: mean loss = 2.4198628e-09
step 300: mean loss = 3.951209e-09
epoch 507: mean loss = 3.992244e-09  learning rate = 6.944279e-06
============================
Start of epoch 508
step 0: mean loss = 3.1678489e-09
step 100: mean loss = 2.912155e-09
step 200: mean loss = 2.8314862e-09
step 300: mean loss = 2.8316258e-09
epoch 508: mean loss = 2.8356086e-09  learning rate = 6.944279e-06
============================
Start of epoch 509
step 0: mean loss = 1.9704305e-09
step 100: mean loss = 2.6929117e-09
step 200: mean loss = 2.5537807e-09
step 300: mean loss = 2.5506417e-09
epoch 509: mean loss = 2.5545217e-09  learning rate = 6.944279e-06
============================
Start of epoch 510
step 0: mean loss = 1.6759355e-09
step 100: mean loss = 3.444725e-09
step 200: mean loss = 3.2831897e-09
step 300: mean loss = 3.179476e-09
epoch 510: mean loss = 3.1688778e-09  learning rate = 6.944279e-06
============================
Start of epoch 511
step 0: mean loss = 3.5156649e-09
step 100: mean loss = 2.9644756e-09
step 200: mean loss = 2.9128657e-09
step 300: mean loss = 2.707382e-09
epoch 511: mean loss = 2.700419e-09  learning rate = 6.944279e-06
============================
Start of epoch 512
step 0: mean loss = 2.7349967e-09
step 100: mean loss = 5.822295e-09
step 200: mean loss = 4.2218047e-09
step 300: mean loss = 3.6878345e-09
epoch 512: mean loss = 3.6415733e-09  learning rate = 6.944279e-06
============================
Start of epoch 513
step 0: mean loss = 1.4932215e-09
step 100: mean loss = 2.6642755e-09
step 200: mean loss = 3.4411598e-09
step 300: mean loss = 3.5232768e-09
epoch 513: mean loss = 3.4705148e-09  learning rate = 6.944279e-06
============================
Start of epoch 514
step 0: mean loss = 1.8611436e-09
step 100: mean loss = 5.4501013e-09
step 200: mean loss = 4.0182035e-09
step 300: mean loss = 3.6196544e-09
epoch 514: mean loss = 3.6044698e-09  learning rate = 6.944279e-06
============================
Start of epoch 515
step 0: mean loss = 3.1568674e-09
step 100: mean loss = 2.3920503e-09
step 200: mean loss = 2.6824059e-09
step 300: mean loss = 3.1162997e-09
epoch 515: mean loss = 3.23183e-09  learning rate = 6.944279e-06
============================
Start of epoch 516
step 0: mean loss = 3.7057575e-09
step 100: mean loss = 2.553364e-09
step 200: mean loss = 2.553278e-09
step 300: mean loss = 3.1252265e-09
epoch 516: mean loss = 3.1881726e-09  learning rate = 6.944279e-06
============================
Start of epoch 517
step 0: mean loss = 8.234732e-09
step 100: mean loss = 2.649499e-09
step 200: mean loss = 2.9180045e-09
step 300: mean loss = 2.948498e-09
epoch 517: mean loss = 2.9427165e-09  learning rate = 6.944279e-06
============================
Start of epoch 518
step 0: mean loss = 1.8883886e-09
step 100: mean loss = 3.0103082e-09
step 200: mean loss = 2.8178637e-09
step 300: mean loss = 2.9264025e-09
epoch 518: mean loss = 3.0286773e-09  learning rate = 6.944279e-06
============================
Start of epoch 519
step 0: mean loss = 8.784246e-09
step 100: mean loss = 3.607045e-09
step 200: mean loss = 3.0168033e-09
step 300: mean loss = 2.8065397e-09
epoch 519: mean loss = 2.8329514e-09  learning rate = 6.597065e-06
============================
Start of epoch 520
step 0: mean loss = 2.9884557e-09
step 100: mean loss = 3.4392176e-09
step 200: mean loss = 3.3506045e-09
step 300: mean loss = 3.0524645e-09
epoch 520: mean loss = 3.0135958e-09  learning rate = 6.597065e-06
============================
Start of epoch 521
step 0: mean loss = 2.338113e-09
step 100: mean loss = 3.7128722e-09
step 200: mean loss = 3.1954879e-09
step 300: mean loss = 2.9610097e-09
epoch 521: mean loss = 2.927331e-09  learning rate = 6.597065e-06
============================
Start of epoch 522
step 0: mean loss = 3.5402437e-09
step 100: mean loss = 3.7602854e-09
step 200: mean loss = 3.4199161e-09
step 300: mean loss = 3.5449486e-09
epoch 522: mean loss = 3.519832e-09  learning rate = 6.597065e-06
============================
Start of epoch 523
step 0: mean loss = 4.51808e-09
step 100: mean loss = 3.4682879e-09
step 200: mean loss = 3.5217222e-09
step 300: mean loss = 3.4881282e-09
epoch 523: mean loss = 3.4346883e-09  learning rate = 6.597065e-06
============================
Start of epoch 524
step 0: mean loss = 4.773888e-09
step 100: mean loss = 2.792047e-09
step 200: mean loss = 2.9728418e-09
step 300: mean loss = 3.3813983e-09
epoch 524: mean loss = 3.3465222e-09  learning rate = 6.597065e-06
============================
Start of epoch 525
step 0: mean loss = 1.947297e-09
step 100: mean loss = 2.1435698e-09
step 200: mean loss = 2.8242646e-09
step 300: mean loss = 2.6300615e-09
epoch 525: mean loss = 2.6180418e-09  learning rate = 6.597065e-06
============================
Start of epoch 526
step 0: mean loss = 6.3638153e-09
step 100: mean loss = 6.184006e-09
step 200: mean loss = 4.268415e-09
step 300: mean loss = 3.6762893e-09
epoch 526: mean loss = 3.6066554e-09  learning rate = 6.597065e-06
============================
Start of epoch 527
step 0: mean loss = 2.8152969e-09
step 100: mean loss = 3.0707958e-09
step 200: mean loss = 3.0503595e-09
step 300: mean loss = 2.9117249e-09
epoch 527: mean loss = 3.0827643e-09  learning rate = 6.597065e-06
============================
Start of epoch 528
step 0: mean loss = 1.4012278e-08
step 100: mean loss = 2.9941187e-09
step 200: mean loss = 2.6299214e-09
step 300: mean loss = 2.6295681e-09
epoch 528: mean loss = 2.6297355e-09  learning rate = 6.597065e-06
============================
Start of epoch 529
step 0: mean loss = 1.7655502e-09
step 100: mean loss = 2.4094369e-09
step 200: mean loss = 3.2233824e-09
step 300: mean loss = 4.6815467e-09
epoch 529: mean loss = 4.700333e-09  learning rate = 6.597065e-06
============================
Start of epoch 530
step 0: mean loss = 3.528698e-09
step 100: mean loss = 2.704213e-09
step 200: mean loss = 2.837149e-09
step 300: mean loss = 2.6158946e-09
epoch 530: mean loss = 2.633189e-09  learning rate = 6.597065e-06
============================
Start of epoch 531
step 0: mean loss = 1.9557869e-09
step 100: mean loss = 2.479887e-09
step 200: mean loss = 2.69608e-09
step 300: mean loss = 2.736044e-09
epoch 531: mean loss = 2.7068414e-09  learning rate = 6.597065e-06
============================
Start of epoch 532
step 0: mean loss = 3.2723417e-09
step 100: mean loss = 2.3234787e-09
step 200: mean loss = 2.7952267e-09
step 300: mean loss = 3.3822907e-09
epoch 532: mean loss = 3.4046441e-09  learning rate = 6.597065e-06
============================
Start of epoch 533
step 0: mean loss = 2.9861909e-09
step 100: mean loss = 2.6959328e-09
step 200: mean loss = 3.002462e-09
step 300: mean loss = 2.8054727e-09
epoch 533: mean loss = 2.8169964e-09  learning rate = 6.597065e-06
============================
Start of epoch 534
step 0: mean loss = 1.959305e-09
step 100: mean loss = 2.5283153e-09
step 200: mean loss = 2.8589087e-09
step 300: mean loss = 2.6918014e-09
epoch 534: mean loss = 2.7890634e-09  learning rate = 6.597065e-06
============================
Start of epoch 535
step 0: mean loss = 3.627574e-09
step 100: mean loss = 2.5065698e-09
step 200: mean loss = 2.4875948e-09
step 300: mean loss = 2.6304812e-09
epoch 535: mean loss = 2.7691527e-09  learning rate = 6.597065e-06
============================
Start of epoch 536
step 0: mean loss = 1.6855534e-09
step 100: mean loss = 3.041761e-09
step 200: mean loss = 2.8320346e-09
step 300: mean loss = 2.767739e-09
epoch 536: mean loss = 2.8729752e-09  learning rate = 6.597065e-06
============================
Start of epoch 537
step 0: mean loss = 4.0866093e-09
step 100: mean loss = 4.2484483e-09
step 200: mean loss = 5.3534084e-09
step 300: mean loss = 4.692933e-09
epoch 537: mean loss = 4.692492e-09  learning rate = 6.597065e-06
============================
Start of epoch 538
step 0: mean loss = 1.4402124e-09
step 100: mean loss = 2.7152163e-09
step 200: mean loss = 2.7749745e-09
step 300: mean loss = 2.6357303e-09
epoch 538: mean loss = 2.604599e-09  learning rate = 6.597065e-06
============================
Start of epoch 539
step 0: mean loss = 1.725201e-09
step 100: mean loss = 2.727587e-09
step 200: mean loss = 2.8251623e-09
step 300: mean loss = 2.9566354e-09
epoch 539: mean loss = 3.1027856e-09  learning rate = 6.597065e-06
============================
Start of epoch 540
step 0: mean loss = 2.3234965e-09
step 100: mean loss = 3.3106482e-09
step 200: mean loss = 2.91022e-09
step 300: mean loss = 3.004814e-09
epoch 540: mean loss = 2.9721094e-09  learning rate = 6.597065e-06
============================
Start of epoch 541
step 0: mean loss = 2.6712932e-09
step 100: mean loss = 3.6121448e-09
step 200: mean loss = 3.1526692e-09
step 300: mean loss = 2.8800495e-09
epoch 541: mean loss = 2.900827e-09  learning rate = 6.597065e-06
============================
Start of epoch 542
step 0: mean loss = 2.5244469e-09
step 100: mean loss = 3.1569443e-09
step 200: mean loss = 3.4742007e-09
step 300: mean loss = 3.3515493e-09
epoch 542: mean loss = 3.3290597e-09  learning rate = 6.597065e-06
============================
Start of epoch 543
step 0: mean loss = 3.572778e-09
step 100: mean loss = 2.920663e-09
step 200: mean loss = 2.89064e-09
step 300: mean loss = 2.7546292e-09
epoch 543: mean loss = 2.7248706e-09  learning rate = 6.597065e-06
============================
Start of epoch 544
step 0: mean loss = 2.3492022e-09
step 100: mean loss = 3.3872254e-09
step 200: mean loss = 4.182253e-09
step 300: mean loss = 3.5142957e-09
epoch 544: mean loss = 3.4820735e-09  learning rate = 6.597065e-06
============================
Start of epoch 545
step 0: mean loss = 1.4005089e-09
step 100: mean loss = 3.6628327e-09
step 200: mean loss = 3.958607e-09
step 300: mean loss = 3.504421e-09
epoch 545: mean loss = 3.4401801e-09  learning rate = 6.597065e-06
============================
Start of epoch 546
step 0: mean loss = 1.7801851e-09
step 100: mean loss = 2.773382e-09
step 200: mean loss = 2.9397258e-09
step 300: mean loss = 2.7072038e-09
epoch 546: mean loss = 2.6782203e-09  learning rate = 6.597065e-06
============================
Start of epoch 547
step 0: mean loss = 2.9193483e-09
step 100: mean loss = 3.27124e-09
step 200: mean loss = 2.7909635e-09
step 300: mean loss = 3.253074e-09
epoch 547: mean loss = 3.762584e-09  learning rate = 6.597065e-06
============================
Start of epoch 548
step 0: mean loss = 9.203671e-09
step 100: mean loss = 5.1411044e-09
step 200: mean loss = 3.6108796e-09
step 300: mean loss = 3.1389906e-09
epoch 548: mean loss = 3.1731118e-09  learning rate = 6.597065e-06
============================
Start of epoch 549
step 0: mean loss = 3.2050593e-09
step 100: mean loss = 2.7910918e-09
step 200: mean loss = 3.0880034e-09
step 300: mean loss = 3.318896e-09
epoch 549: mean loss = 3.2585517e-09  learning rate = 6.597065e-06
============================
Start of epoch 550
step 0: mean loss = 2.0200608e-09
step 100: mean loss = 2.1598312e-09
step 200: mean loss = 2.4153535e-09
step 300: mean loss = 2.7011418e-09
epoch 550: mean loss = 2.72744e-09  learning rate = 6.597065e-06
============================
Start of epoch 551
step 0: mean loss = 1.6518978e-09
step 100: mean loss = 2.4258657e-09
step 200: mean loss = 2.4332776e-09
step 300: mean loss = 2.5503837e-09
epoch 551: mean loss = 2.5467124e-09  learning rate = 6.597065e-06
============================
Start of epoch 552
step 0: mean loss = 2.2728035e-09
step 100: mean loss = 4.4721635e-09
step 200: mean loss = 3.6560737e-09
step 300: mean loss = 3.2020016e-09
epoch 552: mean loss = 3.1575702e-09  learning rate = 6.597065e-06
============================
Start of epoch 553
step 0: mean loss = 2.1812572e-09
step 100: mean loss = 3.3572352e-09
step 200: mean loss = 3.781758e-09
step 300: mean loss = 3.5073218e-09
epoch 553: mean loss = 3.4472796e-09  learning rate = 6.597065e-06
============================
Start of epoch 554
step 0: mean loss = 1.8294122e-09
step 100: mean loss = 2.4190072e-09
step 200: mean loss = 2.4849371e-09
step 300: mean loss = 2.573594e-09
epoch 554: mean loss = 2.5957998e-09  learning rate = 6.597065e-06
============================
Start of epoch 555
step 0: mean loss = 2.0088948e-09
step 100: mean loss = 3.1890957e-09
step 200: mean loss = 3.2063567e-09
step 300: mean loss = 3.216805e-09
epoch 555: mean loss = 3.1963596e-09  learning rate = 6.597065e-06
============================
Start of epoch 556
step 0: mean loss = 3.4964844e-09
step 100: mean loss = 4.203321e-09
step 200: mean loss = 3.561225e-09
step 300: mean loss = 3.0960268e-09
epoch 556: mean loss = 3.0622422e-09  learning rate = 6.597065e-06
============================
Start of epoch 557
step 0: mean loss = 2.4588793e-09
step 100: mean loss = 3.1002014e-09
step 200: mean loss = 2.866478e-09
step 300: mean loss = 2.9533962e-09
epoch 557: mean loss = 2.9487386e-09  learning rate = 6.597065e-06
============================
Start of epoch 558
step 0: mean loss = 2.032237e-09
step 100: mean loss = 2.5172393e-09
step 200: mean loss = 2.6761904e-09
step 300: mean loss = 3.334429e-09
epoch 558: mean loss = 3.2782863e-09  learning rate = 6.597065e-06
============================
Start of epoch 559
step 0: mean loss = 1.5869386e-09
step 100: mean loss = 2.7231577e-09
step 200: mean loss = 2.508973e-09
step 300: mean loss = 2.717521e-09
epoch 559: mean loss = 2.8136922e-09  learning rate = 6.267212e-06
============================
Start of epoch 560
step 0: mean loss = 5.8518483e-09
step 100: mean loss = 2.4760891e-09
step 200: mean loss = 2.3901583e-09
step 300: mean loss = 2.4782751e-09
epoch 560: mean loss = 2.4594784e-09  learning rate = 6.267212e-06
============================
Start of epoch 561
step 0: mean loss = 2.369109e-09
step 100: mean loss = 2.7354263e-09
step 200: mean loss = 2.5811946e-09
step 300: mean loss = 2.6129165e-09
epoch 561: mean loss = 2.6670406e-09  learning rate = 6.267212e-06
============================
Start of epoch 562
step 0: mean loss = 2.3137035e-09
step 100: mean loss = 3.2901375e-09
step 200: mean loss = 4.182281e-09
step 300: mean loss = 3.6533099e-09
epoch 562: mean loss = 3.6436087e-09  learning rate = 6.267212e-06
============================
Start of epoch 563
step 0: mean loss = 2.0599242e-09
step 100: mean loss = 4.1409183e-09
step 200: mean loss = 3.3588787e-09
step 300: mean loss = 3.0705345e-09
epoch 563: mean loss = 3.0346148e-09  learning rate = 6.267212e-06
============================
Start of epoch 564
step 0: mean loss = 1.9850808e-09
step 100: mean loss = 3.2904575e-09
step 200: mean loss = 2.6566458e-09
step 300: mean loss = 2.6154188e-09
epoch 564: mean loss = 2.590112e-09  learning rate = 6.267212e-06
============================
Start of epoch 565
step 0: mean loss = 2.9865954e-09
step 100: mean loss = 3.010398e-09
step 200: mean loss = 2.8097868e-09
step 300: mean loss = 2.8177751e-09
epoch 565: mean loss = 2.8545248e-09  learning rate = 6.267212e-06
============================
Start of epoch 566
step 0: mean loss = 6.1735634e-09
step 100: mean loss = 3.4240812e-09
step 200: mean loss = 3.5782417e-09
step 300: mean loss = 3.3677456e-09
epoch 566: mean loss = 3.5251142e-09  learning rate = 6.267212e-06
============================
Start of epoch 567
step 0: mean loss = 1.2354933e-08
step 100: mean loss = 4.0722155e-09
step 200: mean loss = 3.0477303e-09
step 300: mean loss = 2.821392e-09
epoch 567: mean loss = 2.848624e-09  learning rate = 6.267212e-06
============================
Start of epoch 568
step 0: mean loss = 5.5553384e-09
step 100: mean loss = 2.2111188e-09
step 200: mean loss = 2.3310873e-09
step 300: mean loss = 2.5806006e-09
epoch 568: mean loss = 2.5586204e-09  learning rate = 6.267212e-06
============================
Start of epoch 569
step 0: mean loss = 1.7594861e-09
step 100: mean loss = 3.96159e-09
step 200: mean loss = 3.6753396e-09
step 300: mean loss = 3.3968868e-09
epoch 569: mean loss = 3.3469314e-09  learning rate = 6.267212e-06
============================
Start of epoch 570
step 0: mean loss = 5.416618e-09
step 100: mean loss = 3.4373375e-09
step 200: mean loss = 3.2648577e-09
step 300: mean loss = 3.0737324e-09
epoch 570: mean loss = 3.0647411e-09  learning rate = 6.267212e-06
============================
Start of epoch 571
step 0: mean loss = 2.0910975e-09
step 100: mean loss = 2.242107e-09
step 200: mean loss = 2.3642313e-09
step 300: mean loss = 2.363287e-09
epoch 571: mean loss = 2.3639999e-09  learning rate = 6.267212e-06
============================
Start of epoch 572
step 0: mean loss = 2.8667404e-09
step 100: mean loss = 2.7877884e-09
step 200: mean loss = 3.0784697e-09
step 300: mean loss = 2.8518796e-09
epoch 572: mean loss = 2.813701e-09  learning rate = 6.267212e-06
============================
Start of epoch 573
step 0: mean loss = 3.1441665e-09
step 100: mean loss = 2.988755e-09
step 200: mean loss = 3.3593348e-09
step 300: mean loss = 2.943104e-09
epoch 573: mean loss = 3.080517e-09  learning rate = 6.267212e-06
============================
Start of epoch 574
step 0: mean loss = 1.6283803e-09
step 100: mean loss = 4.2477164e-09
step 200: mean loss = 3.2428114e-09
step 300: mean loss = 3.0134684e-09
epoch 574: mean loss = 2.9718523e-09  learning rate = 6.267212e-06
============================
Start of epoch 575
step 0: mean loss = 2.5498e-09
step 100: mean loss = 3.2422267e-09
step 200: mean loss = 2.8651628e-09
step 300: mean loss = 2.6208047e-09
epoch 575: mean loss = 2.6099984e-09  learning rate = 6.267212e-06
============================
Start of epoch 576
step 0: mean loss = 1.9352158e-09
step 100: mean loss = 2.465294e-09
step 200: mean loss = 2.7136307e-09
step 300: mean loss = 3.0612357e-09
epoch 576: mean loss = 3.0513772e-09  learning rate = 6.267212e-06
============================
Start of epoch 577
step 0: mean loss = 3.3745629e-09
step 100: mean loss = 3.344131e-09
step 200: mean loss = 3.2155256e-09
step 300: mean loss = 3.2242238e-09
epoch 577: mean loss = 3.473266e-09  learning rate = 6.267212e-06
============================
Start of epoch 578
step 0: mean loss = 5.969974e-09
step 100: mean loss = 5.4784386e-09
step 200: mean loss = 4.2005337e-09
step 300: mean loss = 3.6070043e-09
epoch 578: mean loss = 3.5403458e-09  learning rate = 6.267212e-06
============================
Start of epoch 579
step 0: mean loss = 1.7203121e-09
step 100: mean loss = 2.4560116e-09
step 200: mean loss = 2.7243634e-09
step 300: mean loss = 2.6860103e-09
epoch 579: mean loss = 2.674419e-09  learning rate = 6.267212e-06
============================
Start of epoch 580
step 0: mean loss = 3.0322138e-09
step 100: mean loss = 2.3508886e-09
step 200: mean loss = 2.4316378e-09
step 300: mean loss = 2.4971558e-09
epoch 580: mean loss = 2.5102986e-09  learning rate = 6.267212e-06
============================
Start of epoch 581
step 0: mean loss = 3.3805443e-09
step 100: mean loss = 3.0114475e-09
step 200: mean loss = 2.9054552e-09
step 300: mean loss = 2.777235e-09
epoch 581: mean loss = 2.7695397e-09  learning rate = 6.267212e-06
============================
Start of epoch 582
step 0: mean loss = 1.3438133e-09
step 100: mean loss = 3.1488598e-09
step 200: mean loss = 3.872391e-09
step 300: mean loss = 4.0497885e-09
epoch 582: mean loss = 3.9647206e-09  learning rate = 6.267212e-06
============================
Start of epoch 583
step 0: mean loss = 1.577775e-09
step 100: mean loss = 2.2759472e-09
step 200: mean loss = 2.6931406e-09
step 300: mean loss = 2.6191045e-09
epoch 583: mean loss = 2.59522e-09  learning rate = 6.267212e-06
============================
Start of epoch 584
step 0: mean loss = 1.7461499e-09
step 100: mean loss = 2.7939173e-09
step 200: mean loss = 2.7688978e-09
step 300: mean loss = 2.7465923e-09
epoch 584: mean loss = 2.7764135e-09  learning rate = 6.267212e-06
============================
Start of epoch 585
step 0: mean loss = 4.0962886e-09
step 100: mean loss = 3.0412364e-09
step 200: mean loss = 3.4320664e-09
step 300: mean loss = 3.174137e-09
epoch 585: mean loss = 3.2660492e-09  learning rate = 6.267212e-06
============================
Start of epoch 586
step 0: mean loss = 2.700745e-09
step 100: mean loss = 2.2865352e-09
step 200: mean loss = 2.5229152e-09
step 300: mean loss = 2.6754778e-09
epoch 586: mean loss = 2.6494837e-09  learning rate = 6.267212e-06
============================
Start of epoch 587
step 0: mean loss = 1.9228446e-09
step 100: mean loss = 2.5190983e-09
step 200: mean loss = 2.46859e-09
step 300: mean loss = 2.342621e-09
epoch 587: mean loss = 2.3570235e-09  learning rate = 6.267212e-06
============================
Start of epoch 588
step 0: mean loss = 1.3563428e-09
step 100: mean loss = 2.7255957e-09
step 200: mean loss = 2.994435e-09
step 300: mean loss = 3.120118e-09
epoch 588: mean loss = 3.147977e-09  learning rate = 6.267212e-06
============================
Start of epoch 589
step 0: mean loss = 2.3247124e-09
step 100: mean loss = 2.531501e-09
step 200: mean loss = 3.302066e-09
step 300: mean loss = 2.9851428e-09
epoch 589: mean loss = 2.950019e-09  learning rate = 6.267212e-06
============================
Start of epoch 590
step 0: mean loss = 4.0304573e-09
step 100: mean loss = 2.985836e-09
step 200: mean loss = 2.8953402e-09
step 300: mean loss = 2.6403821e-09
epoch 590: mean loss = 2.6132994e-09  learning rate = 6.267212e-06
============================
Start of epoch 591
step 0: mean loss = 1.4299193e-09
step 100: mean loss = 3.3481735e-09
step 200: mean loss = 2.8792875e-09
step 300: mean loss = 2.7195155e-09
epoch 591: mean loss = 2.7129232e-09  learning rate = 6.267212e-06
============================
Start of epoch 592
step 0: mean loss = 2.5495726e-09
step 100: mean loss = 2.346668e-09
step 200: mean loss = 2.76065e-09
step 300: mean loss = 3.1754233e-09
epoch 592: mean loss = 3.2187428e-09  learning rate = 6.267212e-06
============================
Start of epoch 593
step 0: mean loss = 4.316484e-09
step 100: mean loss = 2.7227272e-09
step 200: mean loss = 2.6739195e-09
step 300: mean loss = 2.8287896e-09
epoch 593: mean loss = 2.7831295e-09  learning rate = 6.267212e-06
============================
Start of epoch 594
step 0: mean loss = 1.4146956e-09
step 100: mean loss = 2.200328e-09
step 200: mean loss = 2.4673916e-09
step 300: mean loss = 2.4596583e-09
epoch 594: mean loss = 2.4578182e-09  learning rate = 6.267212e-06
============================
Start of epoch 595
step 0: mean loss = 1.7656291e-09
step 100: mean loss = 2.3012185e-09
step 200: mean loss = 2.9778062e-09
step 300: mean loss = 2.7710407e-09
epoch 595: mean loss = 2.809276e-09  learning rate = 6.267212e-06
============================
Start of epoch 596
step 0: mean loss = 4.5235966e-09
step 100: mean loss = 2.3238913e-09
step 200: mean loss = 4.0886703e-09
step 300: mean loss = 3.6662533e-09
epoch 596: mean loss = 3.6028702e-09  learning rate = 6.267212e-06
============================
Start of epoch 597
step 0: mean loss = 2.3094437e-09
step 100: mean loss = 2.2324609e-09
step 200: mean loss = 2.4993754e-09
step 300: mean loss = 2.435875e-09
epoch 597: mean loss = 2.412959e-09  learning rate = 6.267212e-06
============================
Start of epoch 598
step 0: mean loss = 1.6494053e-09
step 100: mean loss = 2.6770512e-09
step 200: mean loss = 2.6087357e-09
step 300: mean loss = 3.369333e-09
epoch 598: mean loss = 3.4417718e-09  learning rate = 6.267212e-06
============================
Start of epoch 599
step 0: mean loss = 3.2670602e-09
step 100: mean loss = 2.3120825e-09
step 200: mean loss = 2.1203663e-09
step 300: mean loss = 2.1928193e-09
epoch 599: mean loss = 2.199036e-09  learning rate = 5.953851e-06
============================
Start of epoch 600
step 0: mean loss = 2.1416713e-09
step 100: mean loss = 2.3428224e-09
step 200: mean loss = 2.6992883e-09
step 300: mean loss = 2.5412046e-09
epoch 600: mean loss = 2.5212865e-09  learning rate = 5.953851e-06
============================
Start of epoch 601
step 0: mean loss = 1.922531e-09
step 100: mean loss = 2.4435405e-09
step 200: mean loss = 2.6210756e-09
step 300: mean loss = 4.100044e-09
epoch 601: mean loss = 4.0272488e-09  learning rate = 5.953851e-06
============================
Start of epoch 602
step 0: mean loss = 3.2583742e-09
step 100: mean loss = 2.047012e-09
step 200: mean loss = 2.1839528e-09
step 300: mean loss = 2.8086957e-09
epoch 602: mean loss = 2.7990592e-09  learning rate = 5.953851e-06
============================
Start of epoch 603
step 0: mean loss = 3.4578966e-09
step 100: mean loss = 2.1517104e-09
step 200: mean loss = 2.5297195e-09
step 300: mean loss = 2.382105e-09
epoch 603: mean loss = 2.3731275e-09  learning rate = 5.953851e-06
============================
Start of epoch 604
step 0: mean loss = 4.4392428e-09
step 100: mean loss = 2.295918e-09
step 200: mean loss = 2.8674805e-09
step 300: mean loss = 2.689648e-09
epoch 604: mean loss = 2.6583102e-09  learning rate = 5.953851e-06
============================
Start of epoch 605
step 0: mean loss = 1.6311151e-09
step 100: mean loss = 4.199936e-09
step 200: mean loss = 4.013609e-09
step 300: mean loss = 4.7695066e-09
epoch 605: mean loss = 4.661535e-09  learning rate = 5.953851e-06
============================
Start of epoch 606
step 0: mean loss = 2.93011e-09
step 100: mean loss = 2.263695e-09
step 200: mean loss = 2.049778e-09
step 300: mean loss = 2.1245554e-09
epoch 606: mean loss = 2.1116149e-09  learning rate = 5.953851e-06
============================
Start of epoch 607
step 0: mean loss = 1.6582155e-09
step 100: mean loss = 2.1384223e-09
step 200: mean loss = 2.221819e-09
step 300: mean loss = 2.2703808e-09
epoch 607: mean loss = 2.2494842e-09  learning rate = 5.953851e-06
============================
Start of epoch 608
step 0: mean loss = 2.0017186e-09
step 100: mean loss = 2.1180235e-09
step 200: mean loss = 2.1750033e-09
step 300: mean loss = 2.519016e-09
epoch 608: mean loss = 2.6758644e-09  learning rate = 5.953851e-06
============================
slurmstepd: error: *** JOB 775026 ON euler06 CANCELLED AT 2020-04-24T09:25:41 DUE TO TIME LIMIT ***
Start of epoch 609
step 0: mean loss = 2.4901856e-09
step 100: mean loss = 2.747296e-09
step 200: mean loss = 2.7022875e-09
step 300: mean loss = 2.7724838e-09
epoch 609: mean loss = 2.7704201e-09  learning rate = 5.953851e-06
============================
