2020-08-27 13:49:27.224962: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1
2020-08-27 13:49:31.816529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s
2020-08-27 13:49:31.816716: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-27 13:49:31.817928: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-27 13:49:31.819138: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-27 13:49:31.819287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-27 13:49:31.820338: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-27 13:49:31.820929: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-27 13:49:31.823272: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-27 13:49:31.824235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-27 13:49:31.824512: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-08-27 13:49:31.850148: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3493020000 Hz
2020-08-27 13:49:31.851716: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d6a6b96f00 initialized for platform Host (this does not guarantee that XLA will be used). Devices:
2020-08-27 13:49:31.851755: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version
2020-08-27 13:49:31.852486: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties: 
pciBusID: 0000:09:00.0 name: GeForce RTX 2080 SUPER computeCapability: 7.5
coreClock: 1.815GHz coreCount: 48 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 462.00GiB/s
2020-08-27 13:49:31.852527: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-27 13:49:31.852537: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
2020-08-27 13:49:31.852545: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10
2020-08-27 13:49:31.852552: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10
2020-08-27 13:49:31.852560: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10
2020-08-27 13:49:31.852567: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10
2020-08-27 13:49:31.852575: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7
2020-08-27 13:49:31.853372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1703] Adding visible gpu devices: 0
2020-08-27 13:49:31.853397: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1
2020-08-27 13:49:32.623016: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-08-27 13:49:32.623047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]      0 
2020-08-27 13:49:32.623052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1121] 0:   N 
2020-08-27 13:49:32.624427: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1247] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 7384 MB memory) -> physical GPU (device: 0, name: GeForce RTX 2080 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5)
2020-08-27 13:49:32.626192: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x55d6a7e718e0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:
2020-08-27 13:49:32.626205: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): GeForce RTX 2080 SUPER, Compute Capability 7.5
=================================================
Executing 2BodyForcesDist2DSimple.py following Np200_Per_mu_10_rad_1_5.json
2020-08-27 13:49:36.298791: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10
=================================================
We are using the random seed 1234567891011121314
Using data in ../../data/data_2D_YukawaPeriodic_Ncells_10_Np_2_mu_10_minDelta_0.0500_Nsamples_10000.h5
mean of the forces is 0.00000000
std of the forces is 3.67421209
mean of the inputs are 1.17938666 and 0.00000000
std of the inputs are 1.05803081 and 0.70301980
Model: "deepMDsimpleEnergy"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
pyramid_layer (pyramidLayer) multiple                  744       
_________________________________________________________________
pyramid_layer_1 (pyramidLaye multiple                  746       
_________________________________________________________________
pyramid_layer_2 (pyramidLaye multiple                  7360      
_________________________________________________________________
my_dense_layer (MyDenseLayer multiple                  33        
=================================================================
Total params: 8,883
Trainable params: 8,883
Non-trainable params: 0
_________________________________________________________________
Directory  checkpoints/  already exists :)
Training cycles in number of epochs
[200, 400, 800, 1600]
Training batch sizes for each cycle
[8, 16, 32, 64]
++++++++++++++++++++++++++++++
Start of cycle 0
Total number of epochs in this cycle: 200
Batch size in this cycle: 8
============================
WARNING:tensorflow:Layer deepMDsimpleEnergy is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.

If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.

To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.

2020-08-27 13:49:40.136196: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 13:49:40.136268: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 13:49:40.136309: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 13:49:40.136329: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 13:49:40.352366: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 13:49:40.352421: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 13:49:40.352471: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 13:49:40.352478: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 13:50:10.834879: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 13:50:10.834943: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 13:50:10.834958: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 13:50:10.834969: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
Start of epoch 0
step 0: mean loss = 27.141424
step 100: mean loss = 1.4665538
step 200: mean loss = 0.7594851
step 300: mean loss = 0.5132699
step 400: mean loss = 0.3880941
step 500: mean loss = 0.31215623
step 600: mean loss = 0.26112542
step 700: mean loss = 0.22446066
step 800: mean loss = 0.19684254
step 900: mean loss = 0.17529084
step 1000: mean loss = 0.1580044
step 1100: mean loss = 0.14383043
step 1200: mean loss = 0.13199691
epoch 0: mean loss = 0.12809889  learning rate = 0.001
============================
Start of epoch 1
step 0: mean loss = 0.0015363117
step 100: mean loss = 0.0014508924
step 200: mean loss = 0.001374159
step 300: mean loss = 0.0013045997
step 400: mean loss = 0.0018638318
step 500: mean loss = 0.0016811797
step 600: mean loss = 0.0021873876
step 700: mean loss = 0.0020235868
step 800: mean loss = 0.0018593328
step 900: mean loss = 0.002262156
step 1000: mean loss = 0.0021078603
step 1100: mean loss = 0.0019660424
step 1200: mean loss = 0.0021671895
epoch 1: mean loss = 0.0022077109  learning rate = 0.001
============================
Start of epoch 2
step 0: mean loss = 0.0007268392
step 100: mean loss = 0.00048995204
step 200: mean loss = 0.0004554946
step 300: mean loss = 0.0020782594
step 400: mean loss = 0.0019638906
step 500: mean loss = 0.0016414493
step 600: mean loss = 0.0014215028
step 700: mean loss = 0.0013066791
step 800: mean loss = 0.0019032924
step 900: mean loss = 0.0017227343
step 1000: mean loss = 0.0015757956
step 1100: mean loss = 0.0014540493
step 1200: mean loss = 0.0017417825
epoch 2: mean loss = 0.0016967551  learning rate = 0.001
============================
Start of epoch 3
step 0: mean loss = 0.00022522587
step 100: mean loss = 0.00021314899
step 200: mean loss = 0.00020517748
step 300: mean loss = 0.001783728
step 400: mean loss = 0.0013948121
step 500: mean loss = 0.0011510717
step 600: mean loss = 0.0009864271
step 700: mean loss = 0.001022741
step 800: mean loss = 0.0013559307
step 900: mean loss = 0.0012225364
step 1000: mean loss = 0.0011141478
step 1100: mean loss = 0.001435362
step 1200: mean loss = 0.0013327075
epoch 3: mean loss = 0.0012967332  learning rate = 0.001
============================
Start of epoch 4
step 0: mean loss = 0.00012611516
step 100: mean loss = 0.0001204804
step 200: mean loss = 0.00011616105
step 300: mean loss = 0.0008515258
step 400: mean loss = 0.0006708208
step 500: mean loss = 0.0011518454
step 600: mean loss = 0.0010249036
step 700: mean loss = 0.0008928115
step 800: mean loss = 0.0007925416
step 900: mean loss = 0.0010077184
step 1000: mean loss = 0.0009200581
step 1100: mean loss = 0.0008439001
step 1200: mean loss = 0.0007805792
epoch 4: mean loss = 0.00088967365  learning rate = 0.001
============================
Start of epoch 5
step 0: mean loss = 0.0005360844
step 100: mean loss = 0.00012318813
step 200: mean loss = 0.00020770269
step 300: mean loss = 0.00087940507
step 400: mean loss = 0.0006775915
step 500: mean loss = 0.00055469986
step 600: mean loss = 0.0008483888
step 700: mean loss = 0.0007419116
step 800: mean loss = 0.00065674994
step 900: mean loss = 0.0005897016
step 1000: mean loss = 0.0007305374
step 1100: mean loss = 0.0006695008
step 1200: mean loss = 0.00061776204
epoch 5: mean loss = 0.00060063426  learning rate = 0.001
============================
Start of epoch 6
step 0: mean loss = 4.3913737e-05
step 100: mean loss = 0.0016588054
step 200: mean loss = 0.0010311549
step 300: mean loss = 0.00072173297
step 400: mean loss = 0.0008348764
step 500: mean loss = 0.0006815931
step 600: mean loss = 0.0005842309
step 700: mean loss = 0.000665065
step 800: mean loss = 0.0005973943
step 900: mean loss = 0.0005353007
step 1000: mean loss = 0.00065269304
step 1100: mean loss = 0.0006035841
step 1200: mean loss = 0.000556849
epoch 6: mean loss = 0.00054131076  learning rate = 0.001
============================
Start of epoch 7
step 0: mean loss = 3.5874087e-05
step 100: mean loss = 0.000798763
step 200: mean loss = 0.0004213424
step 300: mean loss = 0.00029168025
step 400: mean loss = 0.015080007
step 500: mean loss = 0.013157643
step 600: mean loss = 0.011182411
step 700: mean loss = 0.00967403
step 800: mean loss = 0.008511461
step 900: mean loss = 0.0075947987
step 1000: mean loss = 0.0068552643
step 1100: mean loss = 0.0062466753
step 1200: mean loss = 0.0057373513
epoch 7: mean loss = 0.005569368  learning rate = 0.001
============================
Start of epoch 8
step 0: mean loss = 0.00011364777
step 100: mean loss = 0.00010647936
step 200: mean loss = 0.00010041397
step 300: mean loss = 9.5165124e-05
step 400: mean loss = 9.0540096e-05
step 500: mean loss = 8.6406566e-05
step 600: mean loss = 8.267194e-05
step 700: mean loss = 9.728866e-05
step 800: mean loss = 9.196287e-05
step 900: mean loss = 0.00011958068
step 1000: mean loss = 0.00011478892
step 1100: mean loss = 0.00010832032
step 1200: mean loss = 0.0001026497
epoch 8: mean loss = 0.00012068366  learning rate = 0.001
============================
Start of epoch 9
step 0: mean loss = 0.00049589586
step 100: mean loss = 9.180758e-05
step 200: mean loss = 6.337876e-05
step 300: mean loss = 0.00010995051
step 400: mean loss = 0.00012831885
step 500: mean loss = 0.00010851032
step 600: mean loss = 0.00011661671
step 700: mean loss = 0.00012301328
step 800: mean loss = 0.00011073714
step 900: mean loss = 0.00012914519
step 1000: mean loss = 0.00011868899
step 1100: mean loss = 0.00012307167
step 1200: mean loss = 0.00011587123
epoch 9: mean loss = 0.00011299962  learning rate = 0.001
============================
Start of epoch 10
step 0: mean loss = 1.943085e-05
step 100: mean loss = 0.00021221413
step 200: mean loss = 0.00011601679
step 300: mean loss = 0.00011559817
step 400: mean loss = 9.163928e-05
step 500: mean loss = 0.00012655422
step 600: mean loss = 0.00012334934
step 700: mean loss = 0.000108810986
step 800: mean loss = 0.000122066405
step 900: mean loss = 0.000110394365
step 1000: mean loss = 0.00013073639
step 1100: mean loss = 0.00012024677
step 1200: mean loss = 0.00011969671
epoch 10: mean loss = 0.00011650576  learning rate = 0.00094999996
============================
Start of epoch 11
step 0: mean loss = 1.2319747e-05
step 100: mean loss = 7.75511e-05
step 200: mean loss = 7.4424155e-05
step 300: mean loss = 8.630933e-05
step 400: mean loss = 0.00012537335
step 500: mean loss = 0.00011539663
step 600: mean loss = 0.00010166715
step 700: mean loss = 9.650551e-05
step 800: mean loss = 9.034306e-05
step 900: mean loss = 0.006920399
step 1000: mean loss = 0.006546858
step 1100: mean loss = 0.0060320687
step 1200: mean loss = 0.0056566074
epoch 11: mean loss = 0.0055039544  learning rate = 0.00094999996
============================
Start of epoch 12
step 0: mean loss = 0.00048232102
step 100: mean loss = 0.0003872877
step 200: mean loss = 0.00032868833
step 300: mean loss = 0.000287122
step 400: mean loss = 0.00025593207
step 500: mean loss = 0.00023153592
step 600: mean loss = 0.00021176723
step 700: mean loss = 0.00019533592
step 800: mean loss = 0.00018143293
step 900: mean loss = 0.00016950462
step 1000: mean loss = 0.00015914536
step 1100: mean loss = 0.00015004889
step 1200: mean loss = 0.00014198186
epoch 12: mean loss = 0.00013922088  learning rate = 0.00094999996
============================
Start of epoch 13
step 0: mean loss = 4.8672115e-05
step 100: mean loss = 4.636948e-05
step 200: mean loss = 4.4250184e-05
step 300: mean loss = 4.2293315e-05
step 400: mean loss = 4.0481726e-05
step 500: mean loss = 3.8800932e-05
step 600: mean loss = 4.0849365e-05
step 700: mean loss = 3.909986e-05
step 800: mean loss = 4.075267e-05
step 900: mean loss = 4.4566983e-05
step 1000: mean loss = 4.7726022e-05
step 1100: mean loss = 5.011834e-05
step 1200: mean loss = 5.334751e-05
epoch 13: mean loss = 5.4415417e-05  learning rate = 0.00094999996
============================
Start of epoch 14
step 0: mean loss = 0.00035857773
step 100: mean loss = 0.00014441602
step 200: mean loss = 0.000110573535
step 300: mean loss = 0.00010290279
step 400: mean loss = 0.00022162894
step 500: mean loss = 0.00018142739
step 600: mean loss = 0.0001614721
step 700: mean loss = 0.0001485063
step 800: mean loss = 0.0001388527
step 900: mean loss = 0.00013745195
step 1000: mean loss = 0.0001333404
step 1100: mean loss = 0.00013944245
step 1200: mean loss = 0.00013304067
epoch 14: mean loss = 0.00014434554  learning rate = 0.00094999996
============================
Start of epoch 15
step 0: mean loss = 0.000375557
step 100: mean loss = 3.634787e-05
step 200: mean loss = 7.9550286e-05
step 300: mean loss = 0.00010085192
step 400: mean loss = 9.51522e-05
step 500: mean loss = 9.949519e-05
step 600: mean loss = 0.00014299214
step 700: mean loss = 0.00012474068
step 800: mean loss = 0.000118437056
step 900: mean loss = 0.00011862565
step 1000: mean loss = 0.00010914259
step 1100: mean loss = 0.00014368312
step 1200: mean loss = 0.00013237575
epoch 15: mean loss = 0.00012861636  learning rate = 0.00094999996
============================
Start of epoch 16
step 0: mean loss = 7.4164145e-06
step 100: mean loss = 7.596982e-05
step 200: mean loss = 0.00010208028
step 300: mean loss = 9.286991e-05
step 400: mean loss = 9.429328e-05
step 500: mean loss = 9.1666596e-05
step 600: mean loss = 9.22626e-05
step 700: mean loss = 8.5681546e-05
step 800: mean loss = 0.00012228692
step 900: mean loss = 0.0001134002
step 1000: mean loss = 0.000105113344
step 1100: mean loss = 0.000103601225
step 1200: mean loss = 0.0028081574
epoch 16: mean loss = 0.0031387368  learning rate = 0.00094999996
============================
Start of epoch 17
step 0: mean loss = 0.006534283
step 100: mean loss = 0.0014493295
step 200: mean loss = 0.0008224308
step 300: mean loss = 0.00057734613
step 400: mean loss = 0.00044857975
step 500: mean loss = 0.00036814765
step 600: mean loss = 0.00031395364
step 700: mean loss = 0.00027434516
step 800: mean loss = 0.00024406677
step 900: mean loss = 0.00022014775
step 1000: mean loss = 0.00020088279
step 1100: mean loss = 0.00018487958
step 1200: mean loss = 0.0001712716
epoch 17: mean loss = 0.00016670678  learning rate = 0.00094999996
============================
Start of epoch 18
step 0: mean loss = 1.8886149e-05
step 100: mean loss = 2.0266772e-05
step 200: mean loss = 1.8601459e-05
step 300: mean loss = 1.7899714e-05
step 400: mean loss = 1.7584398e-05
step 500: mean loss = 1.7138515e-05
step 600: mean loss = 1.6906004e-05
step 700: mean loss = 1.6898832e-05
step 800: mean loss = 1.6926102e-05
step 900: mean loss = 1.7737737e-05
step 1000: mean loss = 1.8024475e-05
step 1100: mean loss = 1.9095234e-05
step 1200: mean loss = 2.0644471e-05
epoch 18: mean loss = 2.090232e-05  learning rate = 0.00094999996
============================
Start of epoch 19
step 0: mean loss = 9.10378e-06
step 100: mean loss = 3.292666e-05
step 200: mean loss = 3.7624388e-05
step 300: mean loss = 4.589101e-05
step 400: mean loss = 5.2214054e-05
step 500: mean loss = 5.595345e-05
step 600: mean loss = 5.8267484e-05
step 700: mean loss = 5.8677913e-05
step 800: mean loss = 5.8831673e-05
step 900: mean loss = 6.424292e-05
step 1000: mean loss = 6.6123976e-05
step 1100: mean loss = 7.459101e-05
step 1200: mean loss = 6.878275e-05
epoch 19: mean loss = 6.685456e-05  learning rate = 0.00094999996
============================
Start of epoch 20
step 0: mean loss = 5.139302e-06
step 100: mean loss = 0.00023901794
step 200: mean loss = 0.00012245789
step 300: mean loss = 8.305148e-05
step 400: mean loss = 0.00012366299
step 500: mean loss = 0.000100791985
step 600: mean loss = 8.464218e-05
step 700: mean loss = 0.000106490545
step 800: mean loss = 9.4102164e-05
step 900: mean loss = 8.4042775e-05
step 1000: mean loss = 9.677174e-05
step 1100: mean loss = 8.8386136e-05
step 1200: mean loss = 8.1299484e-05
epoch 20: mean loss = 0.00010017457  learning rate = 0.00090249995
============================
Start of epoch 21
step 0: mean loss = 5.0967166e-05
step 100: mean loss = 1.2593133e-05
step 200: mean loss = 7.994042e-06
step 300: mean loss = 4.9180082e-05
step 400: mean loss = 4.0665785e-05
step 500: mean loss = 6.958381e-05
step 600: mean loss = 6.3280524e-05
step 700: mean loss = 6.0481205e-05
step 800: mean loss = 5.5051358e-05
step 900: mean loss = 6.393622e-05
step 1000: mean loss = 5.7843386e-05
step 1100: mean loss = 0.003194063
step 1200: mean loss = 0.0030721964
epoch 21: mean loss = 0.002999429  learning rate = 0.00090249995
============================
Start of epoch 22
step 0: mean loss = 0.00049053115
step 100: mean loss = 0.00031558378
step 200: mean loss = 0.00023162771
step 300: mean loss = 0.00020386562
step 400: mean loss = 0.0001715353
step 500: mean loss = 0.00014542793
step 600: mean loss = 0.00012746344
step 700: mean loss = 0.00011442745
step 800: mean loss = 0.0001044407
step 900: mean loss = 9.665172e-05
step 1000: mean loss = 9.0150075e-05
step 1100: mean loss = 8.462693e-05
step 1200: mean loss = 7.9627345e-05
epoch 22: mean loss = 7.873776e-05  learning rate = 0.00090249995
============================
Start of epoch 23
step 0: mean loss = 0.00012885977
step 100: mean loss = 1.8143364e-05
step 200: mean loss = 2.4153378e-05
step 300: mean loss = 2.4704199e-05
step 400: mean loss = 2.4558558e-05
step 500: mean loss = 2.3715553e-05
step 600: mean loss = 2.6315172e-05
step 700: mean loss = 2.8358525e-05
step 800: mean loss = 2.6347958e-05
step 900: mean loss = 2.640339e-05
step 1000: mean loss = 2.4854724e-05
step 1100: mean loss = 2.5440351e-05
step 1200: mean loss = 2.529623e-05
epoch 23: mean loss = 2.5445026e-05  learning rate = 0.00090249995
============================
Start of epoch 24
step 0: mean loss = 0.00029548758
step 100: mean loss = 2.6688056e-05
step 200: mean loss = 2.4219258e-05
step 300: mean loss = 3.5998153e-05
step 400: mean loss = 2.8562634e-05
step 500: mean loss = 4.1533225e-05
step 600: mean loss = 3.564752e-05
step 700: mean loss = 3.1273146e-05
step 800: mean loss = 3.2196534e-05
step 900: mean loss = 3.5274777e-05
step 1000: mean loss = 3.72492e-05
step 1100: mean loss = 3.7839684e-05
step 1200: mean loss = 3.5506764e-05
epoch 24: mean loss = 3.4580822e-05  learning rate = 0.00090249995
============================
Start of epoch 25
step 0: mean loss = 4.420523e-06
step 100: mean loss = 1.6542295e-05
step 200: mean loss = 2.6351212e-05
step 300: mean loss = 0.0050030802
step 400: mean loss = 0.011350746
step 500: mean loss = 0.009687396
step 600: mean loss = 0.008404034
step 700: mean loss = 0.007313919
step 800: mean loss = 0.006448714
step 900: mean loss = 0.005763861
step 1000: mean loss = 0.005210071
step 1100: mean loss = 0.0047535556
step 1200: mean loss = 0.0043700156
epoch 25: mean loss = 0.0042432747  learning rate = 0.00090249995
============================
Start of epoch 26
step 0: mean loss = 0.00012483739
step 100: mean loss = 0.00011841464
step 200: mean loss = 0.00010652197
step 300: mean loss = 9.900549e-05
step 400: mean loss = 9.0434485e-05
step 500: mean loss = 8.3951265e-05
step 600: mean loss = 7.7382465e-05
step 700: mean loss = 7.232338e-05
step 800: mean loss = 6.80774e-05
step 900: mean loss = 6.361956e-05
step 1000: mean loss = 6.04484e-05
step 1100: mean loss = 5.6972545e-05
step 1200: mean loss = 5.456638e-05
epoch 26: mean loss = 5.3516516e-05  learning rate = 0.00090249995
============================
Start of epoch 27
step 0: mean loss = 1.8657536e-05
step 100: mean loss = 1.792631e-05
step 200: mean loss = 2.229054e-05
step 300: mean loss = 2.0078574e-05
step 400: mean loss = 2.268167e-05
step 500: mean loss = 2.0938756e-05
step 600: mean loss = 2.1522173e-05
step 700: mean loss = 2.0427777e-05
step 800: mean loss = 2.1202424e-05
step 900: mean loss = 2.026834e-05
step 1000: mean loss = 2.061605e-05
step 1100: mean loss = 1.9851617e-05
step 1200: mean loss = 2.0247679e-05
epoch 27: mean loss = 1.9936544e-05  learning rate = 0.00090249995
============================
Start of epoch 28
step 0: mean loss = 9.338356e-06
step 100: mean loss = 2.4140012e-05
step 200: mean loss = 1.6860318e-05
step 300: mean loss = 1.9257388e-05
step 400: mean loss = 2.1019201e-05
step 500: mean loss = 2.1620295e-05
step 600: mean loss = 2.2416727e-05
step 700: mean loss = 2.1535518e-05
step 800: mean loss = 2.2258893e-05
step 900: mean loss = 2.25491e-05
step 1000: mean loss = 2.2700206e-05
step 1100: mean loss = 2.3702862e-05
step 1200: mean loss = 2.431198e-05
epoch 28: mean loss = 2.4122985e-05  learning rate = 0.00090249995
============================
Start of epoch 29
step 0: mean loss = 1.1616284e-05
step 100: mean loss = 4.601078e-05
step 200: mean loss = 3.5323883e-05
step 300: mean loss = 3.2406027e-05
step 400: mean loss = 3.3341716e-05
step 500: mean loss = 3.6120135e-05
step 600: mean loss = 3.560866e-05
step 700: mean loss = 3.4772987e-05
step 800: mean loss = 3.402388e-05
step 900: mean loss = 3.3764067e-05
step 1000: mean loss = 4.0305113e-05
step 1100: mean loss = 3.7516365e-05
step 1200: mean loss = 0.0042328173
epoch 29: mean loss = 0.004185194  learning rate = 0.00090249995
============================
Start of epoch 30
step 0: mean loss = 0.0011886854
step 100: mean loss = 0.0007389722
step 200: mean loss = 0.0005547882
step 300: mean loss = 0.0004442332
step 400: mean loss = 0.00037033806
step 500: mean loss = 0.00032031751
step 600: mean loss = 0.00028925674
step 700: mean loss = 0.00025845296
step 800: mean loss = 0.0004586607
step 900: mean loss = 0.00044627616
step 1000: mean loss = 0.00041474495
step 1100: mean loss = 0.00038093605
step 1200: mean loss = 0.0003525708
epoch 30: mean loss = 0.000343263  learning rate = 0.0008573749
============================
Start of epoch 31
step 0: mean loss = 3.0431906e-05
step 100: mean loss = 2.756732e-05
step 200: mean loss = 2.9636942e-05
step 300: mean loss = 2.8871844e-05
step 400: mean loss = 2.8449302e-05
step 500: mean loss = 2.7576523e-05
step 600: mean loss = 2.660438e-05
step 700: mean loss = 2.578901e-05
step 800: mean loss = 2.4935765e-05
step 900: mean loss = 2.4358473e-05
step 1000: mean loss = 2.4036344e-05
step 1100: mean loss = 2.3693583e-05
step 1200: mean loss = 2.3341658e-05
epoch 31: mean loss = 2.330211e-05  learning rate = 0.0008573749
============================
Start of epoch 32
step 0: mean loss = 1.2202601e-05
step 100: mean loss = 2.140035e-05
step 200: mean loss = 2.076116e-05
step 300: mean loss = 2.1918037e-05
step 400: mean loss = 2.092199e-05
step 500: mean loss = 2.1307367e-05
step 600: mean loss = 2.2879702e-05
step 700: mean loss = 2.2548276e-05
step 800: mean loss = 2.2290484e-05
step 900: mean loss = 2.4870265e-05
step 1000: mean loss = 2.476298e-05
step 1100: mean loss = 2.4952727e-05
step 1200: mean loss = 2.510626e-05
epoch 32: mean loss = 2.9014212e-05  learning rate = 0.0008573749
============================
Start of epoch 33
step 0: mean loss = 1.9773466e-05
step 100: mean loss = 2.7121845e-05
step 200: mean loss = 2.4061901e-05
step 300: mean loss = 2.5206127e-05
step 400: mean loss = 2.609011e-05
step 500: mean loss = 2.6964517e-05
step 600: mean loss = 3.106203e-05
step 700: mean loss = 3.0826508e-05
step 800: mean loss = 3.160767e-05
step 900: mean loss = 3.1932672e-05
step 1000: mean loss = 3.2586027e-05
step 1100: mean loss = 3.297715e-05
step 1200: mean loss = 3.305926e-05
epoch 33: mean loss = 3.504653e-05  learning rate = 0.0008573749
============================
Start of epoch 34
step 0: mean loss = 2.1761685e-05
step 100: mean loss = 2.5318408e-05
step 200: mean loss = 3.19777e-05
step 300: mean loss = 3.4060256e-05
step 400: mean loss = 3.5407258e-05
step 500: mean loss = 4.4619366e-05
step 600: mean loss = 3.940494e-05
step 700: mean loss = 3.923464e-05
step 800: mean loss = 3.7139034e-05
step 900: mean loss = 3.6459376e-05
step 1000: mean loss = 3.6232832e-05
step 1100: mean loss = 0.001568372
step 1200: mean loss = 0.0014783632
epoch 34: mean loss = 0.0014403921  learning rate = 0.0008573749
============================
Start of epoch 35
step 0: mean loss = 0.00014818953
step 100: mean loss = 0.00017476524
step 200: mean loss = 0.00012724355
step 300: mean loss = 0.000103385486
step 400: mean loss = 8.775693e-05
step 500: mean loss = 7.705809e-05
step 600: mean loss = 6.8090245e-05
step 700: mean loss = 6.2056504e-05
step 800: mean loss = 5.7019974e-05
step 900: mean loss = 5.2167394e-05
step 1000: mean loss = 4.9392387e-05
step 1100: mean loss = 4.659391e-05
step 1200: mean loss = 4.3449003e-05
epoch 35: mean loss = 4.3112283e-05  learning rate = 0.0008573749
============================
Start of epoch 36
step 0: mean loss = 1.1870833e-05
step 100: mean loss = 9.194486e-06
step 200: mean loss = 1.2266878e-05
step 300: mean loss = 1.2284689e-05
step 400: mean loss = 1.2437592e-05
step 500: mean loss = 1.189865e-05
step 600: mean loss = 1.20941995e-05
step 700: mean loss = 1.21574785e-05
step 800: mean loss = 1.205947e-05
step 900: mean loss = 1.1857051e-05
step 1000: mean loss = 1.1779911e-05
step 1100: mean loss = 1.1739353e-05
step 1200: mean loss = 1.1793295e-05
epoch 36: mean loss = 1.1784943e-05  learning rate = 0.0008573749
============================
Start of epoch 37
step 0: mean loss = 4.8781717e-06
step 100: mean loss = 1.1851635e-05
step 200: mean loss = 1.19858505e-05
step 300: mean loss = 1.1618755e-05
step 400: mean loss = 1.1768117e-05
step 500: mean loss = 1.1872256e-05
step 600: mean loss = 1.2081051e-05
step 700: mean loss = 1.260381e-05
step 800: mean loss = 1.3024882e-05
step 900: mean loss = 1.3665856e-05
step 1000: mean loss = 1.4357892e-05
step 1100: mean loss = 1.4700564e-05
step 1200: mean loss = 1.6123864e-05
epoch 37: mean loss = 1.592461e-05  learning rate = 0.0008573749
============================
Start of epoch 38
step 0: mean loss = 5.896809e-06
step 100: mean loss = 2.3812803e-05
step 200: mean loss = 2.458833e-05
step 300: mean loss = 2.5701145e-05
step 400: mean loss = 2.488316e-05
step 500: mean loss = 2.621202e-05
step 600: mean loss = 2.573509e-05
step 700: mean loss = 2.634718e-05
step 800: mean loss = 2.6287275e-05
step 900: mean loss = 2.6168464e-05
step 1000: mean loss = 2.6877215e-05
step 1100: mean loss = 2.6370133e-05
step 1200: mean loss = 2.6543397e-05
epoch 38: mean loss = 2.6855028e-05  learning rate = 0.0008573749
============================
Start of epoch 39
step 0: mean loss = 0.0001289681
step 100: mean loss = 2.3626644e-05
step 200: mean loss = 2.2908602e-05
step 300: mean loss = 2.8885112e-05
step 400: mean loss = 2.6393742e-05
step 500: mean loss = 2.6317814e-05
step 600: mean loss = 2.6686166e-05
step 700: mean loss = 2.695233e-05
step 800: mean loss = 2.77345e-05
step 900: mean loss = 2.7501143e-05
step 1000: mean loss = 2.6735606e-05
step 1100: mean loss = 2.7092772e-05
step 1200: mean loss = 2.7300686e-05
epoch 39: mean loss = 2.681681e-05  learning rate = 0.0008573749
============================
Start of epoch 40
step 0: mean loss = 2.814986e-05
step 100: mean loss = 3.3882883e-05
step 200: mean loss = 2.6455918e-05
step 300: mean loss = 2.7605924e-05
step 400: mean loss = 2.6536796e-05
step 500: mean loss = 2.5969606e-05
step 600: mean loss = 2.3448445e-05
step 700: mean loss = 2.3107983e-05
step 800: mean loss = 2.2856168e-05
step 900: mean loss = 2.3395802e-05
step 1000: mean loss = 0.00049569854
step 1100: mean loss = 0.0005170068
step 1200: mean loss = 0.0005008806
epoch 40: mean loss = 0.00049100554  learning rate = 0.0008145062
============================
Start of epoch 41
step 0: mean loss = 9.789994e-05
step 100: mean loss = 7.401177e-05
step 200: mean loss = 9.080841e-05
step 300: mean loss = 8.0329286e-05
step 400: mean loss = 7.0178154e-05
step 500: mean loss = 6.344278e-05
step 600: mean loss = 5.8426143e-05
step 700: mean loss = 5.3742373e-05
step 800: mean loss = 4.9666032e-05
step 900: mean loss = 4.609352e-05
step 1000: mean loss = 4.3318283e-05
step 1100: mean loss = 4.0933475e-05
step 1200: mean loss = 3.861772e-05
epoch 41: mean loss = 3.7798687e-05  learning rate = 0.0008145062
============================
Start of epoch 42
step 0: mean loss = 1.812495e-05
step 100: mean loss = 1.1977004e-05
step 200: mean loss = 1.1212852e-05
step 300: mean loss = 1.1006135e-05
step 400: mean loss = 1.0549211e-05
step 500: mean loss = 1.0282073e-05
step 600: mean loss = 9.969005e-06
step 700: mean loss = 9.691681e-06
step 800: mean loss = 9.438733e-06
step 900: mean loss = 9.157711e-06
step 1000: mean loss = 8.904308e-06
step 1100: mean loss = 8.690641e-06
step 1200: mean loss = 8.497221e-06
epoch 42: mean loss = 8.486005e-06  learning rate = 0.0008145062
============================
Start of epoch 43
step 0: mean loss = 4.9231703e-06
step 100: mean loss = 1.0434827e-05
step 200: mean loss = 9.112447e-06
step 300: mean loss = 1.1183143e-05
step 400: mean loss = 1.0733355e-05
step 500: mean loss = 1.0799695e-05
step 600: mean loss = 1.1242249e-05
step 700: mean loss = 1.3674914e-05
step 800: mean loss = 1.3146363e-05
step 900: mean loss = 1.3241711e-05
step 1000: mean loss = 1.3740601e-05
step 1100: mean loss = 1.4000671e-05
step 1200: mean loss = 1.6542715e-05
epoch 43: mean loss = 1.6155327e-05  learning rate = 0.0008145062
============================
Start of epoch 44
step 0: mean loss = 3.4211678e-06
step 100: mean loss = 1.2258823e-05
step 200: mean loss = 1.2259956e-05
step 300: mean loss = 1.6468402e-05
step 400: mean loss = 1.6821652e-05
step 500: mean loss = 2.329391e-05
step 600: mean loss = 2.140666e-05
step 700: mean loss = 2.0649462e-05
step 800: mean loss = 1.9942738e-05
step 900: mean loss = 1.9859423e-05
step 1000: mean loss = 2.0609828e-05
step 1100: mean loss = 0.0003145637
step 1200: mean loss = 0.0009488841
epoch 44: mean loss = 0.0009267735  learning rate = 0.0008145062
============================
Start of epoch 45
step 0: mean loss = 0.00015695379
step 100: mean loss = 0.00011528216
step 200: mean loss = 9.021775e-05
step 300: mean loss = 7.514438e-05
step 400: mean loss = 6.511437e-05
step 500: mean loss = 5.7799483e-05
step 600: mean loss = 5.2121057e-05
step 700: mean loss = 4.7804497e-05
step 800: mean loss = 4.406113e-05
step 900: mean loss = 4.1181178e-05
step 1000: mean loss = 3.8653903e-05
step 1100: mean loss = 3.6374688e-05
step 1200: mean loss = 3.4479504e-05
epoch 45: mean loss = 3.384995e-05  learning rate = 0.0008145062
============================
Start of epoch 46
step 0: mean loss = 1.7567465e-05
step 100: mean loss = 1.3738258e-05
step 200: mean loss = 1.9981566e-05
step 300: mean loss = 1.722068e-05
step 400: mean loss = 1.5001575e-05
step 500: mean loss = 1.4131194e-05
step 600: mean loss = 1.31254155e-05
step 700: mean loss = 1.2672296e-05
step 800: mean loss = 1.2299568e-05
step 900: mean loss = 1.2428751e-05
step 1000: mean loss = 1.2789483e-05
step 1100: mean loss = 1.2173798e-05
step 1200: mean loss = 1.1977505e-05
epoch 46: mean loss = 1.2289611e-05  learning rate = 0.0008145062
============================
Start of epoch 47
step 0: mean loss = 1.0077019e-05
step 100: mean loss = 7.93007e-06
step 200: mean loss = 1.2979192e-05
step 300: mean loss = 1.1145618e-05
step 400: mean loss = 1.10644505e-05
step 500: mean loss = 1.1765856e-05
step 600: mean loss = 1.38091555e-05
step 700: mean loss = 1.3312777e-05
step 800: mean loss = 1.4002329e-05
step 900: mean loss = 1.4524061e-05
step 1000: mean loss = 1.5493279e-05
step 1100: mean loss = 1.6371469e-05
step 1200: mean loss = 1.542497e-05
epoch 47: mean loss = 1.6875667e-05  learning rate = 0.0008145062
============================
Start of epoch 48
step 0: mean loss = 5.7115984e-05
step 100: mean loss = 9.444181e-06
step 200: mean loss = 2.3277293e-05
step 300: mean loss = 1.742068e-05
step 400: mean loss = 1.7350683e-05
step 500: mean loss = 1.939597e-05
step 600: mean loss = 2.0319058e-05
step 700: mean loss = 1.8980742e-05
step 800: mean loss = 1.8712899e-05
step 900: mean loss = 2.0705033e-05
step 1000: mean loss = 2.0898777e-05
step 1100: mean loss = 1.951138e-05
step 1200: mean loss = 2.0522815e-05
epoch 48: mean loss = 2.0009598e-05  learning rate = 0.0008145062
============================
Start of epoch 49
step 0: mean loss = 3.6984807e-06
step 100: mean loss = 3.0205734e-05
step 200: mean loss = 3.410492e-05
step 300: mean loss = 2.8161781e-05
step 400: mean loss = 2.1932276e-05
step 500: mean loss = 2.415786e-05
step 600: mean loss = 2.0645753e-05
step 700: mean loss = 2.5891666e-05
step 800: mean loss = 2.304498e-05
step 900: mean loss = 2.424229e-05
step 1000: mean loss = 2.2231092e-05
step 1100: mean loss = 2.3120236e-05
step 1200: mean loss = 2.3049519e-05
epoch 49: mean loss = 2.2444185e-05  learning rate = 0.0008145062
============================
Start of epoch 50
step 0: mean loss = 2.7324522e-06
step 100: mean loss = 2.9363935e-05
step 200: mean loss = 1.6129907e-05
step 300: mean loss = 2.4216122e-05
step 400: mean loss = 2.1707589e-05
step 500: mean loss = 2.0945039e-05
step 600: mean loss = 1.7921195e-05
step 700: mean loss = 1.5702146e-05
step 800: mean loss = 1.8088025e-05
step 900: mean loss = 1.7570403e-05
step 1000: mean loss = 1.7220877e-05
step 1100: mean loss = 1.5842481e-05
step 1200: mean loss = 2.143914e-05
epoch 50: mean loss = 2.0880578e-05  learning rate = 0.00077378086
============================
Start of epoch 51
step 0: mean loss = 2.5012862e-06
step 100: mean loss = 2.300281e-06
step 200: mean loss = 2.1733706e-06
step 300: mean loss = 1.1373833e-05
step 400: mean loss = 9.032038e-06
step 500: mean loss = 1.1040357e-05
step 600: mean loss = 1.06361485e-05
step 700: mean loss = 9.359487e-06
step 800: mean loss = 1.4760411e-05
step 900: mean loss = 1.4895938e-05
step 1000: mean loss = 1.3691651e-05
step 1100: mean loss = 1.48884355e-05
step 1200: mean loss = 1.38517335e-05
epoch 51: mean loss = 1.3484143e-05  learning rate = 0.00077378086
============================
Start of epoch 52
step 0: mean loss = 1.5134888e-06
step 100: mean loss = 2.5760677e-05
step 200: mean loss = 1.3772569e-05
step 300: mean loss = 1.8086012e-05
step 400: mean loss = 1.42402505e-05
step 500: mean loss = 1.4267976e-05
step 600: mean loss = 1.598507e-05
step 700: mean loss = 1.5797381e-05
step 800: mean loss = 1.5831649e-05
step 900: mean loss = 1.46568955e-05
step 1000: mean loss = 1.5407306e-05
step 1100: mean loss = 1.485739e-05
step 1200: mean loss = 1.4393161e-05
epoch 52: mean loss = 1.4028527e-05  learning rate = 0.00077378086
============================
Start of epoch 53
step 0: mean loss = 2.383307e-05
step 100: mean loss = 1.731293e-05
step 200: mean loss = 2.5057987e-05
step 300: mean loss = 2.305291e-05
step 400: mean loss = 1.8255487e-05
step 500: mean loss = 1.9013714e-05
step 600: mean loss = 1.6041095e-05
step 700: mean loss = 1.855692e-05
step 800: mean loss = 1.660984e-05
step 900: mean loss = 1.6585524e-05
step 1000: mean loss = 1.5045657e-05
step 1100: mean loss = 1.5432126e-05
step 1200: mean loss = 1.4253e-05
epoch 53: mean loss = 1.3855199e-05  learning rate = 0.00077378086
============================
Start of epoch 54
step 0: mean loss = 9.280118e-07
step 100: mean loss = 2.366901e-05
step 200: mean loss = 1.2380897e-05
step 300: mean loss = 1.5745663e-05
step 400: mean loss = 1.5751268e-05
step 500: mean loss = 1.2821387e-05
step 600: mean loss = 1.51281465e-05
step 700: mean loss = 1.4281688e-05
step 800: mean loss = 1.4001737e-05
step 900: mean loss = 1.2560955e-05
step 1000: mean loss = 1.3075444e-05
step 1100: mean loss = 1.2484254e-05
step 1200: mean loss = 1.2168015e-05
epoch 54: mean loss = 1.192807e-05  learning rate = 0.00077378086
============================
Start of epoch 55
step 0: mean loss = 5.9955855e-05
step 100: mean loss = 1.8678673e-05
step 200: mean loss = 1.4673615e-05
step 300: mean loss = 1.0304665e-05
step 400: mean loss = 0.0012117795
step 500: mean loss = 0.0009877686
step 600: mean loss = 0.00083089975
step 700: mean loss = 0.0007171828
step 800: mean loss = 0.0006308938
step 900: mean loss = 0.0005633452
step 1000: mean loss = 0.0005091128
step 1100: mean loss = 0.00046450933
step 1200: mean loss = 0.00042723506
epoch 55: mean loss = 0.00041493186  learning rate = 0.00077378086
============================
Start of epoch 56
step 0: mean loss = 1.5345093e-05
step 100: mean loss = 1.5072831e-05
step 200: mean loss = 1.4417006e-05
step 300: mean loss = 1.39761505e-05
step 400: mean loss = 1.3452141e-05
step 500: mean loss = 1.3086316e-05
step 600: mean loss = 1.2622386e-05
step 700: mean loss = 1.228681e-05
step 800: mean loss = 1.1961509e-05
step 900: mean loss = 1.1559532e-05
step 1000: mean loss = 1.1335527e-05
step 1100: mean loss = 1.0958567e-05
step 1200: mean loss = 1.0731196e-05
epoch 56: mean loss = 1.0716199e-05  learning rate = 0.00077378086
============================
Start of epoch 57
step 0: mean loss = 1.5576215e-05
step 100: mean loss = 6.7358687e-06
step 200: mean loss = 8.140207e-06
step 300: mean loss = 9.124146e-06
step 400: mean loss = 8.145829e-06
step 500: mean loss = 9.328699e-06
step 600: mean loss = 1.0585563e-05
step 700: mean loss = 9.71228e-06
step 800: mean loss = 1.1409463e-05
step 900: mean loss = 1.23306145e-05
step 1000: mean loss = 1.25309725e-05
step 1100: mean loss = 1.1739497e-05
step 1200: mean loss = 1.2509479e-05
epoch 57: mean loss = 1.2231934e-05  learning rate = 0.00077378086
============================
Start of epoch 58
step 0: mean loss = 3.153745e-06
step 100: mean loss = 1.9540243e-05
step 200: mean loss = 1.3744546e-05
step 300: mean loss = 1.3487422e-05
step 400: mean loss = 1.4384524e-05
step 500: mean loss = 1.4832014e-05
step 600: mean loss = 1.2916015e-05
step 700: mean loss = 1.34610855e-05
step 800: mean loss = 1.3552861e-05
step 900: mean loss = 1.4255915e-05
step 1000: mean loss = 1.3438791e-05
step 1100: mean loss = 1.3006466e-05
step 1200: mean loss = 1.485143e-05
epoch 58: mean loss = 1.44781525e-05  learning rate = 0.00077378086
============================
Start of epoch 59
step 0: mean loss = 2.0881732e-06
step 100: mean loss = 1.159974e-05
step 200: mean loss = 6.6259245e-06
step 300: mean loss = 1.6862738e-05
step 400: mean loss = 1.3077908e-05
step 500: mean loss = 1.3995612e-05
step 600: mean loss = 1.1902068e-05
step 700: mean loss = 1.3921946e-05
step 800: mean loss = 1.3294195e-05
step 900: mean loss = 1.2140015e-05
step 1000: mean loss = 2.281272e-05
step 1100: mean loss = 4.1718013e-05
step 1200: mean loss = 3.9161998e-05
epoch 59: mean loss = 3.8204867e-05  learning rate = 0.00077378086
============================
Start of epoch 60
step 0: mean loss = 6.4509645e-06
step 100: mean loss = 3.2694697e-05
step 200: mean loss = 1.8306182e-05
step 300: mean loss = 1.3101537e-05
step 400: mean loss = 1.036862e-05
step 500: mean loss = 8.66693e-06
step 600: mean loss = 1.0210831e-05
step 700: mean loss = 8.994051e-06
step 800: mean loss = 8.051236e-06
step 900: mean loss = 7.3039314e-06
step 1000: mean loss = 6.6961793e-06
step 1100: mean loss = 7.998103e-06
step 1200: mean loss = 7.4337495e-06
epoch 60: mean loss = 7.245053e-06  learning rate = 0.00073509186
============================
Start of epoch 61
step 0: mean loss = 1.1047273e-06
step 100: mean loss = 1.0694416e-06
step 200: mean loss = 1.4582148e-05
step 300: mean loss = 1.0209854e-05
step 400: mean loss = 7.914825e-06
step 500: mean loss = 6.525268e-06
step 600: mean loss = 1.1013565e-05
step 700: mean loss = 9.5883215e-06
step 800: mean loss = 1.114467e-05
step 900: mean loss = 1.0016021e-05
step 1000: mean loss = 9.102146e-06
step 1100: mean loss = 9.929622e-06
step 1200: mean loss = 9.3525005e-06
epoch 61: mean loss = 9.574172e-06  learning rate = 0.00073509186
============================
Start of epoch 62
step 0: mean loss = 5.201931e-06
step 100: mean loss = 1.1543659e-06
step 200: mean loss = 8.469036e-06
step 300: mean loss = 6.0871257e-06
step 400: mean loss = 7.107323e-06
step 500: mean loss = 5.8349897e-06
step 600: mean loss = 1.0878976e-05
step 700: mean loss = 9.467689e-06
step 800: mean loss = 8.37631e-06
step 900: mean loss = 7.523004e-06
step 1000: mean loss = 8.756068e-06
step 1100: mean loss = 8.0277305e-06
step 1200: mean loss = 8.6326845e-06
epoch 62: mean loss = 8.477379e-06  learning rate = 0.00073509186
============================
Start of epoch 63
step 0: mean loss = 7.551657e-07
step 100: mean loss = 6.716147e-07
step 200: mean loss = 8.625004e-06
step 300: mean loss = 6.0166417e-06
step 400: mean loss = 8.060875e-06
step 500: mean loss = 6.578918e-06
step 600: mean loss = 9.2435575e-06
step 700: mean loss = 8.472218e-06
step 800: mean loss = 7.4875493e-06
step 900: mean loss = 8.084579e-06
step 1000: mean loss = 7.3380115e-06
step 1100: mean loss = 7.934403e-06
step 1200: mean loss = 7.332233e-06
epoch 63: mean loss = 7.1374116e-06  learning rate = 0.00073509186
============================
Start of epoch 64
step 0: mean loss = 7.2300736e-06
step 100: mean loss = 1.4318284e-05
step 200: mean loss = 1.1638298e-05
step 300: mean loss = 8.488004e-06
step 400: mean loss = 9.159603e-06
step 500: mean loss = 7.4835725e-06
step 600: mean loss = 8.377123e-06
step 700: mean loss = 8.1574435e-06
step 800: mean loss = 7.2198773e-06
step 900: mean loss = 7.821815e-06
step 1000: mean loss = 7.727965e-06
step 1100: mean loss = 7.1087234e-06
step 1200: mean loss = 7.415119e-06
epoch 64: mean loss = 7.631911e-06  learning rate = 0.00073509186
============================
Start of epoch 65
step 0: mean loss = 2.3230654e-05
step 100: mean loss = 3.3943816e-06
step 200: mean loss = 8.384198e-06
step 300: mean loss = 7.755368e-06
step 400: mean loss = 6.2704667e-06
step 500: mean loss = 8.6092205e-06
step 600: mean loss = 1.7257256e-05
step 700: mean loss = 1.4882871e-05
step 800: mean loss = 1.30865765e-05
step 900: mean loss = 1.1683615e-05
step 1000: mean loss = 1.1503545e-05
step 1100: mean loss = 1.0504745e-05
step 1200: mean loss = 1.025244e-05
epoch 65: mean loss = 1.0298147e-05  learning rate = 0.00073509186
============================
Start of epoch 66
step 0: mean loss = 8.1018516e-07
step 100: mean loss = 5.7950047e-07
step 200: mean loss = 5.3964573e-06
step 300: mean loss = 3.9026663e-06
step 400: mean loss = 6.6563825e-06
step 500: mean loss = 1.1438078e-05
step 600: mean loss = 9.620779e-06
step 700: mean loss = 8.311979e-06
step 800: mean loss = 8.043653e-06
step 900: mean loss = 7.354134e-06
step 1000: mean loss = 6.6622842e-06
step 1100: mean loss = 7.3445663e-06
step 1200: mean loss = 6.7717674e-06
epoch 66: mean loss = 6.582105e-06  learning rate = 0.00073509186
============================
Start of epoch 67
step 0: mean loss = 4.6831548e-07
step 100: mean loss = 9.313562e-06
step 200: mean loss = 9.276812e-06
step 300: mean loss = 6.4872734e-06
step 400: mean loss = 7.0491283e-06
step 500: mean loss = 7.315855e-06
step 600: mean loss = 6.792415e-06
step 700: mean loss = 6.7230667e-06
step 800: mean loss = 6.048474e-06
step 900: mean loss = 6.4900128e-06
step 1000: mean loss = 6.318824e-06
step 1100: mean loss = 6.367852e-06
step 1200: mean loss = 6.407348e-06
epoch 67: mean loss = 6.3388206e-06  learning rate = 0.00073509186
============================
Start of epoch 68
step 0: mean loss = 8.177705e-07
step 100: mean loss = 3.96849e-06
step 200: mean loss = 6.290716e-06
step 300: mean loss = 5.9676886e-06
step 400: mean loss = 5.590115e-06
step 500: mean loss = 4.996392e-06
step 600: mean loss = 5.5926357e-06
step 700: mean loss = 5.5139076e-06
step 800: mean loss = 5.9866047e-06
step 900: mean loss = 5.8100495e-06
step 1000: mean loss = 5.6974545e-06
step 1100: mean loss = 5.346744e-06
step 1200: mean loss = 6.2094473e-06
epoch 68: mean loss = 6.0388033e-06  learning rate = 0.00073509186
============================
Start of epoch 69
step 0: mean loss = 3.9900317e-07
step 100: mean loss = 3.679403e-07
step 200: mean loss = 4.4693033e-06
step 300: mean loss = 5.251198e-06
step 400: mean loss = 4.141797e-06
step 500: mean loss = 5.572131e-06
step 600: mean loss = 5.132212e-06
step 700: mean loss = 5.174272e-06
step 800: mean loss = 5.517284e-06
step 900: mean loss = 5.344581e-06
step 1000: mean loss = 5.32658e-06
step 1100: mean loss = 5.0694803e-06
step 1200: mean loss = 6.5123177e-06
epoch 69: mean loss = 6.3304205e-06  learning rate = 0.00073509186
============================
Start of epoch 70
step 0: mean loss = 3.8183177e-07
step 100: mean loss = 3.525161e-07
step 200: mean loss = 1.3237789e-06
step 300: mean loss = 2.1904832e-06
step 400: mean loss = 2.7587025e-06
step 500: mean loss = 9.440949e-06
step 600: mean loss = 7.9431e-06
step 700: mean loss = 6.8601857e-06
step 800: mean loss = 6.5156305e-06
step 900: mean loss = 5.842372e-06
step 1000: mean loss = 5.290127e-06
step 1100: mean loss = 5.3405365e-06
step 1200: mean loss = 4.9241107e-06
epoch 70: mean loss = 4.7877543e-06  learning rate = 0.0006983372
============================
Start of epoch 71
step 0: mean loss = 1.6661336e-06
step 100: mean loss = 1.2933855e-05
step 200: mean loss = 9.004456e-06
step 300: mean loss = 6.284931e-06
step 400: mean loss = 6.910307e-06
step 500: mean loss = 5.775046e-06
step 600: mean loss = 5.9614363e-06
step 700: mean loss = 5.172555e-06
step 800: mean loss = 5.4620705e-06
step 900: mean loss = 5.360462e-06
step 1000: mean loss = 4.878612e-06
step 1100: mean loss = 5.2882137e-06
step 1200: mean loss = 5.153728e-06
epoch 71: mean loss = 5.011408e-06  learning rate = 0.0006983372
============================
Start of epoch 72
step 0: mean loss = 3.2510613e-07
step 100: mean loss = 5.979356e-06
step 200: mean loss = 3.203971e-06
step 300: mean loss = 4.5976094e-06
step 400: mean loss = 4.1610565e-06
step 500: mean loss = 4.3803543e-06
step 600: mean loss = 5.3656513e-06
step 700: mean loss = 4.959778e-06
step 800: mean loss = 5.0730873e-06
step 900: mean loss = 4.5993816e-06
step 1000: mean loss = 5.6812573e-06
step 1100: mean loss = 0.00022668127
step 1200: mean loss = 0.00021254356
epoch 72: mean loss = 0.00020740512  learning rate = 0.0006983372
============================
Start of epoch 73
step 0: mean loss = 3.8495942e-05
step 100: mean loss = 3.4048066e-05
step 200: mean loss = 3.051604e-05
step 300: mean loss = 2.7546748e-05
step 400: mean loss = 2.4972569e-05
step 500: mean loss = 2.2712786e-05
step 600: mean loss = 2.0740712e-05
step 700: mean loss = 1.9042016e-05
step 800: mean loss = 1.7576433e-05
step 900: mean loss = 1.6297705e-05
step 1000: mean loss = 1.5175361e-05
step 1100: mean loss = 1.4188242e-05
step 1200: mean loss = 1.39900885e-05
epoch 73: mean loss = 1.377309e-05  learning rate = 0.0006983372
============================
Start of epoch 74
step 0: mean loss = 3.8576636e-06
step 100: mean loss = 3.179907e-06
step 200: mean loss = 5.708777e-06
step 300: mean loss = 5.346685e-06
step 400: mean loss = 4.5797174e-06
step 500: mean loss = 5.257416e-06
step 600: mean loss = 4.6991127e-06
step 700: mean loss = 4.5177485e-06
step 800: mean loss = 4.6597215e-06
step 900: mean loss = 4.3062146e-06
step 1000: mean loss = 4.030054e-06
step 1100: mean loss = 4.1971803e-06
step 1200: mean loss = 3.947101e-06
epoch 74: mean loss = 3.863223e-06  learning rate = 0.0006983372
============================
Start of epoch 75
step 0: mean loss = 1.1270429e-06
step 100: mean loss = 1.0947924e-06
step 200: mean loss = 4.742111e-06
step 300: mean loss = 3.4975826e-06
step 400: mean loss = 2.8582144e-06
step 500: mean loss = 2.4638161e-06
step 600: mean loss = 2.19307e-06
step 700: mean loss = 2.475868e-06
step 800: mean loss = 2.3071098e-06
step 900: mean loss = 2.1333885e-06
step 1000: mean loss = 1.9902177e-06
step 1100: mean loss = 2.2440847e-06
step 1200: mean loss = 2.4782007e-06
epoch 75: mean loss = 2.5247489e-06  learning rate = 0.0006983372
============================
Start of epoch 76
step 0: mean loss = 6.7248163e-07
step 100: mean loss = 2.99417e-06
step 200: mean loss = 3.258402e-06
step 300: mean loss = 4.2192023e-06
step 400: mean loss = 3.6515323e-06
step 500: mean loss = 4.5693637e-06
step 600: mean loss = 4.161854e-06
step 700: mean loss = 5.2226183e-06
step 800: mean loss = 4.6508007e-06
step 900: mean loss = 4.3326277e-06
step 1000: mean loss = 5.0051376e-06
step 1100: mean loss = 4.588793e-06
step 1200: mean loss = 4.2601605e-06
epoch 76: mean loss = 6.1805604e-06  learning rate = 0.0006983372
============================
Start of epoch 77
step 0: mean loss = 8.572347e-06
step 100: mean loss = 1.5759434e-06
step 200: mean loss = 1.0111825e-06
step 300: mean loss = 8.089806e-07
step 400: mean loss = 3.1828126e-06
step 500: mean loss = 2.6146545e-06
step 600: mean loss = 2.2345625e-06
step 700: mean loss = 3.3687936e-06
step 800: mean loss = 3.0531028e-06
step 900: mean loss = 9.671855e-06
step 1000: mean loss = 9.275265e-06
step 1100: mean loss = 9.488949e-06
step 1200: mean loss = 8.9439945e-06
epoch 77: mean loss = 8.697766e-06  learning rate = 0.0006983372
============================
Start of epoch 78
step 0: mean loss = 6.4230875e-07
step 100: mean loss = 5.4399163e-07
step 200: mean loss = 4.9074e-07
step 300: mean loss = 3.7331645e-06
step 400: mean loss = 2.9005014e-06
step 500: mean loss = 2.3854e-06
step 600: mean loss = 2.0383668e-06
step 700: mean loss = 2.9816854e-06
step 800: mean loss = 2.7104636e-06
step 900: mean loss = 2.8477727e-06
step 1000: mean loss = 2.7782557e-06
step 1100: mean loss = 5.7231373e-06
step 1200: mean loss = 5.3527356e-06
epoch 78: mean loss = 5.202445e-06  learning rate = 0.0006983372
============================
Start of epoch 79
step 0: mean loss = 3.1666914e-07
step 100: mean loss = 3.0347888e-07
step 200: mean loss = 2.944843e-07
step 300: mean loss = 2.8735707e-07
step 400: mean loss = 2.8121264e-07
step 500: mean loss = 1.0602625e-06
step 600: mean loss = 9.308766e-07
step 700: mean loss = 4.0238847e-06
step 800: mean loss = 3.5572994e-06
step 900: mean loss = 3.1914506e-06
step 1000: mean loss = 2.8975744e-06
step 1100: mean loss = 5.2110604e-06
step 1200: mean loss = 4.8182096e-06
epoch 79: mean loss = 4.6824625e-06  learning rate = 0.0006983372
============================
Start of epoch 80
step 0: mean loss = 2.723942e-07
step 100: mean loss = 2.6547838e-07
step 200: mean loss = 2.6026575e-07
step 300: mean loss = 2.5572882e-07
step 400: mean loss = 7.327916e-06
step 500: mean loss = 6.0705274e-06
step 600: mean loss = 5.107814e-06
step 700: mean loss = 4.417133e-06
step 800: mean loss = 4.6536984e-06
step 900: mean loss = 4.2324373e-06
step 1000: mean loss = 3.834647e-06
step 1100: mean loss = 3.5081162e-06
step 1200: mean loss = 4.417286e-06
epoch 80: mean loss = 4.2956367e-06  learning rate = 0.00066342036
============================
Start of epoch 81
step 0: mean loss = 2.750567e-07
step 100: mean loss = 2.610623e-07
step 200: mean loss = 3.5419528e-06
step 300: mean loss = 2.4526112e-06
step 400: mean loss = 1.9062395e-06
step 500: mean loss = 3.7582877e-06
step 600: mean loss = 3.1796158e-06
step 700: mean loss = 3.4254583e-06
step 800: mean loss = 3.027432e-06
step 900: mean loss = 4.3954274e-06
step 1000: mean loss = 3.985081e-06
step 1100: mean loss = 3.6472363e-06
step 1200: mean loss = 3.9622078e-06
epoch 81: mean loss = 3.8512126e-06  learning rate = 0.00066342036
============================
Start of epoch 82
step 0: mean loss = 2.429865e-07
step 100: mean loss = 2.3563041e-07
step 200: mean loss = 4.16097e-06
step 300: mean loss = 2.8891948e-06
step 400: mean loss = 3.3387514e-06
step 500: mean loss = 2.7193119e-06
step 600: mean loss = 4.0359355e-06
step 700: mean loss = 3.4958966e-06
step 800: mean loss = 3.802099e-06
step 900: mean loss = 3.4842128e-06
step 1000: mean loss = 3.1620118e-06
step 1100: mean loss = 4.098819e-06
step 1200: mean loss = 3.7780135e-06
epoch 82: mean loss = 3.7289637e-06  learning rate = 0.00066342036
============================
Start of epoch 83
step 0: mean loss = 4.4896784e-05
step 100: mean loss = 6.2198133e-06
step 200: mean loss = 3.2381283e-06
step 300: mean loss = 4.018865e-06
step 400: mean loss = 4.7707103e-06
step 500: mean loss = 4.176493e-06
step 600: mean loss = 4.1059047e-06
step 700: mean loss = 3.550777e-06
step 800: mean loss = 4.026724e-06
step 900: mean loss = 3.6051188e-06
step 1000: mean loss = 3.7257344e-06
step 1100: mean loss = 3.4190257e-06
step 1200: mean loss = 3.4506272e-06
epoch 83: mean loss = 3.610694e-06  learning rate = 0.00066342036
============================
Start of epoch 84
step 0: mean loss = 2.3890601e-05
step 100: mean loss = 2.5703919e-06
step 200: mean loss = 5.681115e-06
step 300: mean loss = 3.873548e-06
step 400: mean loss = 4.1016588e-06
step 500: mean loss = 1.2598328e-05
step 600: mean loss = 1.0557045e-05
step 700: mean loss = 9.088249e-06
step 800: mean loss = 7.983439e-06
step 900: mean loss = 7.1223294e-06
step 1000: mean loss = 6.432225e-06
step 1100: mean loss = 5.8666933e-06
step 1200: mean loss = 5.6277863e-06
epoch 84: mean loss = 5.5722116e-06  learning rate = 0.00066342036
============================
Start of epoch 85
step 0: mean loss = 7.3125307e-07
step 100: mean loss = 2.4269602e-07
step 200: mean loss = 2.3964442e-06
step 300: mean loss = 1.6818984e-06
step 400: mean loss = 1.7701792e-06
step 500: mean loss = 3.6131598e-06
step 600: mean loss = 3.046688e-06
step 700: mean loss = 3.232849e-06
step 800: mean loss = 2.8551967e-06
step 900: mean loss = 3.3130323e-06
step 1000: mean loss = 3.0384806e-06
step 1100: mean loss = 3.0733781e-06
step 1200: mean loss = 3.1577747e-06
epoch 85: mean loss = 3.6672159e-06  learning rate = 0.00066342036
============================
Start of epoch 86
step 0: mean loss = 5.0765952e-06
step 100: mean loss = 5.2589405e-07
step 200: mean loss = 2.134558e-06
step 300: mean loss = 1.4909833e-06
step 400: mean loss = 2.2710974e-06
step 500: mean loss = 1.8560843e-06
step 600: mean loss = 2.2475613e-06
step 700: mean loss = 2.3899238e-06
step 800: mean loss = 2.6909497e-06
step 900: mean loss = 2.4383087e-06
step 1000: mean loss = 2.903021e-06
step 1100: mean loss = 2.8828442e-06
step 1200: mean loss = 2.6734983e-06
epoch 86: mean loss = 2.8527602e-06  learning rate = 0.00066342036
============================
Start of epoch 87
step 0: mean loss = 1.1782678e-06
step 100: mean loss = 5.4348095e-07
step 200: mean loss = 1.6263145e-06
step 300: mean loss = 3.8354246e-06
step 400: mean loss = 3.1709183e-06
step 500: mean loss = 3.1667105e-06
step 600: mean loss = 2.7613917e-06
step 700: mean loss = 3.013434e-06
step 800: mean loss = 3.175982e-06
step 900: mean loss = 2.9481944e-06
step 1000: mean loss = 2.9265632e-06
step 1100: mean loss = 3.0916058e-06
step 1200: mean loss = 3.6419835e-06
epoch 87: mean loss = 3.539124e-06  learning rate = 0.00066342036
============================
Start of epoch 88
step 0: mean loss = 1.9377279e-07
step 100: mean loss = 4.1503276e-06
step 200: mean loss = 2.183886e-06
step 300: mean loss = 3.137585e-06
step 400: mean loss = 2.4350143e-06
step 500: mean loss = 2.5200204e-06
step 600: mean loss = 2.6404668e-06
step 700: mean loss = 2.4413882e-06
step 800: mean loss = 2.5956313e-06
step 900: mean loss = 2.6616467e-06
step 1000: mean loss = 2.8297356e-06
step 1100: mean loss = 2.6471575e-06
step 1200: mean loss = 2.6875982e-06
epoch 88: mean loss = 2.6307935e-06  learning rate = 0.00066342036
============================
Start of epoch 89
step 0: mean loss = 2.858422e-07
step 100: mean loss = 7.2901903e-06
step 200: mean loss = 3.7634122e-06
step 300: mean loss = 3.8346393e-06
step 400: mean loss = 3.2996516e-06
step 500: mean loss = 3.4764123e-06
step 600: mean loss = 3.068758e-06
step 700: mean loss = 3.2014807e-06
step 800: mean loss = 3.3648248e-06
step 900: mean loss = 3.2658643e-06
step 1000: mean loss = 3.0171263e-06
step 1100: mean loss = 2.9838209e-06
step 1200: mean loss = 2.924818e-06
epoch 89: mean loss = 3.2040157e-06  learning rate = 0.00066342036
============================
Start of epoch 90
step 0: mean loss = 8.976487e-06
step 100: mean loss = 2.8851643e-06
step 200: mean loss = 1.7196263e-06
step 300: mean loss = 2.2872175e-06
step 400: mean loss = 2.8220522e-06
step 500: mean loss = 2.3419811e-06
step 600: mean loss = 2.6902646e-06
step 700: mean loss = 2.5599452e-06
step 800: mean loss = 2.6154376e-06
step 900: mean loss = 2.5789784e-06
step 1000: mean loss = 2.524873e-06
step 1100: mean loss = 2.5880504e-06
step 1200: mean loss = 2.38526e-06
epoch 90: mean loss = 2.4344652e-06  learning rate = 0.0006302493
============================
Start of epoch 91
step 0: mean loss = 3.2165e-05
step 100: mean loss = 2.2497948e-06
step 200: mean loss = 2.5217516e-06
step 300: mean loss = 2.5707936e-06
step 400: mean loss = 2.3249322e-06
step 500: mean loss = 2.287432e-06
step 600: mean loss = 2.4766323e-06
step 700: mean loss = 2.3774828e-06
step 800: mean loss = 2.9053315e-06
step 900: mean loss = 2.709165e-06
step 1000: mean loss = 2.746963e-06
step 1100: mean loss = 2.5114873e-06
step 1200: mean loss = 2.4878104e-06
epoch 91: mean loss = 2.5155655e-06  learning rate = 0.0006302493
============================
Start of epoch 92
step 0: mean loss = 1.594437e-05
step 100: mean loss = 1.8847888e-06
step 200: mean loss = 2.512788e-06
step 300: mean loss = 2.1682308e-06
step 400: mean loss = 2.5206205e-06
step 500: mean loss = 2.2686709e-06
step 600: mean loss = 2.3981277e-06
step 700: mean loss = 2.3215491e-06
step 800: mean loss = 2.436787e-06
step 900: mean loss = 2.447569e-06
step 1000: mean loss = 2.5368768e-06
step 1100: mean loss = 2.403308e-06
step 1200: mean loss = 2.4091376e-06
epoch 92: mean loss = 2.341896e-06  learning rate = 0.0006302493
============================
Start of epoch 93
step 0: mean loss = 1.4515365e-07
step 100: mean loss = 5.0397925e-06
step 200: mean loss = 2.6110524e-06
step 300: mean loss = 2.6928935e-06
step 400: mean loss = 2.6877174e-06
step 500: mean loss = 2.820346e-06
step 600: mean loss = 2.6179532e-06
step 700: mean loss = 2.5173424e-06
step 800: mean loss = 2.7540793e-06
step 900: mean loss = 2.4987623e-06
step 1000: mean loss = 2.4881074e-06
step 1100: mean loss = 2.510037e-06
step 1200: mean loss = 2.6001862e-06
epoch 93: mean loss = 2.5323363e-06  learning rate = 0.0006302493
============================
Start of epoch 94
step 0: mean loss = 9.2351445e-07
step 100: mean loss = 2.3374055e-06
step 200: mean loss = 2.1303254e-06
step 300: mean loss = 3.2000758e-06
step 400: mean loss = 2.5608117e-06
step 500: mean loss = 2.663594e-06
step 600: mean loss = 2.27521e-06
step 700: mean loss = 2.2487097e-06
step 800: mean loss = 2.3504515e-06
step 900: mean loss = 2.3192442e-06
step 1000: mean loss = 2.3214363e-06
step 1100: mean loss = 2.9262499e-06
step 1200: mean loss = 2.7428068e-06
epoch 94: mean loss = 2.665038e-06  learning rate = 0.0006302493
============================
Start of epoch 95
step 0: mean loss = 1.3759983e-07
step 100: mean loss = 3.2785624e-06
step 200: mean loss = 1.7480445e-06
step 300: mean loss = 2.4530054e-06
step 400: mean loss = 1.9830554e-06
step 500: mean loss = 2.1718467e-06
step 600: mean loss = 1.962349e-06
step 700: mean loss = 2.3800653e-06
step 800: mean loss = 2.0995399e-06
step 900: mean loss = 2.301082e-06
step 1000: mean loss = 2.085182e-06
step 1100: mean loss = 2.2919658e-06
step 1200: mean loss = 2.315635e-06
epoch 95: mean loss = 2.3042867e-06  learning rate = 0.0006302493
============================
Start of epoch 96
step 0: mean loss = 3.1331038e-07
step 100: mean loss = 3.437654e-07
step 200: mean loss = 1.8043879e-06
step 300: mean loss = 1.5653236e-06
step 400: mean loss = 2.0165935e-06
step 500: mean loss = 1.8892433e-06
step 600: mean loss = 1.9418399e-06
step 700: mean loss = 1.9851902e-06
step 800: mean loss = 2.2617214e-06
step 900: mean loss = 2.3659304e-06
step 1000: mean loss = 2.160908e-06
step 1100: mean loss = 2.1314995e-06
step 1200: mean loss = 2.1470912e-06
epoch 96: mean loss = 2.1350565e-06  learning rate = 0.0006302493
============================
Start of epoch 97
step 0: mean loss = 5.9578424e-06
step 100: mean loss = 2.3294126e-06
step 200: mean loss = 2.1104386e-06
step 300: mean loss = 1.9996373e-06
step 400: mean loss = 2.5114473e-06
step 500: mean loss = 2.6180885e-06
step 600: mean loss = 2.2711288e-06
step 700: mean loss = 2.133356e-06
step 800: mean loss = 2.179034e-06
step 900: mean loss = 2.2396819e-06
step 1000: mean loss = 2.2268453e-06
step 1100: mean loss = 2.2387915e-06
step 1200: mean loss = 2.1665553e-06
epoch 97: mean loss = 2.2217075e-06  learning rate = 0.0006302493
============================
Start of epoch 98
step 0: mean loss = 2.3513915e-06
step 100: mean loss = 2.6163366e-06
step 200: mean loss = 2.0001962e-06
step 300: mean loss = 1.9809368e-06
step 400: mean loss = 2.3166967e-06
step 500: mean loss = 2.123667e-06
step 600: mean loss = 2.1516303e-06
step 700: mean loss = 2.1397873e-06
step 800: mean loss = 2.1620679e-06
step 900: mean loss = 2.3058687e-06
step 1000: mean loss = 2.133664e-06
step 1100: mean loss = 2.2189254e-06
step 1200: mean loss = 2.2301288e-06
epoch 98: mean loss = 2.1687133e-06  learning rate = 0.0006302493
============================
Start of epoch 99
step 0: mean loss = 1.5815617e-07
step 100: mean loss = 1.8542034e-06
step 200: mean loss = 1.9527572e-06
step 300: mean loss = 1.9946267e-06
step 400: mean loss = 1.974952e-06
step 500: mean loss = 1.9757267e-06
step 600: mean loss = 2.0312805e-06
step 700: mean loss = 1.9845752e-06
step 800: mean loss = 2.2874099e-06
step 900: mean loss = 0.00010302293
step 1000: mean loss = 9.5506606e-05
step 1100: mean loss = 8.784954e-05
step 1200: mean loss = 8.1168415e-05
epoch 99: mean loss = 7.896204e-05  learning rate = 0.0006302493
============================
Start of epoch 100
step 0: mean loss = 1.257328e-05
step 100: mean loss = 5.6045005e-06
step 200: mean loss = 5.651524e-06
step 300: mean loss = 5.6809745e-06
step 400: mean loss = 5.1234756e-06
step 500: mean loss = 5.0587128e-06
step 600: mean loss = 5.1054003e-06
step 700: mean loss = 4.7222065e-06
step 800: mean loss = 4.768066e-06
step 900: mean loss = 4.457158e-06
step 1000: mean loss = 4.567422e-06
step 1100: mean loss = 4.3041587e-06
step 1200: mean loss = 4.387229e-06
epoch 100: mean loss = 4.301363e-06  learning rate = 0.00059873686
============================
Start of epoch 101
step 0: mean loss = 1.4592412e-06
step 100: mean loss = 1.3724845e-06
step 200: mean loss = 2.4899123e-06
step 300: mean loss = 2.0673367e-06
step 400: mean loss = 2.7447386e-06
step 500: mean loss = 2.4134329e-06
step 600: mean loss = 2.5081727e-06
step 700: mean loss = 2.2918962e-06
step 800: mean loss = 2.4856417e-06
step 900: mean loss = 2.3007267e-06
step 1000: mean loss = 2.4399826e-06
step 1100: mean loss = 2.4572669e-06
step 1200: mean loss = 2.410319e-06
epoch 101: mean loss = 2.3576642e-06  learning rate = 0.00059873686
============================
Start of epoch 102
step 0: mean loss = 6.3752566e-07
step 100: mean loss = 4.393303e-06
step 200: mean loss = 2.531392e-06
step 300: mean loss = 1.8749978e-06
step 400: mean loss = 2.3999976e-06
step 500: mean loss = 2.0193324e-06
step 600: mean loss = 2.2434706e-06
step 700: mean loss = 1.989484e-06
step 800: mean loss = 2.054012e-06
step 900: mean loss = 1.9000892e-06
step 1000: mean loss = 1.791665e-06
step 1100: mean loss = 1.8467949e-06
step 1200: mean loss = 1.7220973e-06
epoch 102: mean loss = 1.6806762e-06  learning rate = 0.00059873686
============================
Start of epoch 103
step 0: mean loss = 3.613937e-07
step 100: mean loss = 3.640169e-06
step 200: mean loss = 1.9905071e-06
step 300: mean loss = 2.0006557e-06
step 400: mean loss = 1.9831734e-06
step 500: mean loss = 1.9323677e-06
step 600: mean loss = 1.8257574e-06
step 700: mean loss = 1.7674332e-06
step 800: mean loss = 1.9577672e-06
step 900: mean loss = 1.77878e-06
step 1000: mean loss = 1.9056133e-06
step 1100: mean loss = 1.9371066e-06
step 1200: mean loss = 2.0178643e-06
epoch 103: mean loss = 1.9650663e-06  learning rate = 0.00059873686
============================
Start of epoch 104
step 0: mean loss = 2.4823274e-07
step 100: mean loss = 2.50207e-07
step 200: mean loss = 3.7610564e-06
step 300: mean loss = 2.5939428e-06
step 400: mean loss = 2.0045045e-06
step 500: mean loss = 2.4368928e-06
step 600: mean loss = 2.5870395e-06
step 700: mean loss = 2.2871432e-06
step 800: mean loss = 2.1455696e-06
step 900: mean loss = 2.558726e-06
step 1000: mean loss = 2.3240739e-06
step 1100: mean loss = 2.2228394e-06
step 1200: mean loss = 2.5854692e-06
epoch 104: mean loss = 2.551218e-06  learning rate = 0.00059873686
============================
Start of epoch 105
step 0: mean loss = 2.9933676e-07
step 100: mean loss = 2.1444882e-07
step 200: mean loss = 2.035473e-07
step 300: mean loss = 1.8619795e-06
step 400: mean loss = 1.4467007e-06
step 500: mean loss = 1.6868087e-06
step 600: mean loss = 1.4603081e-06
step 700: mean loss = 2.16022e-06
step 800: mean loss = 1.9167069e-06
step 900: mean loss = 2.1201652e-06
step 1000: mean loss = 1.9257484e-06
step 1100: mean loss = 2.31382e-06
step 1200: mean loss = 2.1989533e-06
epoch 105: mean loss = 2.1385642e-06  learning rate = 0.00059873686
============================
Start of epoch 106
step 0: mean loss = 1.7424657e-07
step 100: mean loss = 3.7249333e-06
step 200: mean loss = 1.9943968e-06
step 300: mean loss = 1.385735e-06
step 400: mean loss = 2.3638538e-06
step 500: mean loss = 1.925361e-06
step 600: mean loss = 1.984968e-06
step 700: mean loss = 2.1667468e-06
step 800: mean loss = 1.9312574e-06
step 900: mean loss = 2.1712287e-06
step 1000: mean loss = 1.9709905e-06
step 1100: mean loss = 2.2293677e-06
step 1200: mean loss = 2.058888e-06
epoch 106: mean loss = 2.0017667e-06  learning rate = 0.00059873686
============================
Start of epoch 107
step 0: mean loss = 1.6269578e-07
step 100: mean loss = 5.573095e-06
step 200: mean loss = 2.8784166e-06
step 300: mean loss = 2.2705435e-06
step 400: mean loss = 2.5355475e-06
step 500: mean loss = 2.6928956e-06
step 600: mean loss = 2.3301227e-06
step 700: mean loss = 2.2869594e-06
step 800: mean loss = 2.175634e-06
step 900: mean loss = 2.1334847e-06
step 1000: mean loss = 2.4948652e-06
step 1100: mean loss = 2.2928891e-06
step 1200: mean loss = 2.477673e-06
epoch 107: mean loss = 2.408563e-06  learning rate = 0.00059873686
============================
Start of epoch 108
step 0: mean loss = 1.473208e-07
step 100: mean loss = 1.381645e-07
step 200: mean loss = 8.19291e-07
step 300: mean loss = 1.1009574e-06
step 400: mean loss = 1.2661972e-06
step 500: mean loss = 1.3141213e-06
step 600: mean loss = 1.6191929e-06
step 700: mean loss = 1.8487577e-06
step 800: mean loss = 2.031485e-06
step 900: mean loss = 1.8243335e-06
step 1000: mean loss = 1.9714184e-06
step 1100: mean loss = 1.8038934e-06
step 1200: mean loss = 1.8986269e-06
epoch 108: mean loss = 1.846205e-06  learning rate = 0.00059873686
============================
Start of epoch 109
step 0: mean loss = 1.287929e-07
step 100: mean loss = 4.596086e-06
step 200: mean loss = 2.5113789e-06
step 300: mean loss = 1.7173863e-06
step 400: mean loss = 2.6311102e-06
step 500: mean loss = 2.171055e-06
step 600: mean loss = 2.2958673e-06
step 700: mean loss = 1.985669e-06
step 800: mean loss = 2.0212087e-06
step 900: mean loss = 2.0776451e-06
step 1000: mean loss = 1.921976e-06
step 1100: mean loss = 2.0590494e-06
step 1200: mean loss = 1.9794265e-06
epoch 109: mean loss = 1.9247893e-06  learning rate = 0.00059873686
============================
Start of epoch 110
step 0: mean loss = 6.249544e-07
step 100: mean loss = 1.9433978e-06
step 200: mean loss = 2.2025472e-06
step 300: mean loss = 1.9241338e-06
step 400: mean loss = 2.3220184e-06
step 500: mean loss = 2.2423246e-06
step 600: mean loss = 2.06309e-06
step 700: mean loss = 2.1841076e-06
step 800: mean loss = 2.090831e-06
step 900: mean loss = 2.2468623e-06
step 1000: mean loss = 2.058933e-06
step 1100: mean loss = 2.0217003e-06
step 1200: mean loss = 1.951338e-06
epoch 110: mean loss = 1.8973249e-06  learning rate = 0.00059873686
============================
Start of epoch 111
step 0: mean loss = 1.7418859e-07
step 100: mean loss = 2.811459e-06
step 200: mean loss = 1.4676103e-06
step 300: mean loss = 1.5316538e-06
step 400: mean loss = 1.6698303e-06
step 500: mean loss = 1.5602319e-06
step 600: mean loss = 1.646798e-06
step 700: mean loss = 1.4635681e-06
step 800: mean loss = 1.6913245e-06
step 900: mean loss = 1.8020492e-06
step 1000: mean loss = 1.6372047e-06
step 1100: mean loss = 1.6653905e-06
step 1200: mean loss = 1.5565843e-06
epoch 111: mean loss = 1.7110037e-06  learning rate = 0.0005688
============================
Start of epoch 112
step 0: mean loss = 9.2965837e-07
step 100: mean loss = 1.8959125e-06
step 200: mean loss = 1.1402191e-06
step 300: mean loss = 1.2288205e-06
step 400: mean loss = 1.4002853e-06
step 500: mean loss = 1.4406864e-06
step 600: mean loss = 1.5002798e-06
step 700: mean loss = 1.6317176e-06
step 800: mean loss = 1.48477e-06
step 900: mean loss = 1.4736825e-06
step 1000: mean loss = 1.4787557e-06
step 1100: mean loss = 1.5601004e-06
step 1200: mean loss = 1.5645356e-06
epoch 112: mean loss = 1.570093e-06  learning rate = 0.0005688
============================
Start of epoch 113
step 0: mean loss = 2.0076291e-07
step 100: mean loss = 1.557197e-06
step 200: mean loss = 1.5759073e-06
step 300: mean loss = 1.5808401e-06
step 400: mean loss = 1.3579814e-06
step 500: mean loss = 1.4149789e-06
step 600: mean loss = 1.4800734e-06
step 700: mean loss = 1.5828556e-06
step 800: mean loss = 1.6030419e-06
step 900: mean loss = 1.5619028e-06
step 1000: mean loss = 1.5193071e-06
step 1100: mean loss = 1.5198752e-06
step 1200: mean loss = 1.5567483e-06
epoch 113: mean loss = 1.515154e-06  learning rate = 0.0005688
============================
Start of epoch 114
step 0: mean loss = 5.251252e-07
step 100: mean loss = 1.9682207e-06
step 200: mean loss = 1.7249776e-06
step 300: mean loss = 2.2869351e-06
step 400: mean loss = 1.8075959e-06
step 500: mean loss = 1.796581e-06
step 600: mean loss = 1.519271e-06
step 700: mean loss = 1.8151668e-06
step 800: mean loss = 1.6698315e-06
step 900: mean loss = 1.6335181e-06
step 1000: mean loss = 1.6240168e-06
step 1100: mean loss = 1.7631403e-06
step 1200: mean loss = 1.6738649e-06
epoch 114: mean loss = 1.6372892e-06  learning rate = 0.0005688
============================
Start of epoch 115
step 0: mean loss = 1.2531196e-07
step 100: mean loss = 1.2146128e-06
step 200: mean loss = 1.7608681e-06
step 300: mean loss = 1.3873623e-06
step 400: mean loss = 1.5172751e-06
step 500: mean loss = 1.562787e-06
step 600: mean loss = 1.5501164e-06
step 700: mean loss = 1.4838993e-06
step 800: mean loss = 1.4547481e-06
step 900: mean loss = 1.4375781e-06
step 1000: mean loss = 1.490436e-06
step 1100: mean loss = 1.4971746e-06
step 1200: mean loss = 1.5530702e-06
epoch 115: mean loss = 1.5137686e-06  learning rate = 0.0005688
============================
Start of epoch 116
step 0: mean loss = 1.1345654e-07
step 100: mean loss = 1.913367e-06
step 200: mean loss = 1.0705205e-06
step 300: mean loss = 1.52722e-06
step 400: mean loss = 1.5123446e-06
step 500: mean loss = 1.6995834e-06
step 600: mean loss = 1.4423769e-06
step 700: mean loss = 1.5960356e-06
step 800: mean loss = 1.4470326e-06
step 900: mean loss = 1.5078454e-06
step 1000: mean loss = 1.5014888e-06
step 1100: mean loss = 1.6160582e-06
step 1200: mean loss = 1.5937503e-06
epoch 116: mean loss = 1.5784609e-06  learning rate = 0.0005688
============================
Start of epoch 117
step 0: mean loss = 2.1868507e-07
step 100: mean loss = 1.0363503e-07
step 200: mean loss = 1.389653e-06
step 300: mean loss = 1.5745215e-06
step 400: mean loss = 1.2503707e-06
step 500: mean loss = 1.6523385e-06
step 600: mean loss = 1.3949153e-06
step 700: mean loss = 1.390279e-06
step 800: mean loss = 1.4439759e-06
step 900: mean loss = 1.3682404e-06
step 1000: mean loss = 1.5746916e-06
step 1100: mean loss = 1.4600248e-06
step 1200: mean loss = 1.4636264e-06
epoch 117: mean loss = 1.4339421e-06  learning rate = 0.0005688
============================
Start of epoch 118
step 0: mean loss = 2.7990612e-07
step 100: mean loss = 1.8862639e-06
step 200: mean loss = 1.1420673e-06
step 300: mean loss = 1.5467871e-06
step 400: mean loss = 1.5820773e-06
step 500: mean loss = 1.543037e-06
step 600: mean loss = 1.3732993e-06
step 700: mean loss = 1.5173806e-06
step 800: mean loss = 1.4113892e-06
step 900: mean loss = 1.5155895e-06
step 1000: mean loss = 1.4429035e-06
step 1100: mean loss = 1.4065556e-06
step 1200: mean loss = 1.4450603e-06
epoch 118: mean loss = 1.4150618e-06  learning rate = 0.0005688
============================
Start of epoch 119
step 0: mean loss = 8.0746176e-08
step 100: mean loss = 2.9004952e-06
step 200: mean loss = 1.5911721e-06
step 300: mean loss = 1.6427376e-06
step 400: mean loss = 1.7319245e-06
step 500: mean loss = 1.4554648e-06
step 600: mean loss = 1.4670088e-06
step 700: mean loss = 1.5446063e-06
step 800: mean loss = 1.4305351e-06
step 900: mean loss = 1.4687199e-06
step 1000: mean loss = 1.473344e-06
step 1100: mean loss = 1.468165e-06
step 1200: mean loss = 1.4821962e-06
epoch 119: mean loss = 1.4650742e-06  learning rate = 0.0005688
============================
Start of epoch 120
step 0: mean loss = 1.3788022e-07
step 100: mean loss = 1.4791212e-06
step 200: mean loss = 1.3932193e-06
step 300: mean loss = 1.4599901e-06
step 400: mean loss = 1.4494186e-06
step 500: mean loss = 1.3420242e-06
step 600: mean loss = 1.3916424e-06
step 700: mean loss = 1.3679288e-06
step 800: mean loss = 1.3841046e-06
step 900: mean loss = 1.4217953e-06
step 1000: mean loss = 1.3287623e-06
step 1100: mean loss = 1.3605829e-06
step 1200: mean loss = 1.3637075e-06
epoch 120: mean loss = 1.3254268e-06  learning rate = 0.0005688
============================
Start of epoch 121
step 0: mean loss = 1.0048816e-07
step 100: mean loss = 2.3520747e-06
step 200: mean loss = 1.8479784e-06
step 300: mean loss = 1.2580678e-06
step 400: mean loss = 1.2526131e-06
step 500: mean loss = 1.0897494e-06
step 600: mean loss = 1.2267674e-06
step 700: mean loss = 1.1980311e-06
step 800: mean loss = 1.1654158e-06
step 900: mean loss = 1.1688327e-06
step 1000: mean loss = 1.2336567e-06
step 1100: mean loss = 1.280915e-06
step 1200: mean loss = 1.1875892e-06
epoch 121: mean loss = 1.3021862e-06  learning rate = 0.00054036005
============================
Start of epoch 122
step 0: mean loss = 9.38438e-07
step 100: mean loss = 3.1847637e-07
step 200: mean loss = 6.061783e-07
step 300: mean loss = 9.768469e-07
step 400: mean loss = 1.1014606e-06
step 500: mean loss = 1.2404821e-06
step 600: mean loss = 1.0578001e-06
step 700: mean loss = 1.1112257e-06
step 800: mean loss = 1.1602784e-06
step 900: mean loss = 1.1043257e-06
step 1000: mean loss = 1.119689e-06
step 1100: mean loss = 1.1394507e-06
step 1200: mean loss = 1.1585001e-06
epoch 122: mean loss = 1.1299593e-06  learning rate = 0.00054036005
============================
Start of epoch 123
step 0: mean loss = 1.4256302e-07
step 100: mean loss = 1.009613e-06
step 200: mean loss = 1.1907165e-06
step 300: mean loss = 1.2435469e-06
step 400: mean loss = 1.3205865e-06
step 500: mean loss = 1.3178845e-06
step 600: mean loss = 1.2055741e-06
step 700: mean loss = 1.1876912e-06
step 800: mean loss = 1.2286263e-06
step 900: mean loss = 1.272884e-06
step 1000: mean loss = 1.1785878e-06
step 1100: mean loss = 1.3326184e-06
step 1200: mean loss = 1.239618e-06
epoch 123: mean loss = 1.2315617e-06  learning rate = 0.00054036005
============================
Start of epoch 124
step 0: mean loss = 8.4433515e-07
step 100: mean loss = 1.2463229e-06
step 200: mean loss = 1.248464e-06
step 300: mean loss = 1.1593488e-06
step 400: mean loss = 1.1967222e-06
step 500: mean loss = 1.1881698e-06
step 600: mean loss = 1.1410532e-06
step 700: mean loss = 1.1383082e-06
step 800: mean loss = 1.0854717e-06
step 900: mean loss = 1.2860371e-06
step 1000: mean loss = 1.2081452e-06
step 1100: mean loss = 1.2057762e-06
step 1200: mean loss = 1.1893127e-06
epoch 124: mean loss = 1.1639268e-06  learning rate = 0.00054036005
============================
Start of epoch 125
step 0: mean loss = 1.4983391e-07
step 100: mean loss = 1.4485021e-06
step 200: mean loss = 1.2786246e-06
step 300: mean loss = 1.2965322e-06
step 400: mean loss = 1.2242417e-06
step 500: mean loss = 1.2447335e-06
step 600: mean loss = 1.2126945e-06
step 700: mean loss = 1.2242834e-06
step 800: mean loss = 1.3179911e-06
step 900: mean loss = 1.2610656e-06
step 1000: mean loss = 1.1857272e-06
step 1100: mean loss = 1.1679113e-06
step 1200: mean loss = 1.159852e-06
epoch 125: mean loss = 1.2189538e-06  learning rate = 0.00054036005
============================
Start of epoch 126
step 0: mean loss = 8.101116e-07
step 100: mean loss = 1.2786039e-06
step 200: mean loss = 9.994634e-07
step 300: mean loss = 9.162698e-07
step 400: mean loss = 1.1743027e-06
step 500: mean loss = 1.0572655e-06
step 600: mean loss = 1.0566375e-06
step 700: mean loss = 1.0503067e-06
step 800: mean loss = 1.0931996e-06
step 900: mean loss = 1.1257048e-06
step 1000: mean loss = 1.2032662e-06
step 1100: mean loss = 1.1185147e-06
step 1200: mean loss = 1.1823853e-06
epoch 126: mean loss = 1.1717896e-06  learning rate = 0.00054036005
============================
Start of epoch 127
step 0: mean loss = 1.0415002e-06
step 100: mean loss = 9.643182e-07
step 200: mean loss = 8.742073e-07
step 300: mean loss = 9.468299e-07
step 400: mean loss = 1.1230649e-06
step 500: mean loss = 9.687055e-07
step 600: mean loss = 9.977133e-07
step 700: mean loss = 1.0289604e-06
step 800: mean loss = 1.0686108e-06
step 900: mean loss = 1.0638022e-06
step 1000: mean loss = 1.0524509e-06
step 1100: mean loss = 1.0621766e-06
step 1200: mean loss = 1.1054524e-06
epoch 127: mean loss = 1.0766569e-06  learning rate = 0.00054036005
============================
Start of epoch 128
step 0: mean loss = 8.108678e-07
step 100: mean loss = 1.0879457e-06
step 200: mean loss = 1.2079165e-06
step 300: mean loss = 1.0613082e-06
step 400: mean loss = 1.219418e-06
step 500: mean loss = 1.2402235e-06
step 600: mean loss = 1.0886714e-06
step 700: mean loss = 1.1145232e-06
step 800: mean loss = 1.1182731e-06
step 900: mean loss = 1.152913e-06
step 1000: mean loss = 1.1869671e-06
step 1100: mean loss = 1.124352e-06
step 1200: mean loss = 1.1083488e-06
epoch 128: mean loss = 1.1056034e-06  learning rate = 0.00054036005
============================
Start of epoch 129
step 0: mean loss = 8.080055e-07
step 100: mean loss = 1.1196073e-06
step 200: mean loss = 1.3080478e-06
step 300: mean loss = 1.4573615e-06
step 400: mean loss = 1.5527124e-06
step 500: mean loss = 1.2551676e-06
step 600: mean loss = 1.3342739e-06
step 700: mean loss = 1.1678999e-06
step 800: mean loss = 1.1497943e-06
step 900: mean loss = 1.1635516e-06
step 1000: mean loss = 1.2014914e-06
step 1100: mean loss = 1.2200535e-06
step 1200: mean loss = 1.1391371e-06
epoch 129: mean loss = 1.1966664e-06  learning rate = 0.00054036005
============================
Start of epoch 130
step 0: mean loss = 8.335919e-08
step 100: mean loss = 4.1587455e-07
step 200: mean loss = 9.045359e-07
step 300: mean loss = 8.5288764e-07
step 400: mean loss = 9.779785e-07
step 500: mean loss = 9.73884e-07
step 600: mean loss = 1.0603853e-06
step 700: mean loss = 1.1332708e-06
step 800: mean loss = 1.1423599e-06
step 900: mean loss = 1.1912243e-06
step 1000: mean loss = 1.092224e-06
step 1100: mean loss = 1.103612e-06
step 1200: mean loss = 1.0494907e-06
epoch 130: mean loss = 1.0568087e-06  learning rate = 0.00054036005
============================
Start of epoch 131
step 0: mean loss = 2.1729805e-07
step 100: mean loss = 5.9112917e-06
step 200: mean loss = 3.309225e-06
step 300: mean loss = 2.2319934e-06
step 400: mean loss = 1.6906254e-06
step 500: mean loss = 1.5927696e-06
step 600: mean loss = 1.3935463e-06
step 700: mean loss = 1.222371e-06
step 800: mean loss = 1.2544725e-06
step 900: mean loss = 1.1222078e-06
step 1000: mean loss = 1.1913611e-06
step 1100: mean loss = 1.2209621e-06
step 1200: mean loss = 1.1259207e-06
epoch 131: mean loss = 1.1127676e-06  learning rate = 0.000513342
============================
Start of epoch 132
step 0: mean loss = 9.650054e-07
step 100: mean loss = 1.0345613e-06
step 200: mean loss = 9.099415e-07
step 300: mean loss = 9.534711e-07
step 400: mean loss = 9.540905e-07
step 500: mean loss = 9.3602597e-07
step 600: mean loss = 1.0549315e-06
step 700: mean loss = 9.1435805e-07
step 800: mean loss = 1.0784419e-06
step 900: mean loss = 1.094186e-06
step 1000: mean loss = 9.952572e-07
step 1100: mean loss = 1.0015702e-06
step 1200: mean loss = 1.0249179e-06
epoch 132: mean loss = 1.0030549e-06  learning rate = 0.000513342
============================
Start of epoch 133
step 0: mean loss = 2.097639e-06
step 100: mean loss = 1.0818956e-06
step 200: mean loss = 1.0636227e-06
step 300: mean loss = 8.528019e-07
step 400: mean loss = 9.1315644e-07
step 500: mean loss = 8.8962264e-07
step 600: mean loss = 8.5160286e-07
step 700: mean loss = 9.0125803e-07
step 800: mean loss = 8.790307e-07
step 900: mean loss = 9.415593e-07
step 1000: mean loss = 9.591629e-07
step 1100: mean loss = 9.695153e-07
step 1200: mean loss = 9.081504e-07
epoch 133: mean loss = 9.4192916e-07  learning rate = 0.000513342
============================
Start of epoch 134
step 0: mean loss = 2.1393262e-07
step 100: mean loss = 1.2611383e-06
step 200: mean loss = 9.215305e-07
step 300: mean loss = 8.6637027e-07
step 400: mean loss = 9.179667e-07
step 500: mean loss = 9.130838e-07
step 600: mean loss = 9.3313497e-07
step 700: mean loss = 9.0902324e-07
step 800: mean loss = 9.399033e-07
step 900: mean loss = 9.587083e-07
step 1000: mean loss = 9.0090833e-07
step 1100: mean loss = 9.3602284e-07
step 1200: mean loss = 9.417832e-07
epoch 134: mean loss = 9.1652765e-07  learning rate = 0.000513342
============================
Start of epoch 135
step 0: mean loss = 8.576786e-08
step 100: mean loss = 8.18148e-07
step 200: mean loss = 8.802204e-07
step 300: mean loss = 1.1007216e-06
step 400: mean loss = 8.83827e-07
step 500: mean loss = 9.3442344e-07
step 600: mean loss = 9.418701e-07
step 700: mean loss = 9.212321e-07
step 800: mean loss = 9.274927e-07
step 900: mean loss = 9.3460744e-07
step 1000: mean loss = 9.118184e-07
step 1100: mean loss = 9.389106e-07
step 1200: mean loss = 9.267666e-07
epoch 135: mean loss = 9.078906e-07  learning rate = 0.000513342
============================
Start of epoch 136
step 0: mean loss = 1.0909606e-07
step 100: mean loss = 1.2996517e-06
step 200: mean loss = 1.001668e-06
step 300: mean loss = 8.9869343e-07
step 400: mean loss = 2.8918788e-05
step 500: mean loss = 2.3870905e-05
step 600: mean loss = 2.0202886e-05
step 700: mean loss = 1.7447688e-05
step 800: mean loss = 1.5373269e-05
step 900: mean loss = 1.3707059e-05
step 1000: mean loss = 1.236541e-05
step 1100: mean loss = 1.1265483e-05
step 1200: mean loss = 1.0347397e-05
epoch 136: mean loss = 1.0044166e-05  learning rate = 0.000513342
============================
Start of epoch 137
step 0: mean loss = 1.9731891e-07
step 100: mean loss = 2.4774317e-07
step 200: mean loss = 2.3037995e-07
step 300: mean loss = 2.238308e-07
step 400: mean loss = 2.1071604e-07
step 500: mean loss = 2.3171557e-07
step 600: mean loss = 2.4218744e-07
step 700: mean loss = 2.3043836e-07
step 800: mean loss = 2.769464e-07
step 900: mean loss = 3.4695367e-07
step 1000: mean loss = 3.687975e-07
step 1100: mean loss = 3.4536922e-07
step 1200: mean loss = 4.2758256e-07
epoch 137: mean loss = 4.178493e-07  learning rate = 0.000513342
============================
Start of epoch 138
step 0: mean loss = 1.00031045e-07
step 100: mean loss = 1.6576195e-06
step 200: mean loss = 8.9065134e-07
step 300: mean loss = 9.181285e-07
step 400: mean loss = 1.005327e-06
step 500: mean loss = 8.4016244e-07
step 600: mean loss = 8.6603654e-07
step 700: mean loss = 1.0008937e-06
step 800: mean loss = 9.479669e-07
step 900: mean loss = 9.877787e-07
step 1000: mean loss = 9.006279e-07
step 1100: mean loss = 9.410341e-07
step 1200: mean loss = 9.699784e-07
epoch 138: mean loss = 9.435376e-07  learning rate = 0.000513342
============================
Start of epoch 139
step 0: mean loss = 7.0612145e-08
step 100: mean loss = 1.4129317e-06
step 200: mean loss = 7.6538873e-07
step 300: mean loss = 1.0990964e-06
step 400: mean loss = 9.109249e-07
step 500: mean loss = 1.1148489e-06
step 600: mean loss = 9.877122e-07
step 700: mean loss = 1.0349702e-06
step 800: mean loss = 1.05007e-06
step 900: mean loss = 1.035037e-06
step 1000: mean loss = 1.0357435e-06
step 1100: mean loss = 1.0193528e-06
step 1200: mean loss = 1.0533248e-06
epoch 139: mean loss = 1.0279122e-06  learning rate = 0.000513342
============================
Start of epoch 140
step 0: mean loss = 2.1631662e-07
step 100: mean loss = 2.5437632e-07
step 200: mean loss = 9.79202e-07
step 300: mean loss = 1.1370347e-06
step 400: mean loss = 8.717445e-07
step 500: mean loss = 1.1667297e-06
step 600: mean loss = 1.1701061e-06
step 700: mean loss = 1.0149831e-06
step 800: mean loss = 1.172906e-06
step 900: mean loss = 1.0509636e-06
step 1000: mean loss = 9.945991e-07
step 1100: mean loss = 1.0111154e-06
step 1200: mean loss = 1.0080643e-06
epoch 140: mean loss = 1.0664565e-06  learning rate = 0.000513342
============================
Start of epoch 141
step 0: mean loss = 2.9907173e-07
step 100: mean loss = 6.7736096e-08
step 200: mean loss = 1.1714261e-06
step 300: mean loss = 8.915455e-07
step 400: mean loss = 6.842562e-07
step 500: mean loss = 7.8608514e-07
step 600: mean loss = 6.6329176e-07
step 700: mean loss = 8.834281e-07
step 800: mean loss = 7.8430395e-07
step 900: mean loss = 7.61116e-07
step 1000: mean loss = 8.163295e-07
step 1100: mean loss = 7.7114413e-07
step 1200: mean loss = 7.956075e-07
epoch 141: mean loss = 7.7319567e-07  learning rate = 0.00048767496
============================
Start of epoch 142
step 0: mean loss = 4.497322e-08
step 100: mean loss = 1.4848827e-06
step 200: mean loss = 1.1223145e-06
step 300: mean loss = 7.8436165e-07
step 400: mean loss = 9.18879e-07
step 500: mean loss = 8.0137204e-07
step 600: mean loss = 8.0978594e-07
step 700: mean loss = 8.259389e-07
step 800: mean loss = 8.438223e-07
step 900: mean loss = 8.117979e-07
step 1000: mean loss = 8.260594e-07
step 1100: mean loss = 8.4905304e-07
step 1200: mean loss = 8.4051e-07
epoch 142: mean loss = 8.169274e-07  learning rate = 0.00048767496
============================
Start of epoch 143
step 0: mean loss = 4.3232316e-08
step 100: mean loss = 1.2066997e-06
step 200: mean loss = 1.0148647e-06
step 300: mean loss = 1.0627202e-06
step 400: mean loss = 8.672512e-07
step 500: mean loss = 8.2323555e-07
step 600: mean loss = 8.3267366e-07
step 700: mean loss = 8.1144907e-07
step 800: mean loss = 8.510219e-07
step 900: mean loss = 8.5938836e-07
step 1000: mean loss = 8.7690637e-07
step 1100: mean loss = 8.0629724e-07
step 1200: mean loss = 8.192695e-07
epoch 143: mean loss = 8.3576396e-07  learning rate = 0.00048767496
============================
Start of epoch 144
step 0: mean loss = 9.0206704e-08
step 100: mean loss = 1.1169278e-06
step 200: mean loss = 6.463267e-07
step 300: mean loss = 6.894427e-07
step 400: mean loss = 7.380134e-07
step 500: mean loss = 7.0116465e-07
step 600: mean loss = 7.4639274e-07
step 700: mean loss = 7.459702e-07
step 800: mean loss = 7.682096e-07
step 900: mean loss = 8.0008624e-07
step 1000: mean loss = 8.4201815e-07
step 1100: mean loss = 8.021701e-07
step 1200: mean loss = 8.368061e-07
epoch 144: mean loss = 8.1295394e-07  learning rate = 0.00048767496
============================
Start of epoch 145
step 0: mean loss = 3.8322604e-08
step 100: mean loss = 7.0490455e-07
step 200: mean loss = 9.283044e-07
step 300: mean loss = 7.428486e-07
step 400: mean loss = 7.4764245e-07
step 500: mean loss = 8.50048e-07
step 600: mean loss = 7.5583426e-07
step 700: mean loss = 7.817419e-07
step 800: mean loss = 7.9794665e-07
step 900: mean loss = 7.880972e-07
step 1000: mean loss = 8.066549e-07
step 1100: mean loss = 7.9747804e-07
step 1200: mean loss = 7.455788e-07
epoch 145: mean loss = 7.9420704e-07  learning rate = 0.00048767496
============================
Start of epoch 146
step 0: mean loss = 3.884161e-07
step 100: mean loss = 1.1619745e-06
step 200: mean loss = 6.0673835e-07
step 300: mean loss = 8.0802675e-07
step 400: mean loss = 7.8723116e-07
step 500: mean loss = 8.222122e-07
step 600: mean loss = 7.66397e-07
step 700: mean loss = 8.0235316e-07
step 800: mean loss = 7.301073e-07
step 900: mean loss = 7.5809055e-07
step 1000: mean loss = 7.985451e-07
step 1100: mean loss = 7.5492125e-07
step 1200: mean loss = 7.4109624e-07
epoch 146: mean loss = 7.7693534e-07  learning rate = 0.00048767496
============================
Start of epoch 147
step 0: mean loss = 4.7679944e-07
step 100: mean loss = 9.742098e-07
step 200: mean loss = 6.2269424e-07
step 300: mean loss = 8.371804e-07
step 400: mean loss = 7.084884e-07
step 500: mean loss = 7.59685e-07
step 600: mean loss = 7.668604e-07
step 700: mean loss = 7.1035004e-07
step 800: mean loss = 7.305354e-07
step 900: mean loss = 7.134227e-07
step 1000: mean loss = 7.623348e-07
step 1100: mean loss = 7.9466577e-07
step 1200: mean loss = 7.4519676e-07
epoch 147: mean loss = 7.36194e-07  learning rate = 0.00048767496
============================
Start of epoch 148
step 0: mean loss = 1.4074128e-07
step 100: mean loss = 1.0131408e-06
step 200: mean loss = 8.547994e-07
step 300: mean loss = 8.0391425e-07
step 400: mean loss = 7.403e-07
step 500: mean loss = 7.728389e-07
step 600: mean loss = 8.0500894e-07
step 700: mean loss = 8.099203e-07
step 800: mean loss = 7.630721e-07
step 900: mean loss = 8.0661545e-07
step 1000: mean loss = 7.3070436e-07
step 1100: mean loss = 8.380501e-07
step 1200: mean loss = 8.63305e-07
epoch 148: mean loss = 8.428772e-07  learning rate = 0.00048767496
============================
Start of epoch 149
step 0: mean loss = 5.1524147e-08
step 100: mean loss = 3.6800586e-08
step 200: mean loss = 8.205209e-07
step 300: mean loss = 5.703532e-07
step 400: mean loss = 7.024221e-07
step 500: mean loss = 6.4385506e-07
step 600: mean loss = 7.32569e-07
step 700: mean loss = 6.8499537e-07
step 800: mean loss = 7.1704403e-07
step 900: mean loss = 6.684423e-07
step 1000: mean loss = 7.149073e-07
step 1100: mean loss = 6.904854e-07
step 1200: mean loss = 7.110327e-07
epoch 149: mean loss = 6.934894e-07  learning rate = 0.00048767496
============================
Start of epoch 150
step 0: mean loss = 4.0658282e-08
step 100: mean loss = 8.759401e-07
step 200: mean loss = 7.089098e-07
step 300: mean loss = 8.2339864e-07
step 400: mean loss = 8.0064007e-07
step 500: mean loss = 6.9836216e-07
step 600: mean loss = 7.99994e-07
step 700: mean loss = 8.0077416e-07
step 800: mean loss = 7.2053325e-07
step 900: mean loss = 7.3420404e-07
step 1000: mean loss = 7.37483e-07
step 1100: mean loss = 7.490338e-07
step 1200: mean loss = 7.391651e-07
epoch 150: mean loss = 7.227802e-07  learning rate = 0.00048767496
============================
Start of epoch 151
step 0: mean loss = 3.115838e-07
step 100: mean loss = 8.534302e-07
step 200: mean loss = 7.0695484e-07
step 300: mean loss = 8.187501e-07
step 400: mean loss = 7.3203637e-07
step 500: mean loss = 7.6489346e-07
step 600: mean loss = 7.507306e-07
step 700: mean loss = 6.483826e-07
step 800: mean loss = 7.4879284e-07
step 900: mean loss = 6.7077247e-07
step 1000: mean loss = 7.0303037e-07
step 1100: mean loss = 6.6391624e-07
step 1200: mean loss = 6.667769e-07
epoch 151: mean loss = 7.0292754e-07  learning rate = 0.00046329116
============================
Start of epoch 152
step 0: mean loss = 1.5330863e-07
step 100: mean loss = 1.2740668e-07
step 200: mean loss = 4.405103e-07
step 300: mean loss = 5.078601e-07
step 400: mean loss = 6.1417086e-07
step 500: mean loss = 5.4487356e-07
step 600: mean loss = 5.858845e-07
step 700: mean loss = 6.2912585e-07
step 800: mean loss = 5.806597e-07
step 900: mean loss = 6.1236534e-07
step 1000: mean loss = 6.8521587e-07
step 1100: mean loss = 6.841793e-07
step 1200: mean loss = 6.4841305e-07
epoch 152: mean loss = 6.3000857e-07  learning rate = 0.00046329116
============================
Start of epoch 153
step 0: mean loss = 3.2392176e-08
step 100: mean loss = 1.1738796e-06
step 200: mean loss = 7.296304e-07
step 300: mean loss = 8.925866e-07
step 400: mean loss = 8.043944e-07
step 500: mean loss = 6.50717e-07
step 600: mean loss = 7.2728363e-07
step 700: mean loss = 6.50379e-07
step 800: mean loss = 7.6503613e-07
step 900: mean loss = 6.8952943e-07
step 1000: mean loss = 6.88181e-07
step 1100: mean loss = 6.5632247e-07
step 1200: mean loss = 6.9299955e-07
epoch 153: mean loss = 6.8461856e-07  learning rate = 0.00046329116
============================
Start of epoch 154
step 0: mean loss = 7.443125e-08
step 100: mean loss = 8.8988975e-07
step 200: mean loss = 6.7765563e-07
step 300: mean loss = 5.885527e-07
step 400: mean loss = 5.7475114e-07
step 500: mean loss = 6.283787e-07
step 600: mean loss = 6.607115e-07
step 700: mean loss = 6.040664e-07
step 800: mean loss = 6.28874e-07
step 900: mean loss = 6.642127e-07
step 1000: mean loss = 6.1133574e-07
step 1100: mean loss = 6.3056643e-07
step 1200: mean loss = 6.3931805e-07
epoch 154: mean loss = 6.2181516e-07  learning rate = 0.00046329116
============================
Start of epoch 155
step 0: mean loss = 3.6002984e-08
step 100: mean loss = 7.711121e-07
step 200: mean loss = 6.8437345e-07
step 300: mean loss = 8.4557456e-07
step 400: mean loss = 6.502286e-07
step 500: mean loss = 6.9249086e-07
step 600: mean loss = 6.652678e-07
step 700: mean loss = 6.2848875e-07
step 800: mean loss = 6.8047257e-07
step 900: mean loss = 6.810393e-07
step 1000: mean loss = 6.880843e-07
step 1100: mean loss = 6.900564e-07
step 1200: mean loss = 6.520642e-07
epoch 155: mean loss = 6.511901e-07  learning rate = 0.00046329116
============================
Start of epoch 156
step 0: mean loss = 4.8832253e-06
step 100: mean loss = 8.579465e-07
step 200: mean loss = 7.3252215e-07
step 300: mean loss = 7.5445683e-07
step 400: mean loss = 6.239988e-07
step 500: mean loss = 6.0374856e-07
step 600: mean loss = 6.3634263e-07
step 700: mean loss = 6.129115e-07
step 800: mean loss = 6.477993e-07
step 900: mean loss = 6.398148e-07
step 1000: mean loss = 7.202906e-07
step 1100: mean loss = 6.625028e-07
step 1200: mean loss = 6.4369925e-07
epoch 156: mean loss = 6.25481e-07  learning rate = 0.00046329116
============================
Start of epoch 157
step 0: mean loss = 7.082156e-08
step 100: mean loss = 8.9145976e-07
step 200: mean loss = 7.0455536e-07
step 300: mean loss = 6.8805866e-07
step 400: mean loss = 7.823966e-07
step 500: mean loss = 6.583678e-07
step 600: mean loss = 6.600187e-07
step 700: mean loss = 6.609496e-07
step 800: mean loss = 6.909343e-07
step 900: mean loss = 6.4256756e-07
step 1000: mean loss = 6.6477844e-07
step 1100: mean loss = 6.552025e-07
step 1200: mean loss = 6.402539e-07
epoch 157: mean loss = 6.3895567e-07  learning rate = 0.00046329116
============================
Start of epoch 158
step 0: mean loss = 2.5350712e-06
step 100: mean loss = 7.990226e-07
step 200: mean loss = 6.925528e-07
step 300: mean loss = 6.181772e-07
step 400: mean loss = 6.927758e-07
step 500: mean loss = 6.882323e-07
step 600: mean loss = 5.932779e-07
step 700: mean loss = 6.60533e-07
step 800: mean loss = 6.0021557e-07
step 900: mean loss = 6.269055e-07
step 1000: mean loss = 6.2015243e-07
step 1100: mean loss = 6.161007e-07
step 1200: mean loss = 6.599642e-07
epoch 158: mean loss = 6.4479326e-07  learning rate = 0.00046329116
============================
Start of epoch 159
step 0: mean loss = 3.6776704e-08
step 100: mean loss = 2.8184292e-07
step 200: mean loss = 4.893656e-07
step 300: mean loss = 5.581678e-07
step 400: mean loss = 4.687669e-07
step 500: mean loss = 6.395615e-07
step 600: mean loss = 5.8778147e-07
step 700: mean loss = 5.920322e-07
step 800: mean loss = 5.7316004e-07
step 900: mean loss = 6.09686e-07
step 1000: mean loss = 6.3239634e-07
step 1100: mean loss = 5.9472643e-07
step 1200: mean loss = 5.847908e-07
epoch 159: mean loss = 6.0888965e-07  learning rate = 0.00046329116
============================
Start of epoch 160
step 0: mean loss = 1.5256509e-06
step 100: mean loss = 5.6186406e-07
step 200: mean loss = 6.6512837e-07
step 300: mean loss = 5.927904e-07
step 400: mean loss = 5.5588924e-07
step 500: mean loss = 6.3621275e-07
step 600: mean loss = 6.6303824e-07
step 700: mean loss = 5.7637243e-07
step 800: mean loss = 6.116754e-07
step 900: mean loss = 6.0648136e-07
step 1000: mean loss = 6.026364e-07
step 1100: mean loss = 5.975982e-07
step 1200: mean loss = 6.0263886e-07
epoch 160: mean loss = 6.021832e-07  learning rate = 0.00046329116
============================
Start of epoch 161
step 0: mean loss = 6.0979137e-06
step 100: mean loss = 4.6934935e-07
step 200: mean loss = 5.4293827e-07
step 300: mean loss = 6.8692333e-07
step 400: mean loss = 5.4964505e-07
step 500: mean loss = 6.463259e-07
step 600: mean loss = 5.918854e-07
step 700: mean loss = 6.903946e-07
step 800: mean loss = 6.08221e-07
step 900: mean loss = 5.589196e-07
step 1000: mean loss = 5.6907203e-07
step 1100: mean loss = 5.804495e-07
step 1200: mean loss = 5.4061985e-07
epoch 161: mean loss = 5.2548506e-07  learning rate = 0.00044012658
============================
Start of epoch 162
step 0: mean loss = 1.5790283e-07
step 100: mean loss = 1.2391015e-06
step 200: mean loss = 7.4912555e-07
step 300: mean loss = 6.4885245e-07
step 400: mean loss = 6.5440537e-07
step 500: mean loss = 6.534092e-07
step 600: mean loss = 5.651683e-07
step 700: mean loss = 5.892496e-07
step 800: mean loss = 5.851352e-07
step 900: mean loss = 5.950329e-07
step 1000: mean loss = 5.91122e-07
step 1100: mean loss = 5.991926e-07
step 1200: mean loss = 5.894291e-07
epoch 162: mean loss = 5.735155e-07  learning rate = 0.00044012658
============================
Start of epoch 163
step 0: mean loss = 3.2190787e-08
step 100: mean loss = 7.355615e-07
step 200: mean loss = 4.70563e-07
step 300: mean loss = 4.906298e-07
step 400: mean loss = 5.6051897e-07
step 500: mean loss = 6.0195686e-07
step 600: mean loss = 5.755715e-07
step 700: mean loss = 5.873613e-07
step 800: mean loss = 5.406749e-07
step 900: mean loss = 5.39769e-07
step 1000: mean loss = 5.3832827e-07
step 1100: mean loss = 5.391352e-07
step 1200: mean loss = 5.3280377e-07
epoch 163: mean loss = 5.3850204e-07  learning rate = 0.00044012658
============================
Start of epoch 164
step 0: mean loss = 1.2155011e-06
step 100: mean loss = 6.78631e-07
step 200: mean loss = 6.126031e-07
step 300: mean loss = 5.6731426e-07
step 400: mean loss = 5.882362e-07
step 500: mean loss = 5.56775e-07
step 600: mean loss = 5.7735787e-07
step 700: mean loss = 5.4012304e-07
step 800: mean loss = 5.403389e-07
step 900: mean loss = 5.3793684e-07
step 1000: mean loss = 5.232617e-07
step 1100: mean loss = 5.362312e-07
step 1200: mean loss = 5.359773e-07
epoch 164: mean loss = 5.4836266e-07  learning rate = 0.00044012658
============================
Start of epoch 165
step 0: mean loss = 3.044208e-06
step 100: mean loss = 2.3230132e-07
step 200: mean loss = 5.410464e-07
step 300: mean loss = 4.907185e-07
step 400: mean loss = 4.895674e-07
step 500: mean loss = 5.704941e-07
step 600: mean loss = 5.489705e-07
step 700: mean loss = 5.537447e-07
step 800: mean loss = 5.369926e-07
step 900: mean loss = 5.4452636e-07
step 1000: mean loss = 5.096997e-07
step 1100: mean loss = 5.336604e-07
step 1200: mean loss = 5.3824095e-07
epoch 165: mean loss = 5.2557675e-07  learning rate = 0.00044012658
============================
Start of epoch 166
step 0: mean loss = 3.7849652e-08
step 100: mean loss = 6.537651e-07
step 200: mean loss = 5.1620003e-07
step 300: mean loss = 5.6004194e-07
step 400: mean loss = 5.3889164e-07
step 500: mean loss = 5.3621994e-07
step 600: mean loss = 5.2868506e-07
step 700: mean loss = 5.253459e-07
step 800: mean loss = 5.3010126e-07
step 900: mean loss = 5.390106e-07
step 1000: mean loss = 5.1581947e-07
step 1100: mean loss = 5.2077905e-07
step 1200: mean loss = 5.3070033e-07
epoch 166: mean loss = 5.1635374e-07  learning rate = 0.00044012658
============================
Start of epoch 167
step 0: mean loss = 6.723483e-08
step 100: mean loss = 6.3276985e-07
step 200: mean loss = 5.9891204e-07
step 300: mean loss = 5.5878814e-07
step 400: mean loss = 5.362445e-07
step 500: mean loss = 5.370928e-07
step 600: mean loss = 5.0955987e-07
step 700: mean loss = 5.199206e-07
step 800: mean loss = 5.1136783e-07
step 900: mean loss = 5.430756e-07
step 1000: mean loss = 5.090956e-07
step 1100: mean loss = 5.270375e-07
step 1200: mean loss = 5.421574e-07
epoch 167: mean loss = 5.280969e-07  learning rate = 0.00044012658
============================
Start of epoch 168
step 0: mean loss = 3.3747032e-08
step 100: mean loss = 5.4311096e-07
step 200: mean loss = 5.68881e-07
step 300: mean loss = 5.2785344e-07
step 400: mean loss = 5.959665e-07
step 500: mean loss = 4.891295e-07
step 600: mean loss = 6.050168e-07
step 700: mean loss = 5.229084e-07
step 800: mean loss = 5.311661e-07
step 900: mean loss = 5.388254e-07
step 1000: mean loss = 5.0935455e-07
step 1100: mean loss = 5.146271e-07
step 1200: mean loss = 5.1161834e-07
epoch 168: mean loss = 5.1349946e-07  learning rate = 0.00044012658
============================
Start of epoch 169
step 0: mean loss = 9.4715e-08
step 100: mean loss = 5.731846e-07
step 200: mean loss = 5.3991386e-07
step 300: mean loss = 5.2342705e-07
step 400: mean loss = 5.0431095e-07
step 500: mean loss = 5.148721e-07
step 600: mean loss = 5.2214796e-07
step 700: mean loss = 5.3441397e-07
step 800: mean loss = 5.0318715e-07
step 900: mean loss = 4.9319294e-07
step 1000: mean loss = 5.562013e-07
step 1100: mean loss = 5.792606e-07
step 1200: mean loss = 5.362204e-07
epoch 169: mean loss = 5.209546e-07  learning rate = 0.00044012658
============================
Start of epoch 170
step 0: mean loss = 2.5405956e-08
step 100: mean loss = 6.6902913e-07
step 200: mean loss = 5.842512e-07
step 300: mean loss = 6.225725e-07
step 400: mean loss = 5.07017e-07
step 500: mean loss = 5.099784e-07
step 600: mean loss = 5.6849376e-07
step 700: mean loss = 5.2266824e-07
step 800: mean loss = 5.214531e-07
step 900: mean loss = 5.2711056e-07
step 1000: mean loss = 5.251549e-07
step 1100: mean loss = 5.539866e-07
step 1200: mean loss = 5.3760414e-07
epoch 170: mean loss = 5.234615e-07  learning rate = 0.00044012658
============================
Start of epoch 171
step 0: mean loss = 3.3288146e-08
step 100: mean loss = 6.7584216e-07
step 200: mean loss = 4.399176e-07
step 300: mean loss = 8.920324e-07
step 400: mean loss = 6.800395e-07
step 500: mean loss = 7.087215e-07
step 600: mean loss = 6.015538e-07
step 700: mean loss = 5.2438065e-07
step 800: mean loss = 5.818579e-07
step 900: mean loss = 5.223028e-07
step 1000: mean loss = 4.7258123e-07
step 1100: mean loss = 5.2774874e-07
step 1200: mean loss = 4.859443e-07
epoch 171: mean loss = 5.324282e-07  learning rate = 0.00041812027
============================
Start of epoch 172
step 0: mean loss = 7.7824984e-07
step 100: mean loss = 9.56271e-08
step 200: mean loss = 1.8408814e-07
step 300: mean loss = 2.8291842e-07
step 400: mean loss = 3.267048e-07
step 500: mean loss = 3.249541e-07
step 600: mean loss = 3.9012323e-07
step 700: mean loss = 4.438834e-07
step 800: mean loss = 3.919548e-07
step 900: mean loss = 4.276829e-07
step 1000: mean loss = 4.2834571e-07
step 1100: mean loss = 4.385871e-07
step 1200: mean loss = 4.0662243e-07
epoch 172: mean loss = 4.2569877e-07  learning rate = 0.00041812027
============================
Start of epoch 173
step 0: mean loss = 1.226748e-07
step 100: mean loss = 3.9020338e-07
step 200: mean loss = 4.2424847e-07
step 300: mean loss = 4.209232e-07
step 400: mean loss = 4.1228373e-07
step 500: mean loss = 4.2926058e-07
step 600: mean loss = 4.3435094e-07
step 700: mean loss = 4.2877377e-07
step 800: mean loss = 4.3682056e-07
step 900: mean loss = 4.4528144e-07
step 1000: mean loss = 4.596883e-07
step 1100: mean loss = 4.5548234e-07
step 1200: mean loss = 4.6277015e-07
epoch 173: mean loss = 4.5328406e-07  learning rate = 0.00041812027
============================
Start of epoch 174
step 0: mean loss = 4.877292e-08
step 100: mean loss = 4.365684e-07
step 200: mean loss = 5.478139e-07
step 300: mean loss = 4.030914e-07
step 400: mean loss = 4.500586e-07
step 500: mean loss = 4.217064e-07
step 600: mean loss = 4.403391e-07
step 700: mean loss = 4.5558323e-07
step 800: mean loss = 4.2207836e-07
step 900: mean loss = 4.3883367e-07
step 1000: mean loss = 4.4086934e-07
step 1100: mean loss = 4.381917e-07
step 1200: mean loss = 4.4409944e-07
epoch 174: mean loss = 4.4381517e-07  learning rate = 0.00041812027
============================
Start of epoch 175
step 0: mean loss = 6.5936786e-07
step 100: mean loss = 3.273125e-07
step 200: mean loss = 3.9802546e-07
step 300: mean loss = 4.997499e-07
step 400: mean loss = 4.212883e-07
step 500: mean loss = 4.400198e-07
step 600: mean loss = 4.489987e-07
step 700: mean loss = 4.495496e-07
step 800: mean loss = 4.5729513e-07
step 900: mean loss = 4.3920434e-07
step 1000: mean loss = 4.552629e-07
step 1100: mean loss = 4.4122388e-07
step 1200: mean loss = 4.6543155e-07
epoch 175: mean loss = 4.5263727e-07  learning rate = 0.00041812027
============================
Start of epoch 176
step 0: mean loss = 2.4867163e-08
step 100: mean loss = 6.088007e-07
step 200: mean loss = 4.0770908e-07
step 300: mean loss = 4.8548026e-07
step 400: mean loss = 4.082091e-07
step 500: mean loss = 4.3156896e-07
step 600: mean loss = 4.793827e-07
step 700: mean loss = 4.853812e-07
step 800: mean loss = 4.3130046e-07
step 900: mean loss = 4.4989156e-07
step 1000: mean loss = 4.6049163e-07
step 1100: mean loss = 4.3475575e-07
step 1200: mean loss = 4.4427833e-07
epoch 176: mean loss = 4.5168693e-07  learning rate = 0.00041812027
============================
Start of epoch 177
step 0: mean loss = 1.9258691e-06
step 100: mean loss = 3.3472693e-07
step 200: mean loss = 4.2778834e-07
step 300: mean loss = 4.259303e-07
step 400: mean loss = 4.130896e-07
step 500: mean loss = 3.9842178e-07
step 600: mean loss = 4.3475714e-07
step 700: mean loss = 4.1746688e-07
step 800: mean loss = 4.3231066e-07
step 900: mean loss = 4.4806916e-07
step 1000: mean loss = 4.1834213e-07
step 1100: mean loss = 4.5268197e-07
step 1200: mean loss = 4.611477e-07
epoch 177: mean loss = 4.5750497e-07  learning rate = 0.00041812027
============================
Start of epoch 178
step 0: mean loss = 6.312675e-08
step 100: mean loss = 1.8351217e-07
step 200: mean loss = 4.2330848e-07
step 300: mean loss = 4.5870388e-07
step 400: mean loss = 3.506789e-07
step 500: mean loss = 4.6939925e-07
step 600: mean loss = 4.89825e-07
step 700: mean loss = 4.3698526e-07
step 800: mean loss = 4.5224112e-07
step 900: mean loss = 4.734895e-07
step 1000: mean loss = 4.3271666e-07
step 1100: mean loss = 4.48752e-07
step 1200: mean loss = 4.4279696e-07
epoch 178: mean loss = 4.303804e-07  learning rate = 0.00041812027
============================
Start of epoch 179
step 0: mean loss = 2.235723e-08
step 100: mean loss = 6.111427e-07
step 200: mean loss = 3.789856e-07
step 300: mean loss = 5.5884226e-07
step 400: mean loss = 4.5092202e-07
step 500: mean loss = 4.5044285e-07
step 600: mean loss = 4.459145e-07
step 700: mean loss = 4.5605782e-07
step 800: mean loss = 4.4711345e-07
step 900: mean loss = 4.6971704e-07
step 1000: mean loss = 4.4396867e-07
step 1100: mean loss = 4.3913684e-07
step 1200: mean loss = 4.382668e-07
epoch 179: mean loss = 4.527271e-07  learning rate = 0.00041812027
============================
Start of epoch 180
step 0: mean loss = 5.70142e-07
step 100: mean loss = 4.1564647e-07
step 200: mean loss = 4.14142e-07
step 300: mean loss = 4.2398625e-07
step 400: mean loss = 4.0971153e-07
step 500: mean loss = 4.137702e-07
step 600: mean loss = 4.012544e-07
step 700: mean loss = 4.4385177e-07
step 800: mean loss = 4.4443732e-07
step 900: mean loss = 4.2709388e-07
step 1000: mean loss = 4.3583663e-07
step 1100: mean loss = 4.1112517e-07
step 1200: mean loss = 4.2661122e-07
epoch 180: mean loss = 4.2383778e-07  learning rate = 0.00041812027
============================
Start of epoch 181
step 0: mean loss = 7.1670925e-08
step 100: mean loss = 3.752687e-07
step 200: mean loss = 4.4406926e-07
step 300: mean loss = 4.643572e-07
step 400: mean loss = 4.1040363e-07
step 500: mean loss = 4.3807495e-07
step 600: mean loss = 4.2561945e-07
step 700: mean loss = 4.3968322e-07
step 800: mean loss = 4.0769842e-07
step 900: mean loss = 4.3296254e-07
step 1000: mean loss = 3.9244384e-07
step 1100: mean loss = 3.9609648e-07
step 1200: mean loss = 3.9375615e-07
epoch 181: mean loss = 3.8364544e-07  learning rate = 0.00039721426
============================
Start of epoch 182
step 0: mean loss = 4.535653e-07
step 100: mean loss = 3.8363413e-07
step 200: mean loss = 3.58018e-07
step 300: mean loss = 4.892062e-07
step 400: mean loss = 4.0337815e-07
step 500: mean loss = 3.9468517e-07
step 600: mean loss = 3.9101963e-07
step 700: mean loss = 3.940458e-07
step 800: mean loss = 3.9224358e-07
step 900: mean loss = 3.981438e-07
step 1000: mean loss = 4.127107e-07
step 1100: mean loss = 4.056387e-07
step 1200: mean loss = 4.0747065e-07
epoch 182: mean loss = 4.0795845e-07  learning rate = 0.00039721426
============================
Start of epoch 183
step 0: mean loss = 6.638852e-08
step 100: mean loss = 5.571098e-07
step 200: mean loss = 3.3773085e-07
step 300: mean loss = 4.0192947e-07
step 400: mean loss = 3.6024568e-07
step 500: mean loss = 3.5556369e-07
step 600: mean loss = 3.5962094e-07
step 700: mean loss = 3.4512817e-07
step 800: mean loss = 3.672666e-07
step 900: mean loss = 3.6621157e-07
step 1000: mean loss = 3.731063e-07
step 1100: mean loss = 3.757043e-07
step 1200: mean loss = 3.7675667e-07
epoch 183: mean loss = 3.82492e-07  learning rate = 0.00039721426
============================
Start of epoch 184
step 0: mean loss = 6.8120187e-07
step 100: mean loss = 3.9811695e-07
step 200: mean loss = 4.0455743e-07
step 300: mean loss = 3.7985347e-07
step 400: mean loss = 3.902358e-07
step 500: mean loss = 3.8535725e-07
step 600: mean loss = 4.2219372e-07
step 700: mean loss = 4.027244e-07
step 800: mean loss = 3.5764134e-07
step 900: mean loss = 3.7616218e-07
step 1000: mean loss = 3.9464265e-07
step 1100: mean loss = 4.0432656e-07
step 1200: mean loss = 3.7280668e-07
epoch 184: mean loss = 3.9019287e-07  learning rate = 0.00039721426
============================
Start of epoch 185
step 0: mean loss = 1.4055183e-07
step 100: mean loss = 4.2441548e-07
step 200: mean loss = 3.3424038e-07
step 300: mean loss = 3.6659588e-07
step 400: mean loss = 3.8752302e-07
step 500: mean loss = 3.615091e-07
step 600: mean loss = 3.8397215e-07
step 700: mean loss = 3.6550705e-07
step 800: mean loss = 3.535312e-07
step 900: mean loss = 3.7560486e-07
step 1000: mean loss = 3.7623167e-07
step 1100: mean loss = 4.093021e-07
step 1200: mean loss = 3.7896314e-07
epoch 185: mean loss = 4.092395e-07  learning rate = 0.00039721426
============================
Start of epoch 186
step 0: mean loss = 7.695104e-07
step 100: mean loss = 1.06808564e-07
step 200: mean loss = 2.6414622e-07
step 300: mean loss = 2.8596097e-07
step 400: mean loss = 3.3125195e-07
step 500: mean loss = 3.4182068e-07
step 600: mean loss = 3.4312507e-07
step 700: mean loss = 3.500332e-07
step 800: mean loss = 3.5047708e-07
step 900: mean loss = 3.554322e-07
step 1000: mean loss = 3.5369635e-07
step 1100: mean loss = 3.5831204e-07
step 1200: mean loss = 3.5242033e-07
epoch 186: mean loss = 3.4358163e-07  learning rate = 0.00039721426
============================
Start of epoch 187
step 0: mean loss = 1.6326958e-07
step 100: mean loss = 5.5845646e-07
step 200: mean loss = 5.070042e-07
step 300: mean loss = 4.6111046e-07
step 400: mean loss = 4.2754053e-07
step 500: mean loss = 4.039488e-07
step 600: mean loss = 4.1714966e-07
step 700: mean loss = 3.7278744e-07
step 800: mean loss = 3.8916895e-07
step 900: mean loss = 3.951566e-07
step 1000: mean loss = 3.874103e-07
step 1100: mean loss = 4.0204333e-07
step 1200: mean loss = 4.040032e-07
epoch 187: mean loss = 3.9259388e-07  learning rate = 0.00039721426
============================
Start of epoch 188
step 0: mean loss = 1.9933902e-08
step 100: mean loss = 4.9730824e-07
step 200: mean loss = 4.5717795e-07
step 300: mean loss = 3.3700783e-07
step 400: mean loss = 4.3746422e-07
step 500: mean loss = 3.7502176e-07
step 600: mean loss = 3.7832632e-07
step 700: mean loss = 3.8078755e-07
step 800: mean loss = 3.656517e-07
step 900: mean loss = 3.7448854e-07
step 1000: mean loss = 3.6490397e-07
step 1100: mean loss = 3.8331163e-07
step 1200: mean loss = 3.932638e-07
epoch 188: mean loss = 3.831824e-07  learning rate = 0.00039721426
============================
Start of epoch 189
step 0: mean loss = 2.6659304e-08
step 100: mean loss = 2.601609e-07
step 200: mean loss = 3.3405948e-07
step 300: mean loss = 3.7324594e-07
step 400: mean loss = 3.281719e-07
step 500: mean loss = 3.7859672e-07
step 600: mean loss = 3.7871922e-07
step 700: mean loss = 3.6429623e-07
step 800: mean loss = 3.8002742e-07
step 900: mean loss = 3.775817e-07
step 1000: mean loss = 3.5936725e-07
step 1100: mean loss = 3.5780616e-07
step 1200: mean loss = 3.591598e-07
epoch 189: mean loss = 3.702649e-07  learning rate = 0.00039721426
============================
Start of epoch 190
step 0: mean loss = 7.325242e-07
step 100: mean loss = 3.969428e-07
step 200: mean loss = 3.5822467e-07
step 300: mean loss = 3.370494e-07
step 400: mean loss = 4.3267366e-07
step 500: mean loss = 3.7626037e-07
step 600: mean loss = 3.9227731e-07
step 700: mean loss = 3.9092785e-07
step 800: mean loss = 3.6111788e-07
step 900: mean loss = 3.7393684e-07
step 1000: mean loss = 3.7329977e-07
step 1100: mean loss = 3.630126e-07
step 1200: mean loss = 3.677895e-07
epoch 190: mean loss = 3.657121e-07  learning rate = 0.00039721426
============================
Start of epoch 191
step 0: mean loss = 6.086697e-07
step 100: mean loss = 6.092491e-07
step 200: mean loss = 4.3187734e-07
step 300: mean loss = 4.0871592e-07
step 400: mean loss = 3.7584755e-07
step 500: mean loss = 3.5191334e-07
step 600: mean loss = 3.9790947e-07
step 700: mean loss = 3.8346423e-07
step 800: mean loss = 3.8219778e-07
step 900: mean loss = 4.0169468e-07
step 1000: mean loss = 3.7130755e-07
step 1100: mean loss = 3.4634107e-07
step 1200: mean loss = 3.670376e-07
epoch 191: mean loss = 3.6624104e-07  learning rate = 0.00037735354
============================
Start of epoch 192
step 0: mean loss = 3.9515715e-08
step 100: mean loss = 3.004385e-08
step 200: mean loss = 2.534859e-07
step 300: mean loss = 2.2231644e-07
step 400: mean loss = 2.83178e-07
step 500: mean loss = 2.9948345e-07
step 600: mean loss = 2.9853146e-07
step 700: mean loss = 3.1236183e-07
step 800: mean loss = 2.9104356e-07
step 900: mean loss = 3.2297606e-07
step 1000: mean loss = 3.1520966e-07
step 1100: mean loss = 3.1547367e-07
step 1200: mean loss = 3.219189e-07
epoch 192: mean loss = 3.2090986e-07  learning rate = 0.00037735354
============================
Start of epoch 193
step 0: mean loss = 2.343699e-07
step 100: mean loss = 3.6236804e-07
step 200: mean loss = 2.733153e-07
step 300: mean loss = 3.3566695e-07
step 400: mean loss = 3.7797435e-07
step 500: mean loss = 3.427892e-07
step 600: mean loss = 3.1301008e-07
step 700: mean loss = 3.160527e-07
step 800: mean loss = 3.2431834e-07
step 900: mean loss = 3.0887466e-07
step 1000: mean loss = 3.4215194e-07
step 1100: mean loss = 3.2698986e-07
step 1200: mean loss = 3.168831e-07
epoch 193: mean loss = 3.3209028e-07  learning rate = 0.00037735354
============================
Start of epoch 194
step 0: mean loss = 1.9898664e-07
step 100: mean loss = 2.973311e-07
step 200: mean loss = 2.9890217e-07
step 300: mean loss = 2.7447174e-07
step 400: mean loss = 3.0717598e-07
step 500: mean loss = 3.155681e-07
step 600: mean loss = 3.2376718e-07
step 700: mean loss = 3.2445507e-07
step 800: mean loss = 3.245432e-07
step 900: mean loss = 3.2903097e-07
step 1000: mean loss = 3.1117096e-07
step 1100: mean loss = 3.3521377e-07
step 1200: mean loss = 3.2030698e-07
epoch 194: mean loss = 3.4317983e-07  learning rate = 0.00037735354
============================
Start of epoch 195
step 0: mean loss = 9.875699e-08
step 100: mean loss = 9.6500656e-08
step 200: mean loss = 2.0462646e-07
step 300: mean loss = 2.690045e-07
step 400: mean loss = 3.0658103e-07
step 500: mean loss = 2.7390288e-07
step 600: mean loss = 3.0443834e-07
step 700: mean loss = 3.026169e-07
step 800: mean loss = 3.0350364e-07
step 900: mean loss = 2.9942757e-07
step 1000: mean loss = 3.0636022e-07
step 1100: mean loss = 3.068194e-07
step 1200: mean loss = 3.092376e-07
epoch 195: mean loss = 3.0184538e-07  learning rate = 0.00037735354
============================
Start of epoch 196
step 0: mean loss = 2.1415742e-07
step 100: mean loss = 4.916772e-07
step 200: mean loss = 3.6406013e-07
step 300: mean loss = 3.6947037e-07
step 400: mean loss = 3.5395433e-07
step 500: mean loss = 3.463731e-07
step 600: mean loss = 3.5222882e-07
step 700: mean loss = 3.601764e-07
step 800: mean loss = 3.3788623e-07
step 900: mean loss = 3.3459898e-07
step 1000: mean loss = 3.3327115e-07
step 1100: mean loss = 3.2921335e-07
step 1200: mean loss = 3.3923047e-07
epoch 196: mean loss = 3.405772e-07  learning rate = 0.00037735354
============================
Start of epoch 197
step 0: mean loss = 2.2654987e-08
step 100: mean loss = 3.4417963e-07
step 200: mean loss = 3.3101009e-07
step 300: mean loss = 3.5069536e-07
step 400: mean loss = 3.638431e-07
step 500: mean loss = 2.9613358e-07
step 600: mean loss = 3.2067223e-07
step 700: mean loss = 3.1246614e-07
step 800: mean loss = 3.2689957e-07
step 900: mean loss = 3.1818527e-07
step 1000: mean loss = 3.2402633e-07
step 1100: mean loss = 3.3674652e-07
step 1200: mean loss = 3.1888038e-07
epoch 197: mean loss = 3.1466743e-07  learning rate = 0.00037735354
============================
Start of epoch 198
step 0: mean loss = 8.569454e-08
step 100: mean loss = 3.804425e-07
step 200: mean loss = 3.9452635e-07
step 300: mean loss = 3.3795823e-07
step 400: mean loss = 3.7470397e-07
step 500: mean loss = 3.4439483e-07
step 600: mean loss = 3.5234592e-07
step 700: mean loss = 3.5004697e-07
step 800: mean loss = 3.4140817e-07
step 900: mean loss = 3.351563e-07
step 1000: mean loss = 3.3523634e-07
step 1100: mean loss = 3.3384265e-07
step 1200: mean loss = 3.364663e-07
epoch 198: mean loss = 3.2768023e-07  learning rate = 0.00037735354
============================
WARNING:tensorflow:5 out of the last 6 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
Start of epoch 199
step 0: mean loss = 2.0313806e-08
step 100: mean loss = 3.50342e-07
step 200: mean loss = 3.542086e-07
step 300: mean loss = 3.6401892e-07
step 400: mean loss = 3.2475208e-07
step 500: mean loss = 3.37543e-07
step 600: mean loss = 3.4048577e-07
step 700: mean loss = 3.285384e-07
step 800: mean loss = 3.4917798e-07
step 900: mean loss = 3.4078613e-07
step 1000: mean loss = 3.4344112e-07
step 1100: mean loss = 3.387435e-07
step 1200: mean loss = 3.373576e-07
epoch 199: mean loss = 3.3458505e-07  learning rate = 0.00037735354
saving the weights
Relative Error in the forces is 0.00025316546
++++++++++++++++++++++++++++++
Start of cycle 1
Total number of epochs in this cycle: 400
Batch size in this cycle: 16
============================
WARNING:tensorflow:6 out of the last 7 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 6 calls to <function DeepMDsimpleEnergy.call at 0x7fccf0380af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
2020-08-27 15:22:25.801228: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 15:22:25.801283: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 15:22:25.801344: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 15:22:25.801364: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
WARNING:tensorflow:7 out of the last 8 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 7 calls to <function pyramidLayer.call at 0x7fcd14295280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 7 calls to <function pyramidLayer.call at 0x7fcd142954c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 7 calls to <function pyramidLayer.call at 0x7fcd14295700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:5 out of the last 7 calls to <function MyDenseLayer.call at 0x7fcd14295940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 7 calls to <function DeepMDsimpleEnergy.call at 0x7fccf0380af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
2020-08-27 15:22:52.544339: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 15:22:52.544387: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 15:22:52.544415: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 15:22:52.544447: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
Start of epoch 0
step 0: mean loss = 3.2048334e-08
step 100: mean loss = 2.4011229e-07
step 200: mean loss = 2.8881277e-07
step 300: mean loss = 2.8143387e-07
step 400: mean loss = 3.046131e-07
step 500: mean loss = 3.31421e-07
step 600: mean loss = 3.3419533e-07
epoch 0: mean loss = 3.260465e-07  learning rate = 0.00037735354
============================
Start of epoch 1
step 0: mean loss = 2.0570075e-08
step 100: mean loss = 2.2309145e-07
step 200: mean loss = 3.064394e-07
step 300: mean loss = 2.7131202e-07
step 400: mean loss = 3.0946336e-07
step 500: mean loss = 3.080764e-07
step 600: mean loss = 3.0512638e-07
epoch 1: mean loss = 2.9676e-07  learning rate = 0.00037735354
============================
Start of epoch 2
step 0: mean loss = 2.027425e-08
step 100: mean loss = 5.635687e-07
step 200: mean loss = 3.5052102e-07
step 300: mean loss = 3.6698435e-07
step 400: mean loss = 3.8159007e-07
step 500: mean loss = 3.4963938e-07
step 600: mean loss = 3.3151244e-07
epoch 2: mean loss = 3.2426934e-07  learning rate = 0.00037735354
============================
Start of epoch 3
step 0: mean loss = 3.0755672e-07
step 100: mean loss = 3.1807284e-07
step 200: mean loss = 4.21571e-07
step 300: mean loss = 3.91892e-07
step 400: mean loss = 3.5627912e-07
step 500: mean loss = 3.9051153e-07
step 600: mean loss = 3.5406313e-07
epoch 3: mean loss = 3.4425153e-07  learning rate = 0.00035848588
============================
Start of epoch 4
step 0: mean loss = 1.648982e-08
step 100: mean loss = 1.6271638e-08
step 200: mean loss = 1.2790474e-07
step 300: mean loss = 1.5501917e-07
step 400: mean loss = 2.2035408e-07
step 500: mean loss = 2.3839945e-07
step 600: mean loss = 2.605845e-07
epoch 4: mean loss = 2.5542568e-07  learning rate = 0.00035848588
============================
Start of epoch 5
step 0: mean loss = 4.724019e-08
step 100: mean loss = 2.9793682e-07
step 200: mean loss = 2.5643092e-07
step 300: mean loss = 2.7429422e-07
step 400: mean loss = 3.215421e-07
step 500: mean loss = 2.7749678e-07
step 600: mean loss = 3.3005483e-07
epoch 5: mean loss = 3.2753493e-07  learning rate = 0.00035848588
============================
Start of epoch 6
step 0: mean loss = 1.1743893e-07
step 100: mean loss = 2.4641489e-08
step 200: mean loss = 2.3104764e-07
step 300: mean loss = 2.442687e-07
step 400: mean loss = 2.11882e-07
step 500: mean loss = 2.2512003e-07
step 600: mean loss = 2.3345355e-07
epoch 6: mean loss = 2.5188334e-07  learning rate = 0.00035848588
============================
Start of epoch 7
step 0: mean loss = 1.2086643e-07
step 100: mean loss = 3.2450612e-07
step 200: mean loss = 2.5894036e-07
step 300: mean loss = 2.5880448e-07
step 400: mean loss = 3.0509017e-07
step 500: mean loss = 2.7687798e-07
step 600: mean loss = 2.935853e-07
epoch 7: mean loss = 2.874601e-07  learning rate = 0.00035848588
============================
Start of epoch 8
step 0: mean loss = 4.7480235e-08
step 100: mean loss = 2.9567227e-07
step 200: mean loss = 2.0504773e-07
step 300: mean loss = 3.0073997e-07
step 400: mean loss = 2.9210247e-07
step 500: mean loss = 2.635763e-07
step 600: mean loss = 2.918394e-07
epoch 8: mean loss = 2.9113616e-07  learning rate = 0.00035848588
============================
Start of epoch 9
step 0: mean loss = 3.934714e-08
step 100: mean loss = 2.4204337e-07
step 200: mean loss = 2.3518254e-07
step 300: mean loss = 2.4661347e-07
step 400: mean loss = 2.457473e-07
step 500: mean loss = 2.8143265e-07
step 600: mean loss = 2.9528465e-07
epoch 9: mean loss = 2.88388e-07  learning rate = 0.00035848588
============================
Start of epoch 10
step 0: mean loss = 3.0821003e-08
step 100: mean loss = 2.0226199e-07
step 200: mean loss = 2.396293e-07
step 300: mean loss = 2.9910302e-07
step 400: mean loss = 2.6154385e-07
step 500: mean loss = 2.8962594e-07
step 600: mean loss = 2.9537742e-07
epoch 10: mean loss = 2.8828032e-07  learning rate = 0.00035848588
============================
Start of epoch 11
step 0: mean loss = 3.8441097e-08
step 100: mean loss = 2.0023106e-07
step 200: mean loss = 2.5889042e-07
step 300: mean loss = 2.460824e-07
step 400: mean loss = 2.72534e-07
step 500: mean loss = 2.8085705e-07
step 600: mean loss = 2.688374e-07
epoch 11: mean loss = 2.625668e-07  learning rate = 0.00035848588
============================
Start of epoch 12
step 0: mean loss = 7.0197196e-08
step 100: mean loss = 2.079131e-07
step 200: mean loss = 2.7627152e-07
step 300: mean loss = 3.062935e-07
step 400: mean loss = 3.0886287e-07
step 500: mean loss = 3.1021722e-07
step 600: mean loss = 2.9754906e-07
epoch 12: mean loss = 2.8947437e-07  learning rate = 0.00035848588
============================
Start of epoch 13
step 0: mean loss = 1.5394102e-08
step 100: mean loss = 4.2176532e-07
step 200: mean loss = 2.4038135e-07
step 300: mean loss = 3.2351178e-07
step 400: mean loss = 2.516906e-07
step 500: mean loss = 3.2144428e-07
step 600: mean loss = 2.857625e-07
epoch 13: mean loss = 2.783261e-07  learning rate = 0.00035848588
============================
Start of epoch 14
step 0: mean loss = 3.123997e-08
step 100: mean loss = 4.079938e-07
step 200: mean loss = 3.9887078e-07
step 300: mean loss = 3.1224974e-07
step 400: mean loss = 3.008833e-07
step 500: mean loss = 2.9404657e-07
step 600: mean loss = 2.9639804e-07
epoch 14: mean loss = 2.9256248e-07  learning rate = 0.00035848588
============================
Start of epoch 15
step 0: mean loss = 9.8378784e-08
step 100: mean loss = 2.7996433e-07
step 200: mean loss = 3.6386285e-07
step 300: mean loss = 2.521855e-07
step 400: mean loss = 2.9398242e-07
step 500: mean loss = 3.21359e-07
step 600: mean loss = 2.771851e-07
epoch 15: mean loss = 3.1263005e-07  learning rate = 0.00035848588
============================
Start of epoch 16
step 0: mean loss = 3.340931e-07
step 100: mean loss = 9.3330655e-08
step 200: mean loss = 1.9991307e-07
step 300: mean loss = 2.5554237e-07
step 400: mean loss = 2.6268648e-07
step 500: mean loss = 2.5986225e-07
step 600: mean loss = 2.4719688e-07
epoch 16: mean loss = 2.741492e-07  learning rate = 0.00035848588
============================
Start of epoch 17
step 0: mean loss = 2.0439717e-08
step 100: mean loss = 8.965631e-08
step 200: mean loss = 2.4655387e-07
step 300: mean loss = 2.8583085e-07
step 400: mean loss = 2.5435747e-07
step 500: mean loss = 2.5884276e-07
step 600: mean loss = 2.695051e-07
epoch 17: mean loss = 2.6283445e-07  learning rate = 0.00035848588
============================
Start of epoch 18
step 0: mean loss = 2.7485724e-08
step 100: mean loss = 2.8948548e-07
step 200: mean loss = 2.3671588e-07
step 300: mean loss = 2.9736677e-07
step 400: mean loss = 2.845549e-07
step 500: mean loss = 2.632615e-07
step 600: mean loss = 2.8557835e-07
epoch 18: mean loss = 2.8640002e-07  learning rate = 0.00035848588
============================
Start of epoch 19
step 0: mean loss = 8.6362185e-08
step 100: mean loss = 2.4798703e-07
step 200: mean loss = 2.9268222e-07
step 300: mean loss = 2.555e-07
step 400: mean loss = 2.7295252e-07
step 500: mean loss = 2.7899375e-07
step 600: mean loss = 2.654006e-07
epoch 19: mean loss = 2.5837588e-07  learning rate = 0.00035848588
============================
Start of epoch 20
step 0: mean loss = 3.7966803e-08
step 100: mean loss = 3.4018723e-07
step 200: mean loss = 3.0098084e-07
step 300: mean loss = 3.01432e-07
step 400: mean loss = 3.16587e-07
step 500: mean loss = 2.999825e-07
step 600: mean loss = 2.957721e-07
epoch 20: mean loss = 2.8963598e-07  learning rate = 0.00035848588
============================
Start of epoch 21
step 0: mean loss = 1.6264504e-08
step 100: mean loss = 2.515278e-07
step 200: mean loss = 2.1860899e-07
step 300: mean loss = 3.062355e-07
step 400: mean loss = 2.4572668e-07
step 500: mean loss = 2.920248e-07
step 600: mean loss = 2.8387743e-07
epoch 21: mean loss = 2.8349137e-07  learning rate = 0.00035848588
============================
Start of epoch 22
step 0: mean loss = 2.0491937e-07
step 100: mean loss = 2.437834e-07
step 200: mean loss = 2.2809765e-07
step 300: mean loss = 2.721713e-07
step 400: mean loss = 2.747284e-07
step 500: mean loss = 2.9327114e-07
step 600: mean loss = 2.6827067e-07
epoch 22: mean loss = 2.980503e-07  learning rate = 0.00035848588
============================
Start of epoch 23
step 0: mean loss = 7.0612873e-07
step 100: mean loss = 5.517555e-08
step 200: mean loss = 2.6043938e-07
step 300: mean loss = 1.8732285e-07
step 400: mean loss = 2.7293282e-07
step 500: mean loss = 2.4322293e-07
step 600: mean loss = 2.597256e-07
epoch 23: mean loss = 2.5369602e-07  learning rate = 0.00035848588
============================
Start of epoch 24
step 0: mean loss = 1.5402986e-08
step 100: mean loss = 1.780286e-07
step 200: mean loss = 1.3907908e-07
step 300: mean loss = 1.8830106e-07
step 400: mean loss = 2.093248e-07
step 500: mean loss = 1.9401136e-07
step 600: mean loss = 2.1882248e-07
epoch 24: mean loss = 2.1290815e-07  learning rate = 0.00034056156
============================
Start of epoch 25
step 0: mean loss = 1.4944524e-08
step 100: mean loss = 3.212597e-07
step 200: mean loss = 3.0597013e-07
step 300: mean loss = 2.9270353e-07
step 400: mean loss = 2.6938076e-07
step 500: mean loss = 2.706668e-07
step 600: mean loss = 2.607869e-07
epoch 25: mean loss = 2.5361547e-07  learning rate = 0.00034056156
============================
Start of epoch 26
step 0: mean loss = 1.4050354e-08
step 100: mean loss = 4.171311e-07
step 200: mean loss = 3.1184737e-07
step 300: mean loss = 3.1076857e-07
step 400: mean loss = 2.6857535e-07
step 500: mean loss = 2.9773423e-07
step 600: mean loss = 2.6569055e-07
epoch 26: mean loss = 2.5838307e-07  learning rate = 0.00034056156
============================
Start of epoch 27
step 0: mean loss = 1.5034733e-08
step 100: mean loss = 2.4800565e-07
step 200: mean loss = 2.6877294e-07
step 300: mean loss = 2.402928e-07
step 400: mean loss = 2.559519e-07
step 500: mean loss = 2.644165e-07
step 600: mean loss = 2.4933462e-07
epoch 27: mean loss = 2.4251068e-07  learning rate = 0.00034056156
============================
Start of epoch 28
step 0: mean loss = 1.495393e-08
step 100: mean loss = 3.8798711e-07
step 200: mean loss = 3.0821224e-07
step 300: mean loss = 2.7466265e-07
step 400: mean loss = 2.676139e-07
step 500: mean loss = 2.7797506e-07
step 600: mean loss = 2.571303e-07
epoch 28: mean loss = 2.510185e-07  learning rate = 0.00034056156
============================
Start of epoch 29
step 0: mean loss = 9.2721336e-08
step 100: mean loss = 2.3586746e-07
step 200: mean loss = 2.4647957e-07
step 300: mean loss = 2.6925082e-07
step 400: mean loss = 2.6515943e-07
step 500: mean loss = 2.5870804e-07
step 600: mean loss = 2.7702316e-07
epoch 29: mean loss = 2.6947325e-07  learning rate = 0.00034056156
============================
Start of epoch 30
step 0: mean loss = 1.6254178e-08
step 100: mean loss = 9.1795435e-08
step 200: mean loss = 2.2680477e-07
step 300: mean loss = 2.5853927e-07
step 400: mean loss = 2.2083233e-07
step 500: mean loss = 2.427537e-07
step 600: mean loss = 2.2525082e-07
epoch 30: mean loss = 2.2232719e-07  learning rate = 0.00034056156
============================
Start of epoch 31
step 0: mean loss = 7.159082e-07
step 100: mean loss = 3.914794e-07
step 200: mean loss = 3.5857371e-07
step 300: mean loss = 2.9103677e-07
step 400: mean loss = 2.7906336e-07
step 500: mean loss = 2.4761806e-07
step 600: mean loss = 2.8759487e-07
epoch 31: mean loss = 2.8990743e-07  learning rate = 0.00034056156
============================
Start of epoch 32
step 0: mean loss = 2.2854888e-07
step 100: mean loss = 8.103368e-08
step 200: mean loss = 1.7068118e-07
step 300: mean loss = 2.0458064e-07
step 400: mean loss = 2.1559264e-07
step 500: mean loss = 2.1694967e-07
step 600: mean loss = 2.3500164e-07
epoch 32: mean loss = 2.2887988e-07  learning rate = 0.00034056156
============================
Start of epoch 33
step 0: mean loss = 5.1251472e-08
step 100: mean loss = 1.3536612e-07
step 200: mean loss = 2.6977514e-07
step 300: mean loss = 2.0896674e-07
step 400: mean loss = 2.5448122e-07
step 500: mean loss = 2.3757724e-07
step 600: mean loss = 2.4120513e-07
epoch 33: mean loss = 2.3739567e-07  learning rate = 0.00034056156
============================
Start of epoch 34
step 0: mean loss = 3.3394986e-08
step 100: mean loss = 3.245247e-07
step 200: mean loss = 2.2063541e-07
step 300: mean loss = 2.8423784e-07
step 400: mean loss = 2.381875e-07
step 500: mean loss = 2.618168e-07
step 600: mean loss = 2.5156845e-07
epoch 34: mean loss = 2.4546762e-07  learning rate = 0.00034056156
============================
Start of epoch 35
step 0: mean loss = 2.10027e-08
step 100: mean loss = 2.8589508e-07
step 200: mean loss = 3.0957042e-07
step 300: mean loss = 2.5522883e-07
step 400: mean loss = 2.8947053e-07
step 500: mean loss = 2.62027e-07
step 600: mean loss = 2.784347e-07
epoch 35: mean loss = 2.715988e-07  learning rate = 0.00034056156
============================
Start of epoch 36
step 0: mean loss = 1.4896583e-08
step 100: mean loss = 1.1457694e-07
step 200: mean loss = 2.7469025e-07
step 300: mean loss = 2.1609097e-07
step 400: mean loss = 2.3154541e-07
step 500: mean loss = 2.0560225e-07
step 600: mean loss = 2.2618386e-07
epoch 36: mean loss = 2.1999819e-07  learning rate = 0.00034056156
============================
Start of epoch 37
step 0: mean loss = 1.3491428e-08
step 100: mean loss = 4.2619908e-07
step 200: mean loss = 3.0564044e-07
step 300: mean loss = 3.12382e-07
step 400: mean loss = 3.0399607e-07
step 500: mean loss = 2.5502547e-07
step 600: mean loss = 2.6505984e-07
epoch 37: mean loss = 2.5773787e-07  learning rate = 0.00034056156
============================
Start of epoch 38
step 0: mean loss = 1.332217e-08
step 100: mean loss = 3.0202852e-07
step 200: mean loss = 2.429824e-07
step 300: mean loss = 2.8392282e-07
step 400: mean loss = 2.2399992e-07
step 500: mean loss = 2.6695324e-07
step 600: mean loss = 2.6010866e-07
epoch 38: mean loss = 2.586282e-07  learning rate = 0.00034056156
============================
Start of epoch 39
step 0: mean loss = 3.9083858e-08
step 100: mean loss = 1.9321588e-07
step 200: mean loss = 2.1473609e-07
step 300: mean loss = 1.9437057e-07
step 400: mean loss = 2.4656123e-07
step 500: mean loss = 2.5198463e-07
step 600: mean loss = 2.4255365e-07
epoch 39: mean loss = 2.3618607e-07  learning rate = 0.00034056156
============================
Start of epoch 40
step 0: mean loss = 1.9765267e-08
step 100: mean loss = 2.879996e-07
step 200: mean loss = 2.0002942e-07
step 300: mean loss = 2.4845914e-07
step 400: mean loss = 2.2324527e-07
step 500: mean loss = 2.5509385e-07
step 600: mean loss = 2.7234196e-07
epoch 40: mean loss = 2.6713155e-07  learning rate = 0.00034056156
============================
Start of epoch 41
step 0: mean loss = 6.352161e-08
step 100: mean loss = 1.9790127e-07
step 200: mean loss = 2.8107306e-07
step 300: mean loss = 2.2315714e-07
step 400: mean loss = 2.0567232e-07
step 500: mean loss = 2.5481302e-07
step 600: mean loss = 2.267345e-07
epoch 41: mean loss = 2.2152517e-07  learning rate = 0.00034056156
============================
Start of epoch 42
step 0: mean loss = 4.1468137e-08
step 100: mean loss = 3.7396643e-07
step 200: mean loss = 2.406942e-07
step 300: mean loss = 2.6837353e-07
step 400: mean loss = 2.7280595e-07
step 500: mean loss = 2.6577058e-07
step 600: mean loss = 2.684609e-07
epoch 42: mean loss = 2.6138474e-07  learning rate = 0.00034056156
============================
Start of epoch 43
step 0: mean loss = 1.9151939e-08
step 100: mean loss = 2.6619304e-07
step 200: mean loss = 2.4101436e-07
step 300: mean loss = 2.3936212e-07
step 400: mean loss = 2.1360532e-07
step 500: mean loss = 2.1774365e-07
step 600: mean loss = 2.4804842e-07
epoch 43: mean loss = 2.6617064e-07  learning rate = 0.00034056156
============================
Start of epoch 44
step 0: mean loss = 5.5625225e-07
step 100: mean loss = 1.7226317e-07
step 200: mean loss = 9.394772e-08
step 300: mean loss = 6.699994e-08
step 400: mean loss = 1.5575104e-07
step 500: mean loss = 1.2800992e-07
step 600: mean loss = 1.8561789e-07
epoch 44: mean loss = 1.8065485e-07  learning rate = 0.00032353346
============================
Start of epoch 45
step 0: mean loss = 1.35909435e-08
step 100: mean loss = 1.3072469e-08
step 200: mean loss = 1.7184057e-07
step 300: mean loss = 1.8957809e-07
step 400: mean loss = 2.2658178e-07
step 500: mean loss = 1.8677667e-07
step 600: mean loss = 2.0575118e-07
epoch 45: mean loss = 2.0983437e-07  learning rate = 0.00032353346
============================
Start of epoch 46
step 0: mean loss = 7.2023397e-07
step 100: mean loss = 2.0732462e-07
step 200: mean loss = 1.7107351e-07
step 300: mean loss = 2.0903195e-07
step 400: mean loss = 2.0786692e-07
step 500: mean loss = 2.3831306e-07
step 600: mean loss = 2.1662517e-07
epoch 46: mean loss = 2.1106194e-07  learning rate = 0.00032353346
============================
Start of epoch 47
step 0: mean loss = 1.5166801e-08
step 100: mean loss = 2.3386121e-07
step 200: mean loss = 2.5868928e-07
step 300: mean loss = 2.758651e-07
step 400: mean loss = 2.5375562e-07
step 500: mean loss = 2.0615575e-07
step 600: mean loss = 2.536249e-07
epoch 47: mean loss = 2.4821136e-07  learning rate = 0.00032353346
============================
Start of epoch 48
step 0: mean loss = 3.9861064e-07
step 100: mean loss = 1.1769496e-07
step 200: mean loss = 1.7509012e-07
step 300: mean loss = 1.9919237e-07
step 400: mean loss = 1.8516701e-07
step 500: mean loss = 1.9153475e-07
step 600: mean loss = 1.9242864e-07
epoch 48: mean loss = 2.1066086e-07  learning rate = 0.00032353346
============================
Start of epoch 49
step 0: mean loss = 6.4257044e-08
step 100: mean loss = 5.6560175e-08
step 200: mean loss = 1.6379634e-07
step 300: mean loss = 1.7805101e-07
step 400: mean loss = 2.0225774e-07
step 500: mean loss = 1.999034e-07
step 600: mean loss = 2.096238e-07
epoch 49: mean loss = 2.0411271e-07  learning rate = 0.00032353346
============================
Start of epoch 50
step 0: mean loss = 1.5033462e-08
step 100: mean loss = 2.416213e-07
step 200: mean loss = 2.0125228e-07
step 300: mean loss = 2.1901732e-07
step 400: mean loss = 2.4630367e-07
step 500: mean loss = 2.1675952e-07
step 600: mean loss = 2.4252148e-07
epoch 50: mean loss = 2.3709487e-07  learning rate = 0.00032353346
============================
Start of epoch 51
step 0: mean loss = 1.6546832e-07
step 100: mean loss = 1.1185641e-07
step 200: mean loss = 1.9398495e-07
step 300: mean loss = 1.6055671e-07
step 400: mean loss = 2.2682654e-07
step 500: mean loss = 1.8824953e-07
step 600: mean loss = 1.9939017e-07
epoch 51: mean loss = 1.9405438e-07  learning rate = 0.00032353346
============================
Start of epoch 52
step 0: mean loss = 1.8097463e-08
step 100: mean loss = 2.719262e-07
step 200: mean loss = 2.425758e-07
step 300: mean loss = 2.1025735e-07
step 400: mean loss = 2.2706459e-07
step 500: mean loss = 2.4161358e-07
step 600: mean loss = 2.2037314e-07
epoch 52: mean loss = 2.2767586e-07  learning rate = 0.00032353346
============================
Start of epoch 53
step 0: mean loss = 1.07885725e-07
step 100: mean loss = 2.0203315e-07
step 200: mean loss = 2.3577788e-07
step 300: mean loss = 1.802496e-07
step 400: mean loss = 2.0858327e-07
step 500: mean loss = 2.2416103e-07
step 600: mean loss = 2.0701431e-07
epoch 53: mean loss = 2.0134583e-07  learning rate = 0.00032353346
============================
Start of epoch 54
step 0: mean loss = 1.2010549e-08
step 100: mean loss = 4.7209082e-07
step 200: mean loss = 2.5028035e-07
step 300: mean loss = 2.647577e-07
step 400: mean loss = 2.3258403e-07
step 500: mean loss = 2.1346483e-07
step 600: mean loss = 2.5608142e-07
epoch 54: mean loss = 2.5173946e-07  learning rate = 0.00032353346
============================
Start of epoch 55
step 0: mean loss = 6.695641e-08
step 100: mean loss = 1.5382703e-08
step 200: mean loss = 2.6802354e-07
step 300: mean loss = 2.0465284e-07
step 400: mean loss = 1.8117372e-07
step 500: mean loss = 2.1834096e-07
step 600: mean loss = 1.8711432e-07
epoch 55: mean loss = 1.9119503e-07  learning rate = 0.00032353346
============================
Start of epoch 56
step 0: mean loss = 1.45431e-06
step 100: mean loss = 2.7423386e-07
step 200: mean loss = 2.550776e-07
step 300: mean loss = 2.502335e-07
step 400: mean loss = 2.3405424e-07
step 500: mean loss = 2.3818316e-07
step 600: mean loss = 2.3340468e-07
epoch 56: mean loss = 2.2715476e-07  learning rate = 0.00032353346
============================
Start of epoch 57
step 0: mean loss = 1.6926247e-08
step 100: mean loss = 2.2758816e-07
step 200: mean loss = 1.97779e-07
step 300: mean loss = 2.2597715e-07
step 400: mean loss = 2.3999237e-07
step 500: mean loss = 2.1650128e-07
step 600: mean loss = 2.355596e-07
epoch 57: mean loss = 2.29837e-07  learning rate = 0.00032353346
============================
Start of epoch 58
step 0: mean loss = 3.471336e-08
step 100: mean loss = 8.051577e-08
step 200: mean loss = 2.693958e-07
step 300: mean loss = 1.8758095e-07
step 400: mean loss = 1.8418851e-07
step 500: mean loss = 1.9481838e-07
step 600: mean loss = 2.013317e-07
epoch 58: mean loss = 1.9613766e-07  learning rate = 0.00032353346
============================
Start of epoch 59
step 0: mean loss = 1.2545433e-08
step 100: mean loss = 3.2523454e-07
step 200: mean loss = 2.0825254e-07
step 300: mean loss = 2.3235505e-07
step 400: mean loss = 2.564198e-07
step 500: mean loss = 2.3565826e-07
step 600: mean loss = 2.3158317e-07
epoch 59: mean loss = 2.2553237e-07  learning rate = 0.00032353346
============================
Start of epoch 60
step 0: mean loss = 1.9539284e-08
step 100: mean loss = 2.8445658e-07
step 200: mean loss = 2.6442743e-07
step 300: mean loss = 1.8801204e-07
step 400: mean loss = 2.1559674e-07
step 500: mean loss = 2.0856993e-07
step 600: mean loss = 2.1089265e-07
epoch 60: mean loss = 2.0593144e-07  learning rate = 0.00032353346
============================
Start of epoch 61
step 0: mean loss = 4.564808e-08
step 100: mean loss = 1.598389e-07
step 200: mean loss = 2.6273742e-07
step 300: mean loss = 2.5466912e-07
step 400: mean loss = 2.4479118e-07
step 500: mean loss = 2.0586302e-07
step 600: mean loss = 2.1596288e-07
epoch 61: mean loss = 2.1547832e-07  learning rate = 0.00032353346
============================
Start of epoch 62
step 0: mean loss = 1.3757178e-06
step 100: mean loss = 2.1557337e-07
step 200: mean loss = 2.4182606e-07
step 300: mean loss = 2.2922339e-07
step 400: mean loss = 2.466053e-07
step 500: mean loss = 2.1316086e-07
step 600: mean loss = 2.3355739e-07
epoch 62: mean loss = 2.2752786e-07  learning rate = 0.00032353346
============================
Start of epoch 63
step 0: mean loss = 1.6017479e-08
step 100: mean loss = 1.08190534e-07
step 200: mean loss = 2.3006572e-07
step 300: mean loss = 1.8596793e-07
step 400: mean loss = 2.0852622e-07
step 500: mean loss = 2.2373275e-07
step 600: mean loss = 2.0245437e-07
epoch 63: mean loss = 1.9699159e-07  learning rate = 0.00032353346
============================
Start of epoch 64
step 0: mean loss = 1.627831e-08
step 100: mean loss = 3.2601847e-07
step 200: mean loss = 2.850686e-07
step 300: mean loss = 2.467844e-07
step 400: mean loss = 1.881766e-07
step 500: mean loss = 2.0351082e-07
step 600: mean loss = 1.79485e-07
epoch 64: mean loss = 2.0558709e-07  learning rate = 0.0003073568
============================
Start of epoch 65
step 0: mean loss = 5.861942e-07
step 100: mean loss = 4.7803283e-08
step 200: mean loss = 1.300369e-07
step 300: mean loss = 1.57979e-07
step 400: mean loss = 1.6928335e-07
step 500: mean loss = 1.708794e-07
step 600: mean loss = 1.6321749e-07
epoch 65: mean loss = 1.6772212e-07  learning rate = 0.0003073568
============================
Start of epoch 66
step 0: mean loss = 1.5827525e-06
step 100: mean loss = 2.4749e-07
step 200: mean loss = 2.1452884e-07
step 300: mean loss = 2.1560824e-07
step 400: mean loss = 1.9510419e-07
step 500: mean loss = 2.3319105e-07
step 600: mean loss = 2.219884e-07
epoch 66: mean loss = 2.2100996e-07  learning rate = 0.0003073568
============================
Start of epoch 67
step 0: mean loss = 7.098132e-08
step 100: mean loss = 1.9642155e-08
step 200: mean loss = 1.795752e-07
step 300: mean loss = 1.5530091e-07
step 400: mean loss = 1.7537343e-07
step 500: mean loss = 1.592535e-07
step 600: mean loss = 1.7270182e-07
epoch 67: mean loss = 1.69742e-07  learning rate = 0.0003073568
============================
Start of epoch 68
step 0: mean loss = 3.777534e-07
step 100: mean loss = 2.1528818e-07
step 200: mean loss = 1.8797921e-07
step 300: mean loss = 1.9872584e-07
step 400: mean loss = 2.059433e-07
step 500: mean loss = 1.9722071e-07
step 600: mean loss = 1.9610296e-07
epoch 68: mean loss = 1.9189392e-07  learning rate = 0.0003073568
============================
Start of epoch 69
step 0: mean loss = 1.5256337e-07
step 100: mean loss = 1.2041305e-07
step 200: mean loss = 2.4332e-07
step 300: mean loss = 1.6927476e-07
step 400: mean loss = 2.0100154e-07
step 500: mean loss = 2.1407864e-07
step 600: mean loss = 1.9259186e-07
epoch 69: mean loss = 1.8820474e-07  learning rate = 0.0003073568
============================
Start of epoch 70
step 0: mean loss = 1.076518e-07
step 100: mean loss = 1.8080223e-07
step 200: mean loss = 2.0778488e-07
step 300: mean loss = 2.1833728e-07
step 400: mean loss = 2.0835769e-07
step 500: mean loss = 2.1796039e-07
step 600: mean loss = 1.8833661e-07
epoch 70: mean loss = 1.8457251e-07  learning rate = 0.0003073568
============================
Start of epoch 71
step 0: mean loss = 4.5852826e-07
step 100: mean loss = 3.54244e-07
step 200: mean loss = 2.0798763e-07
step 300: mean loss = 2.2234927e-07
step 400: mean loss = 2.2183626e-07
step 500: mean loss = 1.9631065e-07
step 600: mean loss = 2.07097e-07
epoch 71: mean loss = 2.1777555e-07  learning rate = 0.0003073568
============================
Start of epoch 72
step 0: mean loss = 1.5784525e-07
step 100: mean loss = 8.866502e-08
step 200: mean loss = 1.6408323e-07
step 300: mean loss = 1.400193e-07
step 400: mean loss = 1.8977092e-07
step 500: mean loss = 1.6682588e-07
step 600: mean loss = 1.7000112e-07
epoch 72: mean loss = 1.7907833e-07  learning rate = 0.0003073568
============================
Start of epoch 73
step 0: mean loss = 5.2517063e-08
step 100: mean loss = 1.6521993e-07
step 200: mean loss = 1.8656655e-07
step 300: mean loss = 1.851221e-07
step 400: mean loss = 1.7975488e-07
step 500: mean loss = 1.8315178e-07
step 600: mean loss = 1.9379827e-07
epoch 73: mean loss = 1.8853518e-07  learning rate = 0.0003073568
============================
Start of epoch 74
step 0: mean loss = 1.2105493e-08
step 100: mean loss = 2.1449152e-07
step 200: mean loss = 1.6919847e-07
step 300: mean loss = 2.0432834e-07
step 400: mean loss = 1.8139548e-07
step 500: mean loss = 1.856696e-07
step 600: mean loss = 2.0931223e-07
epoch 74: mean loss = 2.045438e-07  learning rate = 0.0003073568
============================
Start of epoch 75
step 0: mean loss = 3.5864865e-08
step 100: mean loss = 1.1892674e-07
step 200: mean loss = 1.5535055e-07
step 300: mean loss = 1.6648696e-07
step 400: mean loss = 1.5953421e-07
step 500: mean loss = 1.6110157e-07
step 600: mean loss = 1.9049017e-07
epoch 75: mean loss = 1.8526491e-07  learning rate = 0.0003073568
============================
Start of epoch 76
step 0: mean loss = 1.0711469e-08
step 100: mean loss = 1.7407176e-07
step 200: mean loss = 2.5611595e-07
step 300: mean loss = 1.8770488e-07
step 400: mean loss = 1.998901e-07
step 500: mean loss = 1.8827627e-07
step 600: mean loss = 2.0141253e-07
epoch 76: mean loss = 1.9721632e-07  learning rate = 0.0003073568
============================
Start of epoch 77
step 0: mean loss = 1.9716232e-08
step 100: mean loss = 8.318952e-08
step 200: mean loss = 2.0044165e-07
step 300: mean loss = 1.4955873e-07
step 400: mean loss = 1.8771846e-07
step 500: mean loss = 1.6232472e-07
step 600: mean loss = 1.7664685e-07
epoch 77: mean loss = 1.8999317e-07  learning rate = 0.0003073568
============================
Start of epoch 78
step 0: mean loss = 1.0845851e-07
step 100: mean loss = 3.4077228e-08
step 200: mean loss = 1.6701749e-07
step 300: mean loss = 1.6381624e-07
step 400: mean loss = 1.6021484e-07
step 500: mean loss = 1.6666422e-07
step 600: mean loss = 1.7247933e-07
epoch 78: mean loss = 1.7044343e-07  learning rate = 0.0003073568
============================
Start of epoch 79
step 0: mean loss = 1.102098e-07
step 100: mean loss = 2.0166102e-07
step 200: mean loss = 2.126361e-07
step 300: mean loss = 1.9852021e-07
step 400: mean loss = 2.0083378e-07
step 500: mean loss = 1.9992618e-07
step 600: mean loss = 2.0815587e-07
epoch 79: mean loss = 2.0422765e-07  learning rate = 0.0003073568
============================
Start of epoch 80
step 0: mean loss = 2.606927e-08
step 100: mean loss = 1.7838109e-07
step 200: mean loss = 1.9361805e-07
step 300: mean loss = 1.5615942e-07
step 400: mean loss = 1.5849e-07
step 500: mean loss = 1.6204335e-07
step 600: mean loss = 1.8279728e-07
epoch 80: mean loss = 1.7923965e-07  learning rate = 0.0003073568
============================
Start of epoch 81
step 0: mean loss = 4.0712465e-08
step 100: mean loss = 1.763408e-07
step 200: mean loss = 1.427895e-07
step 300: mean loss = 2.035673e-07
step 400: mean loss = 2.0755462e-07
step 500: mean loss = 1.8160873e-07
step 600: mean loss = 1.9305054e-07
epoch 81: mean loss = 1.8789443e-07  learning rate = 0.0003073568
============================
Start of epoch 82
step 0: mean loss = 1.079089e-08
step 100: mean loss = 2.1731911e-07
step 200: mean loss = 2.2986902e-07
step 300: mean loss = 2.0511573e-07
step 400: mean loss = 2.0418894e-07
step 500: mean loss = 1.9035177e-07
step 600: mean loss = 1.9734298e-07
epoch 82: mean loss = 1.9223955e-07  learning rate = 0.0003073568
============================
Start of epoch 83
step 0: mean loss = 1.7371367e-08
step 100: mean loss = 9.461834e-08
step 200: mean loss = 1.8845023e-07
step 300: mean loss = 1.5155162e-07
step 400: mean loss = 2.1351396e-07
step 500: mean loss = 1.8000871e-07
step 600: mean loss = 1.9975877e-07
epoch 83: mean loss = 1.9442079e-07  learning rate = 0.0003073568
============================
Start of epoch 84
step 0: mean loss = 2.6673435e-08
step 100: mean loss = 8.95183e-08
step 200: mean loss = 1.6755679e-07
step 300: mean loss = 1.7392372e-07
step 400: mean loss = 1.9811094e-07
step 500: mean loss = 1.6113688e-07
step 600: mean loss = 1.5606179e-07
epoch 84: mean loss = 1.5209663e-07  learning rate = 0.00029198892
============================
Start of epoch 85
step 0: mean loss = 1.596379e-08
step 100: mean loss = 2.0626632e-07
step 200: mean loss = 1.3932757e-07
step 300: mean loss = 1.6651317e-07
step 400: mean loss = 1.6746363e-07
step 500: mean loss = 1.695438e-07
step 600: mean loss = 1.614326e-07
epoch 85: mean loss = 1.5716799e-07  learning rate = 0.00029198892
============================
Start of epoch 86
step 0: mean loss = 2.8737213e-08
step 100: mean loss = 2.533655e-07
step 200: mean loss = 2.1527191e-07
step 300: mean loss = 2.1028886e-07
step 400: mean loss = 1.8040853e-07
step 500: mean loss = 1.7321929e-07
step 600: mean loss = 1.7058163e-07
epoch 86: mean loss = 1.752631e-07  learning rate = 0.00029198892
============================
Start of epoch 87
step 0: mean loss = 1.2893734e-07
step 100: mean loss = 1.2074675e-07
step 200: mean loss = 1.4689141e-07
step 300: mean loss = 1.5747445e-07
step 400: mean loss = 1.702046e-07
step 500: mean loss = 1.5915454e-07
step 600: mean loss = 1.7795837e-07
epoch 87: mean loss = 1.7386901e-07  learning rate = 0.00029198892
============================
Start of epoch 88
step 0: mean loss = 2.8331561e-08
step 100: mean loss = 1.9105275e-07
step 200: mean loss = 1.84608e-07
step 300: mean loss = 2.1492244e-07
step 400: mean loss = 1.644027e-07
step 500: mean loss = 1.8088807e-07
step 600: mean loss = 1.7945841e-07
epoch 88: mean loss = 1.7536026e-07  learning rate = 0.00029198892
============================
Start of epoch 89
step 0: mean loss = 2.6347005e-08
step 100: mean loss = 1.730038e-07
step 200: mean loss = 1.5638912e-07
step 300: mean loss = 1.6759584e-07
step 400: mean loss = 1.4097922e-07
step 500: mean loss = 1.5621274e-07
step 600: mean loss = 1.6333003e-07
epoch 89: mean loss = 1.6018527e-07  learning rate = 0.00029198892
============================
Start of epoch 90
step 0: mean loss = 3.5181108e-07
step 100: mean loss = 1.2597383e-07
step 200: mean loss = 1.9179191e-07
step 300: mean loss = 1.9065563e-07
step 400: mean loss = 1.7189632e-07
step 500: mean loss = 1.651023e-07
step 600: mean loss = 1.7435106e-07
epoch 90: mean loss = 1.7207691e-07  learning rate = 0.00029198892
============================
Start of epoch 91
step 0: mean loss = 2.8512765e-08
step 100: mean loss = 2.7712082e-07
step 200: mean loss = 1.7375099e-07
step 300: mean loss = 1.600977e-07
step 400: mean loss = 1.5770749e-07
step 500: mean loss = 1.7080337e-07
step 600: mean loss = 1.5765713e-07
epoch 91: mean loss = 1.7456006e-07  learning rate = 0.00029198892
============================
Start of epoch 92
step 0: mean loss = 4.262148e-07
step 100: mean loss = 6.403736e-08
step 200: mean loss = 1.484193e-07
step 300: mean loss = 1.596916e-07
step 400: mean loss = 1.3706668e-07
step 500: mean loss = 1.7071666e-07
step 600: mean loss = 1.5817355e-07
epoch 92: mean loss = 1.5386492e-07  learning rate = 0.00029198892
============================
Start of epoch 93
step 0: mean loss = 1.0430765e-08
step 100: mean loss = 1.6428878e-07
step 200: mean loss = 1.6303643e-07
step 300: mean loss = 1.8028949e-07
step 400: mean loss = 1.689185e-07
step 500: mean loss = 1.8485721e-07
step 600: mean loss = 1.7619864e-07
epoch 93: mean loss = 1.7377417e-07  learning rate = 0.00029198892
============================
Start of epoch 94
step 0: mean loss = 2.0026884e-07
step 100: mean loss = 1.6961057e-07
step 200: mean loss = 1.5130178e-07
step 300: mean loss = 1.5383597e-07
step 400: mean loss = 1.6433087e-07
step 500: mean loss = 1.632379e-07
step 600: mean loss = 1.7254783e-07
epoch 94: mean loss = 1.6958734e-07  learning rate = 0.00029198892
============================
Start of epoch 95
step 0: mean loss = 2.9842557e-08
step 100: mean loss = 1.5456332e-07
step 200: mean loss = 1.3760801e-07
step 300: mean loss = 1.5793584e-07
step 400: mean loss = 1.4455166e-07
step 500: mean loss = 1.6820529e-07
step 600: mean loss = 1.7316057e-07
epoch 95: mean loss = 1.6980212e-07  learning rate = 0.00029198892
============================
Start of epoch 96
step 0: mean loss = 3.6735656e-08
step 100: mean loss = 6.703445e-08
step 200: mean loss = 1.9198288e-07
step 300: mean loss = 1.8200599e-07
step 400: mean loss = 1.5828238e-07
step 500: mean loss = 1.5979548e-07
step 600: mean loss = 1.5560565e-07
epoch 96: mean loss = 1.8295101e-07  learning rate = 0.00029198892
============================
Start of epoch 97
step 0: mean loss = 4.2038243e-07
step 100: mean loss = 9.406669e-08
step 200: mean loss = 6.901757e-08
step 300: mean loss = 1.4061413e-07
step 400: mean loss = 1.3631154e-07
step 500: mean loss = 1.7073755e-07
step 600: mean loss = 1.561846e-07
epoch 97: mean loss = 1.5213446e-07  learning rate = 0.00029198892
============================
Start of epoch 98
step 0: mean loss = 9.933462e-09
step 100: mean loss = 2.6286347e-07
step 200: mean loss = 1.752138e-07
step 300: mean loss = 1.8147524e-07
step 400: mean loss = 1.7593652e-07
step 500: mean loss = 1.7033392e-07
step 600: mean loss = 1.7225885e-07
epoch 98: mean loss = 1.6792866e-07  learning rate = 0.00029198892
============================
Start of epoch 99
step 0: mean loss = 1.7190581e-08
step 100: mean loss = 9.4383985e-08
step 200: mean loss = 1.6093715e-07
step 300: mean loss = 1.6305538e-07
step 400: mean loss = 1.530342e-07
step 500: mean loss = 1.609127e-07
step 600: mean loss = 1.6854531e-07
epoch 99: mean loss = 1.6397699e-07  learning rate = 0.00029198892
============================
Start of epoch 100
step 0: mean loss = 1.7689073e-08
step 100: mean loss = 2.0715623e-07
step 200: mean loss = 1.6414106e-07
step 300: mean loss = 1.6172366e-07
step 400: mean loss = 1.786254e-07
step 500: mean loss = 1.7469553e-07
step 600: mean loss = 1.7004173e-07
epoch 100: mean loss = 1.6943146e-07  learning rate = 0.00029198892
============================
Start of epoch 101
step 0: mean loss = 1.02313024e-07
step 100: mean loss = 1.13474755e-07
step 200: mean loss = 2.29846e-07
step 300: mean loss = 1.5725041e-07
step 400: mean loss = 1.8542765e-07
step 500: mean loss = 1.7116894e-07
step 600: mean loss = 1.7154602e-07
epoch 101: mean loss = 1.6702653e-07  learning rate = 0.00029198892
============================
Start of epoch 102
step 0: mean loss = 1.4969313e-08
step 100: mean loss = 2.0543565e-07
step 200: mean loss = 1.7395438e-07
step 300: mean loss = 1.719952e-07
step 400: mean loss = 1.5547542e-07
step 500: mean loss = 1.6981174e-07
step 600: mean loss = 1.6989623e-07
epoch 102: mean loss = 1.6539282e-07  learning rate = 0.00029198892
============================
Start of epoch 103
step 0: mean loss = 1.4340814e-08
step 100: mean loss = 1.4390402e-07
step 200: mean loss = 1.6568428e-07
step 300: mean loss = 1.6888133e-07
step 400: mean loss = 1.7354931e-07
step 500: mean loss = 1.8120323e-07
step 600: mean loss = 1.7534e-07
epoch 103: mean loss = 1.7067376e-07  learning rate = 0.00029198892
============================
Start of epoch 104
step 0: mean loss = 1.0879964e-08
step 100: mean loss = 2.0561843e-07
step 200: mean loss = 1.5051434e-07
step 300: mean loss = 1.8571359e-07
step 400: mean loss = 1.6037733e-07
step 500: mean loss = 1.7008303e-07
step 600: mean loss = 1.4362001e-07
epoch 104: mean loss = 1.3971895e-07  learning rate = 0.0002773895
============================
Start of epoch 105
step 0: mean loss = 9.927333e-09
step 100: mean loss = 1.0565946e-07
step 200: mean loss = 1.549425e-07
step 300: mean loss = 1.39727e-07
step 400: mean loss = 1.4519227e-07
step 500: mean loss = 1.620218e-07
step 600: mean loss = 1.6481293e-07
epoch 105: mean loss = 1.6343637e-07  learning rate = 0.0002773895
============================
Start of epoch 106
step 0: mean loss = 2.8007026e-08
step 100: mean loss = 1.2337453e-08
step 200: mean loss = 9.4700646e-08
step 300: mean loss = 9.851067e-08
step 400: mean loss = 1.2233723e-07
step 500: mean loss = 1.2086348e-07
step 600: mean loss = 1.3951042e-07
epoch 106: mean loss = 1.3650956e-07  learning rate = 0.0002773895
============================
Start of epoch 107
step 0: mean loss = 2.522761e-08
step 100: mean loss = 1.747296e-07
step 200: mean loss = 1.2305964e-07
step 300: mean loss = 1.5454833e-07
step 400: mean loss = 1.300205e-07
step 500: mean loss = 1.577067e-07
step 600: mean loss = 1.48856e-07
epoch 107: mean loss = 1.4995082e-07  learning rate = 0.0002773895
============================
Start of epoch 108
step 0: mean loss = 1.05697694e-07
step 100: mean loss = 2.0337683e-07
step 200: mean loss = 1.5969802e-07
step 300: mean loss = 1.6154925e-07
step 400: mean loss = 1.3818436e-07
step 500: mean loss = 1.5258415e-07
step 600: mean loss = 1.5231173e-07
epoch 108: mean loss = 1.4989709e-07  learning rate = 0.0002773895
============================
Start of epoch 109
step 0: mean loss = 1.4605633e-08
step 100: mean loss = 7.9846785e-08
step 200: mean loss = 1.418374e-07
step 300: mean loss = 1.3983791e-07
step 400: mean loss = 1.5180828e-07
step 500: mean loss = 1.5636853e-07
step 600: mean loss = 1.572558e-07
epoch 109: mean loss = 1.538844e-07  learning rate = 0.0002773895
============================
Start of epoch 110
step 0: mean loss = 9.737506e-09
step 100: mean loss = 7.555005e-08
step 200: mean loss = 1.0383079e-07
step 300: mean loss = 1.2897934e-07
step 400: mean loss = 1.2917222e-07
step 500: mean loss = 1.4696802e-07
step 600: mean loss = 1.3866818e-07
epoch 110: mean loss = 1.4794736e-07  learning rate = 0.0002773895
============================
Start of epoch 111
step 0: mean loss = 8.364557e-08
step 100: mean loss = 1.3901321e-07
step 200: mean loss = 1.2477413e-07
step 300: mean loss = 1.5161461e-07
step 400: mean loss = 1.3295426e-07
step 500: mean loss = 1.4030867e-07
step 600: mean loss = 1.3696489e-07
epoch 111: mean loss = 1.5116908e-07  learning rate = 0.0002773895
============================
Start of epoch 112
step 0: mean loss = 1.0539549e-06
step 100: mean loss = 7.7373926e-08
step 200: mean loss = 1.2667755e-07
step 300: mean loss = 1.5681668e-07
step 400: mean loss = 1.5378335e-07
step 500: mean loss = 1.3413215e-07
step 600: mean loss = 1.4209913e-07
epoch 112: mean loss = 1.3853148e-07  learning rate = 0.0002773895
============================
Start of epoch 113
step 0: mean loss = 3.500493e-08
step 100: mean loss = 1.3279484e-07
step 200: mean loss = 1.4557587e-07
step 300: mean loss = 1.5800455e-07
step 400: mean loss = 1.3735115e-07
step 500: mean loss = 1.6053622e-07
step 600: mean loss = 1.4439274e-07
epoch 113: mean loss = 1.4248205e-07  learning rate = 0.0002773895
============================
Start of epoch 114
step 0: mean loss = 4.2373176e-07
step 100: mean loss = 1.9725708e-07
step 200: mean loss = 1.7157315e-07
step 300: mean loss = 1.7361488e-07
step 400: mean loss = 1.7073106e-07
step 500: mean loss = 1.5436726e-07
step 600: mean loss = 1.5943891e-07
epoch 114: mean loss = 1.5508553e-07  learning rate = 0.0002773895
============================
Start of epoch 115
step 0: mean loss = 1.27727775e-08
step 100: mean loss = 2.3075047e-07
step 200: mean loss = 1.4274717e-07
step 300: mean loss = 1.445367e-07
step 400: mean loss = 1.337304e-07
step 500: mean loss = 1.4909541e-07
step 600: mean loss = 1.5471298e-07
epoch 115: mean loss = 1.5050273e-07  learning rate = 0.0002773895
============================
Start of epoch 116
step 0: mean loss = 1.0309832e-08
step 100: mean loss = 1.557211e-07
step 200: mean loss = 1.6388057e-07
step 300: mean loss = 1.3978355e-07
step 400: mean loss = 1.5652132e-07
step 500: mean loss = 1.4131311e-07
step 600: mean loss = 1.6179027e-07
epoch 116: mean loss = 1.6129471e-07  learning rate = 0.0002773895
============================
Start of epoch 117
step 0: mean loss = 4.703123e-07
step 100: mean loss = 4.1903302e-08
step 200: mean loss = 1.02544014e-07
step 300: mean loss = 1.12759565e-07
step 400: mean loss = 1.3010637e-07
step 500: mean loss = 1.3072295e-07
step 600: mean loss = 1.4232316e-07
epoch 117: mean loss = 1.3951507e-07  learning rate = 0.0002773895
============================
Start of epoch 118
step 0: mean loss = 2.6697558e-08
step 100: mean loss = 7.575041e-08
step 200: mean loss = 1.3340511e-07
step 300: mean loss = 1.2982348e-07
step 400: mean loss = 1.4312901e-07
step 500: mean loss = 1.3977497e-07
step 600: mean loss = 1.4294636e-07
epoch 118: mean loss = 1.3905967e-07  learning rate = 0.0002773895
============================
Start of epoch 119
step 0: mean loss = 1.091929e-08
step 100: mean loss = 1.7745933e-07
step 200: mean loss = 1.5706566e-07
step 300: mean loss = 1.5489556e-07
step 400: mean loss = 1.5094038e-07
step 500: mean loss = 1.4495596e-07
step 600: mean loss = 1.4567942e-07
epoch 119: mean loss = 1.5474339e-07  learning rate = 0.0002773895
============================
Start of epoch 120
step 0: mean loss = 4.2148677e-08
step 100: mean loss = 1.5005179e-07
step 200: mean loss = 1.4408272e-07
step 300: mean loss = 1.4878465e-07
step 400: mean loss = 1.5700826e-07
step 500: mean loss = 1.5181402e-07
step 600: mean loss = 1.540113e-07
epoch 120: mean loss = 1.5176188e-07  learning rate = 0.0002773895
============================
Start of epoch 121
step 0: mean loss = 4.829571e-08
step 100: mean loss = 1.2524237e-07
step 200: mean loss = 1.5092333e-07
step 300: mean loss = 1.3574379e-07
step 400: mean loss = 1.3001838e-07
step 500: mean loss = 1.3198914e-07
step 600: mean loss = 1.3286511e-07
epoch 121: mean loss = 1.3838502e-07  learning rate = 0.0002773895
============================
Start of epoch 122
step 0: mean loss = 2.0635454e-07
step 100: mean loss = 1.7963404e-07
step 200: mean loss = 1.4746396e-07
step 300: mean loss = 1.5749126e-07
step 400: mean loss = 1.5932343e-07
step 500: mean loss = 1.5416886e-07
step 600: mean loss = 1.5409246e-07
epoch 122: mean loss = 1.502016e-07  learning rate = 0.0002773895
============================
Start of epoch 123
step 0: mean loss = 1.2556897e-08
step 100: mean loss = 1.3935293e-07
step 200: mean loss = 1.2541732e-07
step 300: mean loss = 1.4811123e-07
step 400: mean loss = 1.5999004e-07
step 500: mean loss = 1.3910267e-07
step 600: mean loss = 1.3754392e-07
epoch 123: mean loss = 1.4335276e-07  learning rate = 0.0002773895
============================
Start of epoch 124
step 0: mean loss = 9.706132e-09
step 100: mean loss = 2.027165e-07
step 200: mean loss = 1.2460958e-07
step 300: mean loss = 1.37837e-07
step 400: mean loss = 1.5463277e-07
step 500: mean loss = 1.5716361e-07
step 600: mean loss = 1.460151e-07
epoch 124: mean loss = 1.4204595e-07  learning rate = 0.0002773895
============================
Start of epoch 125
step 0: mean loss = 8.966474e-09
step 100: mean loss = 1.0845876e-08
step 200: mean loss = 1.0065564e-07
step 300: mean loss = 9.191861e-08
step 400: mean loss = 1.2204804e-07
step 500: mean loss = 1.13108364e-07
step 600: mean loss = 1.2877481e-07
epoch 125: mean loss = 1.2556596e-07  learning rate = 0.00026352002
============================
Start of epoch 126
step 0: mean loss = 4.3505164e-08
step 100: mean loss = 6.536184e-08
step 200: mean loss = 1.4209509e-07
step 300: mean loss = 1.2302404e-07
step 400: mean loss = 1.3142039e-07
step 500: mean loss = 1.3684026e-07
step 600: mean loss = 1.1997844e-07
epoch 126: mean loss = 1.2641638e-07  learning rate = 0.00026352002
============================
Start of epoch 127
step 0: mean loss = 1.7966276e-07
step 100: mean loss = 1.9151231e-07
step 200: mean loss = 1.3134749e-07
step 300: mean loss = 1.3626307e-07
step 400: mean loss = 1.2684224e-07
step 500: mean loss = 1.3557039e-07
step 600: mean loss = 1.2830502e-07
epoch 127: mean loss = 1.371813e-07  learning rate = 0.00026352002
============================
Start of epoch 128
step 0: mean loss = 1.6838116e-07
step 100: mean loss = 1.1472834e-07
step 200: mean loss = 9.805011e-08
step 300: mean loss = 1.2508761e-07
step 400: mean loss = 1.1887488e-07
step 500: mean loss = 1.2297095e-07
step 600: mean loss = 1.3936584e-07
epoch 128: mean loss = 1.3811179e-07  learning rate = 0.00026352002
============================
Start of epoch 129
step 0: mean loss = 3.9827043e-08
step 100: mean loss = 5.0255192e-08
step 200: mean loss = 9.431241e-08
step 300: mean loss = 1.4167466e-07
step 400: mean loss = 1.2589683e-07
step 500: mean loss = 1.08945244e-07
step 600: mean loss = 1.3081782e-07
epoch 129: mean loss = 1.2951996e-07  learning rate = 0.00026352002
============================
Start of epoch 130
step 0: mean loss = 1.863656e-08
step 100: mean loss = 3.551168e-08
step 200: mean loss = 1.3932754e-07
step 300: mean loss = 1.1326099e-07
step 400: mean loss = 1.1363739e-07
step 500: mean loss = 1.1304848e-07
step 600: mean loss = 1.2994717e-07
epoch 130: mean loss = 1.2689641e-07  learning rate = 0.00026352002
============================
Start of epoch 131
step 0: mean loss = 1.4367495e-08
step 100: mean loss = 1.5209731e-07
step 200: mean loss = 1.0947527e-07
step 300: mean loss = 1.5415412e-07
step 400: mean loss = 1.3928091e-07
step 500: mean loss = 1.5216176e-07
step 600: mean loss = 1.434138e-07
epoch 131: mean loss = 1.3990235e-07  learning rate = 0.00026352002
============================
Start of epoch 132
step 0: mean loss = 1.1316638e-08
step 100: mean loss = 7.941036e-08
step 200: mean loss = 1.2451073e-07
step 300: mean loss = 1.2061267e-07
step 400: mean loss = 1.1584679e-07
step 500: mean loss = 1.16855304e-07
step 600: mean loss = 1.3116059e-07
epoch 132: mean loss = 1.2825967e-07  learning rate = 0.00026352002
============================
Start of epoch 133
step 0: mean loss = 1.2983032e-08
step 100: mean loss = 1.5053861e-07
step 200: mean loss = 1.416658e-07
step 300: mean loss = 1.3330812e-07
step 400: mean loss = 1.2132381e-07
step 500: mean loss = 1.225641e-07
step 600: mean loss = 1.229724e-07
epoch 133: mean loss = 1.1965355e-07  learning rate = 0.00026352002
============================
Start of epoch 134
step 0: mean loss = 1.14048e-08
step 100: mean loss = 1.809415e-07
step 200: mean loss = 1.4569184e-07
step 300: mean loss = 1.5101823e-07
step 400: mean loss = 1.3919892e-07
step 500: mean loss = 1.420726e-07
step 600: mean loss = 1.4303187e-07
epoch 134: mean loss = 1.3970524e-07  learning rate = 0.00026352002
============================
Start of epoch 135
step 0: mean loss = 2.31875e-08
step 100: mean loss = 1.3019363e-07
step 200: mean loss = 1.6691952e-07
step 300: mean loss = 1.525536e-07
step 400: mean loss = 1.402362e-07
step 500: mean loss = 1.3414503e-07
step 600: mean loss = 1.295819e-07
epoch 135: mean loss = 1.414743e-07  learning rate = 0.00026352002
============================
Start of epoch 136
step 0: mean loss = 9.1780305e-07
step 100: mean loss = 6.1451395e-08
step 200: mean loss = 1.13839036e-07
step 300: mean loss = 1.1514284e-07
step 400: mean loss = 1.2706475e-07
step 500: mean loss = 1.1494913e-07
step 600: mean loss = 1.2607076e-07
epoch 136: mean loss = 1.3185465e-07  learning rate = 0.00026352002
============================
Start of epoch 137
step 0: mean loss = 2.1942516e-07
step 100: mean loss = 1.06909496e-07
step 200: mean loss = 1.233607e-07
step 300: mean loss = 1.3362721e-07
step 400: mean loss = 1.2774198e-07
step 500: mean loss = 1.439138e-07
step 600: mean loss = 1.309211e-07
epoch 137: mean loss = 1.2806132e-07  learning rate = 0.00026352002
============================
Start of epoch 138
step 0: mean loss = 1.4071051e-08
step 100: mean loss = 1.6129994e-07
step 200: mean loss = 1.1462268e-07
step 300: mean loss = 1.490499e-07
step 400: mean loss = 1.3921068e-07
step 500: mean loss = 1.2388554e-07
step 600: mean loss = 1.2919261e-07
epoch 138: mean loss = 1.258371e-07  learning rate = 0.00026352002
============================
Start of epoch 139
step 0: mean loss = 4.3369806e-08
step 100: mean loss = 1.4309114e-07
step 200: mean loss = 1.5681553e-07
step 300: mean loss = 1.5587014e-07
step 400: mean loss = 1.32774e-07
step 500: mean loss = 1.3884757e-07
step 600: mean loss = 1.2796353e-07
epoch 139: mean loss = 1.2571165e-07  learning rate = 0.00026352002
============================
Start of epoch 140
step 0: mean loss = 3.657036e-07
step 100: mean loss = 2.3221641e-07
step 200: mean loss = 1.458883e-07
step 300: mean loss = 1.6271241e-07
step 400: mean loss = 1.592842e-07
step 500: mean loss = 1.455561e-07
step 600: mean loss = 1.5091713e-07
epoch 140: mean loss = 1.4722299e-07  learning rate = 0.00026352002
============================
Start of epoch 141
step 0: mean loss = 1.0792501e-08
step 100: mean loss = 1.220498e-07
step 200: mean loss = 1.370823e-07
step 300: mean loss = 1.2795547e-07
step 400: mean loss = 1.2976506e-07
step 500: mean loss = 1.2189254e-07
step 600: mean loss = 1.2501602e-07
epoch 141: mean loss = 1.2184361e-07  learning rate = 0.00026352002
============================
Start of epoch 142
step 0: mean loss = 5.8867684e-08
step 100: mean loss = 2.0116053e-07
step 200: mean loss = 1.2700997e-07
step 300: mean loss = 1.4220548e-07
step 400: mean loss = 1.4282496e-07
step 500: mean loss = 1.312899e-07
step 600: mean loss = 1.3720371e-07
epoch 142: mean loss = 1.3994841e-07  learning rate = 0.00026352002
============================
Start of epoch 143
step 0: mean loss = 1.6677099e-08
step 100: mean loss = 2.0217804e-08
step 200: mean loss = 1.321672e-07
step 300: mean loss = 1.4274654e-07
step 400: mean loss = 1.1207299e-07
step 500: mean loss = 1.1821068e-07
step 600: mean loss = 1.1991852e-07
epoch 143: mean loss = 1.3345215e-07  learning rate = 0.00026352002
============================
Start of epoch 144
step 0: mean loss = 3.3312267e-07
step 100: mean loss = 2.8339814e-08
step 200: mean loss = 1.3338199e-07
step 300: mean loss = 1.010052e-07
step 400: mean loss = 1.2591553e-07
step 500: mean loss = 1.0726171e-07
step 600: mean loss = 1.3056463e-07
epoch 144: mean loss = 1.2699958e-07  learning rate = 0.00026352002
============================
Start of epoch 145
step 0: mean loss = 7.903033e-09
step 100: mean loss = 2.0339331e-07
step 200: mean loss = 1.0662036e-07
step 300: mean loss = 7.3782005e-08
step 400: mean loss = 9.066075e-08
step 500: mean loss = 9.2340905e-08
step 600: mean loss = 9.675502e-08
epoch 145: mean loss = 1.0169372e-07  learning rate = 0.00025034402
============================
Start of epoch 146
step 0: mean loss = 1.9979552e-07
step 100: mean loss = 1.0076081e-07
step 200: mean loss = 1.1478286e-07
step 300: mean loss = 1.05546526e-07
step 400: mean loss = 1.1602341e-07
step 500: mean loss = 1.2721499e-07
step 600: mean loss = 1.10538515e-07
epoch 146: mean loss = 1.1865588e-07  learning rate = 0.00025034402
============================
Start of epoch 147
step 0: mean loss = 1.0457354e-07
step 100: mean loss = 9.6734226e-08
step 200: mean loss = 9.963984e-08
step 300: mean loss = 1.2293481e-07
step 400: mean loss = 1.2343604e-07
step 500: mean loss = 1.1935325e-07
step 600: mean loss = 1.1934675e-07
epoch 147: mean loss = 1.16877445e-07  learning rate = 0.00025034402
============================
Start of epoch 148
step 0: mean loss = 4.1835815e-08
step 100: mean loss = 1.0432061e-07
step 200: mean loss = 1.08930344e-07
step 300: mean loss = 1.3482386e-07
step 400: mean loss = 1.3818193e-07
step 500: mean loss = 1.1406295e-07
step 600: mean loss = 1.18932185e-07
epoch 148: mean loss = 1.1585399e-07  learning rate = 0.00025034402
============================
Start of epoch 149
step 0: mean loss = 3.237581e-08
step 100: mean loss = 1.14638325e-07
step 200: mean loss = 1.2874993e-07
step 300: mean loss = 1.2806693e-07
step 400: mean loss = 1.1782397e-07
step 500: mean loss = 1.1143465e-07
step 600: mean loss = 1.1470466e-07
epoch 149: mean loss = 1.2317767e-07  learning rate = 0.00025034402
============================
Start of epoch 150
step 0: mean loss = 1.6198427e-07
step 100: mean loss = 1.3969085e-07
step 200: mean loss = 1.1517834e-07
step 300: mean loss = 1.2471102e-07
step 400: mean loss = 1.0924199e-07
step 500: mean loss = 1.1374693e-07
step 600: mean loss = 1.1168739e-07
epoch 150: mean loss = 1.1653705e-07  learning rate = 0.00025034402
============================
Start of epoch 151
step 0: mean loss = 8.384088e-07
step 100: mean loss = 5.3871336e-08
step 200: mean loss = 1.2270087e-07
step 300: mean loss = 1.00510704e-07
step 400: mean loss = 1.1425674e-07
step 500: mean loss = 1.162421e-07
step 600: mean loss = 1.267024e-07
epoch 151: mean loss = 1.2481281e-07  learning rate = 0.00025034402
============================
Start of epoch 152
step 0: mean loss = 2.9212815e-08
step 100: mean loss = 1.3544764e-07
step 200: mean loss = 8.074331e-08
step 300: mean loss = 1.1083921e-07
step 400: mean loss = 1.1406932e-07
step 500: mean loss = 1.04611686e-07
step 600: mean loss = 1.0854844e-07
epoch 152: mean loss = 1.06549265e-07  learning rate = 0.00025034402
============================
Start of epoch 153
step 0: mean loss = 2.7981448e-08
step 100: mean loss = 1.0379953e-07
step 200: mean loss = 1.3710485e-07
step 300: mean loss = 1.1108161e-07
step 400: mean loss = 1.1989285e-07
step 500: mean loss = 1.11991916e-07
step 600: mean loss = 1.19000475e-07
epoch 153: mean loss = 1.1576467e-07  learning rate = 0.00025034402
============================
Start of epoch 154
step 0: mean loss = 8.7423375e-09
step 100: mean loss = 1.6347899e-07
step 200: mean loss = 1.4293595e-07
step 300: mean loss = 1.2882805e-07
step 400: mean loss = 1.2216299e-07
step 500: mean loss = 1.1946415e-07
step 600: mean loss = 1.18808096e-07
epoch 154: mean loss = 1.2906692e-07  learning rate = 0.00025034402
============================
Start of epoch 155
step 0: mean loss = 1.4058019e-08
step 100: mean loss = 3.3336857e-08
step 200: mean loss = 8.771004e-08
step 300: mean loss = 9.100853e-08
step 400: mean loss = 1.0194757e-07
step 500: mean loss = 1.1348654e-07
step 600: mean loss = 1.09698114e-07
epoch 155: mean loss = 1.0681113e-07  learning rate = 0.00025034402
============================
Start of epoch 156
step 0: mean loss = 8.227312e-09
step 100: mean loss = 1.496839e-07
step 200: mean loss = 1.0795355e-07
step 300: mean loss = 1.3140125e-07
step 400: mean loss = 1.14705216e-07
step 500: mean loss = 1.2184775e-07
step 600: mean loss = 1.11859315e-07
epoch 156: mean loss = 1.08843956e-07  learning rate = 0.00025034402
============================
Start of epoch 157
step 0: mean loss = 1.40758125e-08
step 100: mean loss = 2.6114623e-07
step 200: mean loss = 1.6539998e-07
step 300: mean loss = 1.605602e-07
step 400: mean loss = 1.5324014e-07
step 500: mean loss = 1.2862542e-07
step 600: mean loss = 1.4006767e-07
epoch 157: mean loss = 1.3934498e-07  learning rate = 0.00025034402
============================
Start of epoch 158
step 0: mean loss = 4.1770153e-07
step 100: mean loss = 3.2796027e-08
step 200: mean loss = 9.0037275e-08
step 300: mean loss = 8.960652e-08
step 400: mean loss = 1.0249859e-07
step 500: mean loss = 1.1858932e-07
step 600: mean loss = 1.1186947e-07
epoch 158: mean loss = 1.09451605e-07  learning rate = 0.00025034402
============================
Start of epoch 159
step 0: mean loss = 1.6429363e-08
step 100: mean loss = 1.1903642e-07
step 200: mean loss = 1.09070506e-07
step 300: mean loss = 9.9104305e-08
step 400: mean loss = 1.14282734e-07
step 500: mean loss = 1.1062683e-07
step 600: mean loss = 1.1705456e-07
epoch 159: mean loss = 1.147825e-07  learning rate = 0.00025034402
============================
Start of epoch 160
step 0: mean loss = 3.2843754e-08
step 100: mean loss = 1.1801023e-07
step 200: mean loss = 1.2331273e-07
step 300: mean loss = 1.0764552e-07
step 400: mean loss = 1.1311244e-07
step 500: mean loss = 1.2799876e-07
step 600: mean loss = 1.1011763e-07
epoch 160: mean loss = 1.1113792e-07  learning rate = 0.00025034402
============================
Start of epoch 161
step 0: mean loss = 6.1312267e-07
step 100: mean loss = 1.2324038e-07
step 200: mean loss = 1.08885935e-07
step 300: mean loss = 1.3632166e-07
step 400: mean loss = 1.2999598e-07
step 500: mean loss = 1.2842985e-07
step 600: mean loss = 1.2010206e-07
epoch 161: mean loss = 1.2058639e-07  learning rate = 0.00025034402
============================
Start of epoch 162
step 0: mean loss = 5.729452e-07
step 100: mean loss = 9.149712e-08
step 200: mean loss = 1.03836044e-07
step 300: mean loss = 1.2948277e-07
step 400: mean loss = 1.27133e-07
step 500: mean loss = 1.1942649e-07
step 600: mean loss = 1.2023884e-07
epoch 162: mean loss = 1.1712053e-07  learning rate = 0.00025034402
============================
Start of epoch 163
step 0: mean loss = 8.136882e-09
step 100: mean loss = 1.3103653e-07
step 200: mean loss = 1.1242589e-07
step 300: mean loss = 1.2496326e-07
step 400: mean loss = 1.1864512e-07
step 500: mean loss = 1.2636208e-07
step 600: mean loss = 1.1730369e-07
epoch 163: mean loss = 1.1423607e-07  learning rate = 0.00025034402
============================
Start of epoch 164
step 0: mean loss = 7.958374e-09
step 100: mean loss = 1.7801135e-07
step 200: mean loss = 1.3771874e-07
step 300: mean loss = 1.354444e-07
step 400: mean loss = 1.2049836e-07
step 500: mean loss = 1.2683175e-07
step 600: mean loss = 1.1672796e-07
epoch 164: mean loss = 1.1630505e-07  learning rate = 0.00025034402
============================
Start of epoch 165
step 0: mean loss = 1.0844021e-07
step 100: mean loss = 1.3737838e-07
step 200: mean loss = 1.0527825e-07
step 300: mean loss = 1.01605295e-07
step 400: mean loss = 8.9794014e-08
step 500: mean loss = 9.603447e-08
step 600: mean loss = 1.005835e-07
epoch 165: mean loss = 9.843254e-08  learning rate = 0.00023782681
============================
Start of epoch 166
step 0: mean loss = 1.1057308e-08
step 100: mean loss = 7.079414e-08
step 200: mean loss = 9.371982e-08
step 300: mean loss = 9.735847e-08
step 400: mean loss = 9.691358e-08
step 500: mean loss = 1.1182355e-07
step 600: mean loss = 1.0226161e-07
epoch 166: mean loss = 9.9503644e-08  learning rate = 0.00023782681
============================
Start of epoch 167
step 0: mean loss = 7.223337e-09
step 100: mean loss = 1.7576261e-07
step 200: mean loss = 1.0644369e-07
step 300: mean loss = 1.3344103e-07
step 400: mean loss = 1.0537798e-07
step 500: mean loss = 1.1287419e-07
step 600: mean loss = 1.1277906e-07
epoch 167: mean loss = 1.1026814e-07  learning rate = 0.00023782681
============================
Start of epoch 168
step 0: mean loss = 8.586292e-09
step 100: mean loss = 1.7034274e-07
step 200: mean loss = 1.16075924e-07
step 300: mean loss = 1.209468e-07
step 400: mean loss = 1.0675694e-07
step 500: mean loss = 1.14198876e-07
step 600: mean loss = 1.1318045e-07
epoch 168: mean loss = 1.11983134e-07  learning rate = 0.00023782681
============================
Start of epoch 169
step 0: mean loss = 4.094231e-08
step 100: mean loss = 1.07678424e-07
step 200: mean loss = 7.721966e-08
step 300: mean loss = 9.8636605e-08
step 400: mean loss = 1.1780707e-07
step 500: mean loss = 9.6161855e-08
step 600: mean loss = 1.08163476e-07
epoch 169: mean loss = 1.05237206e-07  learning rate = 0.00023782681
============================
Start of epoch 170
step 0: mean loss = 7.3198403e-09
step 100: mean loss = 7.639321e-08
step 200: mean loss = 8.816432e-08
step 300: mean loss = 1.0607807e-07
step 400: mean loss = 8.707203e-08
step 500: mean loss = 1.03953816e-07
step 600: mean loss = 9.273963e-08
epoch 170: mean loss = 1.02699154e-07  learning rate = 0.00023782681
============================
Start of epoch 171
step 0: mean loss = 1.2503787e-07
step 100: mean loss = 1.2194731e-07
step 200: mean loss = 9.226718e-08
step 300: mean loss = 9.236869e-08
step 400: mean loss = 9.933124e-08
step 500: mean loss = 9.8081706e-08
step 600: mean loss = 9.874149e-08
epoch 171: mean loss = 9.6116594e-08  learning rate = 0.00023782681
============================
Start of epoch 172
step 0: mean loss = 1.2571382e-08
step 100: mean loss = 1.1482536e-07
step 200: mean loss = 1.322334e-07
step 300: mean loss = 1.0681678e-07
step 400: mean loss = 1.1112675e-07
step 500: mean loss = 1.0690535e-07
step 600: mean loss = 1.13089776e-07
epoch 172: mean loss = 1.1010006e-07  learning rate = 0.00023782681
============================
Start of epoch 173
step 0: mean loss = 9.368736e-09
step 100: mean loss = 5.8239163e-08
step 200: mean loss = 9.878423e-08
step 300: mean loss = 9.510195e-08
step 400: mean loss = 9.873395e-08
step 500: mean loss = 1.13258324e-07
step 600: mean loss = 1.1313015e-07
epoch 173: mean loss = 1.1072019e-07  learning rate = 0.00023782681
============================
Start of epoch 174
step 0: mean loss = 1.1311638e-08
step 100: mean loss = 9.237289e-09
step 200: mean loss = 9.129087e-08
step 300: mean loss = 9.9514814e-08
step 400: mean loss = 1.13450554e-07
step 500: mean loss = 1.0830167e-07
step 600: mean loss = 9.6330496e-08
epoch 174: mean loss = 9.401841e-08  learning rate = 0.00023782681
============================
Start of epoch 175
step 0: mean loss = 8.181539e-08
step 100: mean loss = 1.330305e-07
step 200: mean loss = 1.4027869e-07
step 300: mean loss = 1.03833884e-07
step 400: mean loss = 1.2822926e-07
step 500: mean loss = 1.0598758e-07
step 600: mean loss = 1.1467644e-07
epoch 175: mean loss = 1.1181665e-07  learning rate = 0.00023782681
============================
Start of epoch 176
step 0: mean loss = 9.378657e-08
step 100: mean loss = 7.591243e-08
step 200: mean loss = 1.2928203e-07
step 300: mean loss = 1.08703915e-07
step 400: mean loss = 1.1441413e-07
step 500: mean loss = 1.0243668e-07
step 600: mean loss = 1.1015669e-07
epoch 176: mean loss = 1.07207875e-07  learning rate = 0.00023782681
============================
Start of epoch 177
step 0: mean loss = 1.1744998e-08
step 100: mean loss = 5.6835e-08
step 200: mean loss = 1.0192579e-07
step 300: mean loss = 9.578808e-08
step 400: mean loss = 1.0285664e-07
step 500: mean loss = 1.0868744e-07
step 600: mean loss = 1.0368344e-07
epoch 177: mean loss = 1.06247434e-07  learning rate = 0.00023782681
============================
Start of epoch 178
step 0: mean loss = 8.920018e-08
step 100: mean loss = 1.3042735e-07
step 200: mean loss = 9.3226554e-08
step 300: mean loss = 1.04034775e-07
step 400: mean loss = 9.200007e-08
step 500: mean loss = 1.0584971e-07
step 600: mean loss = 9.877034e-08
epoch 178: mean loss = 9.610383e-08  learning rate = 0.00023782681
============================
Start of epoch 179
step 0: mean loss = 6.881915e-09
step 100: mean loss = 1.8407653e-07
step 200: mean loss = 1.2488651e-07
step 300: mean loss = 1.389349e-07
step 400: mean loss = 1.2369463e-07
step 500: mean loss = 1.1031633e-07
step 600: mean loss = 1.1545013e-07
epoch 179: mean loss = 1.1432736e-07  learning rate = 0.00023782681
============================
Start of epoch 180
step 0: mean loss = 4.426618e-08
step 100: mean loss = 1.2268059e-07
step 200: mean loss = 9.529184e-08
step 300: mean loss = 1.2849335e-07
step 400: mean loss = 1.12401416e-07
step 500: mean loss = 9.192811e-08
step 600: mean loss = 1.0812713e-07
epoch 180: mean loss = 1.0662905e-07  learning rate = 0.00023782681
============================
Start of epoch 181
step 0: mean loss = 3.014188e-07
step 100: mean loss = 5.2196302e-08
step 200: mean loss = 1.1354549e-07
step 300: mean loss = 1.1005745e-07
step 400: mean loss = 1.16381116e-07
step 500: mean loss = 1.0288908e-07
step 600: mean loss = 1.0255459e-07
epoch 181: mean loss = 9.9797774e-08  learning rate = 0.00023782681
============================
Start of epoch 182
step 0: mean loss = 8.118226e-09
step 100: mean loss = 1.0950861e-07
step 200: mean loss = 1.0244662e-07
step 300: mean loss = 9.308863e-08
step 400: mean loss = 1.0270446e-07
step 500: mean loss = 1.0124816e-07
step 600: mean loss = 1.07343524e-07
epoch 182: mean loss = 1.04997596e-07  learning rate = 0.00023782681
============================
Start of epoch 183
step 0: mean loss = 2.1487496e-08
step 100: mean loss = 1.1634874e-07
step 200: mean loss = 8.233658e-08
step 300: mean loss = 1.1988965e-07
step 400: mean loss = 1.0205272e-07
step 500: mean loss = 1.101211e-07
step 600: mean loss = 1.09060345e-07
epoch 183: mean loss = 1.0904582e-07  learning rate = 0.00023782681
============================
Start of epoch 184
step 0: mean loss = 3.7715942e-08
step 100: mean loss = 5.9872306e-08
step 200: mean loss = 9.358353e-08
step 300: mean loss = 8.249583e-08
step 400: mean loss = 8.759709e-08
step 500: mean loss = 9.939058e-08
step 600: mean loss = 1.0050116e-07
epoch 184: mean loss = 9.794714e-08  learning rate = 0.00023782681
============================
Start of epoch 185
step 0: mean loss = 8.808603e-09
step 100: mean loss = 5.9082442e-08
step 200: mean loss = 1.3056781e-07
step 300: mean loss = 1.0636877e-07
step 400: mean loss = 1.1565348e-07
step 500: mean loss = 9.4136425e-08
step 600: mean loss = 9.1125635e-08
epoch 185: mean loss = 8.870921e-08  learning rate = 0.00022593547
============================
Start of epoch 186
step 0: mean loss = 7.2352875e-09
step 100: mean loss = 1.1741365e-07
step 200: mean loss = 9.997466e-08
step 300: mean loss = 1.1045638e-07
step 400: mean loss = 8.773706e-08
step 500: mean loss = 9.319004e-08
step 600: mean loss = 9.475887e-08
epoch 186: mean loss = 9.293596e-08  learning rate = 0.00022593547
============================
Start of epoch 187
step 0: mean loss = 1.2337611e-07
step 100: mean loss = 1.2131473e-07
step 200: mean loss = 9.662889e-08
step 300: mean loss = 1.02859985e-07
step 400: mean loss = 9.698387e-08
step 500: mean loss = 9.9309815e-08
step 600: mean loss = 9.7053e-08
epoch 187: mean loss = 1.0540552e-07  learning rate = 0.00022593547
============================
Start of epoch 188
step 0: mean loss = 1.4931132e-07
step 100: mean loss = 1.6930741e-08
step 200: mean loss = 7.495203e-08
step 300: mean loss = 6.757814e-08
step 400: mean loss = 7.599541e-08
step 500: mean loss = 8.968216e-08
step 600: mean loss = 8.833697e-08
epoch 188: mean loss = 8.602534e-08  learning rate = 0.00022593547
============================
Start of epoch 189
step 0: mean loss = 8.633558e-09
step 100: mean loss = 1.1368875e-07
step 200: mean loss = 9.3693046e-08
step 300: mean loss = 1.2214076e-07
step 400: mean loss = 1.04527345e-07
step 500: mean loss = 8.669898e-08
step 600: mean loss = 9.466537e-08
epoch 189: mean loss = 9.629979e-08  learning rate = 0.00022593547
============================
Start of epoch 190
step 0: mean loss = 3.044522e-07
step 100: mean loss = 9.575537e-08
step 200: mean loss = 9.396691e-08
step 300: mean loss = 9.596893e-08
step 400: mean loss = 8.5989164e-08
step 500: mean loss = 8.8017785e-08
step 600: mean loss = 8.802346e-08
epoch 190: mean loss = 8.5706304e-08  learning rate = 0.00022593547
============================
Start of epoch 191
step 0: mean loss = 1.867489e-08
step 100: mean loss = 1.4026011e-07
step 200: mean loss = 1.1363906e-07
step 300: mean loss = 1.0514404e-07
step 400: mean loss = 1.0933919e-07
step 500: mean loss = 1.0006461e-07
step 600: mean loss = 1.08325715e-07
epoch 191: mean loss = 1.05474314e-07  learning rate = 0.00022593547
============================
Start of epoch 192
step 0: mean loss = 8.5549825e-09
step 100: mean loss = 6.8102146e-08
step 200: mean loss = 9.36729e-08
step 300: mean loss = 7.967289e-08
step 400: mean loss = 9.353499e-08
step 500: mean loss = 9.148856e-08
step 600: mean loss = 9.371997e-08
epoch 192: mean loss = 9.1289444e-08  learning rate = 0.00022593547
============================
Start of epoch 193
step 0: mean loss = 7.509488e-09
step 100: mean loss = 1.2192545e-07
step 200: mean loss = 8.135196e-08
step 300: mean loss = 8.2121936e-08
step 400: mean loss = 9.473199e-08
step 500: mean loss = 9.1406676e-08
step 600: mean loss = 9.372062e-08
epoch 193: mean loss = 9.128391e-08  learning rate = 0.00022593547
============================
Start of epoch 194
step 0: mean loss = 8.913337e-09
step 100: mean loss = 7.6580626e-08
step 200: mean loss = 1.0329851e-07
step 300: mean loss = 1.0919416e-07
step 400: mean loss = 1.0727802e-07
step 500: mean loss = 8.8042434e-08
step 600: mean loss = 9.4860766e-08
epoch 194: mean loss = 9.801148e-08  learning rate = 0.00022593547
============================
Start of epoch 195
step 0: mean loss = 1.2116553e-07
step 100: mean loss = 8.91333e-08
step 200: mean loss = 8.965195e-08
step 300: mean loss = 9.276212e-08
step 400: mean loss = 8.8358675e-08
step 500: mean loss = 9.035335e-08
step 600: mean loss = 9.15088e-08
epoch 195: mean loss = 8.939399e-08  learning rate = 0.00022593547
============================
Start of epoch 196
step 0: mean loss = 9.5194e-09
step 100: mean loss = 8.0083026e-08
step 200: mean loss = 1.0015307e-07
step 300: mean loss = 9.4437596e-08
step 400: mean loss = 9.257983e-08
step 500: mean loss = 8.823873e-08
step 600: mean loss = 9.17718e-08
epoch 196: mean loss = 8.933161e-08  learning rate = 0.00022593547
============================
Start of epoch 197
step 0: mean loss = 1.5829928e-08
step 100: mean loss = 1.1490611e-07
step 200: mean loss = 9.382871e-08
step 300: mean loss = 9.794815e-08
step 400: mean loss = 9.3622894e-08
step 500: mean loss = 9.8975505e-08
step 600: mean loss = 9.181258e-08
epoch 197: mean loss = 9.427001e-08  learning rate = 0.00022593547
============================
Start of epoch 198
step 0: mean loss = 1.0958315e-06
step 100: mean loss = 9.366563e-08
step 200: mean loss = 1.0800759e-07
step 300: mean loss = 9.321301e-08
step 400: mean loss = 9.627653e-08
step 500: mean loss = 9.925679e-08
step 600: mean loss = 9.887483e-08
epoch 198: mean loss = 9.6199486e-08  learning rate = 0.00022593547
============================
Start of epoch 199
step 0: mean loss = 6.7014274e-09
step 100: mean loss = 1.2473184e-07
step 200: mean loss = 8.900225e-08
step 300: mean loss = 1.1659717e-07
step 400: mean loss = 1.0177062e-07
step 500: mean loss = 8.9462354e-08
step 600: mean loss = 9.511147e-08
epoch 199: mean loss = 9.268348e-08  learning rate = 0.00022593547
============================
Start of epoch 200
step 0: mean loss = 7.786959e-09
step 100: mean loss = 1.2111617e-07
step 200: mean loss = 1.0160755e-07
step 300: mean loss = 1.0753568e-07
step 400: mean loss = 9.4255796e-08
step 500: mean loss = 1.0701289e-07
step 600: mean loss = 9.8706884e-08
epoch 200: mean loss = 9.6057846e-08  learning rate = 0.00022593547
============================
Start of epoch 201
step 0: mean loss = 7.0785813e-09
step 100: mean loss = 1.6021362e-07
step 200: mean loss = 1.0157707e-07
step 300: mean loss = 9.915395e-08
step 400: mean loss = 1.04627716e-07
step 500: mean loss = 9.892549e-08
step 600: mean loss = 8.8002594e-08
epoch 201: mean loss = 9.403318e-08  learning rate = 0.00022593547
============================
Start of epoch 202
step 0: mean loss = 1.3336506e-06
step 100: mean loss = 7.701895e-08
step 200: mean loss = 8.211791e-08
step 300: mean loss = 8.8992856e-08
step 400: mean loss = 9.01441e-08
step 500: mean loss = 8.644258e-08
step 600: mean loss = 9.363518e-08
epoch 202: mean loss = 9.345204e-08  learning rate = 0.00022593547
============================
Start of epoch 203
step 0: mean loss = 4.2721094e-08
step 100: mean loss = 5.864456e-08
step 200: mean loss = 7.737595e-08
step 300: mean loss = 1.02936575e-07
step 400: mean loss = 8.171709e-08
step 500: mean loss = 9.386843e-08
step 600: mean loss = 8.997874e-08
epoch 203: mean loss = 8.76766e-08  learning rate = 0.00022593547
============================
Start of epoch 204
step 0: mean loss = 9.50014e-09
step 100: mean loss = 1.0935214e-07
step 200: mean loss = 1.0738375e-07
step 300: mean loss = 1.0454693e-07
step 400: mean loss = 9.540515e-08
step 500: mean loss = 9.523608e-08
step 600: mean loss = 9.187115e-08
epoch 204: mean loss = 9.636422e-08  learning rate = 0.00022593547
============================
Start of epoch 205
step 0: mean loss = 3.299084e-07
step 100: mean loss = 8.829031e-08
step 200: mean loss = 7.2567566e-08
step 300: mean loss = 8.3745164e-08
step 400: mean loss = 9.509817e-08
step 500: mean loss = 9.229766e-08
step 600: mean loss = 7.843979e-08
epoch 205: mean loss = 7.633959e-08  learning rate = 0.00021463867
============================
Start of epoch 206
step 0: mean loss = 6.214447e-09
step 100: mean loss = 1.3339194e-07
step 200: mean loss = 8.294432e-08
step 300: mean loss = 7.924579e-08
step 400: mean loss = 8.474685e-08
step 500: mean loss = 8.648523e-08
step 600: mean loss = 7.883277e-08
epoch 206: mean loss = 8.406897e-08  learning rate = 0.00021463867
============================
Start of epoch 207
step 0: mean loss = 5.973343e-08
step 100: mean loss = 7.249049e-08
step 200: mean loss = 6.7817524e-08
step 300: mean loss = 8.466278e-08
step 400: mean loss = 7.395564e-08
step 500: mean loss = 9.312907e-08
step 600: mean loss = 8.95816e-08
epoch 207: mean loss = 8.717277e-08  learning rate = 0.00021463867
============================
Start of epoch 208
step 0: mean loss = 6.341081e-09
step 100: mean loss = 1.2935877e-07
step 200: mean loss = 8.9996924e-08
step 300: mean loss = 8.0348215e-08
step 400: mean loss = 8.1406796e-08
step 500: mean loss = 8.1469615e-08
step 600: mean loss = 8.066346e-08
epoch 208: mean loss = 7.8532025e-08  learning rate = 0.00021463867
============================
Start of epoch 209
step 0: mean loss = 9.139615e-09
step 100: mean loss = 8.954299e-08
step 200: mean loss = 8.443581e-08
step 300: mean loss = 9.274157e-08
step 400: mean loss = 9.196852e-08
step 500: mean loss = 9.2530335e-08
step 600: mean loss = 9.405227e-08
epoch 209: mean loss = 9.1899715e-08  learning rate = 0.00021463867
============================
Start of epoch 210
step 0: mean loss = 7.2474005e-09
step 100: mean loss = 4.2208796e-08
step 200: mean loss = 5.1902436e-08
step 300: mean loss = 7.176601e-08
step 400: mean loss = 7.685896e-08
step 500: mean loss = 7.915778e-08
step 600: mean loss = 7.978109e-08
epoch 210: mean loss = 7.915992e-08  learning rate = 0.00021463867
============================
Start of epoch 211
step 0: mean loss = 1.3967229e-08
step 100: mean loss = 7.99228e-08
step 200: mean loss = 6.331216e-08
step 300: mean loss = 8.729377e-08
step 400: mean loss = 7.616226e-08
step 500: mean loss = 9.009566e-08
step 600: mean loss = 8.408533e-08
epoch 211: mean loss = 8.183701e-08  learning rate = 0.00021463867
============================
Start of epoch 212
step 0: mean loss = 6.38835e-09
step 100: mean loss = 9.366849e-08
step 200: mean loss = 8.47644e-08
step 300: mean loss = 8.803042e-08
step 400: mean loss = 9.942705e-08
step 500: mean loss = 9.694889e-08
step 600: mean loss = 8.34707e-08
epoch 212: mean loss = 8.144366e-08  learning rate = 0.00021463867
============================
Start of epoch 213
step 0: mean loss = 6.293362e-08
step 100: mean loss = 1.0832776e-07
step 200: mean loss = 1.18937834e-07
step 300: mean loss = 9.499065e-08
step 400: mean loss = 8.537087e-08
step 500: mean loss = 8.889166e-08
step 600: mean loss = 9.4108266e-08
epoch 213: mean loss = 9.28748e-08  learning rate = 0.00021463867
============================
Start of epoch 214
step 0: mean loss = 6.7339956e-09
step 100: mean loss = 8.038663e-08
step 200: mean loss = 8.342298e-08
step 300: mean loss = 8.62232e-08
step 400: mean loss = 8.4390216e-08
step 500: mean loss = 9.72833e-08
step 600: mean loss = 8.451354e-08
epoch 214: mean loss = 8.223075e-08  learning rate = 0.00021463867
============================
Start of epoch 215
step 0: mean loss = 6.0445355e-09
step 100: mean loss = 7.054972e-08
step 200: mean loss = 7.962152e-08
step 300: mean loss = 9.1146106e-08
step 400: mean loss = 1.0069735e-07
step 500: mean loss = 8.349565e-08
step 600: mean loss = 7.886167e-08
epoch 215: mean loss = 8.916399e-08  learning rate = 0.00021463867
============================
Start of epoch 216
step 0: mean loss = 1.2892028e-07
step 100: mean loss = 5.4848545e-08
step 200: mean loss = 7.9478404e-08
step 300: mean loss = 7.265938e-08
step 400: mean loss = 8.270387e-08
step 500: mean loss = 6.925373e-08
step 600: mean loss = 8.165099e-08
epoch 216: mean loss = 8.024908e-08  learning rate = 0.00021463867
============================
Start of epoch 217
step 0: mean loss = 2.27367e-08
step 100: mean loss = 1.5524412e-07
step 200: mean loss = 8.90442e-08
step 300: mean loss = 8.544554e-08
step 400: mean loss = 1.0286166e-07
step 500: mean loss = 8.445595e-08
step 600: mean loss = 8.564542e-08
epoch 217: mean loss = 8.333594e-08  learning rate = 0.00021463867
============================
Start of epoch 218
step 0: mean loss = 6.6251924e-09
step 100: mean loss = 1.0528987e-07
step 200: mean loss = 1.0868892e-07
step 300: mean loss = 8.302056e-08
step 400: mean loss = 8.8911655e-08
step 500: mean loss = 8.3747004e-08
step 600: mean loss = 9.606966e-08
epoch 218: mean loss = 9.361709e-08  learning rate = 0.00021463867
============================
Start of epoch 219
step 0: mean loss = 9.25148e-09
step 100: mean loss = 9.0314934e-08
step 200: mean loss = 4.9280324e-08
step 300: mean loss = 7.096074e-08
step 400: mean loss = 7.4451314e-08
step 500: mean loss = 7.7537635e-08
step 600: mean loss = 8.213871e-08
epoch 219: mean loss = 8.06684e-08  learning rate = 0.00021463867
============================
Start of epoch 220
step 0: mean loss = 8.2122344e-09
step 100: mean loss = 5.1345353e-08
step 200: mean loss = 7.62958e-08
step 300: mean loss = 6.817173e-08
step 400: mean loss = 7.1636805e-08
step 500: mean loss = 6.947203e-08
step 600: mean loss = 9.0173295e-08
epoch 220: mean loss = 8.773112e-08  learning rate = 0.00021463867
============================
Start of epoch 221
step 0: mean loss = 6.2603283e-09
step 100: mean loss = 4.9268102e-08
step 200: mean loss = 5.6622245e-08
step 300: mean loss = 6.338446e-08
step 400: mean loss = 7.516352e-08
step 500: mean loss = 7.607358e-08
step 600: mean loss = 7.541565e-08
epoch 221: mean loss = 7.347926e-08  learning rate = 0.00021463867
============================
Start of epoch 222
step 0: mean loss = 7.935435e-09
step 100: mean loss = 1.2956502e-07
step 200: mean loss = 9.4908586e-08
step 300: mean loss = 1.0351903e-07
step 400: mean loss = 8.984054e-08
step 500: mean loss = 9.515336e-08
step 600: mean loss = 8.786156e-08
epoch 222: mean loss = 8.551047e-08  learning rate = 0.00021463867
============================
Start of epoch 223
step 0: mean loss = 6.1178476e-09
step 100: mean loss = 9.773682e-08
step 200: mean loss = 9.560218e-08
step 300: mean loss = 8.295349e-08
step 400: mean loss = 8.026821e-08
step 500: mean loss = 8.284149e-08
step 600: mean loss = 7.724669e-08
epoch 223: mean loss = 9.062173e-08  learning rate = 0.00021463867
============================
Start of epoch 224
step 0: mean loss = 1.844958e-07
step 100: mean loss = 6.821995e-08
step 200: mean loss = 5.3789538e-08
step 300: mean loss = 8.0624424e-08
step 400: mean loss = 6.350917e-08
step 500: mean loss = 8.042091e-08
step 600: mean loss = 6.987356e-08
epoch 224: mean loss = 8.0837914e-08  learning rate = 0.00021463867
============================
Start of epoch 225
step 0: mean loss = 2.9058444e-07
step 100: mean loss = 8.029911e-08
step 200: mean loss = 8.1962675e-08
step 300: mean loss = 7.14175e-08
step 400: mean loss = 8.105523e-08
step 500: mean loss = 7.506428e-08
step 600: mean loss = 7.806455e-08
epoch 225: mean loss = 7.59749e-08  learning rate = 0.00021463867
============================
Start of epoch 226
step 0: mean loss = 6.71049e-09
step 100: mean loss = 7.1540436e-09
step 200: mean loss = 7.0076304e-08
step 300: mean loss = 5.4864454e-08
step 400: mean loss = 5.6936365e-08
step 500: mean loss = 6.143914e-08
step 600: mean loss = 6.511435e-08
epoch 226: mean loss = 6.9579215e-08  learning rate = 0.00020390673
============================
Start of epoch 227
step 0: mean loss = 3.7241765e-08
step 100: mean loss = 7.266304e-08
step 200: mean loss = 6.555668e-08
step 300: mean loss = 7.5568515e-08
step 400: mean loss = 6.9661176e-08
step 500: mean loss = 7.145998e-08
step 600: mean loss = 7.2862434e-08
epoch 227: mean loss = 7.0989636e-08  learning rate = 0.00020390673
============================
Start of epoch 228
step 0: mean loss = 5.869968e-09
step 100: mean loss = 1.04418156e-07
step 200: mean loss = 8.4282455e-08
step 300: mean loss = 7.7794446e-08
step 400: mean loss = 8.037184e-08
step 500: mean loss = 7.2873654e-08
step 600: mean loss = 8.114887e-08
epoch 228: mean loss = 7.9001104e-08  learning rate = 0.00020390673
============================
Start of epoch 229
step 0: mean loss = 1.35921105e-08
step 100: mean loss = 5.006089e-08
step 200: mean loss = 8.969399e-08
step 300: mean loss = 8.3369386e-08
step 400: mean loss = 8.418887e-08
step 500: mean loss = 7.6030176e-08
step 600: mean loss = 7.4254416e-08
epoch 229: mean loss = 7.229596e-08  learning rate = 0.00020390673
============================
Start of epoch 230
step 0: mean loss = 1.0482437e-08
step 100: mean loss = 8.869887e-08
step 200: mean loss = 9.964214e-08
step 300: mean loss = 9.750038e-08
step 400: mean loss = 7.492202e-08
step 500: mean loss = 9.305815e-08
step 600: mean loss = 8.8754184e-08
epoch 230: mean loss = 8.7390674e-08  learning rate = 0.00020390673
============================
Start of epoch 231
step 0: mean loss = 2.0379703e-08
step 100: mean loss = 6.859466e-09
step 200: mean loss = 5.8254006e-08
step 300: mean loss = 5.4030632e-08
step 400: mean loss = 6.1509795e-08
step 500: mean loss = 6.468025e-08
step 600: mean loss = 6.356305e-08
epoch 231: mean loss = 6.1917206e-08  learning rate = 0.00020390673
============================
Start of epoch 232
step 0: mean loss = 1.6255614e-08
step 100: mean loss = 1.2868095e-07
step 200: mean loss = 8.081288e-08
step 300: mean loss = 9.8193354e-08
step 400: mean loss = 8.3084814e-08
step 500: mean loss = 8.579269e-08
step 600: mean loss = 7.922482e-08
epoch 232: mean loss = 7.7483364e-08  learning rate = 0.00020390673
============================
Start of epoch 233
step 0: mean loss = 8.504683e-08
step 100: mean loss = 7.809352e-08
step 200: mean loss = 7.937021e-08
step 300: mean loss = 1.0609129e-07
step 400: mean loss = 8.141687e-08
step 500: mean loss = 8.689701e-08
step 600: mean loss = 8.1138836e-08
epoch 233: mean loss = 8.183228e-08  learning rate = 0.00020390673
============================
Start of epoch 234
step 0: mean loss = 3.625367e-08
step 100: mean loss = 6.350288e-08
step 200: mean loss = 7.860691e-08
step 300: mean loss = 7.831769e-08
step 400: mean loss = 7.361518e-08
step 500: mean loss = 7.321186e-08
step 600: mean loss = 7.630462e-08
epoch 234: mean loss = 7.468164e-08  learning rate = 0.00020390673
============================
Start of epoch 235
step 0: mean loss = 9.789467e-09
step 100: mean loss = 7.365461e-08
step 200: mean loss = 7.163798e-08
step 300: mean loss = 7.564119e-08
step 400: mean loss = 7.83614e-08
step 500: mean loss = 7.815507e-08
step 600: mean loss = 6.685149e-08
epoch 235: mean loss = 7.634607e-08  learning rate = 0.00020390673
============================
Start of epoch 236
step 0: mean loss = 4.705633e-08
step 100: mean loss = 6.655211e-08
step 200: mean loss = 6.894778e-08
step 300: mean loss = 7.926464e-08
step 400: mean loss = 7.321963e-08
step 500: mean loss = 7.511209e-08
step 600: mean loss = 6.85988e-08
epoch 236: mean loss = 6.684149e-08  learning rate = 0.00020390673
============================
Start of epoch 237
step 0: mean loss = 1.5499845e-08
step 100: mean loss = 1.1402501e-07
step 200: mean loss = 1.0460736e-07
step 300: mean loss = 8.9086676e-08
step 400: mean loss = 9.70388e-08
step 500: mean loss = 8.9058744e-08
step 600: mean loss = 7.6777475e-08
epoch 237: mean loss = 7.4840194e-08  learning rate = 0.00020390673
============================
Start of epoch 238
step 0: mean loss = 3.1253048e-08
step 100: mean loss = 8.879353e-08
step 200: mean loss = 7.8782286e-08
step 300: mean loss = 8.361512e-08
step 400: mean loss = 8.432766e-08
step 500: mean loss = 7.8985536e-08
step 600: mean loss = 7.91581e-08
epoch 238: mean loss = 7.7198e-08  learning rate = 0.00020390673
============================
Start of epoch 239
step 0: mean loss = 4.6835925e-08
step 100: mean loss = 1.1357995e-07
step 200: mean loss = 8.108334e-08
step 300: mean loss = 7.4897144e-08
step 400: mean loss = 7.567265e-08
step 500: mean loss = 7.295735e-08
step 600: mean loss = 7.965563e-08
epoch 239: mean loss = 7.808057e-08  learning rate = 0.00020390673
============================
Start of epoch 240
step 0: mean loss = 2.0173688e-08
step 100: mean loss = 9.571825e-08
step 200: mean loss = 7.863253e-08
step 300: mean loss = 7.7686984e-08
step 400: mean loss = 7.4492085e-08
step 500: mean loss = 7.381148e-08
step 600: mean loss = 8.1953054e-08
epoch 240: mean loss = 8.1183046e-08  learning rate = 0.00020390673
============================
Start of epoch 241
step 0: mean loss = 7.4558875e-09
step 100: mean loss = 3.615132e-08
step 200: mean loss = 6.47706e-08
step 300: mean loss = 6.8180036e-08
step 400: mean loss = 5.5921735e-08
step 500: mean loss = 6.725065e-08
step 600: mean loss = 6.5016536e-08
epoch 241: mean loss = 6.341784e-08  learning rate = 0.00020390673
============================
Start of epoch 242
step 0: mean loss = 3.7313598e-08
step 100: mean loss = 9.30249e-08
step 200: mean loss = 9.658021e-08
step 300: mean loss = 8.1579856e-08
step 400: mean loss = 7.6365055e-08
step 500: mean loss = 7.615869e-08
step 600: mean loss = 7.937599e-08
epoch 242: mean loss = 8.240871e-08  learning rate = 0.00020390673
============================
Start of epoch 243
step 0: mean loss = 6.261006e-08
step 100: mean loss = 8.412324e-08
step 200: mean loss = 6.8774085e-08
step 300: mean loss = 7.328847e-08
step 400: mean loss = 6.6078336e-08
step 500: mean loss = 7.258193e-08
step 600: mean loss = 6.754583e-08
epoch 243: mean loss = 6.679395e-08  learning rate = 0.00020390673
============================
Start of epoch 244
step 0: mean loss = 2.952064e-07
step 100: mean loss = 9.316201e-08
step 200: mean loss = 9.8003234e-08
step 300: mean loss = 8.065384e-08
step 400: mean loss = 8.127907e-08
step 500: mean loss = 7.6511974e-08
step 600: mean loss = 7.9255194e-08
epoch 244: mean loss = 7.711379e-08  learning rate = 0.00020390673
============================
Start of epoch 245
step 0: mean loss = 5.562245e-09
step 100: mean loss = 7.713903e-08
step 200: mean loss = 6.560706e-08
step 300: mean loss = 7.696576e-08
step 400: mean loss = 7.932468e-08
step 500: mean loss = 7.74712e-08
step 600: mean loss = 7.834535e-08
epoch 245: mean loss = 7.623796e-08  learning rate = 0.00020390673
============================
Start of epoch 246
step 0: mean loss = 5.5034586e-09
step 100: mean loss = 1.2946201e-07
step 200: mean loss = 6.97646e-08
step 300: mean loss = 4.8395798e-08
step 400: mean loss = 6.219935e-08
step 500: mean loss = 6.057577e-08
step 600: mean loss = 6.251319e-08
epoch 246: mean loss = 6.107535e-08  learning rate = 0.00019371141
============================
Start of epoch 247
step 0: mean loss = 7.4712565e-09
step 100: mean loss = 1.08321956e-07
step 200: mean loss = 6.9814064e-08
step 300: mean loss = 7.751348e-08
step 400: mean loss = 5.9553063e-08
step 500: mean loss = 7.0444536e-08
step 600: mean loss = 7.3882276e-08
epoch 247: mean loss = 7.210754e-08  learning rate = 0.00019371141
============================
Start of epoch 248
step 0: mean loss = 9.083199e-09
step 100: mean loss = 5.6892148e-08
step 200: mean loss = 6.63126e-08
step 300: mean loss = 5.109435e-08
step 400: mean loss = 6.327941e-08
step 500: mean loss = 5.5944184e-08
step 600: mean loss = 6.262975e-08
epoch 248: mean loss = 6.096608e-08  learning rate = 0.00019371141
============================
Start of epoch 249
step 0: mean loss = 5.3863345e-09
step 100: mean loss = 2.0050787e-07
step 200: mean loss = 1.0357445e-07
step 300: mean loss = 8.926796e-08
step 400: mean loss = 6.874369e-08
step 500: mean loss = 7.288328e-08
step 600: mean loss = 6.8831866e-08
epoch 249: mean loss = 7.566554e-08  learning rate = 0.00019371141
============================
Start of epoch 250
step 0: mean loss = 7.805716e-08
step 100: mean loss = 5.611368e-08
step 200: mean loss = 7.3789764e-08
step 300: mean loss = 5.1277606e-08
step 400: mean loss = 6.255594e-08
step 500: mean loss = 5.947125e-08
step 600: mean loss = 6.8566344e-08
epoch 250: mean loss = 6.6733605e-08  learning rate = 0.00019371141
============================
Start of epoch 251
step 0: mean loss = 5.505513e-09
step 100: mean loss = 5.818629e-08
step 200: mean loss = 7.3022264e-08
step 300: mean loss = 6.1441796e-08
step 400: mean loss = 6.778228e-08
step 500: mean loss = 6.497625e-08
step 600: mean loss = 6.456529e-08
epoch 251: mean loss = 6.285314e-08  learning rate = 0.00019371141
============================
Start of epoch 252
step 0: mean loss = 6.002209e-09
step 100: mean loss = 8.946009e-08
step 200: mean loss = 7.6931585e-08
step 300: mean loss = 8.513952e-08
step 400: mean loss = 8.586776e-08
step 500: mean loss = 7.296048e-08
step 600: mean loss = 8.014156e-08
epoch 252: mean loss = 7.9368064e-08  learning rate = 0.00019371141
============================
Start of epoch 253
step 0: mean loss = 7.212085e-09
step 100: mean loss = 4.2862386e-08
step 200: mean loss = 2.7589309e-08
step 300: mean loss = 5.7306686e-08
step 400: mean loss = 5.0985292e-08
step 500: mean loss = 5.5269123e-08
step 600: mean loss = 5.5859296e-08
epoch 253: mean loss = 5.533481e-08  learning rate = 0.00019371141
============================
Start of epoch 254
step 0: mean loss = 2.7799274e-07
step 100: mean loss = 8.695689e-08
step 200: mean loss = 7.681699e-08
step 300: mean loss = 8.532655e-08
step 400: mean loss = 7.497766e-08
step 500: mean loss = 7.787282e-08
step 600: mean loss = 7.277458e-08
epoch 254: mean loss = 7.0839185e-08  learning rate = 0.00019371141
============================
Start of epoch 255
step 0: mean loss = 5.449205e-09
step 100: mean loss = 8.563777e-08
step 200: mean loss = 7.142279e-08
step 300: mean loss = 6.9753455e-08
step 400: mean loss = 7.300635e-08
step 500: mean loss = 7.5370004e-08
step 600: mean loss = 7.071252e-08
epoch 255: mean loss = 6.952672e-08  learning rate = 0.00019371141
============================
Start of epoch 256
step 0: mean loss = 1.7162616e-08
step 100: mean loss = 7.381e-08
step 200: mean loss = 6.2879586e-08
step 300: mean loss = 5.7888457e-08
step 400: mean loss = 6.151611e-08
step 500: mean loss = 6.3449185e-08
step 600: mean loss = 6.9267394e-08
epoch 256: mean loss = 6.8062384e-08  learning rate = 0.00019371141
============================
Start of epoch 257
step 0: mean loss = 8.869062e-09
step 100: mean loss = 8.7008424e-08
step 200: mean loss = 7.320464e-08
step 300: mean loss = 5.746787e-08
step 400: mean loss = 6.732138e-08
step 500: mean loss = 6.7957174e-08
step 600: mean loss = 6.226562e-08
epoch 257: mean loss = 6.321572e-08  learning rate = 0.00019371141
============================
Start of epoch 258
step 0: mean loss = 6.357895e-07
step 100: mean loss = 7.267148e-08
step 200: mean loss = 7.092904e-08
step 300: mean loss = 7.0511426e-08
step 400: mean loss = 8.116826e-08
step 500: mean loss = 7.468692e-08
step 600: mean loss = 6.4855364e-08
epoch 258: mean loss = 8.0440465e-08  learning rate = 0.00019371141
============================
Start of epoch 259
step 0: mean loss = 2.9408852e-07
step 100: mean loss = 2.2248116e-08
step 200: mean loss = 2.8629284e-08
step 300: mean loss = 4.2551026e-08
step 400: mean loss = 4.525598e-08
step 500: mean loss = 5.1927834e-08
step 600: mean loss = 5.252016e-08
epoch 259: mean loss = 5.4330375e-08  learning rate = 0.00019371141
============================
Start of epoch 260
step 0: mean loss = 3.3287094e-07
step 100: mean loss = 9.700015e-08
step 200: mean loss = 7.040019e-08
step 300: mean loss = 7.1591806e-08
step 400: mean loss = 7.395153e-08
step 500: mean loss = 6.745691e-08
step 600: mean loss = 6.5252486e-08
epoch 260: mean loss = 6.5966056e-08  learning rate = 0.00019371141
============================
Start of epoch 261
step 0: mean loss = 4.536669e-07
step 100: mean loss = 8.4192116e-08
step 200: mean loss = 8.266662e-08
step 300: mean loss = 6.6492696e-08
step 400: mean loss = 6.842284e-08
step 500: mean loss = 6.903995e-08
step 600: mean loss = 6.7266555e-08
epoch 261: mean loss = 6.710867e-08  learning rate = 0.00019371141
============================
Start of epoch 262
step 0: mean loss = 1.7964528e-07
step 100: mean loss = 8.36782e-08
step 200: mean loss = 6.867248e-08
step 300: mean loss = 7.08389e-08
step 400: mean loss = 6.8468786e-08
step 500: mean loss = 7.765061e-08
step 600: mean loss = 7.4663646e-08
epoch 262: mean loss = 7.269312e-08  learning rate = 0.00019371141
============================
Start of epoch 263
step 0: mean loss = 5.824225e-09
step 100: mean loss = 9.7576645e-08
step 200: mean loss = 6.7908054e-08
step 300: mean loss = 6.835349e-08
step 400: mean loss = 6.584607e-08
step 500: mean loss = 6.9686145e-08
step 600: mean loss = 6.640651e-08
epoch 263: mean loss = 6.682187e-08  learning rate = 0.00019371141
============================
Start of epoch 264
step 0: mean loss = 3.1749174e-08
step 100: mean loss = 6.451995e-08
step 200: mean loss = 7.371869e-08
step 300: mean loss = 6.5033994e-08
step 400: mean loss = 6.839465e-08
step 500: mean loss = 6.785357e-08
step 600: mean loss = 6.6857446e-08
epoch 264: mean loss = 6.509068e-08  learning rate = 0.00019371141
============================
Start of epoch 265
step 0: mean loss = 5.827336e-09
step 100: mean loss = 1.2077342e-07
step 200: mean loss = 8.3303924e-08
step 300: mean loss = 5.8096564e-08
step 400: mean loss = 7.2247154e-08
step 500: mean loss = 6.425198e-08
step 600: mean loss = 7.5584865e-08
epoch 265: mean loss = 7.35765e-08  learning rate = 0.00019371141
============================
Start of epoch 266
step 0: mean loss = 5.699992e-09
step 100: mean loss = 6.529971e-08
step 200: mean loss = 6.184308e-08
step 300: mean loss = 4.9156142e-08
step 400: mean loss = 4.5404175e-08
step 500: mean loss = 4.9297785e-08
step 600: mean loss = 4.8370186e-08
epoch 266: mean loss = 4.807036e-08  learning rate = 0.00018402583
============================
Start of epoch 267
step 0: mean loss = 4.935732e-08
step 100: mean loss = 5.5652592e-08
step 200: mean loss = 5.8131363e-08
step 300: mean loss = 6.240147e-08
step 400: mean loss = 5.734906e-08
step 500: mean loss = 6.061045e-08
step 600: mean loss = 5.977109e-08
epoch 267: mean loss = 6.616442e-08  learning rate = 0.00018402583
============================
Start of epoch 268
step 0: mean loss = 1.3837478e-08
step 100: mean loss = 1.2484321e-08
step 200: mean loss = 4.785975e-08
step 300: mean loss = 5.4504223e-08
step 400: mean loss = 5.6735054e-08
step 500: mean loss = 5.4501903e-08
step 600: mean loss = 5.7110505e-08
epoch 268: mean loss = 5.5646208e-08  learning rate = 0.00018402583
============================
Start of epoch 269
step 0: mean loss = 6.5212618e-09
step 100: mean loss = 4.2905768e-08
step 200: mean loss = 5.4276143e-08
step 300: mean loss = 6.049884e-08
step 400: mean loss = 6.670266e-08
step 500: mean loss = 6.471222e-08
step 600: mean loss = 5.9436676e-08
epoch 269: mean loss = 6.017677e-08  learning rate = 0.00018402583
============================
Start of epoch 270
step 0: mean loss = 8.256809e-09
step 100: mean loss = 6.0850866e-08
step 200: mean loss = 6.696468e-08
step 300: mean loss = 5.4394008e-08
step 400: mean loss = 5.5273613e-08
step 500: mean loss = 6.111702e-08
step 600: mean loss = 5.7004428e-08
epoch 270: mean loss = 6.439071e-08  learning rate = 0.00018402583
============================
Start of epoch 271
step 0: mean loss = 3.4839964e-08
step 100: mean loss = 3.577096e-08
step 200: mean loss = 5.380337e-08
step 300: mean loss = 5.7606094e-08
step 400: mean loss = 5.3851597e-08
step 500: mean loss = 5.7984913e-08
step 600: mean loss = 6.301966e-08
epoch 271: mean loss = 6.2331885e-08  learning rate = 0.00018402583
============================
Start of epoch 272
step 0: mean loss = 2.3266523e-08
step 100: mean loss = 5.9428782e-08
step 200: mean loss = 5.8376894e-08
step 300: mean loss = 4.6943587e-08
step 400: mean loss = 5.6195017e-08
step 500: mean loss = 5.358031e-08
step 600: mean loss = 5.468729e-08
epoch 272: mean loss = 5.3541886e-08  learning rate = 0.00018402583
============================
Start of epoch 273
step 0: mean loss = 9.3678025e-09
step 100: mean loss = 5.7563884e-08
step 200: mean loss = 8.9084324e-08
step 300: mean loss = 6.364037e-08
step 400: mean loss = 6.5150424e-08
step 500: mean loss = 6.288051e-08
step 600: mean loss = 6.338899e-08
epoch 273: mean loss = 6.173541e-08  learning rate = 0.00018402583
============================
Start of epoch 274
step 0: mean loss = 5.8780474e-09
step 100: mean loss = 5.106828e-08
step 200: mean loss = 6.104518e-08
step 300: mean loss = 6.321488e-08
step 400: mean loss = 5.5981065e-08
step 500: mean loss = 5.7553084e-08
step 600: mean loss = 5.8239483e-08
epoch 274: mean loss = 6.1262604e-08  learning rate = 0.00018402583
============================
Start of epoch 275
step 0: mean loss = 7.232666e-08
step 100: mean loss = 7.0076844e-08
step 200: mean loss = 6.7002915e-08
step 300: mean loss = 7.334098e-08
step 400: mean loss = 5.9402296e-08
step 500: mean loss = 5.70892e-08
step 600: mean loss = 6.2647935e-08
epoch 275: mean loss = 6.1923636e-08  learning rate = 0.00018402583
============================
Start of epoch 276
step 0: mean loss = 2.1699522e-08
step 100: mean loss = 7.1173545e-08
step 200: mean loss = 5.593599e-08
step 300: mean loss = 6.1818604e-08
step 400: mean loss = 5.5061033e-08
step 500: mean loss = 5.6705467e-08
step 600: mean loss = 5.9122616e-08
epoch 276: mean loss = 6.1948064e-08  learning rate = 0.00018402583
============================
Start of epoch 277
step 0: mean loss = 7.567592e-09
step 100: mean loss = 2.1860322e-08
step 200: mean loss = 5.6494276e-08
step 300: mean loss = 6.270701e-08
step 400: mean loss = 6.016367e-08
step 500: mean loss = 5.6771295e-08
step 600: mean loss = 5.99454e-08
epoch 277: mean loss = 5.9477298e-08  learning rate = 0.00018402583
============================
Start of epoch 278
step 0: mean loss = 2.753012e-08
step 100: mean loss = 6.856756e-08
step 200: mean loss = 7.297842e-08
step 300: mean loss = 6.045962e-08
step 400: mean loss = 5.411198e-08
step 500: mean loss = 5.6221662e-08
step 600: mean loss = 5.7708363e-08
epoch 278: mean loss = 5.6212134e-08  learning rate = 0.00018402583
============================
Start of epoch 279
step 0: mean loss = 1.4872452e-08
step 100: mean loss = 9.3824184e-08
step 200: mean loss = 5.6333494e-08
step 300: mean loss = 6.4360584e-08
step 400: mean loss = 5.6872118e-08
step 500: mean loss = 6.260626e-08
step 600: mean loss = 6.014803e-08
epoch 279: mean loss = 5.860146e-08  learning rate = 0.00018402583
============================
Start of epoch 280
step 0: mean loss = 1.6706514e-08
step 100: mean loss = 8.699481e-08
step 200: mean loss = 7.145368e-08
step 300: mean loss = 6.185605e-08
step 400: mean loss = 6.28085e-08
step 500: mean loss = 6.30647e-08
step 600: mean loss = 6.93549e-08
epoch 280: mean loss = 6.7494696e-08  learning rate = 0.00018402583
============================
Start of epoch 281
step 0: mean loss = 5.0779e-09
step 100: mean loss = 8.6140545e-08
step 200: mean loss = 4.6841137e-08
step 300: mean loss = 5.4757933e-08
step 400: mean loss = 5.6554647e-08
step 500: mean loss = 5.9955916e-08
step 600: mean loss = 6.462327e-08
epoch 281: mean loss = 6.8378746e-08  learning rate = 0.00018402583
============================
Start of epoch 282
step 0: mean loss = 1.0467456e-07
step 100: mean loss = 1.4390891e-08
step 200: mean loss = 2.0363956e-08
step 300: mean loss = 4.5435115e-08
step 400: mean loss = 4.100223e-08
step 500: mean loss = 4.333311e-08
step 600: mean loss = 4.7014318e-08
epoch 282: mean loss = 5.344436e-08  learning rate = 0.00018402583
============================
Start of epoch 283
step 0: mean loss = 5.866773e-07
step 100: mean loss = 3.7166114e-08
step 200: mean loss = 4.708638e-08
step 300: mean loss = 5.293252e-08
step 400: mean loss = 5.499724e-08
step 500: mean loss = 6.332502e-08
step 600: mean loss = 5.4003454e-08
epoch 283: mean loss = 6.0640964e-08  learning rate = 0.00018402583
============================
Start of epoch 284
step 0: mean loss = 4.8353803e-07
step 100: mean loss = 3.437802e-08
step 200: mean loss = 4.7649678e-08
step 300: mean loss = 5.946078e-08
step 400: mean loss = 4.662414e-08
step 500: mean loss = 6.056188e-08
step 600: mean loss = 6.4025954e-08
epoch 284: mean loss = 6.285251e-08  learning rate = 0.00018402583
============================
Start of epoch 285
step 0: mean loss = 5.460012e-09
step 100: mean loss = 5.7390124e-09
step 200: mean loss = 4.3334996e-08
step 300: mean loss = 4.592334e-08
step 400: mean loss = 5.5540415e-08
step 500: mean loss = 5.9257893e-08
step 600: mean loss = 5.1162107e-08
epoch 285: mean loss = 5.739242e-08  learning rate = 0.00018402583
============================
Start of epoch 286
step 0: mean loss = 1.4352378e-07
step 100: mean loss = 6.0600634e-08
step 200: mean loss = 6.690454e-08
step 300: mean loss = 5.911626e-08
step 400: mean loss = 5.6137583e-08
step 500: mean loss = 4.600847e-08
step 600: mean loss = 5.5704273e-08
epoch 286: mean loss = 5.4609107e-08  learning rate = 0.00017482454
============================
Start of epoch 287
step 0: mean loss = 9.217121e-09
step 100: mean loss = 2.7716455e-08
step 200: mean loss = 2.646402e-08
step 300: mean loss = 4.3601084e-08
step 400: mean loss = 4.1934342e-08
step 500: mean loss = 4.521327e-08
step 600: mean loss = 4.8030667e-08
epoch 287: mean loss = 4.698258e-08  learning rate = 0.00017482454
============================
Start of epoch 288
step 0: mean loss = 5.336025e-09
step 100: mean loss = 5.1102788e-08
step 200: mean loss = 5.8343876e-08
step 300: mean loss = 5.742917e-08
step 400: mean loss = 5.7461193e-08
step 500: mean loss = 5.7924066e-08
step 600: mean loss = 5.7394853e-08
epoch 288: mean loss = 5.652548e-08  learning rate = 0.00017482454
============================
Start of epoch 289
step 0: mean loss = 5.2037668e-09
step 100: mean loss = 4.872199e-08
step 200: mean loss = 4.794571e-08
step 300: mean loss = 5.554321e-08
step 400: mean loss = 5.6087053e-08
step 500: mean loss = 5.984899e-08
step 600: mean loss = 5.081595e-08
epoch 289: mean loss = 5.0194103e-08  learning rate = 0.00017482454
============================
Start of epoch 290
step 0: mean loss = 1.5145476e-07
step 100: mean loss = 8.320788e-08
step 200: mean loss = 6.7209434e-08
step 300: mean loss = 5.904567e-08
step 400: mean loss = 5.8492557e-08
step 500: mean loss = 5.495136e-08
step 600: mean loss = 5.538515e-08
epoch 290: mean loss = 5.7935722e-08  learning rate = 0.00017482454
============================
Start of epoch 291
step 0: mean loss = 2.3143774e-07
step 100: mean loss = 5.653726e-08
step 200: mean loss = 5.140685e-08
step 300: mean loss = 4.8707257e-08
step 400: mean loss = 5.464949e-08
step 500: mean loss = 5.540913e-08
step 600: mean loss = 5.303123e-08
epoch 291: mean loss = 5.5152004e-08  learning rate = 0.00017482454
============================
Start of epoch 292
step 0: mean loss = 3.1910997e-08
step 100: mean loss = 6.574261e-08
step 200: mean loss = 3.7863284e-08
step 300: mean loss = 5.6650304e-08
step 400: mean loss = 5.288298e-08
step 500: mean loss = 5.0675e-08
step 600: mean loss = 5.2415903e-08
epoch 292: mean loss = 5.1033744e-08  learning rate = 0.00017482454
============================
Start of epoch 293
step 0: mean loss = 5.33433e-09
step 100: mean loss = 7.243397e-08
step 200: mean loss = 5.3981292e-08
step 300: mean loss = 5.748427e-08
step 400: mean loss = 6.101791e-08
step 500: mean loss = 5.48212e-08
step 600: mean loss = 6.161864e-08
epoch 293: mean loss = 5.9994136e-08  learning rate = 0.00017482454
============================
Start of epoch 294
step 0: mean loss = 5.3618394e-09
step 100: mean loss = 3.261829e-08
step 200: mean loss = 4.88145e-08
step 300: mean loss = 5.0991638e-08
step 400: mean loss = 6.409904e-08
step 500: mean loss = 5.6817253e-08
step 600: mean loss = 5.6047305e-08
epoch 294: mean loss = 5.4638573e-08  learning rate = 0.00017482454
============================
Start of epoch 295
step 0: mean loss = 6.1874674e-09
step 100: mean loss = 4.999176e-08
step 200: mean loss = 5.5058987e-08
step 300: mean loss = 4.9034064e-08
step 400: mean loss = 4.7221626e-08
step 500: mean loss = 4.7843415e-08
step 600: mean loss = 5.1662077e-08
epoch 295: mean loss = 5.0519787e-08  learning rate = 0.00017482454
============================
Start of epoch 296
step 0: mean loss = 8.329511e-09
step 100: mean loss = 5.951718e-08
step 200: mean loss = 6.327049e-08
step 300: mean loss = 5.8191883e-08
step 400: mean loss = 5.7719042e-08
step 500: mean loss = 6.237875e-08
step 600: mean loss = 6.0633475e-08
epoch 296: mean loss = 5.9345037e-08  learning rate = 0.00017482454
============================
Start of epoch 297
step 0: mean loss = 9.320498e-09
step 100: mean loss = 7.153731e-08
step 200: mean loss = 4.3530566e-08
step 300: mean loss = 5.018866e-08
step 400: mean loss = 4.398535e-08
step 500: mean loss = 4.8134535e-08
step 600: mean loss = 5.3254816e-08
epoch 297: mean loss = 5.184729e-08  learning rate = 0.00017482454
============================
Start of epoch 298
step 0: mean loss = 4.660181e-09
step 100: mean loss = 4.0787754e-08
step 200: mean loss = 4.287696e-08
step 300: mean loss = 5.5167433e-08
step 400: mean loss = 5.3569867e-08
step 500: mean loss = 5.5955486e-08
step 600: mean loss = 5.05851e-08
epoch 298: mean loss = 5.177246e-08  learning rate = 0.00017482454
============================
Start of epoch 299
step 0: mean loss = 2.660879e-07
step 100: mean loss = 5.7223634e-08
step 200: mean loss = 5.0671968e-08
step 300: mean loss = 5.982646e-08
step 400: mean loss = 6.453496e-08
step 500: mean loss = 5.7624632e-08
step 600: mean loss = 6.0233965e-08
epoch 299: mean loss = 5.901222e-08  learning rate = 0.00017482454
============================
Start of epoch 300
step 0: mean loss = 9.618675e-09
step 100: mean loss = 6.154302e-08
step 200: mean loss = 4.7011962e-08
step 300: mean loss = 5.4630487e-08
step 400: mean loss = 4.912645e-08
step 500: mean loss = 4.8408474e-08
step 600: mean loss = 5.0167166e-08
epoch 300: mean loss = 4.8891124e-08  learning rate = 0.00017482454
============================
Start of epoch 301
step 0: mean loss = 1.3801817e-08
step 100: mean loss = 6.08897e-08
step 200: mean loss = 7.053081e-08
step 300: mean loss = 6.312469e-08
step 400: mean loss = 5.560374e-08
step 500: mean loss = 5.2058745e-08
step 600: mean loss = 5.9670526e-08
epoch 301: mean loss = 5.940565e-08  learning rate = 0.00017482454
============================
Start of epoch 302
step 0: mean loss = 1.0077568e-08
step 100: mean loss = 4.3382947e-08
step 200: mean loss = 5.2926044e-08
step 300: mean loss = 5.0254584e-08
step 400: mean loss = 4.677179e-08
step 500: mean loss = 5.2764968e-08
step 600: mean loss = 5.300283e-08
epoch 302: mean loss = 5.346874e-08  learning rate = 0.00017482454
============================
Start of epoch 303
step 0: mean loss = 3.0153114e-08
step 100: mean loss = 5.4459555e-08
step 200: mean loss = 6.091449e-08
step 300: mean loss = 4.4480576e-08
step 400: mean loss = 5.038271e-08
step 500: mean loss = 5.0064862e-08
step 600: mean loss = 5.362558e-08
epoch 303: mean loss = 5.2579736e-08  learning rate = 0.00017482454
============================
Start of epoch 304
step 0: mean loss = 1.2132168e-08
step 100: mean loss = 5.6484033e-08
step 200: mean loss = 4.3838238e-08
step 300: mean loss = 5.0085966e-08
step 400: mean loss = 5.4206506e-08
step 500: mean loss = 5.0504703e-08
step 600: mean loss = 5.199268e-08
epoch 304: mean loss = 5.0614407e-08  learning rate = 0.00017482454
============================
Start of epoch 305
step 0: mean loss = 4.6131614e-09
step 100: mean loss = 7.532425e-08
step 200: mean loss = 6.7799114e-08
step 300: mean loss = 7.178635e-08
step 400: mean loss = 6.403216e-08
step 500: mean loss = 5.2793556e-08
step 600: mean loss = 5.8708093e-08
epoch 305: mean loss = 5.7137367e-08  learning rate = 0.00017482454
============================
Start of epoch 306
step 0: mean loss = 4.6208912e-09
step 100: mean loss = 8.706843e-08
step 200: mean loss = 6.5101986e-08
step 300: mean loss = 5.4866394e-08
step 400: mean loss = 5.733655e-08
step 500: mean loss = 5.623811e-08
step 600: mean loss = 4.773989e-08
epoch 306: mean loss = 4.6486633e-08  learning rate = 0.00016608331
============================
Start of epoch 307
step 0: mean loss = 5.140487e-09
step 100: mean loss = 3.4292786e-08
step 200: mean loss = 4.9508063e-08
step 300: mean loss = 5.4904945e-08
step 400: mean loss = 5.6053523e-08
step 500: mean loss = 4.8687838e-08
step 600: mean loss = 4.7133582e-08
epoch 307: mean loss = 5.3075425e-08  learning rate = 0.00016608331
============================
Start of epoch 308
step 0: mean loss = 1.7484321e-07
step 100: mean loss = 2.0776087e-08
step 200: mean loss = 3.8532367e-08
step 300: mean loss = 4.396302e-08
step 400: mean loss = 5.0695256e-08
step 500: mean loss = 4.8093867e-08
step 600: mean loss = 4.415839e-08
epoch 308: mean loss = 4.907874e-08  learning rate = 0.00016608331
============================
Start of epoch 309
step 0: mean loss = 5.125753e-08
step 100: mean loss = 1.0378176e-08
step 200: mean loss = 4.5939128e-08
step 300: mean loss = 4.7383228e-08
step 400: mean loss = 4.9628746e-08
step 500: mean loss = 4.073683e-08
step 600: mean loss = 4.769696e-08
epoch 309: mean loss = 4.6443088e-08  learning rate = 0.00016608331
============================
Start of epoch 310
step 0: mean loss = 4.577477e-09
step 100: mean loss = 6.463458e-08
step 200: mean loss = 6.3742625e-08
step 300: mean loss = 4.585419e-08
step 400: mean loss = 5.0638242e-08
step 500: mean loss = 4.752671e-08
step 600: mean loss = 5.380827e-08
epoch 310: mean loss = 5.24054e-08  learning rate = 0.00016608331
============================
Start of epoch 311
step 0: mean loss = 6.1518466e-09
step 100: mean loss = 2.6266596e-08
step 200: mean loss = 3.5924373e-08
step 300: mean loss = 4.842764e-08
step 400: mean loss = 4.6683507e-08
step 500: mean loss = 4.6043066e-08
step 600: mean loss = 4.73823e-08
epoch 311: mean loss = 4.616165e-08  learning rate = 0.00016608331
============================
Start of epoch 312
step 0: mean loss = 5.7251115e-09
step 100: mean loss = 7.390728e-08
step 200: mean loss = 4.9690485e-08
step 300: mean loss = 5.4962722e-08
step 400: mean loss = 4.8465427e-08
step 500: mean loss = 4.641257e-08
step 600: mean loss = 5.048369e-08
epoch 312: mean loss = 5.0068813e-08  learning rate = 0.00016608331
============================
Start of epoch 313
step 0: mean loss = 2.5922425e-08
step 100: mean loss = 4.4121933e-08
step 200: mean loss = 5.5533388e-08
step 300: mean loss = 4.79473e-08
step 400: mean loss = 5.0399194e-08
step 500: mean loss = 4.7564736e-08
step 600: mean loss = 4.9364647e-08
epoch 313: mean loss = 4.806364e-08  learning rate = 0.00016608331
============================
Start of epoch 314
step 0: mean loss = 4.5713553e-09
step 100: mean loss = 4.8848182e-08
step 200: mean loss = 4.7376922e-08
step 300: mean loss = 5.4101832e-08
step 400: mean loss = 5.5321124e-08
step 500: mean loss = 5.52477e-08
step 600: mean loss = 4.790598e-08
epoch 314: mean loss = 4.6697668e-08  learning rate = 0.00016608331
============================
Start of epoch 315
step 0: mean loss = 1.6607311e-08
step 100: mean loss = 5.353646e-08
step 200: mean loss = 5.6075642e-08
step 300: mean loss = 6.2647025e-08
step 400: mean loss = 5.618201e-08
step 500: mean loss = 5.912363e-08
step 600: mean loss = 5.4675578e-08
epoch 315: mean loss = 5.445131e-08  learning rate = 0.00016608331
============================
Start of epoch 316
step 0: mean loss = 1.1615257e-08
step 100: mean loss = 6.913675e-08
step 200: mean loss = 4.5799073e-08
step 300: mean loss = 3.8323485e-08
step 400: mean loss = 4.924546e-08
step 500: mean loss = 5.0604584e-08
step 600: mean loss = 4.7996096e-08
epoch 316: mean loss = 4.7255124e-08  learning rate = 0.00016608331
============================
Start of epoch 317
step 0: mean loss = 1.541653e-08
step 100: mean loss = 7.528803e-08
step 200: mean loss = 5.9151056e-08
step 300: mean loss = 5.927401e-08
step 400: mean loss = 4.973337e-08
step 500: mean loss = 5.0351698e-08
step 600: mean loss = 4.9835297e-08
epoch 317: mean loss = 5.1999713e-08  learning rate = 0.00016608331
============================
Start of epoch 318
step 0: mean loss = 2.5206823e-08
step 100: mean loss = 3.3131784e-08
step 200: mean loss = 3.5428464e-08
step 300: mean loss = 4.2824002e-08
step 400: mean loss = 4.7887173e-08
step 500: mean loss = 4.861161e-08
step 600: mean loss = 4.99359e-08
epoch 318: mean loss = 4.8674185e-08  learning rate = 0.00016608331
============================
Start of epoch 319
step 0: mean loss = 5.1852593e-09
step 100: mean loss = 5.7142596e-08
step 200: mean loss = 3.814423e-08
step 300: mean loss = 5.2655107e-08
step 400: mean loss = 5.116014e-08
step 500: mean loss = 5.4472288e-08
step 600: mean loss = 4.6407237e-08
epoch 319: mean loss = 4.518991e-08  learning rate = 0.00016608331
============================
Start of epoch 320
step 0: mean loss = 5.0546327e-09
step 100: mean loss = 6.620456e-08
step 200: mean loss = 4.7517233e-08
step 300: mean loss = 5.695917e-08
step 400: mean loss = 6.195673e-08
step 500: mean loss = 5.5106074e-08
step 600: mean loss = 5.183659e-08
epoch 320: mean loss = 5.0458613e-08  learning rate = 0.00016608331
============================
Start of epoch 321
step 0: mean loss = 4.412208e-09
step 100: mean loss = 7.6225355e-08
step 200: mean loss = 6.205128e-08
step 300: mean loss = 6.356913e-08
step 400: mean loss = 4.9334055e-08
step 500: mean loss = 5.6282538e-08
step 600: mean loss = 4.953939e-08
epoch 321: mean loss = 4.8237723e-08  learning rate = 0.00016608331
============================
Start of epoch 322
step 0: mean loss = 6.6366623e-09
step 100: mean loss = 7.1970874e-08
step 200: mean loss = 4.7761393e-08
step 300: mean loss = 6.1899236e-08
step 400: mean loss = 4.8616652e-08
step 500: mean loss = 5.1635467e-08
step 600: mean loss = 5.0691323e-08
epoch 322: mean loss = 5.024918e-08  learning rate = 0.00016608331
============================
Start of epoch 323
step 0: mean loss = 3.127955e-07
step 100: mean loss = 7.775485e-08
step 200: mean loss = 5.6249192e-08
step 300: mean loss = 6.0423815e-08
step 400: mean loss = 5.5116367e-08
step 500: mean loss = 5.5103826e-08
step 600: mean loss = 5.1765696e-08
epoch 323: mean loss = 5.094629e-08  learning rate = 0.00016608331
============================
Start of epoch 324
step 0: mean loss = 1.3757592e-08
step 100: mean loss = 4.7389427e-08
step 200: mean loss = 4.618855e-08
step 300: mean loss = 4.7518157e-08
step 400: mean loss = 5.3459406e-08
step 500: mean loss = 5.4624888e-08
step 600: mean loss = 4.695287e-08
epoch 324: mean loss = 4.819706e-08  learning rate = 0.00016608331
============================
Start of epoch 325
step 0: mean loss = 9.239936e-08
step 100: mean loss = 4.310729e-08
step 200: mean loss = 4.836515e-08
step 300: mean loss = 5.0385644e-08
step 400: mean loss = 4.8009746e-08
step 500: mean loss = 4.6338307e-08
step 600: mean loss = 4.83755e-08
epoch 325: mean loss = 4.723752e-08  learning rate = 0.00016608331
============================
Start of epoch 326
step 0: mean loss = 5.050242e-09
step 100: mean loss = 6.145782e-08
step 200: mean loss = 4.6092925e-08
step 300: mean loss = 5.3715034e-08
step 400: mean loss = 5.4645124e-08
step 500: mean loss = 5.525467e-08
step 600: mean loss = 5.4330503e-08
epoch 326: mean loss = 5.585829e-08  learning rate = 0.00015777916
============================
Start of epoch 327
step 0: mean loss = 1.2313726e-08
step 100: mean loss = 8.005061e-09
step 200: mean loss = 2.0695362e-08
step 300: mean loss = 2.2139963e-08
step 400: mean loss = 2.9104239e-08
step 500: mean loss = 2.9449877e-08
step 600: mean loss = 3.2975592e-08
epoch 327: mean loss = 3.3373716e-08  learning rate = 0.00015777916
============================
Start of epoch 328
step 0: mean loss = 1.804588e-08
step 100: mean loss = 3.425673e-08
step 200: mean loss = 4.3172253e-08
step 300: mean loss = 5.1152846e-08
step 400: mean loss = 4.0023274e-08
step 500: mean loss = 4.7890484e-08
step 600: mean loss = 4.123843e-08
epoch 328: mean loss = 4.788845e-08  learning rate = 0.00015777916
============================
Start of epoch 329
step 0: mean loss = 8.925187e-08
step 100: mean loss = 3.9891056e-08
step 200: mean loss = 2.81141e-08
step 300: mean loss = 4.3232163e-08
step 400: mean loss = 4.561847e-08
step 500: mean loss = 4.6381718e-08
step 600: mean loss = 3.9766192e-08
epoch 329: mean loss = 3.873651e-08  learning rate = 0.00015777916
============================
Start of epoch 330
step 0: mean loss = 4.9165045e-09
step 100: mean loss = 7.547099e-08
step 200: mean loss = 5.2988852e-08
step 300: mean loss = 5.7658376e-08
step 400: mean loss = 5.5253274e-08
step 500: mean loss = 5.409177e-08
step 600: mean loss = 4.941647e-08
epoch 330: mean loss = 4.810388e-08  learning rate = 0.00015777916
============================
Start of epoch 331
step 0: mean loss = 4.315836e-09
step 100: mean loss = 5.1334784e-08
step 200: mean loss = 4.1560945e-08
step 300: mean loss = 3.995026e-08
step 400: mean loss = 4.3216776e-08
step 500: mean loss = 4.3809276e-08
step 600: mean loss = 4.76093e-08
epoch 331: mean loss = 4.9089795e-08  learning rate = 0.00015777916
============================
Start of epoch 332
step 0: mean loss = 2.5835284e-08
step 100: mean loss = 3.120059e-08
step 200: mean loss = 2.9339711e-08
step 300: mean loss = 3.4426932e-08
step 400: mean loss = 3.3266893e-08
step 500: mean loss = 4.027489e-08
step 600: mean loss = 4.0562323e-08
epoch 332: mean loss = 3.95181e-08  learning rate = 0.00015777916
============================
Start of epoch 333
step 0: mean loss = 4.6314867e-09
step 100: mean loss = 5.4734333e-08
step 200: mean loss = 5.0474068e-08
step 300: mean loss = 4.6982457e-08
step 400: mean loss = 4.852726e-08
step 500: mean loss = 4.415077e-08
step 600: mean loss = 4.9466273e-08
epoch 333: mean loss = 4.818546e-08  learning rate = 0.00015777916
============================
Start of epoch 334
step 0: mean loss = 4.304247e-09
step 100: mean loss = 2.9176938e-08
step 200: mean loss = 4.0727606e-08
step 300: mean loss = 3.692476e-08
step 400: mean loss = 3.9102417e-08
step 500: mean loss = 4.146926e-08
step 600: mean loss = 3.9722106e-08
epoch 334: mean loss = 3.875422e-08  learning rate = 0.00015777916
============================
Start of epoch 335
step 0: mean loss = 5.3560587e-09
step 100: mean loss = 7.101951e-08
step 200: mean loss = 4.8621526e-08
step 300: mean loss = 4.7919098e-08
step 400: mean loss = 4.5235183e-08
step 500: mean loss = 4.35704e-08
step 600: mean loss = 4.6575256e-08
epoch 335: mean loss = 4.904923e-08  learning rate = 0.00015777916
============================
Start of epoch 336
step 0: mean loss = 2.6477338e-07
step 100: mean loss = 1.9919728e-08
step 200: mean loss = 3.621551e-08
step 300: mean loss = 4.1549537e-08
step 400: mean loss = 3.952816e-08
step 500: mean loss = 4.042444e-08
step 600: mean loss = 3.9807013e-08
epoch 336: mean loss = 4.0180517e-08  learning rate = 0.00015777916
============================
Start of epoch 337
step 0: mean loss = 3.3813984e-07
step 100: mean loss = 5.9535214e-08
step 200: mean loss = 5.9001184e-08
step 300: mean loss = 4.8617498e-08
step 400: mean loss = 5.6880516e-08
step 500: mean loss = 5.2843944e-08
step 600: mean loss = 4.529769e-08
epoch 337: mean loss = 4.4105946e-08  learning rate = 0.00015777916
============================
Start of epoch 338
step 0: mean loss = 4.9042423e-09
step 100: mean loss = 6.239126e-08
step 200: mean loss = 4.3522807e-08
step 300: mean loss = 5.6229034e-08
step 400: mean loss = 5.1738848e-08
step 500: mean loss = 5.1313524e-08
step 600: mean loss = 4.88707e-08
epoch 338: mean loss = 4.8070326e-08  learning rate = 0.00015777916
============================
Start of epoch 339
step 0: mean loss = 6.0933534e-09
step 100: mean loss = 5.671216e-08
step 200: mean loss = 4.177882e-08
step 300: mean loss = 4.0300538e-08
step 400: mean loss = 4.4981707e-08
step 500: mean loss = 4.330258e-08
step 600: mean loss = 4.4313374e-08
epoch 339: mean loss = 4.358546e-08  learning rate = 0.00015777916
============================
Start of epoch 340
step 0: mean loss = 1.208282e-08
step 100: mean loss = 3.1381283e-08
step 200: mean loss = 4.7182912e-08
step 300: mean loss = 5.0482576e-08
step 400: mean loss = 4.426611e-08
step 500: mean loss = 4.616027e-08
step 600: mean loss = 4.3585256e-08
epoch 340: mean loss = 4.2777522e-08  learning rate = 0.00015777916
============================
Start of epoch 341
step 0: mean loss = 1.2090006e-08
step 100: mean loss = 3.3344868e-08
step 200: mean loss = 4.9312106e-08
step 300: mean loss = 5.2113993e-08
step 400: mean loss = 4.7860393e-08
step 500: mean loss = 4.7880174e-08
step 600: mean loss = 4.4118522e-08
epoch 341: mean loss = 4.82223e-08  learning rate = 0.00015777916
============================
Start of epoch 342
step 0: mean loss = 1.6862437e-08
step 100: mean loss = 8.931354e-09
step 200: mean loss = 3.2753018e-08
step 300: mean loss = 3.9942964e-08
step 400: mean loss = 4.5868717e-08
step 500: mean loss = 4.4753396e-08
step 600: mean loss = 4.236569e-08
epoch 342: mean loss = 4.1254566e-08  learning rate = 0.00015777916
============================
Start of epoch 343
step 0: mean loss = 4.148994e-09
step 100: mean loss = 8.385975e-08
step 200: mean loss = 5.616576e-08
step 300: mean loss = 4.18228e-08
step 400: mean loss = 4.5282253e-08
step 500: mean loss = 4.1874475e-08
step 600: mean loss = 4.5694446e-08
epoch 343: mean loss = 4.47809e-08  learning rate = 0.00015777916
============================
Start of epoch 344
step 0: mean loss = 5.409766e-09
step 100: mean loss = 3.9231523e-08
step 200: mean loss = 4.684658e-08
step 300: mean loss = 4.4353087e-08
step 400: mean loss = 4.004378e-08
step 500: mean loss = 4.339934e-08
step 600: mean loss = 4.5909335e-08
epoch 344: mean loss = 4.48261e-08  learning rate = 0.00015777916
============================
Start of epoch 345
step 0: mean loss = 7.3706885e-09
step 100: mean loss = 3.5626147e-08
step 200: mean loss = 3.4357463e-08
step 300: mean loss = 4.1306066e-08
step 400: mean loss = 3.8841666e-08
step 500: mean loss = 4.5733735e-08
step 600: mean loss = 4.342822e-08
epoch 345: mean loss = 4.229096e-08  learning rate = 0.00015777916
============================
Start of epoch 346
step 0: mean loss = 4.2406687e-09
step 100: mean loss = 6.412565e-08
step 200: mean loss = 5.3998285e-08
step 300: mean loss = 5.969338e-08
step 400: mean loss = 4.6272667e-08
step 500: mean loss = 4.5822603e-08
step 600: mean loss = 4.402879e-08
epoch 346: mean loss = 4.3142965e-08  learning rate = 0.00015777916
============================
Start of epoch 347
step 0: mean loss = 5.6423477e-08
step 100: mean loss = 5.410633e-08
step 200: mean loss = 2.9635173e-08
step 300: mean loss = 4.7144784e-08
step 400: mean loss = 4.2236753e-08
step 500: mean loss = 3.519176e-08
step 600: mean loss = 3.855609e-08
epoch 347: mean loss = 3.7561687e-08  learning rate = 0.00014989018
============================
Start of epoch 348
step 0: mean loss = 4.333872e-09
step 100: mean loss = 4.547273e-08
step 200: mean loss = 4.6470618e-08
step 300: mean loss = 4.4534968e-08
step 400: mean loss = 4.2979618e-08
step 500: mean loss = 4.2793786e-08
step 600: mean loss = 4.1711658e-08
epoch 348: mean loss = 4.2260076e-08  learning rate = 0.00014989018
============================
Start of epoch 349
step 0: mean loss = 4.2126107e-09
step 100: mean loss = 3.9408754e-08
step 200: mean loss = 4.294318e-08
step 300: mean loss = 3.0352965e-08
step 400: mean loss = 3.8316696e-08
step 500: mean loss = 3.9985213e-08
step 600: mean loss = 4.0511974e-08
epoch 349: mean loss = 4.3015632e-08  learning rate = 0.00014989018
============================
Start of epoch 350
step 0: mean loss = 8.3238255e-08
step 100: mean loss = 1.1452563e-08
step 200: mean loss = 2.8013869e-08
step 300: mean loss = 3.691506e-08
step 400: mean loss = 3.6341e-08
step 500: mean loss = 4.0567357e-08
step 600: mean loss = 3.481555e-08
epoch 350: mean loss = 3.4010963e-08  learning rate = 0.00014989018
============================
Start of epoch 351
step 0: mean loss = 2.9862818e-08
step 100: mean loss = 5.6546625e-08
step 200: mean loss = 4.131355e-08
step 300: mean loss = 4.4129962e-08
step 400: mean loss = 4.7659526e-08
step 500: mean loss = 4.2930996e-08
step 600: mean loss = 4.49674e-08
epoch 351: mean loss = 4.386874e-08  learning rate = 0.00014989018
============================
Start of epoch 352
step 0: mean loss = 5.2548317e-09
step 100: mean loss = 2.9991913e-08
step 200: mean loss = 4.12331e-08
step 300: mean loss = 3.657041e-08
step 400: mean loss = 3.868016e-08
step 500: mean loss = 3.5870137e-08
step 600: mean loss = 3.687754e-08
epoch 352: mean loss = 3.8309384e-08  learning rate = 0.00014989018
============================
Start of epoch 353
step 0: mean loss = 5.2663417e-08
step 100: mean loss = 3.262745e-08
step 200: mean loss = 3.9204462e-08
step 300: mean loss = 3.6209077e-08
step 400: mean loss = 3.9046068e-08
step 500: mean loss = 3.7508027e-08
step 600: mean loss = 4.2412164e-08
epoch 353: mean loss = 4.129802e-08  learning rate = 0.00014989018
============================
Start of epoch 354
step 0: mean loss = 4.1836525e-09
step 100: mean loss = 2.8088476e-08
step 200: mean loss = 3.812082e-08
step 300: mean loss = 3.4801825e-08
step 400: mean loss = 4.0654513e-08
step 500: mean loss = 4.0744048e-08
step 600: mean loss = 4.1189473e-08
epoch 354: mean loss = 4.0129443e-08  learning rate = 0.00014989018
============================
Start of epoch 355
step 0: mean loss = 4.624033e-09
step 100: mean loss = 5.0853366e-08
step 200: mean loss = 3.653914e-08
step 300: mean loss = 3.9674145e-08
step 400: mean loss = 3.4397583e-08
step 500: mean loss = 3.9296648e-08
step 600: mean loss = 4.1386496e-08
epoch 355: mean loss = 4.0310887e-08  learning rate = 0.00014989018
============================
Start of epoch 356
step 0: mean loss = 4.1129398e-09
step 100: mean loss = 5.310312e-08
step 200: mean loss = 4.7206807e-08
step 300: mean loss = 3.4187455e-08
step 400: mean loss = 3.9230958e-08
step 500: mean loss = 3.623638e-08
step 600: mean loss = 4.2364604e-08
epoch 356: mean loss = 4.1286757e-08  learning rate = 0.00014989018
============================
Start of epoch 357
step 0: mean loss = 1.09220935e-08
step 100: mean loss = 2.6408971e-08
step 200: mean loss = 3.930937e-08
step 300: mean loss = 3.956651e-08
step 400: mean loss = 4.0429974e-08
step 500: mean loss = 3.6790023e-08
step 600: mean loss = 3.7254175e-08
epoch 357: mean loss = 3.6308546e-08  learning rate = 0.00014989018
============================
Start of epoch 358
step 0: mean loss = 9.188061e-09
step 100: mean loss = 5.530558e-08
step 200: mean loss = 5.0873084e-08
step 300: mean loss = 5.4390927e-08
step 400: mean loss = 4.183976e-08
step 500: mean loss = 4.6003773e-08
step 600: mean loss = 4.3560206e-08
epoch 358: mean loss = 4.2417543e-08  learning rate = 0.00014989018
============================
Start of epoch 359
step 0: mean loss = 4.130491e-09
step 100: mean loss = 5.3404012e-08
step 200: mean loss = 3.9909878e-08
step 300: mean loss = 3.981876e-08
step 400: mean loss = 4.1734697e-08
step 500: mean loss = 4.0123222e-08
step 600: mean loss = 3.9888423e-08
epoch 359: mean loss = 3.885461e-08  learning rate = 0.00014989018
============================
Start of epoch 360
step 0: mean loss = 4.3016186e-09
step 100: mean loss = 5.292645e-08
step 200: mean loss = 5.0309332e-08
step 300: mean loss = 4.3202828e-08
step 400: mean loss = 4.9275435e-08
step 500: mean loss = 4.0351587e-08
step 600: mean loss = 4.4413454e-08
epoch 360: mean loss = 4.3259305e-08  learning rate = 0.00014989018
============================
Start of epoch 361
step 0: mean loss = 4.595263e-09
step 100: mean loss = 3.9216445e-08
step 200: mean loss = 4.364662e-08
step 300: mean loss = 3.6312226e-08
step 400: mean loss = 3.7156664e-08
step 500: mean loss = 3.659263e-08
step 600: mean loss = 3.5624815e-08
epoch 361: mean loss = 3.5636706e-08  learning rate = 0.00014989018
============================
Start of epoch 362
step 0: mean loss = 2.5140824e-07
step 100: mean loss = 6.464163e-08
step 200: mean loss = 5.3803156e-08
step 300: mean loss = 4.86765e-08
step 400: mean loss = 4.5969774e-08
step 500: mean loss = 4.4692356e-08
step 600: mean loss = 3.9706578e-08
epoch 362: mean loss = 4.3667523e-08  learning rate = 0.00014989018
============================
Start of epoch 363
step 0: mean loss = 6.224121e-08
step 100: mean loss = 4.064432e-08
step 200: mean loss = 4.4602658e-08
step 300: mean loss = 4.0458723e-08
step 400: mean loss = 4.1338648e-08
step 500: mean loss = 3.782809e-08
step 600: mean loss = 4.1396454e-08
epoch 363: mean loss = 4.035265e-08  learning rate = 0.00014989018
============================
Start of epoch 364
step 0: mean loss = 3.95303e-09
step 100: mean loss = 2.6829978e-08
step 200: mean loss = 6.2109315e-08
step 300: mean loss = 4.8748184e-08
step 400: mean loss = 3.8790223e-08
step 500: mean loss = 4.075476e-08
step 600: mean loss = 4.0922515e-08
epoch 364: mean loss = 3.9861863e-08  learning rate = 0.00014989018
============================
Start of epoch 365
step 0: mean loss = 3.9803805e-09
step 100: mean loss = 6.15629e-08
step 200: mean loss = 4.6434778e-08
step 300: mean loss = 3.7006906e-08
step 400: mean loss = 4.076529e-08
step 500: mean loss = 3.7802327e-08
step 600: mean loss = 3.8812377e-08
epoch 365: mean loss = 3.7798664e-08  learning rate = 0.00014989018
============================
Start of epoch 366
step 0: mean loss = 3.9695784e-09
step 100: mean loss = 5.483007e-08
step 200: mean loss = 4.2741586e-08
step 300: mean loss = 4.5837794e-08
step 400: mean loss = 4.232746e-08
step 500: mean loss = 4.2324906e-08
step 600: mean loss = 4.295229e-08
epoch 366: mean loss = 4.185424e-08  learning rate = 0.00014989018
============================
Start of epoch 367
step 0: mean loss = 5.565125e-09
step 100: mean loss = 4.97313e-08
step 200: mean loss = 5.1650535e-08
step 300: mean loss = 3.9548077e-08
step 400: mean loss = 3.521625e-08
step 500: mean loss = 3.1043108e-08
step 600: mean loss = 3.50679e-08
epoch 367: mean loss = 3.416576e-08  learning rate = 0.00014239567
============================
Start of epoch 368
step 0: mean loss = 3.9626973e-09
step 100: mean loss = 3.045747e-08
step 200: mean loss = 3.719593e-08
step 300: mean loss = 3.8543554e-08
step 400: mean loss = 3.81239e-08
step 500: mean loss = 3.784024e-08
step 600: mean loss = 3.4821152e-08
epoch 368: mean loss = 3.4720987e-08  learning rate = 0.00014239567
============================
Start of epoch 369
step 0: mean loss = 5.1412745e-09
step 100: mean loss = 5.8162172e-08
step 200: mean loss = 5.085446e-08
step 300: mean loss = 3.635853e-08
step 400: mean loss = 3.8996497e-08
step 500: mean loss = 3.9153054e-08
step 600: mean loss = 3.967648e-08
epoch 369: mean loss = 3.8951658e-08  learning rate = 0.00014239567
============================
Start of epoch 370
step 0: mean loss = 6.4484347e-09
step 100: mean loss = 2.206885e-08
step 200: mean loss = 3.357328e-08
step 300: mean loss = 3.4532587e-08
step 400: mean loss = 3.680508e-08
step 500: mean loss = 3.107526e-08
step 600: mean loss = 3.7016893e-08
epoch 370: mean loss = 3.623246e-08  learning rate = 0.00014239567
============================
Start of epoch 371
step 0: mean loss = 7.540329e-09
step 100: mean loss = 3.1340935e-08
step 200: mean loss = 3.6615006e-08
step 300: mean loss = 2.9854334e-08
step 400: mean loss = 3.1913036e-08
step 500: mean loss = 3.1556134e-08
step 600: mean loss = 3.461544e-08
epoch 371: mean loss = 3.4426243e-08  learning rate = 0.00014239567
============================
Start of epoch 372
step 0: mean loss = 2.0848306e-08
step 100: mean loss = 3.2445165e-08
step 200: mean loss = 3.9543387e-08
step 300: mean loss = 3.7866364e-08
step 400: mean loss = 3.496988e-08
step 500: mean loss = 3.822536e-08
step 600: mean loss = 3.7009443e-08
epoch 372: mean loss = 3.644623e-08  learning rate = 0.00014239567
============================
Start of epoch 373
step 0: mean loss = 1.1495519e-08
step 100: mean loss = 4.0322163e-08
step 200: mean loss = 4.416389e-08
step 300: mean loss = 3.7247656e-08
step 400: mean loss = 3.65089e-08
step 500: mean loss = 3.536354e-08
step 600: mean loss = 3.5722863e-08
epoch 373: mean loss = 3.5145e-08  learning rate = 0.00014239567
============================
Start of epoch 374
step 0: mean loss = 4.7153565e-09
step 100: mean loss = 4.7144955e-08
step 200: mean loss = 4.446892e-08
step 300: mean loss = 4.276706e-08
step 400: mean loss = 3.4108467e-08
step 500: mean loss = 3.770343e-08
step 600: mean loss = 3.7626563e-08
epoch 374: mean loss = 3.6653145e-08  learning rate = 0.00014239567
============================
Start of epoch 375
step 0: mean loss = 4.166887e-09
step 100: mean loss = 4.973497e-08
step 200: mean loss = 2.9722447e-08
step 300: mean loss = 3.947677e-08
step 400: mean loss = 4.137417e-08
step 500: mean loss = 3.964017e-08
step 600: mean loss = 3.6128288e-08
epoch 375: mean loss = 3.5265973e-08  learning rate = 0.00014239567
============================
Start of epoch 376
step 0: mean loss = 2.8923274e-08
step 100: mean loss = 4.811508e-08
step 200: mean loss = 3.6897916e-08
step 300: mean loss = 4.191753e-08
step 400: mean loss = 3.75406e-08
step 500: mean loss = 4.0866603e-08
step 600: mean loss = 3.73563e-08
epoch 376: mean loss = 3.6391288e-08  learning rate = 0.00014239567
============================
Start of epoch 377
step 0: mean loss = 4.1003863e-09
step 100: mean loss = 4.8169337e-08
step 200: mean loss = 3.4249293e-08
step 300: mean loss = 3.7230908e-08
step 400: mean loss = 4.1672404e-08
step 500: mean loss = 3.7206465e-08
step 600: mean loss = 4.1361705e-08
epoch 377: mean loss = 4.0311317e-08  learning rate = 0.00014239567
============================
Start of epoch 378
step 0: mean loss = 4.6333644e-09
step 100: mean loss = 3.4996997e-08
step 200: mean loss = 3.958849e-08
step 300: mean loss = 2.798976e-08
step 400: mean loss = 4.115505e-08
step 500: mean loss = 3.7502392e-08
step 600: mean loss = 3.1945962e-08
epoch 378: mean loss = 3.4185284e-08  learning rate = 0.00014239567
============================
Start of epoch 379
step 0: mean loss = 9.173466e-08
step 100: mean loss = 3.7018864e-08
step 200: mean loss = 3.031039e-08
step 300: mean loss = 3.4515033e-08
step 400: mean loss = 3.6125773e-08
step 500: mean loss = 3.760677e-08
step 600: mean loss = 3.652869e-08
epoch 379: mean loss = 3.5587075e-08  learning rate = 0.00014239567
============================
Start of epoch 380
step 0: mean loss = 4.4243245e-09
step 100: mean loss = 3.6780925e-08
step 200: mean loss = 3.9036962e-08
step 300: mean loss = 3.869548e-08
step 400: mean loss = 3.3540132e-08
step 500: mean loss = 3.487696e-08
step 600: mean loss = 3.6083105e-08
epoch 380: mean loss = 3.5148158e-08  learning rate = 0.00014239567
============================
Start of epoch 381
step 0: mean loss = 4.199077e-09
step 100: mean loss = 3.80654e-08
step 200: mean loss = 4.433856e-08
step 300: mean loss = 4.3375355e-08
step 400: mean loss = 4.377314e-08
step 500: mean loss = 3.614408e-08
step 600: mean loss = 3.877334e-08
epoch 381: mean loss = 3.7770565e-08  learning rate = 0.00014239567
============================
Start of epoch 382
step 0: mean loss = 7.2272006e-09
step 100: mean loss = 2.8338668e-08
step 200: mean loss = 3.6923108e-08
step 300: mean loss = 3.4099486e-08
step 400: mean loss = 3.210189e-08
step 500: mean loss = 3.591458e-08
step 600: mean loss = 3.7388393e-08
epoch 382: mean loss = 3.6411095e-08  learning rate = 0.00014239567
============================
Start of epoch 383
step 0: mean loss = 3.7821697e-09
step 100: mean loss = 5.3799877e-08
step 200: mean loss = 4.242413e-08
step 300: mean loss = 3.354112e-08
step 400: mean loss = 3.412289e-08
step 500: mean loss = 3.485895e-08
step 600: mean loss = 3.633161e-08
epoch 383: mean loss = 3.5754695e-08  learning rate = 0.00014239567
============================
Start of epoch 384
step 0: mean loss = 6.8565235e-08
step 100: mean loss = 4.3488605e-08
step 200: mean loss = 3.3818182e-08
step 300: mean loss = 3.687953e-08
step 400: mean loss = 3.477289e-08
step 500: mean loss = 3.6371222e-08
step 600: mean loss = 3.494725e-08
epoch 384: mean loss = 3.6532175e-08  learning rate = 0.00014239567
============================
Start of epoch 385
step 0: mean loss = 4.668501e-09
step 100: mean loss = 3.7425416e-08
step 200: mean loss = 3.3445684e-08
step 300: mean loss = 3.4395217e-08
step 400: mean loss = 3.7871306e-08
step 500: mean loss = 3.642247e-08
step 600: mean loss = 3.6188293e-08
epoch 385: mean loss = 3.5277527e-08  learning rate = 0.00014239567
============================
Start of epoch 386
step 0: mean loss = 4.184268e-09
step 100: mean loss = 5.400004e-08
step 200: mean loss = 4.935085e-08
step 300: mean loss = 3.4385046e-08
step 400: mean loss = 3.6718255e-08
step 500: mean loss = 3.3299862e-08
step 600: mean loss = 3.766211e-08
epoch 386: mean loss = 3.9312187e-08  learning rate = 0.00014239567
============================
Start of epoch 387
step 0: mean loss = 2.2681935e-08
step 100: mean loss = 9.985377e-09
step 200: mean loss = 3.128538e-08
step 300: mean loss = 2.8221724e-08
step 400: mean loss = 3.438931e-08
step 500: mean loss = 2.8276336e-08
step 600: mean loss = 2.8063429e-08
epoch 387: mean loss = 2.7357242e-08  learning rate = 0.00013527591
============================
Start of epoch 388
step 0: mean loss = 3.7106136e-09
step 100: mean loss = 7.9605805e-08
step 200: mean loss = 4.244144e-08
step 300: mean loss = 3.72792e-08
step 400: mean loss = 3.9384606e-08
step 500: mean loss = 3.7157392e-08
step 600: mean loss = 3.30752e-08
epoch 388: mean loss = 3.222167e-08  learning rate = 0.00013527591
============================
Start of epoch 389
step 0: mean loss = 3.7834416e-09
step 100: mean loss = 6.592895e-08
step 200: mean loss = 4.9406015e-08
step 300: mean loss = 3.4890103e-08
step 400: mean loss = 3.619229e-08
step 500: mean loss = 3.6330015e-08
step 600: mean loss = 3.616736e-08
epoch 389: mean loss = 3.5445854e-08  learning rate = 0.00013527591
============================
Start of epoch 390
step 0: mean loss = 6.63379e-09
step 100: mean loss = 4.0293983e-08
step 200: mean loss = 3.395155e-08
step 300: mean loss = 3.3485286e-08
step 400: mean loss = 2.9818114e-08
step 500: mean loss = 3.260203e-08
step 600: mean loss = 3.4317512e-08
epoch 390: mean loss = 3.3543337e-08  learning rate = 0.00013527591
============================
Start of epoch 391
step 0: mean loss = 5.319893e-09
step 100: mean loss = 1.8799806e-08
step 200: mean loss = 2.8541837e-08
step 300: mean loss = 2.6924935e-08
step 400: mean loss = 3.2079637e-08
step 500: mean loss = 3.32549e-08
step 600: mean loss = 3.2678393e-08
epoch 391: mean loss = 3.195922e-08  learning rate = 0.00013527591
============================
Start of epoch 392
step 0: mean loss = 4.873118e-09
step 100: mean loss = 3.7504936e-08
step 200: mean loss = 2.8813783e-08
step 300: mean loss = 3.481136e-08
step 400: mean loss = 3.1072446e-08
step 500: mean loss = 3.404269e-08
step 600: mean loss = 3.2984488e-08
epoch 392: mean loss = 3.2135613e-08  learning rate = 0.00013527591
============================
Start of epoch 393
step 0: mean loss = 3.7330485e-09
step 100: mean loss = 5.1991858e-08
step 200: mean loss = 3.8157037e-08
step 300: mean loss = 3.9022627e-08
step 400: mean loss = 3.5451944e-08
step 500: mean loss = 3.842013e-08
step 600: mean loss = 3.5056615e-08
epoch 393: mean loss = 3.4143532e-08  learning rate = 0.00013527591
============================
Start of epoch 394
step 0: mean loss = 3.652013e-09
step 100: mean loss = 3.0265646e-08
step 200: mean loss = 2.9005943e-08
step 300: mean loss = 3.3699546e-08
step 400: mean loss = 3.4758557e-08
step 500: mean loss = 3.4773773e-08
step 600: mean loss = 2.973045e-08
epoch 394: mean loss = 3.4484476e-08  learning rate = 0.00013527591
============================
Start of epoch 395
step 0: mean loss = 1.8329474e-07
step 100: mean loss = 3.3749256e-08
step 200: mean loss = 2.1259515e-08
step 300: mean loss = 2.7601427e-08
step 400: mean loss = 2.8566046e-08
step 500: mean loss = 2.9194833e-08
step 600: mean loss = 3.123688e-08
epoch 395: mean loss = 3.0578292e-08  learning rate = 0.00013527591
============================
Start of epoch 396
step 0: mean loss = 2.94745e-08
step 100: mean loss = 2.02994e-08
step 200: mean loss = 3.515243e-08
step 300: mean loss = 3.4347163e-08
step 400: mean loss = 3.178941e-08
step 500: mean loss = 3.208303e-08
step 600: mean loss = 3.3151903e-08
epoch 396: mean loss = 3.2941344e-08  learning rate = 0.00013527591
============================
Start of epoch 397
step 0: mean loss = 9.1405994e-08
step 100: mean loss = 3.2308265e-08
step 200: mean loss = 2.9014982e-08
step 300: mean loss = 3.4455766e-08
step 400: mean loss = 2.905789e-08
step 500: mean loss = 3.2727073e-08
step 600: mean loss = 3.4613006e-08
epoch 397: mean loss = 3.3888657e-08  learning rate = 0.00013527591
============================
Start of epoch 398
step 0: mean loss = 5.9224305e-09
step 100: mean loss = 2.383126e-08
step 200: mean loss = 4.2449642e-08
step 300: mean loss = 3.299607e-08
step 400: mean loss = 3.0798592e-08
step 500: mean loss = 3.3895137e-08
step 600: mean loss = 3.2523484e-08
epoch 398: mean loss = 3.1772387e-08  learning rate = 0.00013527591
============================
Start of epoch 399
step 0: mean loss = 5.5682454e-09
step 100: mean loss = 3.076252e-08
step 200: mean loss = 3.2843804e-08
step 300: mean loss = 3.028978e-08
step 400: mean loss = 3.1783387e-08
step 500: mean loss = 3.275505e-08
step 600: mean loss = 3.714171e-08
epoch 399: mean loss = 3.6221717e-08  learning rate = 0.00013527591
saving the weights
Relative Error in the forces is 8.653062e-05
++++++++++++++++++++++++++++++
Start of cycle 2
Total number of epochs in this cycle: 800
Batch size in this cycle: 32
============================
WARNING:tensorflow:8 out of the last 9 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 8 calls to <function pyramidLayer.call at 0x7fcd14295280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 8 calls to <function pyramidLayer.call at 0x7fcd142954c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 8 calls to <function pyramidLayer.call at 0x7fcd14295700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:6 out of the last 8 calls to <function MyDenseLayer.call at 0x7fcd14295940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:7 out of the last 9 calls to <function DeepMDsimpleEnergy.call at 0x7fccf0380af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
2020-08-27 17:59:36.746819: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 17:59:36.746872: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 17:59:36.746880: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 17:59:36.746891: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
Start of epoch 0
step 0: mean loss = 3.7440078e-09
step 100: mean loss = 4.6815507e-09
step 200: mean loss = 2.2575342e-08
step 300: mean loss = 2.2085468e-08
epoch 0: mean loss = 2.1958082e-08  learning rate = 0.00013527591
============================
Start of epoch 1
step 0: mean loss = 4.6781214e-08
step 100: mean loss = 4.7440892e-08
step 200: mean loss = 3.9343316e-08
step 300: mean loss = 3.3503035e-08
epoch 1: mean loss = 3.311251e-08  learning rate = 0.00013527591
============================
Start of epoch 2
step 0: mean loss = 4.6017913e-08
step 100: mean loss = 4.0000852e-08
step 200: mean loss = 3.3894903e-08
step 300: mean loss = 3.9232855e-08
epoch 2: mean loss = 3.8229317e-08  learning rate = 0.00013527591
============================
Start of epoch 3
step 0: mean loss = 3.9914165e-09
step 100: mean loss = 5.006742e-08
step 200: mean loss = 2.7664015e-08
step 300: mean loss = 3.4825607e-08
epoch 3: mean loss = 3.3944353e-08  learning rate = 0.00013527591
============================
Start of epoch 4
step 0: mean loss = 4.4859716e-09
step 100: mean loss = 3.552423e-08
step 200: mean loss = 3.534886e-08
step 300: mean loss = 2.6158347e-08
epoch 4: mean loss = 2.5516554e-08  learning rate = 0.00013527591
============================
Start of epoch 5
step 0: mean loss = 5.0787703e-09
step 100: mean loss = 5.1062717e-08
step 200: mean loss = 3.9154955e-08
step 300: mean loss = 4.2653294e-08
epoch 5: mean loss = 4.189994e-08  learning rate = 0.00013527591
============================
Start of epoch 6
step 0: mean loss = 1.3085884e-08
step 100: mean loss = 3.3648064e-08
step 200: mean loss = 1.981551e-08
step 300: mean loss = 3.201079e-08
epoch 6: mean loss = 3.1193583e-08  learning rate = 0.00013527591
============================
Start of epoch 7
step 0: mean loss = 3.6566419e-09
step 100: mean loss = 3.3771027e-08
step 200: mean loss = 3.920767e-08
step 300: mean loss = 2.8440981e-08
epoch 7: mean loss = 2.7830156e-08  learning rate = 0.00013527591
============================
Start of epoch 8
step 0: mean loss = 1.22055415e-08
step 100: mean loss = 3.6263785e-08
step 200: mean loss = 3.517302e-08
step 300: mean loss = 3.168227e-08
epoch 8: mean loss = 3.0935954e-08  learning rate = 0.00013527591
============================
Start of epoch 9
step 0: mean loss = 7.471784e-09
step 100: mean loss = 4.4534502e-08
step 200: mean loss = 4.0334157e-08
step 300: mean loss = 3.5339216e-08
epoch 9: mean loss = 3.449064e-08  learning rate = 0.00013527591
============================
Start of epoch 10
step 0: mean loss = 4.766713e-09
step 100: mean loss = 2.7671884e-08
step 200: mean loss = 3.3208018e-08
step 300: mean loss = 3.2421273e-08
epoch 10: mean loss = 3.159186e-08  learning rate = 0.00013527591
============================
Start of epoch 11
step 0: mean loss = 4.2014516e-09
step 100: mean loss = 3.9041964e-08
step 200: mean loss = 3.534973e-08
step 300: mean loss = 3.1452334e-08
epoch 11: mean loss = 3.0671668e-08  learning rate = 0.00013527591
============================
Start of epoch 12
step 0: mean loss = 3.8028793e-09
step 100: mean loss = 4.2739362e-08
step 200: mean loss = 4.2684228e-08
step 300: mean loss = 3.8724075e-08
epoch 12: mean loss = 3.8053248e-08  learning rate = 0.00013527591
============================
Start of epoch 13
step 0: mean loss = 1.6655623e-08
step 100: mean loss = 2.5329605e-08
step 200: mean loss = 2.9948055e-08
step 300: mean loss = 2.5586983e-08
epoch 13: mean loss = 2.5739322e-08  learning rate = 0.00013527591
============================
Start of epoch 14
step 0: mean loss = 1.2193858e-07
step 100: mean loss = 5.6970276e-08
step 200: mean loss = 3.2903863e-08
step 300: mean loss = 3.6358408e-08
epoch 14: mean loss = 3.5407076e-08  learning rate = 0.00013527591
============================
Start of epoch 15
step 0: mean loss = 3.6747054e-09
step 100: mean loss = 4.7074973e-08
step 200: mean loss = 2.8939114e-08
step 300: mean loss = 2.999369e-08
epoch 15: mean loss = 2.9924045e-08  learning rate = 0.0001285121
============================
Start of epoch 16
step 0: mean loss = 7.2866237e-09
step 100: mean loss = 5.3075735e-09
step 200: mean loss = 2.6124555e-08
step 300: mean loss = 2.915878e-08
epoch 16: mean loss = 2.8553877e-08  learning rate = 0.0001285121
============================
Start of epoch 17
step 0: mean loss = 7.266582e-09
step 100: mean loss = 4.120819e-09
step 200: mean loss = 2.8245658e-08
step 300: mean loss = 2.947068e-08
epoch 17: mean loss = 3.0760177e-08  learning rate = 0.0001285121
============================
Start of epoch 18
step 0: mean loss = 5.4524033e-08
step 100: mean loss = 8.8104235e-09
step 200: mean loss = 2.116772e-08
step 300: mean loss = 2.4577465e-08
epoch 18: mean loss = 2.39698e-08  learning rate = 0.0001285121
============================
Start of epoch 19
step 0: mean loss = 3.5928998e-09
step 100: mean loss = 2.9499613e-08
step 200: mean loss = 2.7184583e-08
step 300: mean loss = 2.8899759e-08
epoch 19: mean loss = 2.8324488e-08  learning rate = 0.0001285121
============================
Start of epoch 20
step 0: mean loss = 2.2385805e-08
step 100: mean loss = 3.0032716e-08
step 200: mean loss = 2.8590033e-08
step 300: mean loss = 3.0683882e-08
epoch 20: mean loss = 2.9910492e-08  learning rate = 0.0001285121
============================
Start of epoch 21
step 0: mean loss = 4.700524e-09
step 100: mean loss = 3.3439694e-08
step 200: mean loss = 3.2911235e-08
step 300: mean loss = 2.8421425e-08
epoch 21: mean loss = 3.2424765e-08  learning rate = 0.0001285121
============================
Start of epoch 22
step 0: mean loss = 7.148736e-08
step 100: mean loss = 2.3871843e-08
step 200: mean loss = 2.4532744e-08
step 300: mean loss = 2.7987756e-08
epoch 22: mean loss = 2.7281265e-08  learning rate = 0.0001285121
============================
Start of epoch 23
step 0: mean loss = 3.539107e-09
step 100: mean loss = 4.049866e-08
step 200: mean loss = 3.479403e-08
step 300: mean loss = 3.6575038e-08
epoch 23: mean loss = 3.615315e-08  learning rate = 0.0001285121
============================
Start of epoch 24
step 0: mean loss = 2.2542393e-08
step 100: mean loss = 1.5387027e-08
step 200: mean loss = 2.3972516e-08
step 300: mean loss = 2.4534776e-08
epoch 24: mean loss = 2.3952582e-08  learning rate = 0.0001285121
============================
Start of epoch 25
step 0: mean loss = 4.16173e-09
step 100: mean loss = 3.3543206e-08
step 200: mean loss = 3.666444e-08
step 300: mean loss = 2.9820132e-08
epoch 25: mean loss = 3.5819948e-08  learning rate = 0.0001285121
============================
Start of epoch 26
step 0: mean loss = 1.8775587e-07
step 100: mean loss = 1.3768861e-08
step 200: mean loss = 1.7518495e-08
step 300: mean loss = 2.2377897e-08
epoch 26: mean loss = 2.3992836e-08  learning rate = 0.0001285121
============================
Start of epoch 27
step 0: mean loss = 4.7220214e-09
step 100: mean loss = 3.471859e-08
step 200: mean loss = 2.5675945e-08
step 300: mean loss = 2.9385545e-08
epoch 27: mean loss = 2.9760788e-08  learning rate = 0.0001285121
============================
Start of epoch 28
step 0: mean loss = 1.3668157e-08
step 100: mean loss = 2.20956e-08
step 200: mean loss = 2.9552163e-08
step 300: mean loss = 2.4932163e-08
epoch 28: mean loss = 2.4464804e-08  learning rate = 0.0001285121
============================
Start of epoch 29
step 0: mean loss = 2.6905722e-08
step 100: mean loss = 5.231718e-08
step 200: mean loss = 3.784802e-08
step 300: mean loss = 3.3535947e-08
epoch 29: mean loss = 3.273569e-08  learning rate = 0.0001285121
============================
Start of epoch 30
step 0: mean loss = 5.0985256e-09
step 100: mean loss = 3.0937663e-08
step 200: mean loss = 2.8999306e-08
step 300: mean loss = 2.838694e-08
epoch 30: mean loss = 2.9989756e-08  learning rate = 0.0001285121
============================
Start of epoch 31
step 0: mean loss = 2.7186744e-07
step 100: mean loss = 2.8521574e-08
step 200: mean loss = 2.755436e-08
step 300: mean loss = 2.6568754e-08
epoch 31: mean loss = 2.5904713e-08  learning rate = 0.0001285121
============================
Start of epoch 32
step 0: mean loss = 4.4781867e-09
step 100: mean loss = 4.2568296e-08
step 200: mean loss = 4.0074532e-08
step 300: mean loss = 3.927027e-08
epoch 32: mean loss = 3.97893e-08  learning rate = 0.0001285121
============================
Start of epoch 33
step 0: mean loss = 4.341062e-09
step 100: mean loss = 1.8775387e-08
step 200: mean loss = 2.3409209e-08
step 300: mean loss = 2.45492e-08
epoch 33: mean loss = 2.3946896e-08  learning rate = 0.0001285121
============================
Start of epoch 34
step 0: mean loss = 4.008516e-09
step 100: mean loss = 3.605744e-08
step 200: mean loss = 3.0436784e-08
step 300: mean loss = 3.2834194e-08
epoch 34: mean loss = 3.2014693e-08  learning rate = 0.0001285121
============================
Start of epoch 35
step 0: mean loss = 3.837499e-09
step 100: mean loss = 1.5412512e-08
step 200: mean loss = 1.9652475e-08
step 300: mean loss = 3.0222477e-08
epoch 35: mean loss = 2.9518926e-08  learning rate = 0.0001285121
============================
Start of epoch 36
step 0: mean loss = 3.6309242e-09
step 100: mean loss = 2.51509e-08
step 200: mean loss = 3.3117544e-08
step 300: mean loss = 2.7840745e-08
epoch 36: mean loss = 2.7175567e-08  learning rate = 0.0001285121
============================
Start of epoch 37
step 0: mean loss = 5.135696e-09
step 100: mean loss = 4.9123706e-08
step 200: mean loss = 3.3075665e-08
step 300: mean loss = 3.4724003e-08
epoch 37: mean loss = 3.4323048e-08  learning rate = 0.0001285121
============================
Start of epoch 38
step 0: mean loss = 2.6468056e-08
step 100: mean loss = 2.8433323e-08
step 200: mean loss = 1.6760737e-08
step 300: mean loss = 2.4396279e-08
epoch 38: mean loss = 2.4194053e-08  learning rate = 0.0001285121
============================
Start of epoch 39
step 0: mean loss = 5.3540205e-08
step 100: mean loss = 2.4202757e-08
step 200: mean loss = 2.9229438e-08
step 300: mean loss = 3.4782225e-08
epoch 39: mean loss = 3.616524e-08  learning rate = 0.0001285121
============================
Start of epoch 40
step 0: mean loss = 7.924925e-08
step 100: mean loss = 2.2666235e-08
step 200: mean loss = 1.6987597e-08
step 300: mean loss = 2.6273003e-08
epoch 40: mean loss = 2.561091e-08  learning rate = 0.0001285121
============================
Start of epoch 41
step 0: mean loss = 3.450198e-09
step 100: mean loss = 1.8703773e-08
step 200: mean loss = 2.4278151e-08
step 300: mean loss = 2.7750847e-08
epoch 41: mean loss = 2.7086491e-08  learning rate = 0.0001285121
============================
Start of epoch 42
step 0: mean loss = 5.587823e-09
step 100: mean loss = 3.0346424e-08
step 200: mean loss = 2.6810909e-08
step 300: mean loss = 3.3210572e-08
epoch 42: mean loss = 3.237238e-08  learning rate = 0.0001285121
============================
Start of epoch 43
step 0: mean loss = 4.5050204e-09
step 100: mean loss = 1.582455e-08
step 200: mean loss = 2.87392e-08
step 300: mean loss = 2.582608e-08
epoch 43: mean loss = 2.5177362e-08  learning rate = 0.0001285121
============================
Start of epoch 44
step 0: mean loss = 3.5728567e-09
step 100: mean loss = 4.527133e-08
step 200: mean loss = 2.8746344e-08
step 300: mean loss = 3.2896793e-08
epoch 44: mean loss = 3.4403143e-08  learning rate = 0.0001285121
============================
Start of epoch 45
step 0: mean loss = 2.3087727e-08
step 100: mean loss = 2.9826612e-08
step 200: mean loss = 3.0319327e-08
step 300: mean loss = 2.9994506e-08
epoch 45: mean loss = 2.9240907e-08  learning rate = 0.0001285121
============================
Start of epoch 46
step 0: mean loss = 3.8190997e-09
step 100: mean loss = 3.7729983e-08
step 200: mean loss = 2.6641908e-08
step 300: mean loss = 3.0488255e-08
epoch 46: mean loss = 2.9739901e-08  learning rate = 0.0001285121
============================
Start of epoch 47
step 0: mean loss = 3.6171295e-09
step 100: mean loss = 2.0793214e-08
step 200: mean loss = 3.650914e-08
step 300: mean loss = 2.8728689e-08
epoch 47: mean loss = 2.7994975e-08  learning rate = 0.0001285121
============================
Start of epoch 48
step 0: mean loss = 3.4915524e-09
step 100: mean loss = 3.5584623e-08
step 200: mean loss = 2.3128722e-08
step 300: mean loss = 3.032224e-08
epoch 48: mean loss = 3.3519477e-08  learning rate = 0.0001285121
============================
Start of epoch 49
step 0: mean loss = 1.9198247e-07
step 100: mean loss = 1.3187778e-08
step 200: mean loss = 3.0625515e-08
step 300: mean loss = 2.5380682e-08
epoch 49: mean loss = 2.4752259e-08  learning rate = 0.0001285121
============================
Start of epoch 50
step 0: mean loss = 3.4803107e-09
step 100: mean loss = 3.354985e-08
step 200: mean loss = 4.449435e-08
step 300: mean loss = 3.094863e-08
epoch 50: mean loss = 3.2107387e-08  learning rate = 0.0001285121
============================
Start of epoch 51
step 0: mean loss = 2.598072e-07
step 100: mean loss = 2.4695083e-08
step 200: mean loss = 3.5540474e-08
step 300: mean loss = 3.1083573e-08
epoch 51: mean loss = 3.0382584e-08  learning rate = 0.0001285121
============================
Start of epoch 52
step 0: mean loss = 4.9130926e-09
step 100: mean loss = 5.2948185e-08
step 200: mean loss = 2.8614252e-08
step 300: mean loss = 2.8613295e-08
epoch 52: mean loss = 2.7883567e-08  learning rate = 0.0001285121
============================
Start of epoch 53
step 0: mean loss = 3.5596894e-09
step 100: mean loss = 3.7271914e-08
step 200: mean loss = 2.9133284e-08
step 300: mean loss = 3.0810725e-08
epoch 53: mean loss = 3.3154105e-08  learning rate = 0.0001285121
============================
Start of epoch 54
step 0: mean loss = 3.520812e-08
step 100: mean loss = 3.1244237e-08
step 200: mean loss = 2.6851477e-08
step 300: mean loss = 2.7791748e-08
epoch 54: mean loss = 2.725829e-08  learning rate = 0.0001285121
============================
Start of epoch 55
step 0: mean loss = 3.9664334e-09
step 100: mean loss = 2.1651703e-08
step 200: mean loss = 2.8024894e-08
step 300: mean loss = 2.3192213e-08
epoch 55: mean loss = 2.2621837e-08  learning rate = 0.0001220865
============================
Start of epoch 56
step 0: mean loss = 3.5697372e-09
step 100: mean loss = 3.177161e-08
step 200: mean loss = 2.6218409e-08
step 300: mean loss = 2.9379809e-08
epoch 56: mean loss = 2.9656125e-08  learning rate = 0.0001220865
============================
Start of epoch 57
step 0: mean loss = 3.2630368e-08
step 100: mean loss = 1.5554392e-08
step 200: mean loss = 2.213739e-08
step 300: mean loss = 2.203042e-08
epoch 57: mean loss = 2.151218e-08  learning rate = 0.0001220865
============================
Start of epoch 58
step 0: mean loss = 3.776846e-09
step 100: mean loss = 2.7150234e-08
step 200: mean loss = 2.9710721e-08
step 300: mean loss = 2.6177702e-08
epoch 58: mean loss = 2.5653572e-08  learning rate = 0.0001220865
============================
Start of epoch 59
step 0: mean loss = 1.6626238e-08
step 100: mean loss = 2.2909528e-08
step 200: mean loss = 3.061145e-08
step 300: mean loss = 3.0770178e-08
epoch 59: mean loss = 3.071836e-08  learning rate = 0.0001220865
============================
Start of epoch 60
step 0: mean loss = 2.0418627e-08
step 100: mean loss = 2.6225607e-08
step 200: mean loss = 2.7575947e-08
step 300: mean loss = 2.4046106e-08
epoch 60: mean loss = 2.3512063e-08  learning rate = 0.0001220865
============================
Start of epoch 61
step 0: mean loss = 3.4356986e-09
step 100: mean loss = 2.910397e-08
step 200: mean loss = 2.235532e-08
step 300: mean loss = 3.0294995e-08
epoch 61: mean loss = 3.0854697e-08  learning rate = 0.0001220865
============================
Start of epoch 62
step 0: mean loss = 1.000031e-07
step 100: mean loss = 1.08844675e-08
step 200: mean loss = 2.0948496e-08
step 300: mean loss = 2.2314477e-08
epoch 62: mean loss = 2.3002734e-08  learning rate = 0.0001220865
============================
Start of epoch 63
step 0: mean loss = 5.1431172e-08
step 100: mean loss = 2.4235003e-08
step 200: mean loss = 2.4836638e-08
step 300: mean loss = 2.6570419e-08
epoch 63: mean loss = 2.6244628e-08  learning rate = 0.0001220865
============================
Start of epoch 64
step 0: mean loss = 1.3433737e-08
step 100: mean loss = 2.2460108e-08
step 200: mean loss = 2.7532584e-08
step 300: mean loss = 2.4658885e-08
epoch 64: mean loss = 2.5968415e-08  learning rate = 0.0001220865
============================
Start of epoch 65
step 0: mean loss = 8.887524e-08
step 100: mean loss = 3.22782e-08
step 200: mean loss = 2.5906338e-08
step 300: mean loss = 2.7017975e-08
epoch 65: mean loss = 2.6590195e-08  learning rate = 0.0001220865
============================
Start of epoch 66
step 0: mean loss = 3.5573304e-08
step 100: mean loss = 3.5885744e-08
step 200: mean loss = 2.405622e-08
step 300: mean loss = 3.1706108e-08
epoch 66: mean loss = 3.1042614e-08  learning rate = 0.0001220865
============================
Start of epoch 67
step 0: mean loss = 8.914928e-09
step 100: mean loss = 2.5811502e-08
step 200: mean loss = 2.190775e-08
step 300: mean loss = 2.3322798e-08
epoch 67: mean loss = 2.289418e-08  learning rate = 0.0001220865
============================
Start of epoch 68
step 0: mean loss = 1.8469992e-08
step 100: mean loss = 3.6992674e-08
step 200: mean loss = 2.7109746e-08
step 300: mean loss = 2.6172296e-08
epoch 68: mean loss = 3.0458956e-08  learning rate = 0.0001220865
============================
Start of epoch 69
step 0: mean loss = 4.6689483e-08
step 100: mean loss = 1.0672003e-08
step 200: mean loss = 2.7033959e-08
step 300: mean loss = 2.5632863e-08
epoch 69: mean loss = 2.7233995e-08  learning rate = 0.0001220865
============================
Start of epoch 70
step 0: mean loss = 2.9603038e-08
step 100: mean loss = 3.1987753e-08
step 200: mean loss = 1.8478772e-08
step 300: mean loss = 2.2156112e-08
epoch 70: mean loss = 2.2430457e-08  learning rate = 0.0001220865
============================
Start of epoch 71
step 0: mean loss = 9.430651e-08
step 100: mean loss = 3.360437e-08
step 200: mean loss = 3.0909142e-08
step 300: mean loss = 3.6692473e-08
epoch 71: mean loss = 3.7219444e-08  learning rate = 0.0001220865
============================
Start of epoch 72
step 0: mean loss = 3.703228e-08
step 100: mean loss = 1.5908913e-08
step 200: mean loss = 1.4212236e-08
step 300: mean loss = 1.6665746e-08
epoch 72: mean loss = 1.6312825e-08  learning rate = 0.0001220865
============================
Start of epoch 73
step 0: mean loss = 5.6606986e-09
step 100: mean loss = 3.054551e-08
step 200: mean loss = 2.7767868e-08
step 300: mean loss = 3.195719e-08
epoch 73: mean loss = 3.1214416e-08  learning rate = 0.0001220865
============================
Start of epoch 74
step 0: mean loss = 4.751852e-09
step 100: mean loss = 1.5960746e-08
step 200: mean loss = 2.844725e-08
step 300: mean loss = 2.6647855e-08
epoch 74: mean loss = 2.5990703e-08  learning rate = 0.0001220865
============================
Start of epoch 75
step 0: mean loss = 3.905332e-09
step 100: mean loss = 4.0006547e-08
step 200: mean loss = 2.8346513e-08
step 300: mean loss = 2.8405253e-08
epoch 75: mean loss = 2.884648e-08  learning rate = 0.0001220865
============================
Start of epoch 76
step 0: mean loss = 3.850171e-08
step 100: mean loss = 1.6316259e-08
step 200: mean loss = 1.8352258e-08
step 300: mean loss = 2.1791134e-08
epoch 76: mean loss = 2.1259325e-08  learning rate = 0.0001220865
============================
Start of epoch 77
step 0: mean loss = 3.5028915e-09
step 100: mean loss = 3.2681008e-08
step 200: mean loss = 2.5306193e-08
step 300: mean loss = 3.0708875e-08
epoch 77: mean loss = 3.0135475e-08  learning rate = 0.0001220865
============================
Start of epoch 78
step 0: mean loss = 2.4234645e-08
step 100: mean loss = 2.1139309e-08
step 200: mean loss = 2.670314e-08
step 300: mean loss = 2.602711e-08
epoch 78: mean loss = 2.5387973e-08  learning rate = 0.0001220865
============================
Start of epoch 79
step 0: mean loss = 3.4518057e-09
step 100: mean loss = 2.5235504e-08
step 200: mean loss = 3.3251386e-08
step 300: mean loss = 2.7377872e-08
epoch 79: mean loss = 2.6748285e-08  learning rate = 0.0001220865
============================
Start of epoch 80
step 0: mean loss = 4.906407e-09
step 100: mean loss = 2.7778803e-08
step 200: mean loss = 2.4243507e-08
step 300: mean loss = 2.4598533e-08
epoch 80: mean loss = 2.4056401e-08  learning rate = 0.0001220865
============================
Start of epoch 81
step 0: mean loss = 1.2583634e-08
step 100: mean loss = 3.9302908e-08
step 200: mean loss = 3.2093762e-08
step 300: mean loss = 2.6951527e-08
epoch 81: mean loss = 3.0170696e-08  learning rate = 0.0001220865
============================
Start of epoch 82
step 0: mean loss = 4.5449497e-08
step 100: mean loss = 1.8535928e-08
step 200: mean loss = 2.494308e-08
step 300: mean loss = 2.6467369e-08
epoch 82: mean loss = 2.583506e-08  learning rate = 0.0001220865
============================
Start of epoch 83
step 0: mean loss = 5.10981e-09
step 100: mean loss = 3.060079e-08
step 200: mean loss = 2.4792579e-08
step 300: mean loss = 2.676571e-08
epoch 83: mean loss = 2.6146527e-08  learning rate = 0.0001220865
============================
Start of epoch 84
step 0: mean loss = 9.548976e-09
step 100: mean loss = 1.55082e-08
step 200: mean loss = 3.158668e-08
step 300: mean loss = 2.6732025e-08
epoch 84: mean loss = 2.6063638e-08  learning rate = 0.0001220865
============================
Start of epoch 85
step 0: mean loss = 4.146098e-09
step 100: mean loss = 3.308093e-08
step 200: mean loss = 2.7983768e-08
step 300: mean loss = 2.821359e-08
epoch 85: mean loss = 2.7500999e-08  learning rate = 0.0001220865
============================
Start of epoch 86
step 0: mean loss = 3.7622425e-09
step 100: mean loss = 2.4809573e-08
step 200: mean loss = 2.1746695e-08
step 300: mean loss = 2.7302928e-08
epoch 86: mean loss = 2.6606939e-08  learning rate = 0.0001220865
============================
Start of epoch 87
step 0: mean loss = 3.4129597e-09
step 100: mean loss = 3.0734164e-08
step 200: mean loss = 3.579377e-08
step 300: mean loss = 2.5165264e-08
epoch 87: mean loss = 2.5618727e-08  learning rate = 0.0001220865
============================
Start of epoch 88
step 0: mean loss = 1.0913971e-07
step 100: mean loss = 3.254715e-08
step 200: mean loss = 3.1600777e-08
step 300: mean loss = 2.82747e-08
epoch 88: mean loss = 2.7554682e-08  learning rate = 0.0001220865
============================
Start of epoch 89
step 0: mean loss = 3.4025185e-09
step 100: mean loss = 3.309798e-08
step 200: mean loss = 2.4082103e-08
step 300: mean loss = 2.6621677e-08
epoch 89: mean loss = 3.1104488e-08  learning rate = 0.0001220865
============================
Start of epoch 90
step 0: mean loss = 1.4614469e-07
step 100: mean loss = 1.227821e-08
step 200: mean loss = 2.862102e-08
step 300: mean loss = 2.24431e-08
epoch 90: mean loss = 2.6228653e-08  learning rate = 0.0001220865
============================
Start of epoch 91
step 0: mean loss = 7.169282e-08
step 100: mean loss = 2.8298555e-08
step 200: mean loss = 1.9457424e-08
step 300: mean loss = 2.4717604e-08
epoch 91: mean loss = 2.4095158e-08  learning rate = 0.0001220865
============================
Start of epoch 92
step 0: mean loss = 3.2790732e-09
step 100: mean loss = 3.1639775e-08
step 200: mean loss = 3.545814e-08
step 300: mean loss = 2.4780435e-08
epoch 92: mean loss = 2.4199135e-08  learning rate = 0.0001220865
============================
Start of epoch 93
step 0: mean loss = 7.1664443e-09
step 100: mean loss = 3.841893e-08
step 200: mean loss = 3.336684e-08
step 300: mean loss = 3.0544232e-08
epoch 93: mean loss = 2.9758441e-08  learning rate = 0.0001220865
============================
Start of epoch 94
step 0: mean loss = 3.481319e-09
step 100: mean loss = 3.2678717e-08
step 200: mean loss = 2.6594716e-08
step 300: mean loss = 2.7990398e-08
epoch 94: mean loss = 2.7275458e-08  learning rate = 0.0001220865
============================
Start of epoch 95
step 0: mean loss = 3.3243612e-09
step 100: mean loss = 2.7063445e-08
step 200: mean loss = 2.4043427e-08
step 300: mean loss = 2.500022e-08
epoch 95: mean loss = 2.4468418e-08  learning rate = 0.0001220865
============================
Start of epoch 96
step 0: mean loss = 1.9356978e-08
step 100: mean loss = 2.3223015e-08
step 200: mean loss = 2.5813776e-08
step 300: mean loss = 2.2083402e-08
epoch 96: mean loss = 2.1536552e-08  learning rate = 0.00011598217
============================
Start of epoch 97
step 0: mean loss = 3.2491596e-09
step 100: mean loss = 2.77949e-08
step 200: mean loss = 2.41378e-08
step 300: mean loss = 2.82413e-08
epoch 97: mean loss = 2.7729367e-08  learning rate = 0.00011598217
============================
Start of epoch 98
step 0: mean loss = 4.203554e-09
step 100: mean loss = 2.331086e-08
step 200: mean loss = 2.1487002e-08
step 300: mean loss = 2.0621265e-08
epoch 98: mean loss = 2.0123151e-08  learning rate = 0.00011598217
============================
Start of epoch 99
step 0: mean loss = 3.6565513e-09
step 100: mean loss = 2.8165104e-08
step 200: mean loss = 2.6144585e-08
step 300: mean loss = 2.4441015e-08
epoch 99: mean loss = 2.3836732e-08  learning rate = 0.00011598217
============================
Start of epoch 100
step 0: mean loss = 3.4258698e-09
step 100: mean loss = 3.541972e-08
step 200: mean loss = 2.5525459e-08
step 300: mean loss = 2.8022287e-08
epoch 100: mean loss = 2.734317e-08  learning rate = 0.00011598217
============================
Start of epoch 101
step 0: mean loss = 4.423584e-09
step 100: mean loss = 1.9909645e-08
step 200: mean loss = 3.159851e-08
step 300: mean loss = 2.5125312e-08
epoch 101: mean loss = 2.4885852e-08  learning rate = 0.00011598217
============================
Start of epoch 102
step 0: mean loss = 4.880742e-09
step 100: mean loss = 2.1856925e-08
step 200: mean loss = 2.6745692e-08
step 300: mean loss = 2.0085713e-08
epoch 102: mean loss = 1.959692e-08  learning rate = 0.00011598217
============================
Start of epoch 103
step 0: mean loss = 3.3337446e-09
step 100: mean loss = 3.5883858e-08
step 200: mean loss = 3.514099e-08
step 300: mean loss = 2.8935617e-08
epoch 103: mean loss = 2.8389536e-08  learning rate = 0.00011598217
============================
Start of epoch 104
step 0: mean loss = 4.139976e-09
step 100: mean loss = 2.361686e-08
step 200: mean loss = 2.7442919e-08
step 300: mean loss = 2.8435942e-08
epoch 104: mean loss = 2.7865715e-08  learning rate = 0.00011598217
============================
Start of epoch 105
step 0: mean loss = 3.878729e-09
step 100: mean loss = 3.567411e-09
step 200: mean loss = 2.021017e-08
step 300: mean loss = 2.1203466e-08
epoch 105: mean loss = 2.0693061e-08  learning rate = 0.00011598217
============================
Start of epoch 106
step 0: mean loss = 3.252917e-09
step 100: mean loss = 4.0143263e-08
step 200: mean loss = 2.8105667e-08
step 300: mean loss = 2.3065967e-08
epoch 106: mean loss = 2.635771e-08  learning rate = 0.00011598217
============================
Start of epoch 107
step 0: mean loss = 6.040025e-08
step 100: mean loss = 1.8347242e-08
step 200: mean loss = 2.1830306e-08
step 300: mean loss = 2.1855772e-08
epoch 107: mean loss = 2.1327681e-08  learning rate = 0.00011598217
============================
Start of epoch 108
step 0: mean loss = 4.0622807e-09
step 100: mean loss = 2.7926562e-08
step 200: mean loss = 3.2020974e-08
step 300: mean loss = 2.2849685e-08
epoch 108: mean loss = 2.245318e-08  learning rate = 0.00011598217
============================
Start of epoch 109
step 0: mean loss = 3.6157882e-08
step 100: mean loss = 4.548324e-08
step 200: mean loss = 3.3020854e-08
step 300: mean loss = 2.9490746e-08
epoch 109: mean loss = 3.143309e-08  learning rate = 0.00011598217
============================
Start of epoch 110
step 0: mean loss = 9.2944305e-08
step 100: mean loss = 7.9700095e-09
step 200: mean loss = 1.8861492e-08
step 300: mean loss = 1.9857426e-08
epoch 110: mean loss = 1.937704e-08  learning rate = 0.00011598217
============================
Start of epoch 111
step 0: mean loss = 3.5290202e-09
step 100: mean loss = 2.812742e-08
step 200: mean loss = 2.8474163e-08
step 300: mean loss = 2.4683237e-08
epoch 111: mean loss = 2.4075936e-08  learning rate = 0.00011598217
============================
Start of epoch 112
step 0: mean loss = 3.874095e-09
step 100: mean loss = 2.7080775e-08
step 200: mean loss = 2.712067e-08
step 300: mean loss = 2.546325e-08
epoch 112: mean loss = 2.4890957e-08  learning rate = 0.00011598217
============================
Start of epoch 113
step 0: mean loss = 3.450444e-09
step 100: mean loss = 1.8503401e-08
step 200: mean loss = 3.083385e-08
step 300: mean loss = 2.1729049e-08
epoch 113: mean loss = 2.1193982e-08  learning rate = 0.00011598217
============================
Start of epoch 114
step 0: mean loss = 3.6959735e-09
step 100: mean loss = 5.190757e-08
step 200: mean loss = 3.8939238e-08
step 300: mean loss = 2.7171707e-08
epoch 114: mean loss = 2.6478803e-08  learning rate = 0.00011598217
============================
Start of epoch 115
step 0: mean loss = 3.7355026e-09
step 100: mean loss = 4.2065388e-08
step 200: mean loss = 2.8419551e-08
step 300: mean loss = 3.2210796e-08
epoch 115: mean loss = 3.1473192e-08  learning rate = 0.00011598217
============================
Start of epoch 116
step 0: mean loss = 3.9810186e-09
step 100: mean loss = 4.829354e-09
step 200: mean loss = 2.1239206e-08
step 300: mean loss = 1.6661444e-08
epoch 116: mean loss = 1.6390883e-08  learning rate = 0.00011598217
============================
Start of epoch 117
step 0: mean loss = 2.1531493e-08
step 100: mean loss = 3.6533354e-08
step 200: mean loss = 2.6970092e-08
step 300: mean loss = 2.7960656e-08
epoch 117: mean loss = 2.7826914e-08  learning rate = 0.00011598217
============================
Start of epoch 118
step 0: mean loss = 8.336032e-08
step 100: mean loss = 2.1134257e-08
step 200: mean loss = 3.0761758e-08
step 300: mean loss = 2.4518009e-08
epoch 118: mean loss = 2.3924065e-08  learning rate = 0.00011598217
============================
Start of epoch 119
step 0: mean loss = 3.7743426e-09
step 100: mean loss = 2.4405717e-08
step 200: mean loss = 2.7250099e-08
step 300: mean loss = 2.7225896e-08
epoch 119: mean loss = 2.6669454e-08  learning rate = 0.00011598217
============================
Start of epoch 120
step 0: mean loss = 9.638605e-09
step 100: mean loss = 1.8824409e-08
step 200: mean loss = 2.5634645e-08
step 300: mean loss = 2.4697853e-08
epoch 120: mean loss = 2.4107637e-08  learning rate = 0.00011598217
============================
Start of epoch 121
step 0: mean loss = 3.7076224e-09
step 100: mean loss = 2.9360736e-08
step 200: mean loss = 2.3849516e-08
step 300: mean loss = 2.2860666e-08
epoch 121: mean loss = 2.2296561e-08  learning rate = 0.00011598217
============================
Start of epoch 122
step 0: mean loss = 3.1788097e-09
step 100: mean loss = 2.7184125e-08
step 200: mean loss = 2.5215876e-08
step 300: mean loss = 2.74713e-08
epoch 122: mean loss = 2.67687e-08  learning rate = 0.00011598217
============================
Start of epoch 123
step 0: mean loss = 3.169436e-09
step 100: mean loss = 2.9906538e-08
step 200: mean loss = 1.9304164e-08
step 300: mean loss = 2.2946356e-08
epoch 123: mean loss = 2.2372058e-08  learning rate = 0.00011598217
============================
Start of epoch 124
step 0: mean loss = 3.2104452e-09
step 100: mean loss = 2.033802e-08
step 200: mean loss = 2.0845748e-08
step 300: mean loss = 2.2351722e-08
epoch 124: mean loss = 2.4488354e-08  learning rate = 0.00011598217
============================
Start of epoch 125
step 0: mean loss = 2.303352e-07
step 100: mean loss = 3.2911558e-08
step 200: mean loss = 2.4520398e-08
step 300: mean loss = 2.5360858e-08
epoch 125: mean loss = 2.5437513e-08  learning rate = 0.00011598217
============================
Start of epoch 126
step 0: mean loss = 1.7237797e-08
step 100: mean loss = 2.4318947e-08
step 200: mean loss = 2.6511145e-08
step 300: mean loss = 2.5899887e-08
epoch 126: mean loss = 2.6830408e-08  learning rate = 0.00011598217
============================
Start of epoch 127
step 0: mean loss = 1.0497295e-08
step 100: mean loss = 1.0676347e-08
step 200: mean loss = 1.7588166e-08
step 300: mean loss = 2.3719497e-08
epoch 127: mean loss = 2.4515364e-08  learning rate = 0.00011598217
============================
Start of epoch 128
step 0: mean loss = 4.2293188e-08
step 100: mean loss = 5.67883e-09
step 200: mean loss = 2.176753e-08
step 300: mean loss = 2.1723741e-08
epoch 128: mean loss = 2.2202563e-08  learning rate = 0.00011598217
============================
Start of epoch 129
step 0: mean loss = 6.01112e-09
step 100: mean loss = 2.5935616e-08
step 200: mean loss = 2.78364e-08
step 300: mean loss = 1.9739357e-08
epoch 129: mean loss = 1.930994e-08  learning rate = 0.00011598217
============================
Start of epoch 130
step 0: mean loss = 1.0085216e-08
step 100: mean loss = 3.5058736e-08
step 200: mean loss = 3.021991e-08
step 300: mean loss = 3.3066268e-08
epoch 130: mean loss = 3.2205598e-08  learning rate = 0.00011598217
============================
Start of epoch 131
step 0: mean loss = 3.3064194e-09
step 100: mean loss = 9.0193994e-09
step 200: mean loss = 2.3881297e-08
step 300: mean loss = 2.131846e-08
epoch 131: mean loss = 2.1485924e-08  learning rate = 0.00011598217
============================
Start of epoch 132
step 0: mean loss = 2.236358e-08
step 100: mean loss = 2.3751069e-08
step 200: mean loss = 2.4951575e-08
step 300: mean loss = 2.3955211e-08
epoch 132: mean loss = 2.336648e-08  learning rate = 0.00011598217
============================
Start of epoch 133
step 0: mean loss = 3.5930492e-09
step 100: mean loss = 2.9400342e-08
step 200: mean loss = 2.6970588e-08
step 300: mean loss = 2.8463885e-08
epoch 133: mean loss = 2.7771259e-08  learning rate = 0.00011598217
============================
Start of epoch 134
step 0: mean loss = 3.802467e-09
step 100: mean loss = 3.3991983e-09
step 200: mean loss = 1.7727823e-08
step 300: mean loss = 2.1371013e-08
epoch 134: mean loss = 2.0846418e-08  learning rate = 0.00011598217
============================
Start of epoch 135
step 0: mean loss = 3.4161558e-09
step 100: mean loss = 1.7806032e-08
step 200: mean loss = 2.2030415e-08
step 300: mean loss = 2.507273e-08
epoch 135: mean loss = 2.4646585e-08  learning rate = 0.00011598217
============================
Start of epoch 136
step 0: mean loss = 2.0717064e-08
step 100: mean loss = 1.7933848e-08
step 200: mean loss = 1.9305606e-08
step 300: mean loss = 1.3928336e-08
epoch 136: mean loss = 1.3620039e-08  learning rate = 0.00011018306
============================
Start of epoch 137
step 0: mean loss = 3.6977161e-09
step 100: mean loss = 2.9926348e-08
step 200: mean loss = 2.8370689e-08
step 300: mean loss = 2.822957e-08
epoch 137: mean loss = 2.7815194e-08  learning rate = 0.00011018306
============================
Start of epoch 138
step 0: mean loss = 8.142743e-09
step 100: mean loss = 2.1178401e-08
step 200: mean loss = 1.9347029e-08
step 300: mean loss = 1.8341822e-08
epoch 138: mean loss = 1.8930328e-08  learning rate = 0.00011018306
============================
Start of epoch 139
step 0: mean loss = 1.1643144e-07
step 100: mean loss = 1.757875e-08
step 200: mean loss = 2.2508845e-08
step 300: mean loss = 2.720206e-08
epoch 139: mean loss = 2.6511536e-08  learning rate = 0.00011018306
============================
Start of epoch 140
step 0: mean loss = 3.131566e-09
step 100: mean loss = 1.7883563e-08
step 200: mean loss = 2.0514884e-08
step 300: mean loss = 1.9156671e-08
epoch 140: mean loss = 1.8922869e-08  learning rate = 0.00011018306
============================
Start of epoch 141
step 0: mean loss = 1.0712988e-08
step 100: mean loss = 3.1826364e-08
step 200: mean loss = 2.217629e-08
step 300: mean loss = 2.2073996e-08
epoch 141: mean loss = 2.1543862e-08  learning rate = 0.00011018306
============================
Start of epoch 142
step 0: mean loss = 3.2813956e-09
step 100: mean loss = 2.871016e-08
step 200: mean loss = 2.0623437e-08
step 300: mean loss = 2.0347272e-08
epoch 142: mean loss = 1.9847729e-08  learning rate = 0.00011018306
============================
Start of epoch 143
step 0: mean loss = 3.1626974e-09
step 100: mean loss = 3.911122e-08
step 200: mean loss = 2.969961e-08
step 300: mean loss = 3.005356e-08
epoch 143: mean loss = 3.025292e-08  learning rate = 0.00011018306
============================
Start of epoch 144
step 0: mean loss = 1.2744647e-08
step 100: mean loss = 8.646422e-09
step 200: mean loss = 1.1360692e-08
step 300: mean loss = 1.5897264e-08
epoch 144: mean loss = 1.5525659e-08  learning rate = 0.00011018306
============================
Start of epoch 145
step 0: mean loss = 3.1696594e-09
step 100: mean loss = 3.008234e-08
step 200: mean loss = 2.809853e-08
step 300: mean loss = 2.905421e-08
epoch 145: mean loss = 2.871988e-08  learning rate = 0.00011018306
============================
Start of epoch 146
step 0: mean loss = 1.1509902e-08
step 100: mean loss = 1.5747835e-08
step 200: mean loss = 1.7561257e-08
step 300: mean loss = 1.8348302e-08
epoch 146: mean loss = 1.7907508e-08  learning rate = 0.00011018306
============================
Start of epoch 147
step 0: mean loss = 3.3700511e-09
step 100: mean loss = 2.3093246e-08
step 200: mean loss = 2.382305e-08
step 300: mean loss = 2.6083592e-08
epoch 147: mean loss = 2.5781748e-08  learning rate = 0.00011018306
============================
Start of epoch 148
step 0: mean loss = 9.829684e-09
step 100: mean loss = 1.1317985e-08
step 200: mean loss = 1.6709784e-08
step 300: mean loss = 1.720487e-08
epoch 148: mean loss = 1.6797992e-08  learning rate = 0.00011018306
============================
Start of epoch 149
step 0: mean loss = 3.3599923e-09
step 100: mean loss = 2.4284706e-08
step 200: mean loss = 2.0518954e-08
step 300: mean loss = 2.4892529e-08
epoch 149: mean loss = 2.4283997e-08  learning rate = 0.00011018306
============================
Start of epoch 150
step 0: mean loss = 5.7156946e-09
step 100: mean loss = 1.827405e-08
step 200: mean loss = 2.5348356e-08
step 300: mean loss = 2.1859801e-08
epoch 150: mean loss = 2.1323146e-08  learning rate = 0.00011018306
============================
Start of epoch 151
step 0: mean loss = 3.5192926e-09
step 100: mean loss = 2.1809134e-08
step 200: mean loss = 2.3390616e-08
step 300: mean loss = 2.4248125e-08
epoch 151: mean loss = 2.3641864e-08  learning rate = 0.00011018306
============================
Start of epoch 152
step 0: mean loss = 3.3049872e-09
step 100: mean loss = 2.713459e-08
step 200: mean loss = 2.020932e-08
step 300: mean loss = 2.636761e-08
epoch 152: mean loss = 2.5821402e-08  learning rate = 0.00011018306
============================
Start of epoch 153
step 0: mean loss = 3.2974397e-09
step 100: mean loss = 1.614191e-08
step 200: mean loss = 1.403727e-08
step 300: mean loss = 2.0566114e-08
epoch 153: mean loss = 2.0315062e-08  learning rate = 0.00011018306
============================
Start of epoch 154
step 0: mean loss = 1.1961268e-08
step 100: mean loss = 2.1322702e-08
step 200: mean loss = 1.5172292e-08
step 300: mean loss = 2.3533554e-08
epoch 154: mean loss = 2.3324509e-08  learning rate = 0.00011018306
============================
Start of epoch 155
step 0: mean loss = 3.150428e-09
step 100: mean loss = 4.074884e-09
step 200: mean loss = 1.4875742e-08
step 300: mean loss = 1.6474274e-08
epoch 155: mean loss = 1.7061268e-08  learning rate = 0.00011018306
============================
Start of epoch 156
step 0: mean loss = 1.7294391e-07
step 100: mean loss = 3.4465845e-08
step 200: mean loss = 2.338215e-08
step 300: mean loss = 2.353351e-08
epoch 156: mean loss = 2.3491461e-08  learning rate = 0.00011018306
============================
Start of epoch 157
step 0: mean loss = 5.3773128e-08
step 100: mean loss = 3.134902e-08
step 200: mean loss = 2.2236366e-08
step 300: mean loss = 2.1868347e-08
epoch 157: mean loss = 2.1326699e-08  learning rate = 0.00011018306
============================
Start of epoch 158
step 0: mean loss = 3.3842134e-09
step 100: mean loss = 2.3002862e-08
step 200: mean loss = 2.5027514e-08
step 300: mean loss = 2.2980789e-08
epoch 158: mean loss = 2.2692948e-08  learning rate = 0.00011018306
============================
Start of epoch 159
step 0: mean loss = 2.903184e-08
step 100: mean loss = 1.707456e-08
step 200: mean loss = 2.1962885e-08
step 300: mean loss = 2.1983583e-08
epoch 159: mean loss = 2.1457216e-08  learning rate = 0.00011018306
============================
Start of epoch 160
step 0: mean loss = 3.4317378e-09
step 100: mean loss = 2.1175659e-08
step 200: mean loss = 1.8918028e-08
step 300: mean loss = 2.1269829e-08
epoch 160: mean loss = 2.0744656e-08  learning rate = 0.00011018306
============================
Start of epoch 161
step 0: mean loss = 3.3638308e-09
step 100: mean loss = 2.956032e-08
step 200: mean loss = 2.0652896e-08
step 300: mean loss = 2.413357e-08
epoch 161: mean loss = 2.3522182e-08  learning rate = 0.00011018306
============================
Start of epoch 162
step 0: mean loss = 3.038086e-09
step 100: mean loss = 3.2024996e-08
step 200: mean loss = 2.5757599e-08
step 300: mean loss = 2.7102036e-08
epoch 162: mean loss = 2.6857684e-08  learning rate = 0.00011018306
============================
Start of epoch 163
step 0: mean loss = 6.815298e-09
step 100: mean loss = 3.884382e-09
step 200: mean loss = 1.991553e-08
step 300: mean loss = 1.6052061e-08
epoch 163: mean loss = 1.5674107e-08  learning rate = 0.00011018306
============================
Start of epoch 164
step 0: mean loss = 3.0364151e-09
step 100: mean loss = 3.6283772e-08
step 200: mean loss = 2.8024601e-08
step 300: mean loss = 2.9292272e-08
epoch 164: mean loss = 2.9596876e-08  learning rate = 0.00011018306
============================
Start of epoch 165
step 0: mean loss = 2.1199362e-08
step 100: mean loss = 8.714147e-09
step 200: mean loss = 1.4705069e-08
step 300: mean loss = 2.4172198e-08
epoch 165: mean loss = 2.3572415e-08  learning rate = 0.00011018306
============================
Start of epoch 166
step 0: mean loss = 3.5081198e-09
step 100: mean loss = 6.6898727e-09
step 200: mean loss = 1.5482838e-08
step 300: mean loss = 1.8465194e-08
epoch 166: mean loss = 1.8401568e-08  learning rate = 0.00011018306
============================
Start of epoch 167
step 0: mean loss = 1.4213622e-08
step 100: mean loss = 2.612836e-08
step 200: mean loss = 1.5864538e-08
step 300: mean loss = 2.289216e-08
epoch 167: mean loss = 2.2713914e-08  learning rate = 0.00011018306
============================
Start of epoch 168
step 0: mean loss = 1.1381461e-08
step 100: mean loss = 1.2483098e-08
step 200: mean loss = 2.0360448e-08
step 300: mean loss = 2.1102752e-08
epoch 168: mean loss = 2.0741016e-08  learning rate = 0.00011018306
============================
Start of epoch 169
step 0: mean loss = 6.116437e-09
step 100: mean loss = 2.6957332e-08
step 200: mean loss = 2.3681432e-08
step 300: mean loss = 2.5920686e-08
epoch 169: mean loss = 2.5615678e-08  learning rate = 0.00011018306
============================
Start of epoch 170
step 0: mean loss = 6.7011143e-09
step 100: mean loss = 3.6178638e-09
step 200: mean loss = 1.680992e-08
step 300: mean loss = 2.0029363e-08
epoch 170: mean loss = 1.953704e-08  learning rate = 0.00011018306
============================
Start of epoch 171
step 0: mean loss = 3.0269092e-09
step 100: mean loss = 2.449989e-08
step 200: mean loss = 1.9470688e-08
step 300: mean loss = 2.215682e-08
epoch 171: mean loss = 2.1625612e-08  learning rate = 0.00011018306
============================
Start of epoch 172
step 0: mean loss = 3.845111e-09
step 100: mean loss = 1.9274179e-08
step 200: mean loss = 2.2323048e-08
step 300: mean loss = 2.381571e-08
epoch 172: mean loss = 2.3626484e-08  learning rate = 0.00011018306
============================
Start of epoch 173
step 0: mean loss = 1.853461e-08
step 100: mean loss = 2.1357776e-08
step 200: mean loss = 2.0018344e-08
step 300: mean loss = 1.9184299e-08
epoch 173: mean loss = 1.8738334e-08  learning rate = 0.00011018306
============================
Start of epoch 174
step 0: mean loss = 3.6538967e-09
step 100: mean loss = 2.9565554e-08
step 200: mean loss = 2.693231e-08
step 300: mean loss = 2.426129e-08
epoch 174: mean loss = 2.3963963e-08  learning rate = 0.00011018306
============================
Start of epoch 175
step 0: mean loss = 7.326312e-09
step 100: mean loss = 2.6165068e-08
step 200: mean loss = 1.4783002e-08
step 300: mean loss = 2.2202771e-08
epoch 175: mean loss = 2.167037e-08  learning rate = 0.00011018306
============================
Start of epoch 176
step 0: mean loss = 5.1099303e-09
step 100: mean loss = 2.2676197e-08
step 200: mean loss = 2.4859146e-08
step 300: mean loss = 1.7645057e-08
epoch 176: mean loss = 1.7219536e-08  learning rate = 0.000104673905
============================
Start of epoch 177
step 0: mean loss = 2.992989e-09
step 100: mean loss = 1.3588515e-08
step 200: mean loss = 1.4235265e-08
step 300: mean loss = 1.6575163e-08
epoch 177: mean loss = 1.6837737e-08  learning rate = 0.000104673905
============================
Start of epoch 178
step 0: mean loss = 9.166868e-08
step 100: mean loss = 3.1645367e-08
step 200: mean loss = 1.763783e-08
step 300: mean loss = 2.2408058e-08
epoch 178: mean loss = 2.3631692e-08  learning rate = 0.000104673905
============================
Start of epoch 179
step 0: mean loss = 3.132082e-08
step 100: mean loss = 1.0095025e-08
step 200: mean loss = 2.355015e-08
step 300: mean loss = 1.7520073e-08
epoch 179: mean loss = 1.7101979e-08  learning rate = 0.000104673905
============================
Start of epoch 180
step 0: mean loss = 3.3205418e-09
step 100: mean loss = 1.7754076e-08
step 200: mean loss = 2.1162569e-08
step 300: mean loss = 2.2001913e-08
epoch 180: mean loss = 2.1648951e-08  learning rate = 0.000104673905
============================
Start of epoch 181
step 0: mean loss = 6.930079e-09
step 100: mean loss = 1.6527881e-08
step 200: mean loss = 1.7454626e-08
step 300: mean loss = 1.9799488e-08
epoch 181: mean loss = 1.9359677e-08  learning rate = 0.000104673905
============================
Start of epoch 182
step 0: mean loss = 6.9602497e-09
step 100: mean loss = 1.596291e-08
step 200: mean loss = 2.1285999e-08
step 300: mean loss = 1.7430242e-08
epoch 182: mean loss = 2.3213026e-08  learning rate = 0.000104673905
============================
Start of epoch 183
step 0: mean loss = 4.8788532e-08
step 100: mean loss = 1.2942186e-08
step 200: mean loss = 1.6758467e-08
step 300: mean loss = 1.940709e-08
epoch 183: mean loss = 1.903393e-08  learning rate = 0.000104673905
============================
Start of epoch 184
step 0: mean loss = 6.01296e-09
step 100: mean loss = 2.493234e-08
step 200: mean loss = 2.210343e-08
step 300: mean loss = 1.6518733e-08
epoch 184: mean loss = 1.6666688e-08  learning rate = 0.000104673905
============================
Start of epoch 185
step 0: mean loss = 8.705618e-08
step 100: mean loss = 2.7455346e-08
step 200: mean loss = 2.1550152e-08
step 300: mean loss = 2.3092632e-08
epoch 185: mean loss = 2.2509589e-08  learning rate = 0.000104673905
============================
Start of epoch 186
step 0: mean loss = 2.9983445e-09
step 100: mean loss = 2.0210866e-08
step 200: mean loss = 2.3975273e-08
step 300: mean loss = 2.1012022e-08
epoch 186: mean loss = 2.1625436e-08  learning rate = 0.000104673905
============================
Start of epoch 187
step 0: mean loss = 1.0449119e-08
step 100: mean loss = 1.885452e-08
step 200: mean loss = 2.0714113e-08
step 300: mean loss = 1.690543e-08
epoch 187: mean loss = 1.6542065e-08  learning rate = 0.000104673905
============================
Start of epoch 188
step 0: mean loss = 6.1530225e-09
step 100: mean loss = 3.1049414e-08
step 200: mean loss = 2.3374204e-08
step 300: mean loss = 2.185621e-08
epoch 188: mean loss = 2.1335385e-08  learning rate = 0.000104673905
============================
Start of epoch 189
step 0: mean loss = 3.6167205e-09
step 100: mean loss = 2.7774865e-08
step 200: mean loss = 1.7161462e-08
step 300: mean loss = 2.0844146e-08
epoch 189: mean loss = 2.0330889e-08  learning rate = 0.000104673905
============================
Start of epoch 190
step 0: mean loss = 3.282216e-09
step 100: mean loss = 1.753296e-08
step 200: mean loss = 2.067007e-08
step 300: mean loss = 2.2905228e-08
epoch 190: mean loss = 2.2338375e-08  learning rate = 0.000104673905
============================
Start of epoch 191
step 0: mean loss = 3.4253946e-09
step 100: mean loss = 2.5050289e-08
step 200: mean loss = 1.418109e-08
step 300: mean loss = 1.9542712e-08
epoch 191: mean loss = 1.9213736e-08  learning rate = 0.000104673905
============================
Start of epoch 192
step 0: mean loss = 1.7718257e-08
step 100: mean loss = 1.0047841e-08
step 200: mean loss = 2.108665e-08
step 300: mean loss = 2.2670454e-08
epoch 192: mean loss = 2.277832e-08  learning rate = 0.000104673905
============================
Start of epoch 193
step 0: mean loss = 8.541697e-09
step 100: mean loss = 4.699884e-09
step 200: mean loss = 2.0986358e-08
step 300: mean loss = 1.6768318e-08
epoch 193: mean loss = 1.6367373e-08  learning rate = 0.000104673905
============================
Start of epoch 194
step 0: mean loss = 2.987731e-09
step 100: mean loss = 2.3438185e-08
step 200: mean loss = 1.9180954e-08
step 300: mean loss = 2.0167267e-08
epoch 194: mean loss = 1.9667434e-08  learning rate = 0.000104673905
============================
Start of epoch 195
step 0: mean loss = 2.9407425e-09
step 100: mean loss = 2.6559695e-08
step 200: mean loss = 2.1873882e-08
step 300: mean loss = 2.1303997e-08
epoch 195: mean loss = 2.0798582e-08  learning rate = 0.000104673905
============================
Start of epoch 196
step 0: mean loss = 5.1050852e-09
step 100: mean loss = 3.009745e-08
step 200: mean loss = 2.35374e-08
step 300: mean loss = 2.2453928e-08
epoch 196: mean loss = 2.3028543e-08  learning rate = 0.000104673905
============================
Start of epoch 197
step 0: mean loss = 3.8019472e-08
step 100: mean loss = 1.85351e-08
step 200: mean loss = 1.9474465e-08
step 300: mean loss = 1.6521955e-08
epoch 197: mean loss = 1.6127531e-08  learning rate = 0.000104673905
============================
Start of epoch 198
step 0: mean loss = 2.9251401e-09
step 100: mean loss = 3.8423522e-08
step 200: mean loss = 2.4256796e-08
step 300: mean loss = 2.4411813e-08
epoch 198: mean loss = 2.3885942e-08  learning rate = 0.000104673905
============================
Start of epoch 199
step 0: mean loss = 3.8940398e-09
step 100: mean loss = 1.2158411e-08
step 200: mean loss = 1.6137264e-08
step 300: mean loss = 1.8501515e-08
epoch 199: mean loss = 1.815517e-08  learning rate = 0.000104673905
============================
Start of epoch 200
step 0: mean loss = 4.1718136e-09
step 100: mean loss = 2.2213595e-08
step 200: mean loss = 1.8966364e-08
step 300: mean loss = 2.2583043e-08
epoch 200: mean loss = 2.2027358e-08  learning rate = 0.000104673905
============================
Start of epoch 201
step 0: mean loss = 3.0077545e-09
step 100: mean loss = 9.866015e-09
step 200: mean loss = 1.6632969e-08
step 300: mean loss = 1.7315127e-08
epoch 201: mean loss = 1.6902206e-08  learning rate = 0.000104673905
============================
Start of epoch 202
step 0: mean loss = 3.0210325e-09
step 100: mean loss = 2.4726322e-08
step 200: mean loss = 2.2377497e-08
step 300: mean loss = 2.277747e-08
epoch 202: mean loss = 2.228584e-08  learning rate = 0.000104673905
============================
Start of epoch 203
step 0: mean loss = 3.144238e-09
step 100: mean loss = 9.804469e-09
step 200: mean loss = 1.6540262e-08
step 300: mean loss = 1.7252512e-08
epoch 203: mean loss = 1.6855417e-08  learning rate = 0.000104673905
============================
Start of epoch 204
step 0: mean loss = 3.5833034e-09
step 100: mean loss = 2.0376925e-08
step 200: mean loss = 1.9198323e-08
step 300: mean loss = 2.2583656e-08
epoch 204: mean loss = 2.2086017e-08  learning rate = 0.000104673905
============================
Start of epoch 205
step 0: mean loss = 5.394553e-09
step 100: mean loss = 2.4224713e-08
step 200: mean loss = 2.2660286e-08
step 300: mean loss = 2.0778765e-08
epoch 205: mean loss = 2.1078337e-08  learning rate = 0.000104673905
============================
Start of epoch 206
step 0: mean loss = 3.3999115e-08
step 100: mean loss = 1.9003892e-08
step 200: mean loss = 2.0536381e-08
step 300: mean loss = 1.9771239e-08
epoch 206: mean loss = 1.9318126e-08  learning rate = 0.000104673905
============================
Start of epoch 207
step 0: mean loss = 4.226923e-09
step 100: mean loss = 2.4210001e-08
step 200: mean loss = 1.8364863e-08
step 300: mean loss = 2.074077e-08
epoch 207: mean loss = 2.025207e-08  learning rate = 0.000104673905
============================
Start of epoch 208
step 0: mean loss = 4.0941845e-09
step 100: mean loss = 9.820631e-09
step 200: mean loss = 1.8334447e-08
step 300: mean loss = 1.9958168e-08
epoch 208: mean loss = 1.9923425e-08  learning rate = 0.000104673905
============================
Start of epoch 209
step 0: mean loss = 2.0855426e-08
step 100: mean loss = 1.37100304e-08
step 200: mean loss = 1.8935701e-08
step 300: mean loss = 1.875702e-08
epoch 209: mean loss = 1.8330597e-08  learning rate = 0.000104673905
============================
Start of epoch 210
step 0: mean loss = 5.556217e-09
step 100: mean loss = 1.8634388e-08
step 200: mean loss = 2.3966798e-08
step 300: mean loss = 2.0867233e-08
epoch 210: mean loss = 2.0347423e-08  learning rate = 0.000104673905
============================
Start of epoch 211
step 0: mean loss = 3.0013876e-09
step 100: mean loss = 2.4571893e-08
step 200: mean loss = 2.111651e-08
step 300: mean loss = 2.239407e-08
epoch 211: mean loss = 2.1840915e-08  learning rate = 0.000104673905
============================
Start of epoch 212
step 0: mean loss = 2.9243155e-09
step 100: mean loss = 1.016544e-08
step 200: mean loss = 2.013509e-08
step 300: mean loss = 2.0597211e-08
epoch 212: mean loss = 2.0127324e-08  learning rate = 0.000104673905
============================
Start of epoch 213
step 0: mean loss = 2.8926572e-09
step 100: mean loss = 2.439123e-08
step 200: mean loss = 1.9872097e-08
step 300: mean loss = 2.1134358e-08
epoch 213: mean loss = 2.069328e-08  learning rate = 0.000104673905
============================
Start of epoch 214
step 0: mean loss = 3.3945526e-09
step 100: mean loss = 1.6356813e-08
step 200: mean loss = 1.6986219e-08
step 300: mean loss = 1.9588956e-08
epoch 214: mean loss = 1.9152653e-08  learning rate = 0.000104673905
============================
Start of epoch 215
step 0: mean loss = 3.2283418e-09
step 100: mean loss = 1.8969539e-08
step 200: mean loss = 2.4753527e-08
step 300: mean loss = 1.7819902e-08
epoch 215: mean loss = 2.0608379e-08  learning rate = 0.000104673905
============================
Start of epoch 216
step 0: mean loss = 6.159959e-08
step 100: mean loss = 2.644932e-08
step 200: mean loss = 1.6897392e-08
step 300: mean loss = 1.7085267e-08
epoch 216: mean loss = 1.7112047e-08  learning rate = 0.000104673905
============================
Start of epoch 217
step 0: mean loss = 4.3367095e-08
step 100: mean loss = 1.3175586e-08
step 200: mean loss = 1.43914365e-08
step 300: mean loss = 1.6376323e-08
epoch 217: mean loss = 1.6102861e-08  learning rate = 9.944021e-05
============================
Start of epoch 218
step 0: mean loss = 6.1035275e-09
step 100: mean loss = 2.4754296e-08
step 200: mean loss = 1.5832944e-08
step 300: mean loss = 1.6848e-08
epoch 218: mean loss = 1.6442591e-08  learning rate = 9.944021e-05
============================
Start of epoch 219
step 0: mean loss = 2.891977e-09
step 100: mean loss = 2.9699272e-08
step 200: mean loss = 1.704351e-08
step 300: mean loss = 1.9544082e-08
epoch 219: mean loss = 1.942494e-08  learning rate = 9.944021e-05
============================
Start of epoch 220
step 0: mean loss = 5.863102e-08
step 100: mean loss = 2.2685667e-08
step 200: mean loss = 2.1259027e-08
step 300: mean loss = 1.825959e-08
epoch 220: mean loss = 1.7834171e-08  learning rate = 9.944021e-05
============================
Start of epoch 221
step 0: mean loss = 3.7222285e-09
step 100: mean loss = 2.2472436e-08
step 200: mean loss = 1.9515301e-08
step 300: mean loss = 1.9874307e-08
epoch 221: mean loss = 1.9381757e-08  learning rate = 9.944021e-05
============================
Start of epoch 222
step 0: mean loss = 2.8681697e-09
step 100: mean loss = 1.4939703e-08
step 200: mean loss = 1.694548e-08
step 300: mean loss = 1.7794816e-08
epoch 222: mean loss = 1.739381e-08  learning rate = 9.944021e-05
============================
Start of epoch 223
step 0: mean loss = 3.928831e-09
step 100: mean loss = 3.081381e-08
step 200: mean loss = 2.1972847e-08
step 300: mean loss = 1.9509825e-08
epoch 223: mean loss = 1.9225881e-08  learning rate = 9.944021e-05
============================
Start of epoch 224
step 0: mean loss = 9.030701e-09
step 100: mean loss = 2.0274118e-08
step 200: mean loss = 1.7804897e-08
step 300: mean loss = 1.7296506e-08
epoch 224: mean loss = 1.6882122e-08  learning rate = 9.944021e-05
============================
Start of epoch 225
step 0: mean loss = 2.9365885e-09
step 100: mean loss = 2.5620137e-08
step 200: mean loss = 2.0823318e-08
step 300: mean loss = 1.9830397e-08
epoch 225: mean loss = 1.9348521e-08  learning rate = 9.944021e-05
============================
Start of epoch 226
step 0: mean loss = 3.4333894e-09
step 100: mean loss = 2.2666976e-08
step 200: mean loss = 2.093065e-08
step 300: mean loss = 1.9564458e-08
epoch 226: mean loss = 2.0639229e-08  learning rate = 9.944021e-05
============================
Start of epoch 227
step 0: mean loss = 1.4697894e-08
step 100: mean loss = 5.9812306e-09
step 200: mean loss = 1.3963909e-08
step 300: mean loss = 1.4897081e-08
epoch 227: mean loss = 1.4553313e-08  learning rate = 9.944021e-05
============================
Start of epoch 228
step 0: mean loss = 3.1648222e-09
step 100: mean loss = 2.6320883e-08
step 200: mean loss = 2.4347552e-08
step 300: mean loss = 2.2352395e-08
epoch 228: mean loss = 2.1972744e-08  learning rate = 9.944021e-05
============================
Start of epoch 229
step 0: mean loss = 9.2920445e-09
step 100: mean loss = 1.312769e-08
step 200: mean loss = 1.7448434e-08
step 300: mean loss = 1.8990892e-08
epoch 229: mean loss = 1.871829e-08  learning rate = 9.944021e-05
============================
Start of epoch 230
step 0: mean loss = 4.6850688e-09
step 100: mean loss = 9.881292e-09
step 200: mean loss = 1.1417324e-08
step 300: mean loss = 1.6778085e-08
epoch 230: mean loss = 1.6839602e-08  learning rate = 9.944021e-05
============================
Start of epoch 231
step 0: mean loss = 3.6859484e-09
step 100: mean loss = 1.7785391e-08
step 200: mean loss = 1.6058292e-08
step 300: mean loss = 1.7507704e-08
epoch 231: mean loss = 1.7084334e-08  learning rate = 9.944021e-05
============================
Start of epoch 232
step 0: mean loss = 2.9287124e-09
step 100: mean loss = 2.2371188e-08
step 200: mean loss = 1.8535598e-08
step 300: mean loss = 1.852439e-08
epoch 232: mean loss = 1.8089287e-08  learning rate = 9.944021e-05
============================
Start of epoch 233
step 0: mean loss = 3.3996994e-09
step 100: mean loss = 1.42597605e-08
step 200: mean loss = 1.5732544e-08
step 300: mean loss = 2.0319906e-08
epoch 233: mean loss = 1.9989171e-08  learning rate = 9.944021e-05
============================
Start of epoch 234
step 0: mean loss = 7.088291e-09
step 100: mean loss = 9.15174e-09
step 200: mean loss = 1.7701561e-08
step 300: mean loss = 1.7830326e-08
epoch 234: mean loss = 1.7396342e-08  learning rate = 9.944021e-05
============================
Start of epoch 235
step 0: mean loss = 2.8450737e-09
step 100: mean loss = 2.7391112e-08
step 200: mean loss = 1.7987752e-08
step 300: mean loss = 1.7717767e-08
epoch 235: mean loss = 1.7379946e-08  learning rate = 9.944021e-05
============================
Start of epoch 236
step 0: mean loss = 9.88965e-09
step 100: mean loss = 2.2686267e-08
step 200: mean loss = 2.0783357e-08
step 300: mean loss = 2.07063e-08
epoch 236: mean loss = 2.0199868e-08  learning rate = 9.944021e-05
============================
Start of epoch 237
step 0: mean loss = 3.030144e-09
step 100: mean loss = 2.267575e-08
step 200: mean loss = 1.4763146e-08
step 300: mean loss = 1.8612516e-08
epoch 237: mean loss = 1.815476e-08  learning rate = 9.944021e-05
============================
Start of epoch 238
step 0: mean loss = 2.8465683e-09
step 100: mean loss = 2.6626104e-08
step 200: mean loss = 1.4874815e-08
step 300: mean loss = 1.794086e-08
epoch 238: mean loss = 1.751192e-08  learning rate = 9.944021e-05
============================
Start of epoch 239
step 0: mean loss = 3.428115e-09
step 100: mean loss = 2.1508209e-08
step 200: mean loss = 1.5814912e-08
step 300: mean loss = 1.7646265e-08
epoch 239: mean loss = 1.8403549e-08  learning rate = 9.944021e-05
============================
Start of epoch 240
step 0: mean loss = 3.784859e-08
step 100: mean loss = 1.8367839e-08
step 200: mean loss = 1.4083059e-08
step 300: mean loss = 1.876688e-08
epoch 240: mean loss = 1.9923641e-08  learning rate = 9.944021e-05
============================
Start of epoch 241
step 0: mean loss = 6.769915e-09
step 100: mean loss = 5.585981e-09
step 200: mean loss = 1.715279e-08
step 300: mean loss = 1.804724e-08
epoch 241: mean loss = 1.851323e-08  learning rate = 9.944021e-05
============================
Start of epoch 242
step 0: mean loss = 1.8966306e-08
step 100: mean loss = 9.515601e-09
step 200: mean loss = 1.5025705e-08
step 300: mean loss = 1.3288228e-08
epoch 242: mean loss = 1.5402149e-08  learning rate = 9.944021e-05
============================
Start of epoch 243
step 0: mean loss = 2.2906562e-07
step 100: mean loss = 2.1959483e-08
step 200: mean loss = 1.5367366e-08
step 300: mean loss = 1.8399682e-08
epoch 243: mean loss = 1.7953365e-08  learning rate = 9.944021e-05
============================
Start of epoch 244
step 0: mean loss = 3.6774293e-09
step 100: mean loss = 2.0233955e-08
step 200: mean loss = 2.0285379e-08
step 300: mean loss = 2.166676e-08
epoch 244: mean loss = 2.1226581e-08  learning rate = 9.944021e-05
============================
Start of epoch 245
step 0: mean loss = 4.7518967e-09
step 100: mean loss = 1.679365e-08
step 200: mean loss = 1.7969706e-08
step 300: mean loss = 1.7647256e-08
epoch 245: mean loss = 1.7346826e-08  learning rate = 9.944021e-05
============================
Start of epoch 246
step 0: mean loss = 4.430813e-09
step 100: mean loss = 1.8342606e-08
step 200: mean loss = 1.6484384e-08
step 300: mean loss = 1.5788933e-08
epoch 246: mean loss = 1.5432327e-08  learning rate = 9.944021e-05
============================
Start of epoch 247
step 0: mean loss = 5.5195675e-09
step 100: mean loss = 2.5625095e-08
step 200: mean loss = 2.1417325e-08
step 300: mean loss = 2.0786729e-08
epoch 247: mean loss = 2.0291337e-08  learning rate = 9.944021e-05
============================
Start of epoch 248
step 0: mean loss = 3.1655483e-09
step 100: mean loss = 2.4179164e-08
step 200: mean loss = 1.3560244e-08
step 300: mean loss = 2.054399e-08
epoch 248: mean loss = 2.0029098e-08  learning rate = 9.944021e-05
============================
Start of epoch 249
step 0: mean loss = 2.8129836e-09
step 100: mean loss = 1.8239497e-08
step 200: mean loss = 1.9844292e-08
step 300: mean loss = 1.6596061e-08
epoch 249: mean loss = 1.6398744e-08  learning rate = 9.944021e-05
============================
Start of epoch 250
step 0: mean loss = 8.769174e-09
step 100: mean loss = 1.9406682e-08
step 200: mean loss = 1.9797673e-08
step 300: mean loss = 1.8455792e-08
epoch 250: mean loss = 1.8005482e-08  learning rate = 9.944021e-05
============================
Start of epoch 251
step 0: mean loss = 2.9952514e-09
step 100: mean loss = 1.9245773e-08
step 200: mean loss = 1.9048047e-08
step 300: mean loss = 2.2587338e-08
epoch 251: mean loss = 2.2014627e-08  learning rate = 9.944021e-05
============================
Start of epoch 252
step 0: mean loss = 2.843816e-09
step 100: mean loss = 3.9553716e-09
step 200: mean loss = 1.476303e-08
step 300: mean loss = 1.7576232e-08
epoch 252: mean loss = 1.812829e-08  learning rate = 9.944021e-05
============================
Start of epoch 253
step 0: mean loss = 1.8203929e-08
step 100: mean loss = 1.6750818e-08
step 200: mean loss = 1.29646125e-08
step 300: mean loss = 1.43453285e-08
epoch 253: mean loss = 1.401689e-08  learning rate = 9.944021e-05
============================
Start of epoch 254
step 0: mean loss = 3.615494e-09
step 100: mean loss = 1.8315228e-08
step 200: mean loss = 2.305932e-08
step 300: mean loss = 2.3088917e-08
epoch 254: mean loss = 2.2805823e-08  learning rate = 9.944021e-05
============================
Start of epoch 255
step 0: mean loss = 1.36027065e-08
step 100: mean loss = 1.4247828e-08
step 200: mean loss = 1.6250127e-08
step 300: mean loss = 1.5340586e-08
epoch 255: mean loss = 1.6624409e-08  learning rate = 9.944021e-05
============================
Start of epoch 256
step 0: mean loss = 3.0384655e-08
step 100: mean loss = 1.8690745e-08
step 200: mean loss = 1.8983107e-08
step 300: mean loss = 1.6173459e-08
epoch 256: mean loss = 1.5808167e-08  learning rate = 9.944021e-05
============================
Start of epoch 257
step 0: mean loss = 2.9416976e-09
step 100: mean loss = 2.3514236e-08
step 200: mean loss = 1.3280908e-08
step 300: mean loss = 1.4155969e-08
epoch 257: mean loss = 1.3832888e-08  learning rate = 9.446819e-05
============================
Start of epoch 258
step 0: mean loss = 2.9903264e-09
step 100: mean loss = 1.8747393e-08
step 200: mean loss = 1.584865e-08
step 300: mean loss = 1.6694488e-08
epoch 258: mean loss = 1.629239e-08  learning rate = 9.446819e-05
============================
Start of epoch 259
step 0: mean loss = 2.8703697e-09
step 100: mean loss = 1.7350693e-08
step 200: mean loss = 1.8100451e-08
step 300: mean loss = 1.7120877e-08
epoch 259: mean loss = 1.7357783e-08  learning rate = 9.446819e-05
============================
Start of epoch 260
step 0: mean loss = 6.5024284e-09
step 100: mean loss = 1.1885231e-08
step 200: mean loss = 1.4694962e-08
step 300: mean loss = 1.6577964e-08
epoch 260: mean loss = 1.7415665e-08  learning rate = 9.446819e-05
============================
Start of epoch 261
step 0: mean loss = 4.495683e-08
step 100: mean loss = 1.2381325e-08
step 200: mean loss = 1.515972e-08
step 300: mean loss = 1.8631393e-08
epoch 261: mean loss = 1.83657e-08  learning rate = 9.446819e-05
============================
Start of epoch 262
step 0: mean loss = 5.475043e-09
step 100: mean loss = 1.787919e-08
step 200: mean loss = 1.0729012e-08
step 300: mean loss = 1.4661046e-08
epoch 262: mean loss = 1.4316536e-08  learning rate = 9.446819e-05
============================
Start of epoch 263
step 0: mean loss = 2.778903e-09
step 100: mean loss = 1.4031342e-08
step 200: mean loss = 1.4708108e-08
step 300: mean loss = 1.7902682e-08
epoch 263: mean loss = 1.7477142e-08  learning rate = 9.446819e-05
============================
Start of epoch 264
step 0: mean loss = 3.0271077e-09
step 100: mean loss = 1.536728e-08
step 200: mean loss = 1.576231e-08
step 300: mean loss = 1.3856205e-08
epoch 264: mean loss = 1.3558855e-08  learning rate = 9.446819e-05
============================
Start of epoch 265
step 0: mean loss = 4.905397e-09
step 100: mean loss = 1.8093528e-08
step 200: mean loss = 1.7708073e-08
step 300: mean loss = 1.7363714e-08
epoch 265: mean loss = 1.6941044e-08  learning rate = 9.446819e-05
============================
Start of epoch 266
step 0: mean loss = 2.8107454e-09
step 100: mean loss = 1.927508e-08
step 200: mean loss = 2.0633863e-08
step 300: mean loss = 2.2303045e-08
epoch 266: mean loss = 2.2473168e-08  learning rate = 9.446819e-05
============================
Start of epoch 267
step 0: mean loss = 3.92302e-09
step 100: mean loss = 9.857254e-09
step 200: mean loss = 8.132431e-09
step 300: mean loss = 1.4011223e-08
epoch 267: mean loss = 1.3687517e-08  learning rate = 9.446819e-05
============================
Start of epoch 268
step 0: mean loss = 2.8468634e-09
step 100: mean loss = 1.737614e-08
step 200: mean loss = 1.8638342e-08
step 300: mean loss = 1.3827347e-08
epoch 268: mean loss = 1.7030391e-08  learning rate = 9.446819e-05
============================
Start of epoch 269
step 0: mean loss = 4.152174e-08
step 100: mean loss = 1.467471e-08
step 200: mean loss = 1.5351644e-08
step 300: mean loss = 1.7462908e-08
epoch 269: mean loss = 1.7045524e-08  learning rate = 9.446819e-05
============================
Start of epoch 270
step 0: mean loss = 3.0650005e-09
step 100: mean loss = 1.969728e-08
step 200: mean loss = 1.4710362e-08
step 300: mean loss = 1.5879046e-08
epoch 270: mean loss = 1.551943e-08  learning rate = 9.446819e-05
============================
Start of epoch 271
step 0: mean loss = 3.0032354e-09
step 100: mean loss = 1.777226e-08
step 200: mean loss = 1.5038811e-08
step 300: mean loss = 1.683365e-08
epoch 271: mean loss = 1.6449919e-08  learning rate = 9.446819e-05
============================
Start of epoch 272
step 0: mean loss = 5.140848e-09
step 100: mean loss = 1.0734733e-08
step 200: mean loss = 1.7331486e-08
step 300: mean loss = 1.6103725e-08
epoch 272: mean loss = 1.5718424e-08  learning rate = 9.446819e-05
============================
Start of epoch 273
step 0: mean loss = 2.9896468e-09
step 100: mean loss = 1.8004634e-08
step 200: mean loss = 1.8341476e-08
step 300: mean loss = 1.7018145e-08
epoch 273: mean loss = 1.6603225e-08  learning rate = 9.446819e-05
============================
Start of epoch 274
step 0: mean loss = 2.735287e-09
step 100: mean loss = 2.4390712e-08
step 200: mean loss = 1.9940662e-08
step 300: mean loss = 2.0293177e-08
epoch 274: mean loss = 1.9809223e-08  learning rate = 9.446819e-05
============================
Start of epoch 275
step 0: mean loss = 2.7346032e-09
step 100: mean loss = 1.2488474e-08
step 200: mean loss = 1.30163365e-08
step 300: mean loss = 1.6209535e-08
epoch 275: mean loss = 1.5818145e-08  learning rate = 9.446819e-05
============================
Start of epoch 276
step 0: mean loss = 2.7217002e-09
step 100: mean loss = 2.017638e-08
step 200: mean loss = 1.9302519e-08
step 300: mean loss = 1.4529266e-08
epoch 276: mean loss = 1.4396829e-08  learning rate = 9.446819e-05
============================
Start of epoch 277
step 0: mean loss = 3.3779553e-08
step 100: mean loss = 2.4575973e-08
step 200: mean loss = 2.1545299e-08
step 300: mean loss = 1.9016095e-08
epoch 277: mean loss = 1.8611292e-08  learning rate = 9.446819e-05
============================
Start of epoch 278
step 0: mean loss = 3.7091628e-09
step 100: mean loss = 1.38844465e-08
step 200: mean loss = 1.3546162e-08
step 300: mean loss = 1.5023353e-08
epoch 278: mean loss = 1.4716585e-08  learning rate = 9.446819e-05
============================
Start of epoch 279
step 0: mean loss = 5.592166e-09
step 100: mean loss = 2.1823038e-08
step 200: mean loss = 2.6883399e-08
step 300: mean loss = 1.895396e-08
epoch 279: mean loss = 1.8482368e-08  learning rate = 9.446819e-05
============================
Start of epoch 280
step 0: mean loss = 2.7194467e-09
step 100: mean loss = 1.3516117e-08
step 200: mean loss = 1.6266275e-08
step 300: mean loss = 1.5535553e-08
epoch 280: mean loss = 1.5949333e-08  learning rate = 9.446819e-05
============================
Start of epoch 281
step 0: mean loss = 7.0618604e-08
step 100: mean loss = 1.09330625e-08
step 200: mean loss = 1.5985037e-08
step 300: mean loss = 1.6602227e-08
epoch 281: mean loss = 1.6199213e-08  learning rate = 9.446819e-05
============================
Start of epoch 282
step 0: mean loss = 2.7393896e-09
step 100: mean loss = 3.2369908e-08
step 200: mean loss = 1.7614363e-08
step 300: mean loss = 1.7007324e-08
epoch 282: mean loss = 1.703441e-08  learning rate = 9.446819e-05
============================
Start of epoch 283
step 0: mean loss = 5.158162e-08
step 100: mean loss = 1.3606985e-08
step 200: mean loss = 1.76984e-08
step 300: mean loss = 1.6834447e-08
epoch 283: mean loss = 1.642457e-08  learning rate = 9.446819e-05
============================
Start of epoch 284
step 0: mean loss = 2.7296883e-09
step 100: mean loss = 2.4466772e-08
step 200: mean loss = 1.7203217e-08
step 300: mean loss = 2.1932268e-08
epoch 284: mean loss = 2.1396819e-08  learning rate = 9.446819e-05
============================
Start of epoch 285
step 0: mean loss = 3.3510759e-09
step 100: mean loss = 1.4251979e-08
step 200: mean loss = 8.715937e-09
step 300: mean loss = 1.3649228e-08
epoch 285: mean loss = 1.3332335e-08  learning rate = 9.446819e-05
============================
Start of epoch 286
step 0: mean loss = 2.7187281e-09
step 100: mean loss = 1.4545931e-08
step 200: mean loss = 1.753812e-08
step 300: mean loss = 1.6383106e-08
epoch 286: mean loss = 1.6010112e-08  learning rate = 9.446819e-05
============================
Start of epoch 287
step 0: mean loss = 4.21524e-09
step 100: mean loss = 1.675735e-08
step 200: mean loss = 1.6527874e-08
step 300: mean loss = 1.6013896e-08
epoch 287: mean loss = 1.5670894e-08  learning rate = 9.446819e-05
============================
Start of epoch 288
step 0: mean loss = 8.676924e-09
step 100: mean loss = 1.7880966e-08
step 200: mean loss = 1.7440138e-08
step 300: mean loss = 1.8188453e-08
epoch 288: mean loss = 1.7739332e-08  learning rate = 9.446819e-05
============================
Start of epoch 289
step 0: mean loss = 2.6984832e-09
step 100: mean loss = 3.0960656e-08
step 200: mean loss = 1.747992e-08
step 300: mean loss = 1.644947e-08
epoch 289: mean loss = 1.6051086e-08  learning rate = 9.446819e-05
============================
Start of epoch 290
step 0: mean loss = 2.8027796e-09
step 100: mean loss = 2.5510385e-08
step 200: mean loss = 2.2001824e-08
step 300: mean loss = 2.2739226e-08
epoch 290: mean loss = 2.2243478e-08  learning rate = 9.446819e-05
============================
Start of epoch 291
step 0: mean loss = 4.183549e-09
step 100: mean loss = 2.9093727e-09
step 200: mean loss = 1.1846808e-08
step 300: mean loss = 1.3729629e-08
epoch 291: mean loss = 1.3413608e-08  learning rate = 9.446819e-05
============================
Start of epoch 292
step 0: mean loss = 2.7322913e-09
step 100: mean loss = 2.0029661e-08
step 200: mean loss = 1.8152095e-08
step 300: mean loss = 1.3170554e-08
epoch 292: mean loss = 1.371486e-08  learning rate = 9.446819e-05
============================
Start of epoch 293
step 0: mean loss = 1.3106846e-07
step 100: mean loss = 2.6207703e-08
step 200: mean loss = 2.324556e-08
step 300: mean loss = 2.143252e-08
epoch 293: mean loss = 2.125958e-08  learning rate = 9.446819e-05
============================
Start of epoch 294
step 0: mean loss = 3.108588e-09
step 100: mean loss = 1.3673339e-08
step 200: mean loss = 1.6819623e-08
step 300: mean loss = 1.6309155e-08
epoch 294: mean loss = 1.6716315e-08  learning rate = 9.446819e-05
============================
Start of epoch 295
step 0: mean loss = 4.603382e-09
step 100: mean loss = 1.1371705e-08
step 200: mean loss = 1.5691072e-08
step 300: mean loss = 1.5962748e-08
epoch 295: mean loss = 1.599124e-08  learning rate = 9.446819e-05
============================
Start of epoch 296
step 0: mean loss = 8.899092e-09
step 100: mean loss = 1.2513746e-08
step 200: mean loss = 1.8802867e-08
step 300: mean loss = 1.6416534e-08
epoch 296: mean loss = 1.7947874e-08  learning rate = 9.446819e-05
============================
Start of epoch 297
step 0: mean loss = 4.9753176e-08
step 100: mean loss = 5.818534e-09
step 200: mean loss = 1.197363e-08
step 300: mean loss = 1.0432881e-08
epoch 297: mean loss = 1.0207408e-08  learning rate = 8.974478e-05
============================
Start of epoch 298
step 0: mean loss = 2.670564e-09
step 100: mean loss = 1.2535851e-08
step 200: mean loss = 1.3085604e-08
step 300: mean loss = 1.6374523e-08
epoch 298: mean loss = 1.5991928e-08  learning rate = 8.974478e-05
============================
Start of epoch 299
step 0: mean loss = 3.026581e-09
step 100: mean loss = 1.496803e-08
step 200: mean loss = 1.6103089e-08
step 300: mean loss = 1.1772497e-08
epoch 299: mean loss = 1.1635993e-08  learning rate = 8.974478e-05
============================
Start of epoch 300
step 0: mean loss = 1.8810566e-08
step 100: mean loss = 2.0644375e-08
step 200: mean loss = 1.7946787e-08
step 300: mean loss = 1.846379e-08
epoch 300: mean loss = 1.800745e-08  learning rate = 8.974478e-05
============================
Start of epoch 301
step 0: mean loss = 2.7064915e-09
step 100: mean loss = 1.4313084e-08
step 200: mean loss = 1.37916425e-08
step 300: mean loss = 1.492852e-08
epoch 301: mean loss = 1.4587746e-08  learning rate = 8.974478e-05
============================
Start of epoch 302
step 0: mean loss = 3.2985292e-09
step 100: mean loss = 1.0133843e-08
step 200: mean loss = 1.4176067e-08
step 300: mean loss = 1.39574166e-08
epoch 302: mean loss = 1.5794361e-08  learning rate = 8.974478e-05
============================
Start of epoch 303
step 0: mean loss = 1.3132748e-07
step 100: mean loss = 9.3949675e-09
step 200: mean loss = 1.5289363e-08
step 300: mean loss = 1.5024941e-08
epoch 303: mean loss = 1.4743046e-08  learning rate = 8.974478e-05
============================
Start of epoch 304
step 0: mean loss = 2.7264269e-09
step 100: mean loss = 1.126024e-08
step 200: mean loss = 1.6638076e-08
step 300: mean loss = 1.444899e-08
epoch 304: mean loss = 1.4116159e-08  learning rate = 8.974478e-05
============================
Start of epoch 305
step 0: mean loss = 2.676262e-09
step 100: mean loss = 2.0013937e-08
step 200: mean loss = 1.41447085e-08
step 300: mean loss = 1.5320161e-08
epoch 305: mean loss = 1.6689947e-08  learning rate = 8.974478e-05
============================
Start of epoch 306
step 0: mean loss = 1.3256609e-08
step 100: mean loss = 1.7282993e-08
step 200: mean loss = 1.613338e-08
step 300: mean loss = 1.4876378e-08
epoch 306: mean loss = 1.4597082e-08  learning rate = 8.974478e-05
============================
Start of epoch 307
step 0: mean loss = 3.2598917e-09
step 100: mean loss = 1.532559e-08
step 200: mean loss = 1.8117161e-08
step 300: mean loss = 1.8008878e-08
epoch 307: mean loss = 1.7713912e-08  learning rate = 8.974478e-05
============================
Start of epoch 308
step 0: mean loss = 6.38753e-09
step 100: mean loss = 2.951403e-09
step 200: mean loss = 1.313605e-08
step 300: mean loss = 1.3632216e-08
epoch 308: mean loss = 1.33172104e-08  learning rate = 8.974478e-05
============================
Start of epoch 309
step 0: mean loss = 2.799739e-09
step 100: mean loss = 2.128924e-08
step 200: mean loss = 1.5903504e-08
step 300: mean loss = 1.48634625e-08
epoch 309: mean loss = 1.4529117e-08  learning rate = 8.974478e-05
============================
Start of epoch 310
step 0: mean loss = 3.91659e-09
step 100: mean loss = 1.9595385e-08
step 200: mean loss = 1.5035239e-08
step 300: mean loss = 1.497848e-08
epoch 310: mean loss = 1.4657827e-08  learning rate = 8.974478e-05
============================
Start of epoch 311
step 0: mean loss = 3.01215e-09
step 100: mean loss = 2.3729935e-08
step 200: mean loss = 1.9014738e-08
step 300: mean loss = 1.5596067e-08
epoch 311: mean loss = 1.8114177e-08  learning rate = 8.974478e-05
============================
Start of epoch 312
step 0: mean loss = 8.358578e-08
step 100: mean loss = 1.0365895e-08
step 200: mean loss = 1.3351469e-08
step 300: mean loss = 1.1353562e-08
epoch 312: mean loss = 1.1659901e-08  learning rate = 8.974478e-05
============================
Start of epoch 313
step 0: mean loss = 1.0100248e-07
step 100: mean loss = 2.0452154e-08
step 200: mean loss = 2.0115333e-08
step 300: mean loss = 1.8214994e-08
epoch 313: mean loss = 1.8515122e-08  learning rate = 8.974478e-05
============================
Start of epoch 314
step 0: mean loss = 1.5499518e-08
step 100: mean loss = 1.25277415e-08
step 200: mean loss = 1.3813529e-08
step 300: mean loss = 1.4317785e-08
epoch 314: mean loss = 1.5396887e-08  learning rate = 8.974478e-05
============================
Start of epoch 315
step 0: mean loss = 3.728769e-09
step 100: mean loss = 1.5481566e-08
step 200: mean loss = 1.4694998e-08
step 300: mean loss = 1.1362481e-08
epoch 315: mean loss = 1.3678794e-08  learning rate = 8.974478e-05
============================
Start of epoch 316
step 0: mean loss = 1.06295516e-07
step 100: mean loss = 1.4611095e-08
step 200: mean loss = 1.4666455e-08
step 300: mean loss = 1.4892991e-08
epoch 316: mean loss = 1.48248755e-08  learning rate = 8.974478e-05
============================
Start of epoch 317
step 0: mean loss = 5.89781e-09
step 100: mean loss = 1.2739264e-08
step 200: mean loss = 1.5192644e-08
step 300: mean loss = 1.3564312e-08
epoch 317: mean loss = 1.3661277e-08  learning rate = 8.974478e-05
============================
Start of epoch 318
step 0: mean loss = 4.4237282e-08
step 100: mean loss = 2.1609752e-08
step 200: mean loss = 1.819324e-08
step 300: mean loss = 1.7401893e-08
epoch 318: mean loss = 1.6972702e-08  learning rate = 8.974478e-05
============================
Start of epoch 319
step 0: mean loss = 2.629326e-09
step 100: mean loss = 1.0944441e-08
step 200: mean loss = 1.4402414e-08
step 300: mean loss = 1.4451446e-08
epoch 319: mean loss = 1.4126059e-08  learning rate = 8.974478e-05
============================
Start of epoch 320
step 0: mean loss = 3.667019e-09
step 100: mean loss = 1.510728e-08
step 200: mean loss = 1.547685e-08
step 300: mean loss = 1.7360247e-08
epoch 320: mean loss = 1.6944565e-08  learning rate = 8.974478e-05
============================
Start of epoch 321
step 0: mean loss = 2.6914357e-09
step 100: mean loss = 7.2096302e-09
step 200: mean loss = 1.3032356e-08
step 300: mean loss = 1.646183e-08
epoch 321: mean loss = 1.6108501e-08  learning rate = 8.974478e-05
============================
Start of epoch 322
step 0: mean loss = 3.7099048e-09
step 100: mean loss = 1.4698654e-08
step 200: mean loss = 9.013043e-09
step 300: mean loss = 1.3526256e-08
epoch 322: mean loss = 1.3214766e-08  learning rate = 8.974478e-05
============================
Start of epoch 323
step 0: mean loss = 2.8675329e-09
step 100: mean loss = 1.2813156e-08
step 200: mean loss = 1.5239081e-08
step 300: mean loss = 1.3632203e-08
epoch 323: mean loss = 1.5683533e-08  learning rate = 8.974478e-05
============================
Start of epoch 324
step 0: mean loss = 2.766207e-08
step 100: mean loss = 1.6117252e-08
step 200: mean loss = 1.7077861e-08
step 300: mean loss = 1.5342273e-08
epoch 324: mean loss = 1.5682943e-08  learning rate = 8.974478e-05
============================
Start of epoch 325
step 0: mean loss = 5.5739826e-09
step 100: mean loss = 1.4976964e-08
step 200: mean loss = 1.524842e-08
step 300: mean loss = 1.3436347e-08
epoch 325: mean loss = 1.6034928e-08  learning rate = 8.974478e-05
============================
Start of epoch 326
step 0: mean loss = 1.5064657e-08
step 100: mean loss = 6.9679778e-09
step 200: mean loss = 1.1415961e-08
step 300: mean loss = 1.29079e-08
epoch 326: mean loss = 1.26492035e-08  learning rate = 8.974478e-05
============================
Start of epoch 327
step 0: mean loss = 4.3902673e-09
step 100: mean loss = 1.6120264e-08
step 200: mean loss = 1.6680636e-08
step 300: mean loss = 1.4636567e-08
epoch 327: mean loss = 1.4348148e-08  learning rate = 8.974478e-05
============================
Start of epoch 328
step 0: mean loss = 5.8138845e-09
step 100: mean loss = 1.8231324e-08
step 200: mean loss = 1.4757206e-08
step 300: mean loss = 1.6993381e-08
epoch 328: mean loss = 1.6757154e-08  learning rate = 8.974478e-05
============================
Start of epoch 329
step 0: mean loss = 8.9613845e-09
step 100: mean loss = 1.5067902e-08
step 200: mean loss = 1.4964643e-08
step 300: mean loss = 1.4223773e-08
epoch 329: mean loss = 1.3898317e-08  learning rate = 8.974478e-05
============================
Start of epoch 330
step 0: mean loss = 2.7537226e-09
step 100: mean loss = 2.0873667e-08
step 200: mean loss = 1.7523883e-08
step 300: mean loss = 1.8131628e-08
epoch 330: mean loss = 1.7770562e-08  learning rate = 8.974478e-05
============================
Start of epoch 331
step 0: mean loss = 3.2960696e-09
step 100: mean loss = 8.069656e-09
step 200: mean loss = 1.2994142e-08
step 300: mean loss = 1.6180199e-08
epoch 331: mean loss = 1.6224496e-08  learning rate = 8.974478e-05
============================
Start of epoch 332
step 0: mean loss = 4.3352717e-09
step 100: mean loss = 1.319092e-08
step 200: mean loss = 8.51585e-09
step 300: mean loss = 1.117075e-08
epoch 332: mean loss = 1.0937707e-08  learning rate = 8.974478e-05
============================
Start of epoch 333
step 0: mean loss = 4.974382e-09
step 100: mean loss = 1.7300312e-08
step 200: mean loss = 1.778323e-08
step 300: mean loss = 1.642218e-08
epoch 333: mean loss = 1.6053374e-08  learning rate = 8.974478e-05
============================
Start of epoch 334
step 0: mean loss = 2.6172382e-09
step 100: mean loss = 1.5054482e-08
step 200: mean loss = 1.8169136e-08
step 300: mean loss = 1.6711668e-08
epoch 334: mean loss = 1.6504728e-08  learning rate = 8.974478e-05
============================
Start of epoch 335
step 0: mean loss = 9.736999e-09
step 100: mean loss = 1.1231115e-08
step 200: mean loss = 1.3522254e-08
step 300: mean loss = 1.3426372e-08
epoch 335: mean loss = 1.31722855e-08  learning rate = 8.974478e-05
============================
Start of epoch 336
step 0: mean loss = 1.11039045e-08
step 100: mean loss = 1.9169867e-08
step 200: mean loss = 1.956805e-08
step 300: mean loss = 1.8050054e-08
epoch 336: mean loss = 1.7642286e-08  learning rate = 8.974478e-05
============================
Start of epoch 337
step 0: mean loss = 2.609467e-09
step 100: mean loss = 1.4423941e-08
step 200: mean loss = 1.3924061e-08
step 300: mean loss = 1.5743966e-08
epoch 337: mean loss = 1.5381445e-08  learning rate = 8.974478e-05
============================
Start of epoch 338
step 0: mean loss = 2.7880287e-09
step 100: mean loss = 2.6182476e-09
step 200: mean loss = 7.250244e-09
step 300: mean loss = 1.0303286e-08
epoch 338: mean loss = 1.0131988e-08  learning rate = 8.525754e-05
============================
Start of epoch 339
step 0: mean loss = 3.4011225e-09
step 100: mean loss = 2.8238234e-09
step 200: mean loss = 1.2859069e-08
step 300: mean loss = 1.7739083e-08
epoch 339: mean loss = 1.7311981e-08  learning rate = 8.525754e-05
============================
Start of epoch 340
step 0: mean loss = 2.9051934e-09
step 100: mean loss = 2.5929927e-09
step 200: mean loss = 1.1069142e-08
step 300: mean loss = 8.432645e-09
epoch 340: mean loss = 1.0909298e-08  learning rate = 8.525754e-05
============================
Start of epoch 341
step 0: mean loss = 1.1821238e-07
step 100: mean loss = 8.732767e-09
step 200: mean loss = 1.23870105e-08
step 300: mean loss = 1.0956422e-08
epoch 341: mean loss = 1.2040217e-08  learning rate = 8.525754e-05
============================
Start of epoch 342
step 0: mean loss = 1.3195053e-07
step 100: mean loss = 1.9461998e-08
step 200: mean loss = 1.6143673e-08
step 300: mean loss = 1.378965e-08
epoch 342: mean loss = 1.3482932e-08  learning rate = 8.525754e-05
============================
Start of epoch 343
step 0: mean loss = 3.536427e-09
step 100: mean loss = 1.3404659e-08
step 200: mean loss = 1.7189917e-08
step 300: mean loss = 1.5885634e-08
epoch 343: mean loss = 1.6253056e-08  learning rate = 8.525754e-05
============================
Start of epoch 344
step 0: mean loss = 4.974879e-09
step 100: mean loss = 8.953757e-09
step 200: mean loss = 1.2011727e-08
step 300: mean loss = 1.2406284e-08
epoch 344: mean loss = 1.2720898e-08  learning rate = 8.525754e-05
============================
Start of epoch 345
step 0: mean loss = 2.6864754e-08
step 100: mean loss = 1.1391467e-08
step 200: mean loss = 1.2271349e-08
step 300: mean loss = 1.4195678e-08
epoch 345: mean loss = 1.3901826e-08  learning rate = 8.525754e-05
============================
Start of epoch 346
step 0: mean loss = 3.9229966e-09
step 100: mean loss = 1.47683865e-08
step 200: mean loss = 1.3092246e-08
step 300: mean loss = 1.47937955e-08
epoch 346: mean loss = 1.4441884e-08  learning rate = 8.525754e-05
============================
Start of epoch 347
step 0: mean loss = 2.6282343e-09
step 100: mean loss = 1.6634282e-08
step 200: mean loss = 1.5414653e-08
step 300: mean loss = 1.14337215e-08
epoch 347: mean loss = 1.413384e-08  learning rate = 8.525754e-05
============================
Start of epoch 348
step 0: mean loss = 1.2754579e-07
step 100: mean loss = 9.364809e-09
step 200: mean loss = 1.1850229e-08
step 300: mean loss = 1.26611255e-08
epoch 348: mean loss = 1.2368032e-08  learning rate = 8.525754e-05
============================
Start of epoch 349
step 0: mean loss = 2.5826037e-09
step 100: mean loss = 1.5705522e-08
step 200: mean loss = 1.4367056e-08
step 300: mean loss = 1.4260179e-08
epoch 349: mean loss = 1.3927682e-08  learning rate = 8.525754e-05
============================
Start of epoch 350
step 0: mean loss = 2.701705e-09
step 100: mean loss = 1.2378592e-08
step 200: mean loss = 1.2973689e-08
step 300: mean loss = 1.3585068e-08
epoch 350: mean loss = 1.4559282e-08  learning rate = 8.525754e-05
============================
Start of epoch 351
step 0: mean loss = 8.084406e-09
step 100: mean loss = 1.3352351e-08
step 200: mean loss = 1.2260728e-08
step 300: mean loss = 1.2994696e-08
epoch 351: mean loss = 1.3209884e-08  learning rate = 8.525754e-05
============================
Start of epoch 352
step 0: mean loss = 1.9737838e-08
step 100: mean loss = 1.0280542e-08
step 200: mean loss = 1.43498875e-08
step 300: mean loss = 1.2583868e-08
epoch 352: mean loss = 1.4127156e-08  learning rate = 8.525754e-05
============================
Start of epoch 353
step 0: mean loss = 6.9260584e-09
step 100: mean loss = 8.74494e-09
step 200: mean loss = 1.3544518e-08
step 300: mean loss = 1.5065481e-08
epoch 353: mean loss = 1.47774495e-08  learning rate = 8.525754e-05
============================
Start of epoch 354
step 0: mean loss = 3.1301346e-09
step 100: mean loss = 1.1997043e-08
step 200: mean loss = 1.1596737e-08
step 300: mean loss = 1.119623e-08
epoch 354: mean loss = 1.1673914e-08  learning rate = 8.525754e-05
============================
Start of epoch 355
step 0: mean loss = 6.520513e-08
step 100: mean loss = 1.870049e-08
step 200: mean loss = 1.4938324e-08
step 300: mean loss = 1.4508116e-08
epoch 355: mean loss = 1.4164001e-08  learning rate = 8.525754e-05
============================
Start of epoch 356
step 0: mean loss = 2.6678755e-09
step 100: mean loss = 1.6643538e-08
step 200: mean loss = 1.5005284e-08
step 300: mean loss = 1.3047667e-08
epoch 356: mean loss = 1.2746465e-08  learning rate = 8.525754e-05
============================
Start of epoch 357
step 0: mean loss = 2.6445128e-09
step 100: mean loss = 1.9637412e-08
step 200: mean loss = 1.6004876e-08
step 300: mean loss = 1.5077314e-08
epoch 357: mean loss = 1.4714001e-08  learning rate = 8.525754e-05
============================
Start of epoch 358
step 0: mean loss = 2.5719407e-09
step 100: mean loss = 1.9243316e-08
step 200: mean loss = 1.8082915e-08
step 300: mean loss = 1.3222747e-08
epoch 358: mean loss = 1.2913636e-08  learning rate = 8.525754e-05
============================
Start of epoch 359
step 0: mean loss = 2.733337e-09
step 100: mean loss = 2.6855236e-08
step 200: mean loss = 1.5095479e-08
step 300: mean loss = 1.570667e-08
epoch 359: mean loss = 1.5325266e-08  learning rate = 8.525754e-05
============================
Start of epoch 360
step 0: mean loss = 2.5247955e-09
step 100: mean loss = 1.3429214e-08
step 200: mean loss = 1.35844616e-08
step 300: mean loss = 1.4750218e-08
epoch 360: mean loss = 1.4400863e-08  learning rate = 8.525754e-05
============================
Start of epoch 361
step 0: mean loss = 2.5426445e-09
step 100: mean loss = 1.5582733e-08
step 200: mean loss = 1.6530146e-08
step 300: mean loss = 1.1955403e-08
epoch 361: mean loss = 1.3078035e-08  learning rate = 8.525754e-05
============================
Start of epoch 362
step 0: mean loss = 1.4749733e-07
step 100: mean loss = 1.417727e-08
step 200: mean loss = 1.7051391e-08
step 300: mean loss = 1.3407898e-08
epoch 362: mean loss = 1.309641e-08  learning rate = 8.525754e-05
============================
Start of epoch 363
step 0: mean loss = 3.2419671e-09
step 100: mean loss = 2.2339414e-08
step 200: mean loss = 1.4697027e-08
step 300: mean loss = 1.5514917e-08
epoch 363: mean loss = 1.5260374e-08  learning rate = 8.525754e-05
============================
Start of epoch 364
step 0: mean loss = 1.4851322e-08
step 100: mean loss = 9.076074e-09
step 200: mean loss = 1.370654e-08
step 300: mean loss = 1.2783618e-08
epoch 364: mean loss = 1.24946675e-08  learning rate = 8.525754e-05
============================
Start of epoch 365
step 0: mean loss = 3.7315058e-09
step 100: mean loss = 1.934223e-08
step 200: mean loss = 2.1034364e-08
step 300: mean loss = 1.9313788e-08
epoch 365: mean loss = 1.8883826e-08  learning rate = 8.525754e-05
============================
Start of epoch 366
step 0: mean loss = 2.8011327e-09
step 100: mean loss = 2.6733133e-09
step 200: mean loss = 9.5990975e-09
step 300: mean loss = 1.250687e-08
epoch 366: mean loss = 1.238076e-08  learning rate = 8.525754e-05
============================
Start of epoch 367
step 0: mean loss = 5.5122875e-09
step 100: mean loss = 1.4167625e-08
step 200: mean loss = 9.043499e-09
step 300: mean loss = 1.2088777e-08
epoch 367: mean loss = 1.3027345e-08  learning rate = 8.525754e-05
============================
Start of epoch 368
step 0: mean loss = 1.7183234e-08
step 100: mean loss = 1.2776736e-08
step 200: mean loss = 1.4603691e-08
step 300: mean loss = 1.5765853e-08
epoch 368: mean loss = 1.5434233e-08  learning rate = 8.525754e-05
============================
Start of epoch 369
step 0: mean loss = 2.7059068e-09
step 100: mean loss = 2.9959137e-09
step 200: mean loss = 9.201533e-09
step 300: mean loss = 1.2109248e-08
epoch 369: mean loss = 1.1842696e-08  learning rate = 8.525754e-05
============================
Start of epoch 370
step 0: mean loss = 3.7204644e-09
step 100: mean loss = 1.3949918e-08
step 200: mean loss = 1.7476635e-08
step 300: mean loss = 1.5189235e-08
epoch 370: mean loss = 1.5252887e-08  learning rate = 8.525754e-05
============================
Start of epoch 371
step 0: mean loss = 4.474819e-09
step 100: mean loss = 1.4936663e-08
step 200: mean loss = 9.615487e-09
step 300: mean loss = 1.2351468e-08
epoch 371: mean loss = 1.2146758e-08  learning rate = 8.525754e-05
============================
Start of epoch 372
step 0: mean loss = 2.5891322e-09
step 100: mean loss = 2.0996158e-08
step 200: mean loss = 1.2191602e-08
step 300: mean loss = 1.4533264e-08
epoch 372: mean loss = 1.419596e-08  learning rate = 8.525754e-05
============================
Start of epoch 373
step 0: mean loss = 3.6238545e-09
step 100: mean loss = 1.3221808e-08
step 200: mean loss = 1.3080299e-08
step 300: mean loss = 1.2689389e-08
epoch 373: mean loss = 1.2408642e-08  learning rate = 8.525754e-05
============================
Start of epoch 374
step 0: mean loss = 3.2274048e-09
step 100: mean loss = 1.7230466e-08
step 200: mean loss = 1.4199709e-08
step 300: mean loss = 1.5489265e-08
epoch 374: mean loss = 1.6570471e-08  learning rate = 8.525754e-05
============================
Start of epoch 375
step 0: mean loss = 4.9674025e-09
step 100: mean loss = 1.4225142e-08
step 200: mean loss = 8.930557e-09
step 300: mean loss = 1.2549165e-08
epoch 375: mean loss = 1.240874e-08  learning rate = 8.525754e-05
============================
Start of epoch 376
step 0: mean loss = 1.39874325e-08
step 100: mean loss = 1.3073517e-08
step 200: mean loss = 1.3072714e-08
step 300: mean loss = 1.3119446e-08
epoch 376: mean loss = 1.2884852e-08  learning rate = 8.525754e-05
============================
Start of epoch 377
step 0: mean loss = 9.004773e-09
step 100: mean loss = 1.0730182e-08
step 200: mean loss = 1.44940095e-08
step 300: mean loss = 1.3155421e-08
epoch 377: mean loss = 1.4384872e-08  learning rate = 8.525754e-05
============================
Start of epoch 378
step 0: mean loss = 1.765919e-07
step 100: mean loss = 1.4774682e-08
step 200: mean loss = 8.6608e-09
step 300: mean loss = 9.241217e-09
epoch 378: mean loss = 9.113235e-09  learning rate = 8.0994665e-05
============================
Start of epoch 379
step 0: mean loss = 9.796204e-09
step 100: mean loss = 1.29432705e-08
step 200: mean loss = 1.4849614e-08
step 300: mean loss = 1.2942894e-08
epoch 379: mean loss = 1.2640471e-08  learning rate = 8.0994665e-05
============================
Start of epoch 380
step 0: mean loss = 2.5510674e-09
step 100: mean loss = 1.4264271e-08
step 200: mean loss = 1.4977605e-08
step 300: mean loss = 1.4068868e-08
epoch 380: mean loss = 1.4146712e-08  learning rate = 8.0994665e-05
============================
Start of epoch 381
step 0: mean loss = 1.5368022e-08
step 100: mean loss = 1.21593535e-08
step 200: mean loss = 1.350533e-08
step 300: mean loss = 1.2203218e-08
epoch 381: mean loss = 1.1952931e-08  learning rate = 8.0994665e-05
============================
Start of epoch 382
step 0: mean loss = 3.0822072e-09
step 100: mean loss = 1.3140004e-08
step 200: mean loss = 1.1493508e-08
step 300: mean loss = 1.28529685e-08
epoch 382: mean loss = 1.25533814e-08  learning rate = 8.0994665e-05
============================
Start of epoch 383
step 0: mean loss = 2.4705593e-09
step 100: mean loss = 1.2878888e-08
step 200: mean loss = 1.4033074e-08
step 300: mean loss = 1.4265097e-08
epoch 383: mean loss = 1.4220915e-08  learning rate = 8.0994665e-05
============================
Start of epoch 384
step 0: mean loss = 5.755197e-09
step 100: mean loss = 1.14174314e-08
step 200: mean loss = 1.0471298e-08
step 300: mean loss = 1.05282725e-08
epoch 384: mean loss = 1.03065805e-08  learning rate = 8.0994665e-05
============================
Start of epoch 385
step 0: mean loss = 2.6124747e-09
step 100: mean loss = 1.4779896e-08
step 200: mean loss = 1.402751e-08
step 300: mean loss = 1.2637648e-08
epoch 385: mean loss = 1.2962299e-08  learning rate = 8.0994665e-05
============================
Start of epoch 386
step 0: mean loss = 4.955915e-08
step 100: mean loss = 1.383599e-08
step 200: mean loss = 1.1228398e-08
step 300: mean loss = 1.3093917e-08
epoch 386: mean loss = 1.2823472e-08  learning rate = 8.0994665e-05
============================
Start of epoch 387
step 0: mean loss = 3.1486604e-09
step 100: mean loss = 1.1517622e-08
step 200: mean loss = 1.1747018e-08
step 300: mean loss = 1.3061087e-08
epoch 387: mean loss = 1.2789043e-08  learning rate = 8.0994665e-05
============================
Start of epoch 388
step 0: mean loss = 3.2366214e-09
step 100: mean loss = 1.3062841e-08
step 200: mean loss = 1.2493222e-08
step 300: mean loss = 1.5035065e-08
epoch 388: mean loss = 1.4679231e-08  learning rate = 8.0994665e-05
============================
Start of epoch 389
step 0: mean loss = 2.7949882e-09
step 100: mean loss = 7.959062e-09
step 200: mean loss = 1.2921354e-08
step 300: mean loss = 1.1073842e-08
epoch 389: mean loss = 1.1396294e-08  learning rate = 8.0994665e-05
============================
Start of epoch 390
step 0: mean loss = 2.0434454e-08
step 100: mean loss = 1.45088155e-08
step 200: mean loss = 1.30842555e-08
step 300: mean loss = 1.5004415e-08
epoch 390: mean loss = 1.4788055e-08  learning rate = 8.0994665e-05
============================
Start of epoch 391
step 0: mean loss = 4.1345443e-09
step 100: mean loss = 2.7915057e-09
step 200: mean loss = 8.632509e-09
step 300: mean loss = 9.69889e-09
epoch 391: mean loss = 9.569676e-09  learning rate = 8.0994665e-05
============================
Start of epoch 392
step 0: mean loss = 3.944474e-09
step 100: mean loss = 9.878497e-09
step 200: mean loss = 1.41741685e-08
step 300: mean loss = 1.2529859e-08
epoch 392: mean loss = 1.2248354e-08  learning rate = 8.0994665e-05
============================
Start of epoch 393
step 0: mean loss = 2.540356e-09
step 100: mean loss = 1.7338396e-08
step 200: mean loss = 1.6114694e-08
step 300: mean loss = 1.5960506e-08
epoch 393: mean loss = 1.5600243e-08  learning rate = 8.0994665e-05
============================
Start of epoch 394
step 0: mean loss = 3.239498e-09
step 100: mean loss = 2.5627032e-09
step 200: mean loss = 9.210863e-09
step 300: mean loss = 9.672017e-09
epoch 394: mean loss = 9.594742e-09  learning rate = 8.0994665e-05
============================
Start of epoch 395
step 0: mean loss = 2.229856e-08
step 100: mean loss = 1.5821032e-08
step 200: mean loss = 1.404398e-08
step 300: mean loss = 1.43323495e-08
epoch 395: mean loss = 1.4391493e-08  learning rate = 8.0994665e-05
============================
Start of epoch 396
step 0: mean loss = 7.332098e-09
step 100: mean loss = 1.3381807e-08
step 200: mean loss = 1.17207835e-08
step 300: mean loss = 1.2575391e-08
epoch 396: mean loss = 1.230769e-08  learning rate = 8.0994665e-05
============================
Start of epoch 397
step 0: mean loss = 2.86855e-09
step 100: mean loss = 1.0260387e-08
step 200: mean loss = 1.1774917e-08
step 300: mean loss = 1.1181813e-08
epoch 397: mean loss = 1.1016422e-08  learning rate = 8.0994665e-05
============================
Start of epoch 398
step 0: mean loss = 1.285781e-08
step 100: mean loss = 1.5942625e-08
step 200: mean loss = 1.4605096e-08
step 300: mean loss = 1.3813317e-08
epoch 398: mean loss = 1.3763907e-08  learning rate = 8.0994665e-05
============================
Start of epoch 399
step 0: mean loss = 1.5679353e-08
step 100: mean loss = 1.0103842e-08
step 200: mean loss = 1.1857534e-08
step 300: mean loss = 1.1843837e-08
epoch 399: mean loss = 1.1574438e-08  learning rate = 8.0994665e-05
============================
Start of epoch 400
step 0: mean loss = 2.787973e-09
step 100: mean loss = 1.7998579e-08
step 200: mean loss = 1.1841527e-08
step 300: mean loss = 1.4827031e-08
epoch 400: mean loss = 1.4470489e-08  learning rate = 8.0994665e-05
============================
Start of epoch 401
step 0: mean loss = 2.5329718e-09
step 100: mean loss = 1.36553835e-08
step 200: mean loss = 1.1107279e-08
step 300: mean loss = 1.2620643e-08
epoch 401: mean loss = 1.2846626e-08  learning rate = 8.0994665e-05
============================
Start of epoch 402
step 0: mean loss = 2.0871193e-08
step 100: mean loss = 7.505893e-09
step 200: mean loss = 1.1948969e-08
step 300: mean loss = 1.1353455e-08
epoch 402: mean loss = 1.1148668e-08  learning rate = 8.0994665e-05
============================
Start of epoch 403
step 0: mean loss = 3.3957253e-09
step 100: mean loss = 2.1618755e-08
step 200: mean loss = 1.6143165e-08
step 300: mean loss = 1.1803526e-08
epoch 403: mean loss = 1.3723043e-08  learning rate = 8.0994665e-05
============================
Start of epoch 404
step 0: mean loss = 1.0901973e-07
step 100: mean loss = 1.0751614e-08
step 200: mean loss = 1.4221057e-08
step 300: mean loss = 1.1411858e-08
epoch 404: mean loss = 1.12946115e-08  learning rate = 8.0994665e-05
============================
Start of epoch 405
step 0: mean loss = 1.5221474e-08
step 100: mean loss = 2.0732704e-08
step 200: mean loss = 1.587083e-08
step 300: mean loss = 1.487449e-08
epoch 405: mean loss = 1.4769962e-08  learning rate = 8.0994665e-05
============================
Start of epoch 406
step 0: mean loss = 3.315438e-09
step 100: mean loss = 6.9817165e-09
step 200: mean loss = 1.0373087e-08
step 300: mean loss = 9.882768e-09
epoch 406: mean loss = 9.805054e-09  learning rate = 8.0994665e-05
============================
Start of epoch 407
step 0: mean loss = 2.5001755e-08
step 100: mean loss = 1.8960478e-08
step 200: mean loss = 1.3280367e-08
step 300: mean loss = 1.3192391e-08
epoch 407: mean loss = 1.3435648e-08  learning rate = 8.0994665e-05
============================
Start of epoch 408
step 0: mean loss = 8.81101e-08
step 100: mean loss = 1.2984981e-08
step 200: mean loss = 1.5651487e-08
step 300: mean loss = 1.375755e-08
epoch 408: mean loss = 1.3549738e-08  learning rate = 8.0994665e-05
============================
Start of epoch 409
step 0: mean loss = 5.9217298e-09
step 100: mean loss = 9.848586e-09
step 200: mean loss = 1.2904002e-08
step 300: mean loss = 1.5372617e-08
epoch 409: mean loss = 1.5317644e-08  learning rate = 8.0994665e-05
============================
Start of epoch 410
step 0: mean loss = 5.193992e-09
step 100: mean loss = 9.26046e-09
step 200: mean loss = 6.0807706e-09
step 300: mean loss = 9.727758e-09
epoch 410: mean loss = 9.517201e-09  learning rate = 8.0994665e-05
============================
Start of epoch 411
step 0: mean loss = 2.416576e-09
step 100: mean loss = 1.9230294e-08
step 200: mean loss = 1.2755553e-08
step 300: mean loss = 1.3682094e-08
epoch 411: mean loss = 1.33905935e-08  learning rate = 8.0994665e-05
============================
Start of epoch 412
step 0: mean loss = 2.8709615e-09
step 100: mean loss = 9.675253e-09
step 200: mean loss = 1.1869431e-08
step 300: mean loss = 1.2053897e-08
epoch 412: mean loss = 1.1860408e-08  learning rate = 8.0994665e-05
============================
Start of epoch 413
step 0: mean loss = 1.3339218e-08
step 100: mean loss = 1.3566233e-08
step 200: mean loss = 1.8191873e-08
step 300: mean loss = 1.3180095e-08
epoch 413: mean loss = 1.502404e-08  learning rate = 8.0994665e-05
============================
Start of epoch 414
step 0: mean loss = 1.5864247e-08
step 100: mean loss = 5.8251977e-09
step 200: mean loss = 1.1509658e-08
step 300: mean loss = 1.0509591e-08
epoch 414: mean loss = 1.0289259e-08  learning rate = 8.0994665e-05
============================
Start of epoch 415
step 0: mean loss = 2.5367302e-09
step 100: mean loss = 1.3230018e-08
step 200: mean loss = 1.5053736e-08
step 300: mean loss = 1.40130725e-08
epoch 415: mean loss = 1.36772e-08  learning rate = 8.0994665e-05
============================
Start of epoch 416
step 0: mean loss = 2.4761855e-09
step 100: mean loss = 1.900323e-08
step 200: mean loss = 1.3830988e-08
step 300: mean loss = 1.4006195e-08
epoch 416: mean loss = 1.3930598e-08  learning rate = 8.0994665e-05
============================
Start of epoch 417
step 0: mean loss = 1.1488029e-08
step 100: mean loss = 7.226076e-09
step 200: mean loss = 9.731977e-09
step 300: mean loss = 1.2676388e-08
epoch 417: mean loss = 1.2730107e-08  learning rate = 8.0994665e-05
============================
Start of epoch 418
step 0: mean loss = 1.3769145e-08
step 100: mean loss = 1.3265274e-08
step 200: mean loss = 8.9002485e-09
step 300: mean loss = 1.2378216e-08
epoch 418: mean loss = 1.2088735e-08  learning rate = 7.694493e-05
============================
Start of epoch 419
step 0: mean loss = 2.3952946e-09
step 100: mean loss = 2.398111e-09
step 200: mean loss = 8.820754e-09
step 300: mean loss = 1.0373512e-08
epoch 419: mean loss = 1.0400945e-08  learning rate = 7.694493e-05
============================
Start of epoch 420
step 0: mean loss = 9.6316715e-09
step 100: mean loss = 3.0629372e-09
step 200: mean loss = 1.0266039e-08
step 300: mean loss = 8.832654e-09
epoch 420: mean loss = 8.653722e-09  learning rate = 7.694493e-05
============================
Start of epoch 421
step 0: mean loss = 2.6057376e-09
step 100: mean loss = 9.840113e-09
step 200: mean loss = 1.2306534e-08
step 300: mean loss = 1.1321918e-08
epoch 421: mean loss = 1.1154094e-08  learning rate = 7.694493e-05
============================
Start of epoch 422
step 0: mean loss = 1.4315569e-08
step 100: mean loss = 1.2522671e-08
step 200: mean loss = 1.43336365e-08
step 300: mean loss = 1.3093831e-08
epoch 422: mean loss = 1.33265e-08  learning rate = 7.694493e-05
============================
Start of epoch 423
step 0: mean loss = 1.8704272e-08
step 100: mean loss = 1.1102767e-08
step 200: mean loss = 1.4035275e-08
step 300: mean loss = 1.0224854e-08
epoch 423: mean loss = 1.0034103e-08  learning rate = 7.694493e-05
============================
Start of epoch 424
step 0: mean loss = 7.970714e-09
step 100: mean loss = 1.6980243e-08
step 200: mean loss = 1.0747724e-08
step 300: mean loss = 1.2924737e-08
epoch 424: mean loss = 1.2735274e-08  learning rate = 7.694493e-05
============================
Start of epoch 425
step 0: mean loss = 6.8486177e-09
step 100: mean loss = 1.2491577e-08
step 200: mean loss = 9.84603e-09
step 300: mean loss = 1.1621403e-08
epoch 425: mean loss = 1.177781e-08  learning rate = 7.694493e-05
============================
Start of epoch 426
step 0: mean loss = 1.4985028e-08
step 100: mean loss = 1.7241828e-08
step 200: mean loss = 1.0110613e-08
step 300: mean loss = 1.0916132e-08
epoch 426: mean loss = 1.0672315e-08  learning rate = 7.694493e-05
============================
Start of epoch 427
step 0: mean loss = 2.7467113e-09
step 100: mean loss = 1.6109077e-08
step 200: mean loss = 1.2171309e-08
step 300: mean loss = 1.1592076e-08
epoch 427: mean loss = 1.1400013e-08  learning rate = 7.694493e-05
============================
Start of epoch 428
step 0: mean loss = 9.787783e-09
step 100: mean loss = 9.972248e-09
step 200: mean loss = 1.1972668e-08
step 300: mean loss = 1.1543516e-08
epoch 428: mean loss = 1.12788925e-08  learning rate = 7.694493e-05
============================
Start of epoch 429
step 0: mean loss = 2.4307427e-09
step 100: mean loss = 1.6284853e-08
step 200: mean loss = 1.3003984e-08
step 300: mean loss = 1.255032e-08
epoch 429: mean loss = 1.22633805e-08  learning rate = 7.694493e-05
============================
Start of epoch 430
step 0: mean loss = 2.4291054e-09
step 100: mean loss = 1.3907599e-08
step 200: mean loss = 1.4538575e-08
step 300: mean loss = 1.2965047e-08
epoch 430: mean loss = 1.2809363e-08  learning rate = 7.694493e-05
============================
Start of epoch 431
step 0: mean loss = 4.3976867e-09
step 100: mean loss = 1.1247439e-08
step 200: mean loss = 1.1684153e-08
step 300: mean loss = 1.1870323e-08
epoch 431: mean loss = 1.2521151e-08  learning rate = 7.694493e-05
============================
Start of epoch 432
step 0: mean loss = 1.5029942e-08
step 100: mean loss = 4.06882e-09
step 200: mean loss = 1.07613065e-08
step 300: mean loss = 8.607536e-09
epoch 432: mean loss = 8.567898e-09  learning rate = 7.694493e-05
============================
Start of epoch 433
step 0: mean loss = 1.7991443e-08
step 100: mean loss = 1.6823678e-08
step 200: mean loss = 1.5021598e-08
step 300: mean loss = 1.1355742e-08
epoch 433: mean loss = 1.26555335e-08  learning rate = 7.694493e-05
============================
Start of epoch 434
step 0: mean loss = 7.710849e-09
step 100: mean loss = 1.3834731e-08
step 200: mean loss = 1.358508e-08
step 300: mean loss = 1.1007902e-08
epoch 434: mean loss = 1.0765618e-08  learning rate = 7.694493e-05
============================
Start of epoch 435
step 0: mean loss = 2.4668785e-09
step 100: mean loss = 1.6859385e-08
step 200: mean loss = 1.1910012e-08
step 300: mean loss = 1.2490103e-08
epoch 435: mean loss = 1.2197461e-08  learning rate = 7.694493e-05
============================
Start of epoch 436
step 0: mean loss = 2.4170204e-09
step 100: mean loss = 9.626834e-09
step 200: mean loss = 1.0802838e-08
step 300: mean loss = 1.1488138e-08
epoch 436: mean loss = 1.123041e-08  learning rate = 7.694493e-05
============================
Start of epoch 437
step 0: mean loss = 2.8720046e-09
step 100: mean loss = 1.4701566e-08
step 200: mean loss = 1.3166973e-08
step 300: mean loss = 1.3019727e-08
epoch 437: mean loss = 1.2714532e-08  learning rate = 7.694493e-05
============================
Start of epoch 438
step 0: mean loss = 2.4715248e-09
step 100: mean loss = 1.4243816e-08
step 200: mean loss = 1.0029198e-08
step 300: mean loss = 1.1503626e-08
epoch 438: mean loss = 1.128724e-08  learning rate = 7.694493e-05
============================
Start of epoch 439
step 0: mean loss = 2.7226437e-09
step 100: mean loss = 1.02965405e-08
step 200: mean loss = 1.1241626e-08
step 300: mean loss = 1.1354048e-08
epoch 439: mean loss = 1.1113994e-08  learning rate = 7.694493e-05
============================
Start of epoch 440
step 0: mean loss = 2.4262488e-09
step 100: mean loss = 1.612503e-08
step 200: mean loss = 1.2959292e-08
step 300: mean loss = 1.2427606e-08
epoch 440: mean loss = 1.2157859e-08  learning rate = 7.694493e-05
============================
Start of epoch 441
step 0: mean loss = 2.8077927e-09
step 100: mean loss = 1.4614653e-08
step 200: mean loss = 1.2869019e-08
step 300: mean loss = 9.9676685e-09
epoch 441: mean loss = 9.928511e-09  learning rate = 7.694493e-05
============================
Start of epoch 442
step 0: mean loss = 2.6625433e-08
step 100: mean loss = 1.3172423e-08
step 200: mean loss = 1.31815465e-08
step 300: mean loss = 1.3475884e-08
epoch 442: mean loss = 1.31531595e-08  learning rate = 7.694493e-05
============================
Start of epoch 443
step 0: mean loss = 2.3610451e-09
step 100: mean loss = 1.7320128e-08
step 200: mean loss = 1.1233786e-08
step 300: mean loss = 1.0312045e-08
epoch 443: mean loss = 1.2423876e-08  learning rate = 7.694493e-05
============================
Start of epoch 444
step 0: mean loss = 5.2341203e-08
step 100: mean loss = 6.241573e-09
step 200: mean loss = 1.0484643e-08
step 300: mean loss = 1.1397471e-08
epoch 444: mean loss = 1.1136487e-08  learning rate = 7.694493e-05
============================
Start of epoch 445
step 0: mean loss = 2.3542959e-09
step 100: mean loss = 1.5664426e-08
step 200: mean loss = 1.2313383e-08
step 300: mean loss = 1.0313509e-08
epoch 445: mean loss = 1.2714952e-08  learning rate = 7.694493e-05
============================
Start of epoch 446
step 0: mean loss = 6.9105006e-08
step 100: mean loss = 6.5836896e-09
step 200: mean loss = 8.705352e-09
step 300: mean loss = 1.0262034e-08
epoch 446: mean loss = 1.0035441e-08  learning rate = 7.694493e-05
============================
Start of epoch 447
step 0: mean loss = 2.3700553e-09
step 100: mean loss = 1.4450762e-08
step 200: mean loss = 1.3611267e-08
step 300: mean loss = 1.3017345e-08
epoch 447: mean loss = 1.3341301e-08  learning rate = 7.694493e-05
============================
Start of epoch 448
step 0: mean loss = 2.099847e-08
step 100: mean loss = 6.222397e-09
step 200: mean loss = 9.346998e-09
step 300: mean loss = 8.863502e-09
epoch 448: mean loss = 8.913146e-09  learning rate = 7.694493e-05
============================
Start of epoch 449
step 0: mean loss = 8.147139e-09
step 100: mean loss = 1.2774717e-08
step 200: mean loss = 1.5161183e-08
step 300: mean loss = 1.1585029e-08
epoch 449: mean loss = 1.1338923e-08  learning rate = 7.694493e-05
============================
Start of epoch 450
step 0: mean loss = 5.0721605e-09
step 100: mean loss = 1.3321103e-08
step 200: mean loss = 1.2166961e-08
step 300: mean loss = 1.3289474e-08
epoch 450: mean loss = 1.2971404e-08  learning rate = 7.694493e-05
============================
Start of epoch 451
step 0: mean loss = 2.3319497e-09
step 100: mean loss = 1.1468376e-08
step 200: mean loss = 1.0491113e-08
step 300: mean loss = 1.1115572e-08
epoch 451: mean loss = 1.14104814e-08  learning rate = 7.694493e-05
============================
Start of epoch 452
step 0: mean loss = 1.8785645e-08
step 100: mean loss = 1.4237635e-08
step 200: mean loss = 1.1001274e-08
step 300: mean loss = 1.3096829e-08
epoch 452: mean loss = 1.2801502e-08  learning rate = 7.694493e-05
============================
Start of epoch 453
step 0: mean loss = 2.3978888e-09
step 100: mean loss = 5.5219087e-09
step 200: mean loss = 1.259859e-08
step 300: mean loss = 9.857973e-09
epoch 453: mean loss = 1.0232776e-08  learning rate = 7.694493e-05
============================
Start of epoch 454
step 0: mean loss = 2.8928788e-08
step 100: mean loss = 1.0258055e-08
step 200: mean loss = 1.3394876e-08
step 300: mean loss = 1.1194793e-08
epoch 454: mean loss = 1.0971232e-08  learning rate = 7.694493e-05
============================
Start of epoch 455
step 0: mean loss = 2.5636142e-09
step 100: mean loss = 1.1440011e-08
step 200: mean loss = 1.3215521e-08
step 300: mean loss = 1.16915375e-08
epoch 455: mean loss = 1.144289e-08  learning rate = 7.694493e-05
============================
Start of epoch 456
step 0: mean loss = 2.4896594e-09
step 100: mean loss = 1.21263355e-08
step 200: mean loss = 1.2168779e-08
step 300: mean loss = 1.1213679e-08
epoch 456: mean loss = 1.1207435e-08  learning rate = 7.694493e-05
============================
Start of epoch 457
step 0: mean loss = 2.4119547e-08
step 100: mean loss = 1.8474795e-08
step 200: mean loss = 1.3313164e-08
step 300: mean loss = 1.2284811e-08
epoch 457: mean loss = 1.2080328e-08  learning rate = 7.694493e-05
============================
Start of epoch 458
step 0: mean loss = 4.4974304e-09
step 100: mean loss = 2.0646672e-08
step 200: mean loss = 1.1605765e-08
step 300: mean loss = 1.0942684e-08
epoch 458: mean loss = 1.0741076e-08  learning rate = 7.694493e-05
============================
Start of epoch 459
step 0: mean loss = 6.48394e-09
step 100: mean loss = 7.791881e-09
step 200: mean loss = 8.268393e-09
step 300: mean loss = 8.390807e-09
epoch 459: mean loss = 8.231574e-09  learning rate = 7.309768e-05
============================
Start of epoch 460
step 0: mean loss = 3.7073147e-09
step 100: mean loss = 9.084533e-09
step 200: mean loss = 1.1259339e-08
step 300: mean loss = 1.0413516e-08
epoch 460: mean loss = 1.0202152e-08  learning rate = 7.309768e-05
============================
Start of epoch 461
step 0: mean loss = 3.8343404e-09
step 100: mean loss = 1.38569645e-08
step 200: mean loss = 1.6043934e-08
step 300: mean loss = 1.2489665e-08
epoch 461: mean loss = 1.2197746e-08  learning rate = 7.309768e-05
============================
Start of epoch 462
step 0: mean loss = 2.446788e-09
step 100: mean loss = 8.8439975e-09
step 200: mean loss = 1.2511649e-08
step 300: mean loss = 1.18555485e-08
epoch 462: mean loss = 1.1820187e-08  learning rate = 7.309768e-05
============================
Start of epoch 463
step 0: mean loss = 9.498831e-09
step 100: mean loss = 2.8167095e-09
step 200: mean loss = 7.821894e-09
step 300: mean loss = 9.760058e-09
epoch 463: mean loss = 1.0136017e-08  learning rate = 7.309768e-05
============================
Start of epoch 464
step 0: mean loss = 2.2390106e-08
step 100: mean loss = 3.5710435e-09
step 200: mean loss = 8.941522e-09
step 300: mean loss = 8.458898e-09
epoch 464: mean loss = 8.422665e-09  learning rate = 7.309768e-05
============================
Start of epoch 465
step 0: mean loss = 1.523214e-08
step 100: mean loss = 1.4502066e-08
step 200: mean loss = 1.1037484e-08
step 300: mean loss = 1.1196532e-08
epoch 465: mean loss = 1.1466031e-08  learning rate = 7.309768e-05
============================
Start of epoch 466
step 0: mean loss = 3.6624115e-08
step 100: mean loss = 1.2731851e-08
step 200: mean loss = 9.260071e-09
step 300: mean loss = 1.07229985e-08
epoch 466: mean loss = 1.07055005e-08  learning rate = 7.309768e-05
============================
Start of epoch 467
step 0: mean loss = 6.186978e-09
step 100: mean loss = 7.4380186e-09
step 200: mean loss = 9.4261114e-09
step 300: mean loss = 9.107988e-09
epoch 467: mean loss = 9.027874e-09  learning rate = 7.309768e-05
============================
Start of epoch 468
step 0: mean loss = 2.285028e-08
step 100: mean loss = 1.9454422e-08
step 200: mean loss = 1.185198e-08
step 300: mean loss = 1.2181328e-08
epoch 468: mean loss = 1.1977945e-08  learning rate = 7.309768e-05
============================
Start of epoch 469
step 0: mean loss = 7.1618604e-09
step 100: mean loss = 9.9424495e-09
step 200: mean loss = 1.0328529e-08
step 300: mean loss = 1.0631325e-08
epoch 469: mean loss = 1.03965165e-08  learning rate = 7.309768e-05
============================
Start of epoch 470
step 0: mean loss = 2.46676e-09
step 100: mean loss = 1.0511224e-08
step 200: mean loss = 1.0043553e-08
step 300: mean loss = 9.9195e-09
epoch 470: mean loss = 9.700292e-09  learning rate = 7.309768e-05
============================
Start of epoch 471
step 0: mean loss = 2.4383922e-09
step 100: mean loss = 1.8074045e-08
step 200: mean loss = 1.3866019e-08
step 300: mean loss = 1.1866018e-08
epoch 471: mean loss = 1.1774412e-08  learning rate = 7.309768e-05
============================
Start of epoch 472
step 0: mean loss = 4.3142556e-09
step 100: mean loss = 8.97898e-09
step 200: mean loss = 1.07554525e-08
step 300: mean loss = 1.0590872e-08
epoch 472: mean loss = 1.0362397e-08  learning rate = 7.309768e-05
============================
Start of epoch 473
step 0: mean loss = 2.6557923e-09
step 100: mean loss = 1.258118e-08
step 200: mean loss = 1.3439086e-08
step 300: mean loss = 1.24931665e-08
epoch 473: mean loss = 1.2822778e-08  learning rate = 7.309768e-05
============================
Start of epoch 474
step 0: mean loss = 5.9511454e-09
step 100: mean loss = 3.5138477e-09
step 200: mean loss = 9.401894e-09
step 300: mean loss = 9.954124e-09
epoch 474: mean loss = 9.789172e-09  learning rate = 7.309768e-05
============================
Start of epoch 475
step 0: mean loss = 3.4658336e-09
step 100: mean loss = 1.04898135e-08
step 200: mean loss = 7.881879e-09
step 300: mean loss = 9.839879e-09
epoch 475: mean loss = 1.0191463e-08  learning rate = 7.309768e-05
============================
Start of epoch 476
step 0: mean loss = 5.5396367e-08
step 100: mean loss = 7.4339703e-09
step 200: mean loss = 1.04864215e-08
step 300: mean loss = 1.0728544e-08
epoch 476: mean loss = 1.0519182e-08  learning rate = 7.309768e-05
============================
Start of epoch 477
step 0: mean loss = 2.962622e-09
step 100: mean loss = 1.0079535e-08
step 200: mean loss = 1.1241375e-08
step 300: mean loss = 9.410925e-09
epoch 477: mean loss = 9.208801e-09  learning rate = 7.309768e-05
============================
Start of epoch 478
step 0: mean loss = 2.39348e-09
step 100: mean loss = 1.3951966e-08
step 200: mean loss = 1.0986653e-08
step 300: mean loss = 1.00833075e-08
epoch 478: mean loss = 9.975639e-09  learning rate = 7.309768e-05
============================
Start of epoch 479
step 0: mean loss = 2.1158378e-08
step 100: mean loss = 1.424512e-08
step 200: mean loss = 1.3470885e-08
step 300: mean loss = 1.1359862e-08
epoch 479: mean loss = 1.1110668e-08  learning rate = 7.309768e-05
============================
Start of epoch 480
step 0: mean loss = 2.6847726e-09
step 100: mean loss = 1.5772326e-08
step 200: mean loss = 1.2702321e-08
step 300: mean loss = 1.1476855e-08
epoch 480: mean loss = 1.1231798e-08  learning rate = 7.309768e-05
============================
Start of epoch 481
step 0: mean loss = 2.6429496e-09
step 100: mean loss = 1.4564037e-08
step 200: mean loss = 1.2719925e-08
step 300: mean loss = 1.0643617e-08
epoch 481: mean loss = 1.1428308e-08  learning rate = 7.309768e-05
============================
Start of epoch 482
step 0: mean loss = 2.6930048e-08
step 100: mean loss = 1.0613592e-08
step 200: mean loss = 1.1236833e-08
step 300: mean loss = 1.1003241e-08
epoch 482: mean loss = 1.0917563e-08  learning rate = 7.309768e-05
============================
Start of epoch 483
step 0: mean loss = 3.3907441e-09
step 100: mean loss = 7.147945e-09
step 200: mean loss = 7.922084e-09
step 300: mean loss = 9.137983e-09
epoch 483: mean loss = 8.973976e-09  learning rate = 7.309768e-05
============================
Start of epoch 484
step 0: mean loss = 2.9112945e-09
step 100: mean loss = 1.47575125e-08
step 200: mean loss = 1.27775435e-08
step 300: mean loss = 1.2682755e-08
epoch 484: mean loss = 1.31627695e-08  learning rate = 7.309768e-05
============================
Start of epoch 485
step 0: mean loss = 3.0674297e-08
step 100: mean loss = 6.383554e-09
step 200: mean loss = 5.8619474e-09
step 300: mean loss = 9.125059e-09
epoch 485: mean loss = 8.926693e-09  learning rate = 7.309768e-05
============================
Start of epoch 486
step 0: mean loss = 2.3065718e-09
step 100: mean loss = 1.0980649e-08
step 200: mean loss = 1.14074075e-08
step 300: mean loss = 1.0565229e-08
epoch 486: mean loss = 1.03527595e-08  learning rate = 7.309768e-05
============================
Start of epoch 487
step 0: mean loss = 3.345113e-09
step 100: mean loss = 9.275384e-09
step 200: mean loss = 1.2368702e-08
step 300: mean loss = 1.1492117e-08
epoch 487: mean loss = 1.1920632e-08  learning rate = 7.309768e-05
============================
Start of epoch 488
step 0: mean loss = 2.1772161e-08
step 100: mean loss = 1.0600473e-08
step 200: mean loss = 6.890883e-09
step 300: mean loss = 9.405861e-09
epoch 488: mean loss = 9.314425e-09  learning rate = 7.309768e-05
============================
Start of epoch 489
step 0: mean loss = 2.950548e-09
step 100: mean loss = 1.229428e-08
step 200: mean loss = 1.1908236e-08
step 300: mean loss = 1.16202905e-08
epoch 489: mean loss = 1.1471323e-08  learning rate = 7.309768e-05
============================
Start of epoch 490
step 0: mean loss = 3.9194656e-09
step 100: mean loss = 5.944415e-09
step 200: mean loss = 8.625764e-09
step 300: mean loss = 9.560098e-09
epoch 490: mean loss = 9.4418615e-09  learning rate = 7.309768e-05
============================
Start of epoch 491
step 0: mean loss = 6.2299637e-09
step 100: mean loss = 1.1711483e-08
step 200: mean loss = 1.1761478e-08
step 300: mean loss = 1.1585868e-08
epoch 491: mean loss = 1.1896154e-08  learning rate = 7.309768e-05
============================
Start of epoch 492
step 0: mean loss = 2.1060698e-08
step 100: mean loss = 1.0464891e-08
step 200: mean loss = 1.0609786e-08
step 300: mean loss = 8.236785e-09
epoch 492: mean loss = 8.204865e-09  learning rate = 7.309768e-05
============================
Start of epoch 493
step 0: mean loss = 1.9043387e-08
step 100: mean loss = 1.2214944e-08
step 200: mean loss = 1.2818307e-08
step 300: mean loss = 1.1460431e-08
epoch 493: mean loss = 1.1193464e-08  learning rate = 7.309768e-05
============================
Start of epoch 494
step 0: mean loss = 2.310672e-09
step 100: mean loss = 1.4750741e-08
step 200: mean loss = 1.1980072e-08
step 300: mean loss = 1.160418e-08
epoch 494: mean loss = 1.1468536e-08  learning rate = 7.309768e-05
============================
Start of epoch 495
step 0: mean loss = 4.373778e-09
step 100: mean loss = 1.5434118e-08
step 200: mean loss = 8.892924e-09
step 300: mean loss = 1.0103125e-08
epoch 495: mean loss = 9.878775e-09  learning rate = 7.309768e-05
============================
Start of epoch 496
step 0: mean loss = 2.496652e-09
step 100: mean loss = 1.0537454e-08
step 200: mean loss = 1.1372213e-08
step 300: mean loss = 1.1025164e-08
epoch 496: mean loss = 1.07747224e-08  learning rate = 7.309768e-05
============================
Start of epoch 497
step 0: mean loss = 2.4270894e-09
step 100: mean loss = 1.1627384e-08
step 200: mean loss = 9.633053e-09
step 300: mean loss = 1.0652803e-08
epoch 497: mean loss = 1.0521376e-08  learning rate = 7.309768e-05
============================
Start of epoch 498
step 0: mean loss = 5.2948144e-09
step 100: mean loss = 1.3474647e-08
step 200: mean loss = 1.04142295e-08
step 300: mean loss = 1.0335191e-08
epoch 498: mean loss = 1.0328655e-08  learning rate = 7.309768e-05
============================
Start of epoch 499
step 0: mean loss = 1.521382e-08
step 100: mean loss = 1.5397001e-08
step 200: mean loss = 8.943209e-09
step 300: mean loss = 8.724812e-09
epoch 499: mean loss = 8.544965e-09  learning rate = 6.9442794e-05
============================
Start of epoch 500
step 0: mean loss = 2.3268374e-09
step 100: mean loss = 1.0781e-08
step 200: mean loss = 9.2582e-09
step 300: mean loss = 9.037912e-09
epoch 500: mean loss = 8.843378e-09  learning rate = 6.9442794e-05
============================
Start of epoch 501
step 0: mean loss = 2.3392506e-09
step 100: mean loss = 8.489709e-09
step 200: mean loss = 8.554191e-09
step 300: mean loss = 1.101924e-08
epoch 501: mean loss = 1.0764297e-08  learning rate = 6.9442794e-05
============================
Start of epoch 502
step 0: mean loss = 2.2381903e-09
step 100: mean loss = 1.0131789e-08
step 200: mean loss = 8.479063e-09
step 300: mean loss = 9.196022e-09
epoch 502: mean loss = 9.002071e-09  learning rate = 6.9442794e-05
============================
Start of epoch 503
step 0: mean loss = 2.4635909e-09
step 100: mean loss = 1.0478663e-08
step 200: mean loss = 1.1875822e-08
step 300: mean loss = 1.0043999e-08
epoch 503: mean loss = 9.869208e-09  learning rate = 6.9442794e-05
============================
Start of epoch 504
step 0: mean loss = 2.5458347e-09
step 100: mean loss = 1.1262891e-08
step 200: mean loss = 8.935193e-09
step 300: mean loss = 1.03352535e-08
epoch 504: mean loss = 1.0117351e-08  learning rate = 6.9442794e-05
============================
Start of epoch 505
step 0: mean loss = 2.5218887e-09
step 100: mean loss = 1.2927503e-08
step 200: mean loss = 1.0001582e-08
step 300: mean loss = 1.0318997e-08
epoch 505: mean loss = 1.0272913e-08  learning rate = 6.9442794e-05
============================
Start of epoch 506
step 0: mean loss = 7.0180817e-09
step 100: mean loss = 7.803281e-09
step 200: mean loss = 9.190261e-09
step 300: mean loss = 9.210887e-09
epoch 506: mean loss = 9.103076e-09  learning rate = 6.9442794e-05
============================
Start of epoch 507
step 0: mean loss = 4.337018e-09
step 100: mean loss = 8.476695e-09
step 200: mean loss = 9.113285e-09
step 300: mean loss = 8.6487795e-09
epoch 507: mean loss = 9.470277e-09  learning rate = 6.9442794e-05
============================
Start of epoch 508
step 0: mean loss = 4.9701e-09
step 100: mean loss = 6.553918e-09
step 200: mean loss = 8.873992e-09
step 300: mean loss = 9.9782556e-09
epoch 508: mean loss = 1.051643e-08  learning rate = 6.9442794e-05
============================
Start of epoch 509
step 0: mean loss = 2.5103972e-08
step 100: mean loss = 5.8812604e-09
step 200: mean loss = 7.472137e-09
step 300: mean loss = 8.423007e-09
epoch 509: mean loss = 8.312024e-09  learning rate = 6.9442794e-05
============================
Start of epoch 510
step 0: mean loss = 2.753747e-09
step 100: mean loss = 8.245589e-09
step 200: mean loss = 1.0895993e-08
step 300: mean loss = 9.789479e-09
epoch 510: mean loss = 9.573451e-09  learning rate = 6.9442794e-05
============================
Start of epoch 511
step 0: mean loss = 2.3434676e-09
step 100: mean loss = 1.0383424e-08
step 200: mean loss = 1.0398452e-08
step 300: mean loss = 1.0784713e-08
epoch 511: mean loss = 1.053633e-08  learning rate = 6.9442794e-05
============================
Start of epoch 512
step 0: mean loss = 2.2409856e-09
step 100: mean loss = 1.4294367e-08
step 200: mean loss = 9.371735e-09
step 300: mean loss = 9.934687e-09
epoch 512: mean loss = 1.00791455e-08  learning rate = 6.9442794e-05
============================
Start of epoch 513
step 0: mean loss = 1.0198285e-08
step 100: mean loss = 8.479466e-09
step 200: mean loss = 9.216141e-09
step 300: mean loss = 8.91199e-09
epoch 513: mean loss = 9.566526e-09  learning rate = 6.9442794e-05
============================
Start of epoch 514
step 0: mean loss = 2.8930302e-08
step 100: mean loss = 9.021336e-09
step 200: mean loss = 9.063695e-09
step 300: mean loss = 9.2552686e-09
epoch 514: mean loss = 9.062182e-09  learning rate = 6.9442794e-05
============================
Start of epoch 515
step 0: mean loss = 2.6696947e-09
step 100: mean loss = 1.06397e-08
step 200: mean loss = 1.1715806e-08
step 300: mean loss = 9.60951e-09
epoch 515: mean loss = 9.407517e-09  learning rate = 6.9442794e-05
============================
Start of epoch 516
step 0: mean loss = 2.5262352e-09
step 100: mean loss = 9.827581e-09
step 200: mean loss = 8.878878e-09
step 300: mean loss = 9.426476e-09
epoch 516: mean loss = 9.734521e-09  learning rate = 6.9442794e-05
============================
Start of epoch 517
step 0: mean loss = 4.427594e-08
step 100: mean loss = 6.548709e-09
step 200: mean loss = 1.09750165e-08
step 300: mean loss = 9.521815e-09
epoch 517: mean loss = 9.7758965e-09  learning rate = 6.9442794e-05
============================
Start of epoch 518
step 0: mean loss = 1.17183045e-08
step 100: mean loss = 7.1713613e-09
step 200: mean loss = 9.795939e-09
step 300: mean loss = 8.766804e-09
epoch 518: mean loss = 8.622235e-09  learning rate = 6.9442794e-05
============================
Start of epoch 519
step 0: mean loss = 6.8872463e-09
step 100: mean loss = 1.3819752e-08
step 200: mean loss = 1.3006943e-08
step 300: mean loss = 9.7950235e-09
epoch 519: mean loss = 9.590632e-09  learning rate = 6.9442794e-05
============================
Start of epoch 520
step 0: mean loss = 4.060571e-09
step 100: mean loss = 1.2651318e-08
step 200: mean loss = 1.0513324e-08
step 300: mean loss = 1.027233e-08
epoch 520: mean loss = 1.0682196e-08  learning rate = 6.9442794e-05
============================
Start of epoch 521
step 0: mean loss = 5.128784e-08
step 100: mean loss = 1.5216452e-08
step 200: mean loss = 9.005599e-09
step 300: mean loss = 1.02774065e-08
epoch 521: mean loss = 1.0812525e-08  learning rate = 6.9442794e-05
============================
Start of epoch 522
step 0: mean loss = 1.570962e-08
step 100: mean loss = 3.6411716e-09
step 200: mean loss = 8.386764e-09
step 300: mean loss = 8.630352e-09
epoch 522: mean loss = 8.792e-09  learning rate = 6.9442794e-05
============================
Start of epoch 523
step 0: mean loss = 2.4710674e-09
step 100: mean loss = 1.0987163e-08
step 200: mean loss = 8.297343e-09
step 300: mean loss = 9.103892e-09
epoch 523: mean loss = 8.908525e-09  learning rate = 6.9442794e-05
============================
Start of epoch 524
step 0: mean loss = 2.5861298e-09
step 100: mean loss = 1.02279305e-08
step 200: mean loss = 9.802744e-09
step 300: mean loss = 1.0579048e-08
epoch 524: mean loss = 1.0381815e-08  learning rate = 6.9442794e-05
============================
Start of epoch 525
step 0: mean loss = 5.007122e-09
step 100: mean loss = 9.700666e-09
step 200: mean loss = 8.306578e-09
step 300: mean loss = 9.759783e-09
epoch 525: mean loss = 9.821533e-09  learning rate = 6.9442794e-05
============================
Start of epoch 526
step 0: mean loss = 8.214491e-09
step 100: mean loss = 8.71768e-09
step 200: mean loss = 8.9585575e-09
step 300: mean loss = 9.018217e-09
epoch 526: mean loss = 9.711167e-09  learning rate = 6.9442794e-05
============================
Start of epoch 527
step 0: mean loss = 8.693948e-09
step 100: mean loss = 1.1230592e-08
step 200: mean loss = 8.8583425e-09
step 300: mean loss = 8.364001e-09
epoch 527: mean loss = 8.224361e-09  learning rate = 6.9442794e-05
============================
Start of epoch 528
step 0: mean loss = 5.036636e-09
step 100: mean loss = 1.0397736e-08
step 200: mean loss = 1.0490219e-08
step 300: mean loss = 1.1040637e-08
epoch 528: mean loss = 1.0784752e-08  learning rate = 6.9442794e-05
============================
Start of epoch 529
step 0: mean loss = 2.2271054e-09
step 100: mean loss = 9.99885e-09
step 200: mean loss = 1.1504056e-08
step 300: mean loss = 9.7729895e-09
epoch 529: mean loss = 9.574734e-09  learning rate = 6.9442794e-05
============================
Start of epoch 530
step 0: mean loss = 2.6882703e-09
step 100: mean loss = 8.452042e-09
step 200: mean loss = 1.0736696e-08
step 300: mean loss = 8.401718e-09
epoch 530: mean loss = 8.7495975e-09  learning rate = 6.9442794e-05
============================
Start of epoch 531
step 0: mean loss = 7.298323e-08
step 100: mean loss = 1.4333391e-08
step 200: mean loss = 1.0623034e-08
step 300: mean loss = 9.707535e-09
epoch 531: mean loss = 1.0956343e-08  learning rate = 6.9442794e-05
============================
Start of epoch 532
step 0: mean loss = 7.3399676e-08
step 100: mean loss = 7.084821e-09
step 200: mean loss = 1.0752273e-08
step 300: mean loss = 8.148474e-09
epoch 532: mean loss = 9.160818e-09  learning rate = 6.9442794e-05
============================
Start of epoch 533
step 0: mean loss = 6.954772e-08
step 100: mean loss = 8.1996685e-09
step 200: mean loss = 8.785067e-09
step 300: mean loss = 9.218196e-09
epoch 533: mean loss = 9.0306616e-09  learning rate = 6.9442794e-05
============================
Start of epoch 534
step 0: mean loss = 3.1607255e-09
step 100: mean loss = 1.1367203e-08
step 200: mean loss = 1.0481675e-08
step 300: mean loss = 9.8396e-09
epoch 534: mean loss = 1.0016781e-08  learning rate = 6.9442794e-05
============================
Start of epoch 535
step 0: mean loss = 3.858979e-08
step 100: mean loss = 8.800644e-09
step 200: mean loss = 1.0581471e-08
step 300: mean loss = 9.533191e-09
epoch 535: mean loss = 9.386047e-09  learning rate = 6.9442794e-05
============================
Start of epoch 536
step 0: mean loss = 4.838472e-09
step 100: mean loss = 1.322735e-08
step 200: mean loss = 1.1544493e-08
step 300: mean loss = 1.1036476e-08
epoch 536: mean loss = 1.0801347e-08  learning rate = 6.9442794e-05
============================
Start of epoch 537
step 0: mean loss = 2.242895e-09
step 100: mean loss = 1.223526e-08
step 200: mean loss = 8.483797e-09
step 300: mean loss = 8.295248e-09
epoch 537: mean loss = 8.903121e-09  learning rate = 6.9442794e-05
============================
Start of epoch 538
step 0: mean loss = 7.60516e-08
step 100: mean loss = 7.810613e-09
step 200: mean loss = 1.1382858e-08
step 300: mean loss = 9.4987005e-09
epoch 538: mean loss = 1.0005705e-08  learning rate = 6.9442794e-05
============================
Start of epoch 539
step 0: mean loss = 1.31214835e-08
step 100: mean loss = 1.0125959e-08
step 200: mean loss = 1.1534513e-08
step 300: mean loss = 8.466673e-09
epoch 539: mean loss = 8.283877e-09  learning rate = 6.597066e-05
============================
Start of epoch 540
step 0: mean loss = 2.1712043e-09
step 100: mean loss = 8.599367e-09
step 200: mean loss = 5.825835e-09
step 300: mean loss = 7.3564155e-09
epoch 540: mean loss = 8.229346e-09  learning rate = 6.597066e-05
============================
Start of epoch 541
step 0: mean loss = 3.1261482e-08
step 100: mean loss = 6.747558e-09
step 200: mean loss = 7.979078e-09
step 300: mean loss = 7.999816e-09
epoch 541: mean loss = 7.835525e-09  learning rate = 6.597066e-05
============================
Start of epoch 542
step 0: mean loss = 2.4051534e-09
step 100: mean loss = 9.819858e-09
step 200: mean loss = 8.418755e-09
step 300: mean loss = 1.0189498e-08
epoch 542: mean loss = 1.0252186e-08  learning rate = 6.597066e-05
============================
Start of epoch 543
step 0: mean loss = 1.0194863e-08
step 100: mean loss = 6.4367573e-09
step 200: mean loss = 8.326493e-09
step 300: mean loss = 8.346222e-09
epoch 543: mean loss = 8.183638e-09  learning rate = 6.597066e-05
============================
Start of epoch 544
step 0: mean loss = 2.7677896e-09
step 100: mean loss = 8.321e-09
step 200: mean loss = 8.014173e-09
step 300: mean loss = 8.330416e-09
epoch 544: mean loss = 9.098503e-09  learning rate = 6.597066e-05
============================
Start of epoch 545
step 0: mean loss = 1.1522577e-08
step 100: mean loss = 8.277742e-09
step 200: mean loss = 8.944377e-09
step 300: mean loss = 8.288031e-09
epoch 545: mean loss = 8.11434e-09  learning rate = 6.597066e-05
============================
Start of epoch 546
step 0: mean loss = 2.3967206e-09
step 100: mean loss = 8.772136e-09
step 200: mean loss = 1.0618651e-08
step 300: mean loss = 8.61923e-09
epoch 546: mean loss = 8.438771e-09  learning rate = 6.597066e-05
============================
Start of epoch 547
step 0: mean loss = 3.2533523e-09
step 100: mean loss = 1.4292874e-08
step 200: mean loss = 8.58707e-09
step 300: mean loss = 9.689089e-09
epoch 547: mean loss = 1.0036626e-08  learning rate = 6.597066e-05
============================
Start of epoch 548
step 0: mean loss = 3.9706737e-08
step 100: mean loss = 8.716832e-09
step 200: mean loss = 8.453308e-09
step 300: mean loss = 9.368883e-09
epoch 548: mean loss = 9.306757e-09  learning rate = 6.597066e-05
============================
Start of epoch 549
step 0: mean loss = 3.8630925e-09
step 100: mean loss = 7.468244e-09
step 200: mean loss = 7.913066e-09
step 300: mean loss = 9.534685e-09
epoch 549: mean loss = 9.388945e-09  learning rate = 6.597066e-05
============================
Start of epoch 550
step 0: mean loss = 3.785875e-09
step 100: mean loss = 6.5503856e-09
step 200: mean loss = 8.664773e-09
step 300: mean loss = 8.402686e-09
epoch 550: mean loss = 8.2452365e-09  learning rate = 6.597066e-05
============================
Start of epoch 551
step 0: mean loss = 2.4481162e-09
step 100: mean loss = 1.1056599e-08
step 200: mean loss = 8.839413e-09
step 300: mean loss = 9.587181e-09
epoch 551: mean loss = 9.424327e-09  learning rate = 6.597066e-05
============================
Start of epoch 552
step 0: mean loss = 2.315385e-09
step 100: mean loss = 7.3720146e-09
step 200: mean loss = 7.849162e-09
step 300: mean loss = 9.767321e-09
epoch 552: mean loss = 9.8499315e-09  learning rate = 6.597066e-05
============================
Start of epoch 553
step 0: mean loss = 2.8514158e-09
step 100: mean loss = 5.1898246e-09
step 200: mean loss = 4.8374242e-09
step 300: mean loss = 6.736343e-09
epoch 553: mean loss = 7.675369e-09  learning rate = 6.597066e-05
============================
Start of epoch 554
step 0: mean loss = 2.4044368e-08
step 100: mean loss = 1.1700408e-08
step 200: mean loss = 7.6391515e-09
step 300: mean loss = 8.286035e-09
epoch 554: mean loss = 8.2557925e-09  learning rate = 6.597066e-05
============================
Start of epoch 555
step 0: mean loss = 2.428365e-09
step 100: mean loss = 9.79697e-09
step 200: mean loss = 8.621173e-09
step 300: mean loss = 9.080919e-09
epoch 555: mean loss = 8.892115e-09  learning rate = 6.597066e-05
============================
Start of epoch 556
step 0: mean loss = 2.997509e-09
step 100: mean loss = 1.0147105e-08
step 200: mean loss = 8.450617e-09
step 300: mean loss = 8.4451655e-09
epoch 556: mean loss = 8.26502e-09  learning rate = 6.597066e-05
============================
Start of epoch 557
step 0: mean loss = 2.4055857e-09
step 100: mean loss = 1.2461373e-08
step 200: mean loss = 9.253487e-09
step 300: mean loss = 9.4807495e-09
epoch 557: mean loss = 9.270063e-09  learning rate = 6.597066e-05
============================
Start of epoch 558
step 0: mean loss = 2.1757502e-09
step 100: mean loss = 1.7628574e-08
step 200: mean loss = 1.0518471e-08
step 300: mean loss = 9.1613845e-09
epoch 558: mean loss = 9.0805745e-09  learning rate = 6.597066e-05
============================
Start of epoch 559
step 0: mean loss = 1.9920703e-08
step 100: mean loss = 1.11413785e-08
step 200: mean loss = 1.1903792e-08
step 300: mean loss = 9.993354e-09
epoch 559: mean loss = 9.967475e-09  learning rate = 6.597066e-05
============================
Start of epoch 560
step 0: mean loss = 2.9460603e-09
step 100: mean loss = 1.0795434e-08
step 200: mean loss = 9.052728e-09
step 300: mean loss = 8.846188e-09
epoch 560: mean loss = 9.001303e-09  learning rate = 6.597066e-05
============================
Start of epoch 561
step 0: mean loss = 9.575338e-09
step 100: mean loss = 4.891442e-09
step 200: mean loss = 7.0826034e-09
step 300: mean loss = 7.964096e-09
epoch 561: mean loss = 7.80298e-09  learning rate = 6.597066e-05
============================
Start of epoch 562
step 0: mean loss = 2.5219884e-09
step 100: mean loss = 9.953763e-09
step 200: mean loss = 8.6824565e-09
step 300: mean loss = 8.9557615e-09
epoch 562: mean loss = 8.783563e-09  learning rate = 6.597066e-05
============================
Start of epoch 563
step 0: mean loss = 3.2731657e-09
step 100: mean loss = 9.408174e-09
step 200: mean loss = 9.414981e-09
step 300: mean loss = 8.942669e-09
epoch 563: mean loss = 8.811772e-09  learning rate = 6.597066e-05
============================
Start of epoch 564
step 0: mean loss = 1.038142e-08
step 100: mean loss = 9.317576e-09
step 200: mean loss = 1.0843627e-08
step 300: mean loss = 8.715815e-09
epoch 564: mean loss = 8.551789e-09  learning rate = 6.597066e-05
============================
Start of epoch 565
step 0: mean loss = 3.6200247e-09
step 100: mean loss = 1.2224615e-08
step 200: mean loss = 9.625988e-09
step 300: mean loss = 9.318571e-09
epoch 565: mean loss = 9.11216e-09  learning rate = 6.597066e-05
============================
Start of epoch 566
step 0: mean loss = 2.3291604e-09
step 100: mean loss = 8.692418e-09
step 200: mean loss = 9.22818e-09
step 300: mean loss = 9.339578e-09
epoch 566: mean loss = 9.133359e-09  learning rate = 6.597066e-05
============================
Start of epoch 567
step 0: mean loss = 2.3387716e-09
step 100: mean loss = 8.753426e-09
step 200: mean loss = 1.1262309e-08
step 300: mean loss = 9.034122e-09
epoch 567: mean loss = 8.896115e-09  learning rate = 6.597066e-05
============================
Start of epoch 568
step 0: mean loss = 3.3747989e-09
step 100: mean loss = 9.9845305e-09
step 200: mean loss = 9.315978e-09
step 300: mean loss = 1.0676414e-08
epoch 568: mean loss = 1.0433728e-08  learning rate = 6.597066e-05
============================
Start of epoch 569
step 0: mean loss = 2.3326172e-09
step 100: mean loss = 6.4794934e-09
step 200: mean loss = 8.5832665e-09
step 300: mean loss = 6.984082e-09
epoch 569: mean loss = 6.8459904e-09  learning rate = 6.597066e-05
============================
Start of epoch 570
step 0: mean loss = 2.4215083e-09
step 100: mean loss = 1.269042e-08
step 200: mean loss = 1.0689774e-08
step 300: mean loss = 1.1217523e-08
epoch 570: mean loss = 1.1185522e-08  learning rate = 6.597066e-05
============================
Start of epoch 571
step 0: mean loss = 4.1462944e-09
step 100: mean loss = 2.6199507e-09
step 200: mean loss = 7.179603e-09
step 300: mean loss = 7.6352995e-09
epoch 571: mean loss = 7.481558e-09  learning rate = 6.597066e-05
============================
Start of epoch 572
step 0: mean loss = 2.3465059e-09
step 100: mean loss = 1.7216635e-08
step 200: mean loss = 9.76758e-09
step 300: mean loss = 8.56911e-09
epoch 572: mean loss = 8.381737e-09  learning rate = 6.597066e-05
============================
Start of epoch 573
step 0: mean loss = 2.1276712e-09
step 100: mean loss = 1.4505485e-08
step 200: mean loss = 1.0692701e-08
step 300: mean loss = 9.223816e-09
epoch 573: mean loss = 9.019663e-09  learning rate = 6.597066e-05
============================
Start of epoch 574
step 0: mean loss = 2.2691375e-09
step 100: mean loss = 1.2253954e-08
step 200: mean loss = 1.1491256e-08
step 300: mean loss = 1.129129e-08
epoch 574: mean loss = 1.1065626e-08  learning rate = 6.597066e-05
============================
Start of epoch 575
step 0: mean loss = 2.19121e-09
step 100: mean loss = 2.4154114e-09
step 200: mean loss = 6.929009e-09
step 300: mean loss = 8.436373e-09
epoch 575: mean loss = 8.270385e-09  learning rate = 6.597066e-05
============================
Start of epoch 576
step 0: mean loss = 2.2727569e-09
step 100: mean loss = 7.109006e-09
step 200: mean loss = 1.0995676e-08
step 300: mean loss = 8.124109e-09
epoch 576: mean loss = 7.949602e-09  learning rate = 6.597066e-05
============================
Start of epoch 577
step 0: mean loss = 2.113652e-09
step 100: mean loss = 1.229014e-08
step 200: mean loss = 1.1568889e-08
step 300: mean loss = 9.7248565e-09
epoch 577: mean loss = 9.6067145e-09  learning rate = 6.597066e-05
============================
Start of epoch 578
step 0: mean loss = 7.914923e-09
step 100: mean loss = 1.001157e-08
step 200: mean loss = 9.293902e-09
step 300: mean loss = 8.410529e-09
epoch 578: mean loss = 8.270433e-09  learning rate = 6.597066e-05
============================
Start of epoch 579
step 0: mean loss = 2.7206173e-09
step 100: mean loss = 9.149139e-09
step 200: mean loss = 1.0143996e-08
step 300: mean loss = 9.472193e-09
epoch 579: mean loss = 9.318848e-09  learning rate = 6.267212e-05
============================
Start of epoch 580
step 0: mean loss = 2.7621736e-09
step 100: mean loss = 2.1690179e-09
step 200: mean loss = 6.502269e-09
step 300: mean loss = 5.056879e-09
epoch 580: mean loss = 4.977506e-09  learning rate = 6.267212e-05
============================
Start of epoch 581
step 0: mean loss = 3.1660796e-09
step 100: mean loss = 1.0999548e-08
step 200: mean loss = 1.3195019e-08
step 300: mean loss = 9.515243e-09
epoch 581: mean loss = 9.300087e-09  learning rate = 6.267212e-05
============================
Start of epoch 582
step 0: mean loss = 2.1041335e-09
step 100: mean loss = 7.925073e-09
step 200: mean loss = 8.574255e-09
step 300: mean loss = 8.524216e-09
epoch 582: mean loss = 8.351332e-09  learning rate = 6.267212e-05
============================
Start of epoch 583
step 0: mean loss = 2.8047873e-09
step 100: mean loss = 7.216255e-09
step 200: mean loss = 8.161606e-09
step 300: mean loss = 8.0585805e-09
epoch 583: mean loss = 7.8960625e-09  learning rate = 6.267212e-05
============================
Start of epoch 584
step 0: mean loss = 3.2233425e-09
step 100: mean loss = 8.916485e-09
step 200: mean loss = 1.0258663e-08
step 300: mean loss = 8.276973e-09
epoch 584: mean loss = 8.1006295e-09  learning rate = 6.267212e-05
============================
Start of epoch 585
step 0: mean loss = 2.45283e-09
step 100: mean loss = 1.0144075e-08
step 200: mean loss = 8.930756e-09
step 300: mean loss = 7.940713e-09
epoch 585: mean loss = 7.771324e-09  learning rate = 6.267212e-05
============================
Start of epoch 586
step 0: mean loss = 2.1282272e-09
step 100: mean loss = 1.09819e-08
step 200: mean loss = 9.845066e-09
step 300: mean loss = 9.034813e-09
epoch 586: mean loss = 8.852774e-09  learning rate = 6.267212e-05
============================
Start of epoch 587
step 0: mean loss = 2.557317e-09
step 100: mean loss = 7.3499207e-09
step 200: mean loss = 7.2852497e-09
step 300: mean loss = 8.048394e-09
epoch 587: mean loss = 8.106146e-09  learning rate = 6.267212e-05
============================
Start of epoch 588
step 0: mean loss = 3.0515834e-09
step 100: mean loss = 6.6123347e-09
step 200: mean loss = 9.296755e-09
step 300: mean loss = 7.6731395e-09
epoch 588: mean loss = 8.84871e-09  learning rate = 6.267212e-05
============================
Start of epoch 589
step 0: mean loss = 2.82537e-09
step 100: mean loss = 6.6986448e-09
step 200: mean loss = 7.748494e-09
step 300: mean loss = 7.908817e-09
epoch 589: mean loss = 7.744399e-09  learning rate = 6.267212e-05
============================
Start of epoch 590
step 0: mean loss = 2.1317295e-09
step 100: mean loss = 1.18684e-08
step 200: mean loss = 7.513511e-09
step 300: mean loss = 8.633705e-09
epoch 590: mean loss = 8.566018e-09  learning rate = 6.267212e-05
============================
Start of epoch 591
step 0: mean loss = 4.8089905e-09
step 100: mean loss = 9.502253e-09
step 200: mean loss = 8.1257925e-09
step 300: mean loss = 8.504485e-09
epoch 591: mean loss = 8.3185245e-09  learning rate = 6.267212e-05
============================
Start of epoch 592
step 0: mean loss = 2.1027184e-09
step 100: mean loss = 9.203814e-09
step 200: mean loss = 7.0285138e-09
step 300: mean loss = 7.2325346e-09
epoch 592: mean loss = 7.404131e-09  learning rate = 6.267212e-05
============================
Start of epoch 593
step 0: mean loss = 2.8925747e-08
step 100: mean loss = 1.1913354e-08
step 200: mean loss = 8.617562e-09
step 300: mean loss = 8.157631e-09
epoch 593: mean loss = 7.981921e-09  learning rate = 6.267212e-05
============================
Start of epoch 594
step 0: mean loss = 2.1168662e-09
step 100: mean loss = 9.983169e-09
step 200: mean loss = 8.469997e-09
step 300: mean loss = 8.594141e-09
epoch 594: mean loss = 8.727839e-09  learning rate = 6.267212e-05
============================
Start of epoch 595
step 0: mean loss = 3.542217e-09
step 100: mean loss = 7.2510122e-09
step 200: mean loss = 6.874272e-09
step 300: mean loss = 8.0301366e-09
epoch 595: mean loss = 7.857544e-09  learning rate = 6.267212e-05
============================
Start of epoch 596
step 0: mean loss = 2.084909e-09
step 100: mean loss = 8.502604e-09
step 200: mean loss = 8.779211e-09
step 300: mean loss = 8.51129e-09
epoch 596: mean loss = 8.331416e-09  learning rate = 6.267212e-05
============================
Start of epoch 597
step 0: mean loss = 2.1770097e-09
step 100: mean loss = 6.212987e-09
step 200: mean loss = 9.209553e-09
step 300: mean loss = 8.336794e-09
epoch 597: mean loss = 8.160862e-09  learning rate = 6.267212e-05
============================
Start of epoch 598
step 0: mean loss = 2.297252e-09
step 100: mean loss = 8.877419e-09
step 200: mean loss = 9.599511e-09
step 300: mean loss = 8.887459e-09
epoch 598: mean loss = 8.691247e-09  learning rate = 6.267212e-05
============================
Start of epoch 599
step 0: mean loss = 2.1339803e-09
step 100: mean loss = 8.764418e-09
step 200: mean loss = 8.325614e-09
step 300: mean loss = 8.750743e-09
epoch 599: mean loss = 8.564523e-09  learning rate = 6.267212e-05
============================
Start of epoch 600
step 0: mean loss = 2.3175746e-09
step 100: mean loss = 8.487034e-09
step 200: mean loss = 9.377634e-09
step 300: mean loss = 7.3529858e-09
epoch 600: mean loss = 7.2646724e-09  learning rate = 6.267212e-05
============================
Start of epoch 601
step 0: mean loss = 7.656983e-09
step 100: mean loss = 9.692047e-09
step 200: mean loss = 8.377442e-09
step 300: mean loss = 8.118208e-09
epoch 601: mean loss = 7.945665e-09  learning rate = 6.267212e-05
============================
Start of epoch 602
step 0: mean loss = 2.0683226e-09
step 100: mean loss = 1.0722943e-08
step 200: mean loss = 1.0744964e-08
step 300: mean loss = 8.693153e-09
epoch 602: mean loss = 9.3574215e-09  learning rate = 6.267212e-05
============================
Start of epoch 603
step 0: mean loss = 1.9967029e-08
step 100: mean loss = 3.864048e-09
step 200: mean loss = 8.397684e-09
step 300: mean loss = 6.6977925e-09
epoch 603: mean loss = 6.670637e-09  learning rate = 6.267212e-05
============================
Start of epoch 604
step 0: mean loss = 1.5465178e-08
step 100: mean loss = 1.2369752e-08
step 200: mean loss = 9.35132e-09
step 300: mean loss = 8.493243e-09
epoch 604: mean loss = 8.318598e-09  learning rate = 6.267212e-05
============================
Start of epoch 605
step 0: mean loss = 3.5992116e-09
step 100: mean loss = 1.3200049e-08
step 200: mean loss = 9.438286e-09
step 300: mean loss = 1.0115743e-08
epoch 605: mean loss = 9.97149e-09  learning rate = 6.267212e-05
============================
Start of epoch 606
step 0: mean loss = 5.766418e-09
step 100: mean loss = 1.01822994e-08
step 200: mean loss = 7.605593e-09
step 300: mean loss = 8.691174e-09
epoch 606: mean loss = 9.0127354e-09  learning rate = 6.267212e-05
============================
Start of epoch 607
step 0: mean loss = 3.3719851e-09
step 100: mean loss = 3.448325e-09
step 200: mean loss = 6.1606378e-09
step 300: mean loss = 7.348461e-09
epoch 607: mean loss = 7.36355e-09  learning rate = 6.267212e-05
============================
Start of epoch 608
step 0: mean loss = 4.9430473e-09
step 100: mean loss = 4.483398e-09
step 200: mean loss = 6.2822023e-09
step 300: mean loss = 6.6397297e-09
epoch 608: mean loss = 6.5327295e-09  learning rate = 6.267212e-05
============================
Start of epoch 609
step 0: mean loss = 4.1146473e-09
step 100: mean loss = 1.0444192e-08
step 200: mean loss = 8.305936e-09
step 300: mean loss = 8.191083e-09
epoch 609: mean loss = 8.28284e-09  learning rate = 6.267212e-05
============================
Start of epoch 610
step 0: mean loss = 1.7086197e-08
step 100: mean loss = 1.1173742e-08
step 200: mean loss = 1.0725985e-08
step 300: mean loss = 7.909216e-09
epoch 610: mean loss = 8.550646e-09  learning rate = 6.267212e-05
============================
Start of epoch 611
step 0: mean loss = 8.18439e-08
step 100: mean loss = 7.564278e-09
step 200: mean loss = 8.396245e-09
step 300: mean loss = 7.8348155e-09
epoch 611: mean loss = 7.668206e-09  learning rate = 6.267212e-05
============================
Start of epoch 612
step 0: mean loss = 2.2423363e-09
step 100: mean loss = 1.04595035e-08
step 200: mean loss = 9.4158565e-09
step 300: mean loss = 8.820815e-09
epoch 612: mean loss = 8.640571e-09  learning rate = 6.267212e-05
============================
Start of epoch 613
step 0: mean loss = 2.4286024e-09
step 100: mean loss = 1.0037394e-08
step 200: mean loss = 9.00776e-09
step 300: mean loss = 8.295411e-09
epoch 613: mean loss = 8.121216e-09  learning rate = 6.267212e-05
============================
Start of epoch 614
step 0: mean loss = 2.4238858e-09
step 100: mean loss = 1.3759058e-08
step 200: mean loss = 8.0726e-09
step 300: mean loss = 8.6815914e-09
epoch 614: mean loss = 8.489218e-09  learning rate = 6.267212e-05
============================
Start of epoch 615
step 0: mean loss = 2.05647e-09
step 100: mean loss = 1.0136487e-08
step 200: mean loss = 9.952059e-09
step 300: mean loss = 9.930311e-09
epoch 615: mean loss = 9.906414e-09  learning rate = 6.267212e-05
============================
Start of epoch 616
step 0: mean loss = 4.2858335e-09
step 100: mean loss = 2.601232e-09
step 200: mean loss = 6.1838565e-09
step 300: mean loss = 7.3039192e-09
epoch 616: mean loss = 7.169252e-09  learning rate = 6.267212e-05
============================
Start of epoch 617
step 0: mean loss = 2.1428601e-09
step 100: mean loss = 9.6977955e-09
step 200: mean loss = 5.920079e-09
step 300: mean loss = 8.246377e-09
epoch 617: mean loss = 8.0677545e-09  learning rate = 6.267212e-05
============================
Start of epoch 618
step 0: mean loss = 2.2798345e-09
step 100: mean loss = 5.609664e-09
step 200: mean loss = 9.202914e-09
step 300: mean loss = 7.25445e-09
epoch 618: mean loss = 7.506235e-09  learning rate = 6.267212e-05
============================
Start of epoch 619
step 0: mean loss = 4.15353e-09
step 100: mean loss = 1.0260379e-08
step 200: mean loss = 7.730552e-09
step 300: mean loss = 8.1885005e-09
epoch 619: mean loss = 8.0200495e-09  learning rate = 6.267212e-05
============================
Start of epoch 620
step 0: mean loss = 2.3670013e-09
step 100: mean loss = 7.442404e-09
step 200: mean loss = 4.766017e-09
step 300: mean loss = 6.179493e-09
epoch 620: mean loss = 6.0648926e-09  learning rate = 5.9538517e-05
============================
Start of epoch 621
step 0: mean loss = 2.2898572e-09
step 100: mean loss = 8.44103e-09
step 200: mean loss = 6.5394636e-09
step 300: mean loss = 6.9267085e-09
epoch 621: mean loss = 6.883198e-09  learning rate = 5.9538517e-05
============================
Start of epoch 622
step 0: mean loss = 1.4426303e-08
step 100: mean loss = 7.93865e-09
step 200: mean loss = 8.164269e-09
step 300: mean loss = 8.3762e-09
epoch 622: mean loss = 8.192208e-09  learning rate = 5.9538517e-05
============================
Start of epoch 623
step 0: mean loss = 2.033464e-09
step 100: mean loss = 9.186641e-09
step 200: mean loss = 8.886065e-09
step 300: mean loss = 8.4061655e-09
epoch 623: mean loss = 8.495712e-09  learning rate = 5.9538517e-05
============================
Start of epoch 624
step 0: mean loss = 3.1647374e-09
step 100: mean loss = 2.5140268e-09
step 200: mean loss = 7.3469932e-09
step 300: mean loss = 7.5379605e-09
epoch 624: mean loss = 7.3828392e-09  learning rate = 5.9538517e-05
============================
Start of epoch 625
step 0: mean loss = 2.2681883e-09
step 100: mean loss = 1.0590009e-08
step 200: mean loss = 7.1625537e-09
step 300: mean loss = 6.454208e-09
epoch 625: mean loss = 6.3368977e-09  learning rate = 5.9538517e-05
============================
Start of epoch 626
step 0: mean loss = 3.0996115e-09
step 100: mean loss = 1.0375134e-08
step 200: mean loss = 7.5294375e-09
step 300: mean loss = 8.164569e-09
epoch 626: mean loss = 8.1901685e-09  learning rate = 5.9538517e-05
============================
Start of epoch 627
step 0: mean loss = 2.8720404e-09
step 100: mean loss = 8.458937e-09
step 200: mean loss = 8.077555e-09
step 300: mean loss = 8.026243e-09
epoch 627: mean loss = 7.86264e-09  learning rate = 5.9538517e-05
============================
Start of epoch 628
step 0: mean loss = 2.5704052e-09
step 100: mean loss = 6.9491812e-09
step 200: mean loss = 7.056947e-09
step 300: mean loss = 8.043979e-09
epoch 628: mean loss = 7.884952e-09  learning rate = 5.9538517e-05
============================
Start of epoch 629
step 0: mean loss = 2.158713e-09
step 100: mean loss = 7.915129e-09
step 200: mean loss = 8.69012e-09
step 300: mean loss = 6.595066e-09
epoch 629: mean loss = 6.4627375e-09  learning rate = 5.9538517e-05
============================
Start of epoch 630
step 0: mean loss = 2.0489919e-09
step 100: mean loss = 1.1122387e-08
step 200: mean loss = 8.514413e-09
step 300: mean loss = 7.871643e-09
epoch 630: mean loss = 7.711953e-09  learning rate = 5.9538517e-05
============================
Start of epoch 631
step 0: mean loss = 2.4536952e-09
step 100: mean loss = 8.92747e-09
step 200: mean loss = 8.848054e-09
step 300: mean loss = 8.63918e-09
epoch 631: mean loss = 8.46164e-09  learning rate = 5.9538517e-05
============================
Start of epoch 632
step 0: mean loss = 2.0481494e-09
step 100: mean loss = 1.000611e-08
step 200: mean loss = 6.6925807e-09
step 300: mean loss = 6.7306067e-09
epoch 632: mean loss = 6.594939e-09  learning rate = 5.9538517e-05
============================
Start of epoch 633
step 0: mean loss = 2.0423938e-09
step 100: mean loss = 1.2672703e-08
step 200: mean loss = 8.1865625e-09
step 300: mean loss = 7.9086435e-09
epoch 633: mean loss = 7.7643465e-09  learning rate = 5.9538517e-05
============================
Start of epoch 634
step 0: mean loss = 2.6173257e-09
step 100: mean loss = 8.531328e-09
step 200: mean loss = 9.431566e-09
step 300: mean loss = 9.131345e-09
epoch 634: mean loss = 9.23779e-09  learning rate = 5.9538517e-05
============================
Start of epoch 635
step 0: mean loss = 4.778467e-09
step 100: mean loss = 2.6135385e-09
step 200: mean loss = 5.971798e-09
step 300: mean loss = 6.4810033e-09
epoch 635: mean loss = 6.355125e-09  learning rate = 5.9538517e-05
============================
Start of epoch 636
step 0: mean loss = 2.0540154e-09
step 100: mean loss = 9.593557e-09
step 200: mean loss = 7.1156574e-09
step 300: mean loss = 7.2461512e-09
epoch 636: mean loss = 7.0997737e-09  learning rate = 5.9538517e-05
============================
Start of epoch 637
step 0: mean loss = 2.2859947e-09
step 100: mean loss = 9.570936e-09
step 200: mean loss = 8.045774e-09
step 300: mean loss = 7.312984e-09
epoch 637: mean loss = 7.1618813e-09  learning rate = 5.9538517e-05
============================
Start of epoch 638
step 0: mean loss = 2.2403848e-09
step 100: mean loss = 8.659298e-09
step 200: mean loss = 8.388961e-09
step 300: mean loss = 9.068197e-09
epoch 638: mean loss = 8.883605e-09  learning rate = 5.9538517e-05
============================
Start of epoch 639
step 0: mean loss = 2.6900269e-09
step 100: mean loss = 7.142991e-09
step 200: mean loss = 5.7824487e-09
step 300: mean loss = 7.747239e-09
epoch 639: mean loss = 7.755768e-09  learning rate = 5.9538517e-05
============================
Start of epoch 640
step 0: mean loss = 4.526345e-09
step 100: mean loss = 2.3639144e-09
step 200: mean loss = 7.386752e-09
step 300: mean loss = 7.094219e-09
epoch 640: mean loss = 6.9511787e-09  learning rate = 5.9538517e-05
============================
Start of epoch 641
step 0: mean loss = 2.0066924e-09
step 100: mean loss = 7.1535595e-09
step 200: mean loss = 6.1122427e-09
step 300: mean loss = 6.845636e-09
epoch 641: mean loss = 6.7228174e-09  learning rate = 5.9538517e-05
============================
Start of epoch 642
step 0: mean loss = 3.0326128e-09
step 100: mean loss = 7.248365e-09
step 200: mean loss = 7.6859665e-09
step 300: mean loss = 7.459335e-09
epoch 642: mean loss = 7.309549e-09  learning rate = 5.9538517e-05
============================
Start of epoch 643
step 0: mean loss = 2.5016198e-09
step 100: mean loss = 8.659092e-09
step 200: mean loss = 8.222689e-09
step 300: mean loss = 8.363767e-09
epoch 643: mean loss = 8.323487e-09  learning rate = 5.9538517e-05
============================
Start of epoch 644
step 0: mean loss = 5.633354e-09
step 100: mean loss = 6.373006e-09
step 200: mean loss = 7.554121e-09
step 300: mean loss = 7.22171e-09
epoch 644: mean loss = 7.0721597e-09  learning rate = 5.9538517e-05
============================
Start of epoch 645
step 0: mean loss = 2.1057864e-09
step 100: mean loss = 7.962169e-09
step 200: mean loss = 6.95899e-09
step 300: mean loss = 7.3856294e-09
epoch 645: mean loss = 7.2293598e-09  learning rate = 5.9538517e-05
============================
Start of epoch 646
step 0: mean loss = 2.0105952e-09
step 100: mean loss = 8.333214e-09
step 200: mean loss = 7.59471e-09
step 300: mean loss = 7.69777e-09
epoch 646: mean loss = 7.583791e-09  learning rate = 5.9538517e-05
============================
Start of epoch 647
step 0: mean loss = 2.4901299e-09
step 100: mean loss = 6.532831e-09
step 200: mean loss = 8.4856495e-09
step 300: mean loss = 8.360753e-09
epoch 647: mean loss = 8.315108e-09  learning rate = 5.9538517e-05
============================
Start of epoch 648
step 0: mean loss = 2.3508586e-09
step 100: mean loss = 4.103529e-09
step 200: mean loss = 5.590835e-09
step 300: mean loss = 6.879571e-09
epoch 648: mean loss = 6.746428e-09  learning rate = 5.9538517e-05
============================
Start of epoch 649
step 0: mean loss = 2.565956e-09
step 100: mean loss = 6.622095e-09
step 200: mean loss = 7.453736e-09
step 300: mean loss = 7.79736e-09
epoch 649: mean loss = 7.70153e-09  learning rate = 5.9538517e-05
============================
Start of epoch 650
step 0: mean loss = 3.2046767e-09
step 100: mean loss = 4.5872097e-09
step 200: mean loss = 7.0670008e-09
step 300: mean loss = 7.32944e-09
epoch 650: mean loss = 7.1780955e-09  learning rate = 5.9538517e-05
============================
Start of epoch 651
step 0: mean loss = 2.263555e-09
step 100: mean loss = 7.942397e-09
step 200: mean loss = 8.814678e-09
step 300: mean loss = 7.482052e-09
epoch 651: mean loss = 7.3260282e-09  learning rate = 5.9538517e-05
============================
Start of epoch 652
step 0: mean loss = 2.1161188e-09
step 100: mean loss = 7.3199864e-09
step 200: mean loss = 8.258814e-09
step 300: mean loss = 7.771816e-09
epoch 652: mean loss = 7.605272e-09  learning rate = 5.9538517e-05
============================
Start of epoch 653
step 0: mean loss = 2.0471933e-09
step 100: mean loss = 1.0534083e-08
step 200: mean loss = 8.822646e-09
step 300: mean loss = 8.378571e-09
epoch 653: mean loss = 8.209713e-09  learning rate = 5.9538517e-05
============================
Start of epoch 654
step 0: mean loss = 2.1362996e-09
step 100: mean loss = 8.319e-09
step 200: mean loss = 6.8709562e-09
step 300: mean loss = 7.5413205e-09
epoch 654: mean loss = 7.3964137e-09  learning rate = 5.9538517e-05
============================
Start of epoch 655
step 0: mean loss = 2.0262354e-09
step 100: mean loss = 6.865799e-09
step 200: mean loss = 7.3508963e-09
step 300: mean loss = 6.9080346e-09
epoch 655: mean loss = 6.8023382e-09  learning rate = 5.9538517e-05
============================
Start of epoch 656
step 0: mean loss = 6.320783e-09
step 100: mean loss = 7.892771e-09
step 200: mean loss = 8.227412e-09
step 300: mean loss = 7.5924405e-09
epoch 656: mean loss = 7.4320146e-09  learning rate = 5.9538517e-05
============================
Start of epoch 657
step 0: mean loss = 2.0420767e-09
step 100: mean loss = 9.347332e-09
step 200: mean loss = 9.480348e-09
step 300: mean loss = 8.772796e-09
epoch 657: mean loss = 8.727124e-09  learning rate = 5.9538517e-05
============================
Start of epoch 658
step 0: mean loss = 2.2637978e-09
step 100: mean loss = 6.915026e-09
step 200: mean loss = 7.537496e-09
step 300: mean loss = 5.8799774e-09
epoch 658: mean loss = 7.239479e-09  learning rate = 5.9538517e-05
============================
Start of epoch 659
step 0: mean loss = 3.4774697e-08
step 100: mean loss = 9.186921e-09
step 200: mean loss = 5.8342593e-09
step 300: mean loss = 7.2349065e-09
epoch 659: mean loss = 7.156634e-09  learning rate = 5.9538517e-05
============================
Start of epoch 660
step 0: mean loss = 4.3636224e-09
step 100: mean loss = 9.019428e-09
step 200: mean loss = 8.55729e-09
step 300: mean loss = 6.393695e-09
epoch 660: mean loss = 6.265581e-09  learning rate = 5.6561592e-05
============================
Start of epoch 661
step 0: mean loss = 1.982559e-09
step 100: mean loss = 8.2300655e-09
step 200: mean loss = 5.6227973e-09
step 300: mean loss = 5.9569722e-09
epoch 661: mean loss = 6.2461214e-09  learning rate = 5.6561592e-05
============================
Start of epoch 662
step 0: mean loss = 2.5159672e-08
step 100: mean loss = 8.286473e-09
step 200: mean loss = 6.170669e-09
step 300: mean loss = 6.6551253e-09
epoch 662: mean loss = 6.525262e-09  learning rate = 5.6561592e-05
============================
Start of epoch 663
step 0: mean loss = 2.404993e-09
step 100: mean loss = 8.200357e-09
step 200: mean loss = 8.15796e-09
step 300: mean loss = 7.3033823e-09
epoch 663: mean loss = 7.1488904e-09  learning rate = 5.6561592e-05
============================
Start of epoch 664
step 0: mean loss = 1.9837036e-09
step 100: mean loss = 1.4407003e-08
step 200: mean loss = 8.262767e-09
step 300: mean loss = 8.188972e-09
epoch 664: mean loss = 8.019147e-09  learning rate = 5.6561592e-05
============================
Start of epoch 665
step 0: mean loss = 2.0946191e-09
step 100: mean loss = 6.6579324e-09
step 200: mean loss = 6.9674417e-09
step 300: mean loss = 5.468947e-09
epoch 665: mean loss = 5.5880354e-09  learning rate = 5.6561592e-05
============================
Start of epoch 666
step 0: mean loss = 3.3126312e-08
step 100: mean loss = 8.965892e-09
step 200: mean loss = 7.747962e-09
step 300: mean loss = 8.066689e-09
epoch 666: mean loss = 7.890376e-09  learning rate = 5.6561592e-05
============================
Start of epoch 667
step 0: mean loss = 2.006277e-09
step 100: mean loss = 6.962104e-09
step 200: mean loss = 6.813015e-09
step 300: mean loss = 6.8782824e-09
epoch 667: mean loss = 6.7412267e-09  learning rate = 5.6561592e-05
============================
Start of epoch 668
step 0: mean loss = 2.2414057e-09
step 100: mean loss = 6.4417853e-09
step 200: mean loss = 7.099875e-09
step 300: mean loss = 7.4404265e-09
epoch 668: mean loss = 7.2940587e-09  learning rate = 5.6561592e-05
============================
Start of epoch 669
step 0: mean loss = 2.3972362e-09
step 100: mean loss = 8.828735e-09
step 200: mean loss = 7.933029e-09
step 300: mean loss = 6.678592e-09
epoch 669: mean loss = 6.5417862e-09  learning rate = 5.6561592e-05
============================
Start of epoch 670
step 0: mean loss = 1.9684843e-09
step 100: mean loss = 1.0420002e-08
step 200: mean loss = 8.078844e-09
step 300: mean loss = 7.2396853e-09
epoch 670: mean loss = 7.1089574e-09  learning rate = 5.6561592e-05
============================
Start of epoch 671
step 0: mean loss = 2.0247195e-09
step 100: mean loss = 7.3120265e-09
step 200: mean loss = 7.0471122e-09
step 300: mean loss = 7.1413213e-09
epoch 671: mean loss = 6.9942594e-09  learning rate = 5.6561592e-05
============================
Start of epoch 672
step 0: mean loss = 1.9662993e-09
step 100: mean loss = 8.8427345e-09
step 200: mean loss = 5.437204e-09
step 300: mean loss = 8.099441e-09
epoch 672: mean loss = 7.937484e-09  learning rate = 5.6561592e-05
============================
Start of epoch 673
step 0: mean loss = 2.5573614e-09
step 100: mean loss = 7.4621385e-09
step 200: mean loss = 5.8653424e-09
step 300: mean loss = 6.6485595e-09
epoch 673: mean loss = 6.547346e-09  learning rate = 5.6561592e-05
============================
Start of epoch 674
step 0: mean loss = 2.3724207e-09
step 100: mean loss = 7.370714e-09
step 200: mean loss = 6.344558e-09
step 300: mean loss = 6.5877557e-09
epoch 674: mean loss = 6.463921e-09  learning rate = 5.6561592e-05
============================
Start of epoch 675
step 0: mean loss = 2.6215412e-09
step 100: mean loss = 7.42203e-09
step 200: mean loss = 6.563364e-09
step 300: mean loss = 6.971126e-09
epoch 675: mean loss = 6.8264994e-09  learning rate = 5.6561592e-05
============================
Start of epoch 676
step 0: mean loss = 1.9560944e-09
step 100: mean loss = 6.106533e-09
step 200: mean loss = 6.06647e-09
step 300: mean loss = 6.6319354e-09
epoch 676: mean loss = 6.5052546e-09  learning rate = 5.6561592e-05
============================
Start of epoch 677
step 0: mean loss = 2.9715779e-09
step 100: mean loss = 6.394546e-09
step 200: mean loss = 7.700996e-09
step 300: mean loss = 7.7212965e-09
epoch 677: mean loss = 7.554084e-09  learning rate = 5.6561592e-05
============================
Start of epoch 678
step 0: mean loss = 1.9531645e-09
step 100: mean loss = 8.209818e-09
step 200: mean loss = 7.575603e-09
step 300: mean loss = 7.489421e-09
epoch 678: mean loss = 7.486584e-09  learning rate = 5.6561592e-05
============================
Start of epoch 679
step 0: mean loss = 6.5748957e-09
step 100: mean loss = 6.8726163e-09
step 200: mean loss = 5.058338e-09
step 300: mean loss = 6.6634582e-09
epoch 679: mean loss = 6.7561654e-09  learning rate = 5.6561592e-05
============================
Start of epoch 680
step 0: mean loss = 1.2389405e-08
step 100: mean loss = 5.6196137e-09
step 200: mean loss = 6.0163754e-09
step 300: mean loss = 6.402441e-09
epoch 680: mean loss = 6.2751013e-09  learning rate = 5.6561592e-05
============================
Start of epoch 681
step 0: mean loss = 2.0205004e-09
step 100: mean loss = 7.676334e-09
step 200: mean loss = 6.7596195e-09
step 300: mean loss = 7.0993917e-09
epoch 681: mean loss = 6.9506796e-09  learning rate = 5.6561592e-05
============================
Start of epoch 682
step 0: mean loss = 1.9884547e-09
step 100: mean loss = 6.72893e-09
step 200: mean loss = 6.193863e-09
step 300: mean loss = 7.3200734e-09
epoch 682: mean loss = 7.1655295e-09  learning rate = 5.6561592e-05
============================
Start of epoch 683
step 0: mean loss = 1.9849122e-09
step 100: mean loss = 7.623504e-09
step 200: mean loss = 5.975228e-09
step 300: mean loss = 6.595692e-09
epoch 683: mean loss = 6.4918932e-09  learning rate = 5.6561592e-05
============================
Start of epoch 684
step 0: mean loss = 2.3269242e-09
step 100: mean loss = 7.970903e-09
step 200: mean loss = 6.9401778e-09
step 300: mean loss = 7.6813e-09
epoch 684: mean loss = 7.527293e-09  learning rate = 5.6561592e-05
============================
Start of epoch 685
step 0: mean loss = 2.318196e-09
step 100: mean loss = 4.7602167e-09
step 200: mean loss = 5.505299e-09
step 300: mean loss = 5.673106e-09
epoch 685: mean loss = 6.203811e-09  learning rate = 5.6561592e-05
============================
Start of epoch 686
step 0: mean loss = 6.627563e-08
step 100: mean loss = 8.464626e-09
step 200: mean loss = 6.0441216e-09
step 300: mean loss = 7.724488e-09
epoch 686: mean loss = 7.556635e-09  learning rate = 5.6561592e-05
============================
Start of epoch 687
step 0: mean loss = 1.9396242e-09
step 100: mean loss = 6.6260735e-09
step 200: mean loss = 6.978395e-09
step 300: mean loss = 6.6044765e-09
epoch 687: mean loss = 6.497593e-09  learning rate = 5.6561592e-05
============================
Start of epoch 688
step 0: mean loss = 3.221291e-09
step 100: mean loss = 5.612532e-09
step 200: mean loss = 6.325552e-09
step 300: mean loss = 6.8122468e-09
epoch 688: mean loss = 7.1745396e-09  learning rate = 5.6561592e-05
============================
Start of epoch 689
step 0: mean loss = 3.700555e-08
step 100: mean loss = 4.147306e-09
step 200: mean loss = 7.1874555e-09
step 300: mean loss = 6.8023653e-09
epoch 689: mean loss = 6.6622965e-09  learning rate = 5.6561592e-05
============================
Start of epoch 690
step 0: mean loss = 1.9391284e-09
step 100: mean loss = 8.220603e-09
step 200: mean loss = 7.739696e-09
step 300: mean loss = 8.169073e-09
epoch 690: mean loss = 7.993889e-09  learning rate = 5.6561592e-05
============================
Start of epoch 691
step 0: mean loss = 2.0403097e-09
step 100: mean loss = 2.1295978e-09
step 200: mean loss = 5.842444e-09
step 300: mean loss = 6.8321513e-09
epoch 691: mean loss = 6.867246e-09  learning rate = 5.6561592e-05
============================
Start of epoch 692
step 0: mean loss = 2.2762734e-09
step 100: mean loss = 5.351248e-09
step 200: mean loss = 6.4051964e-09
step 300: mean loss = 5.6254685e-09
epoch 692: mean loss = 5.5613296e-09  learning rate = 5.6561592e-05
============================
Start of epoch 693
step 0: mean loss = 2.6780895e-09
step 100: mean loss = 8.596771e-09
step 200: mean loss = 7.366171e-09
step 300: mean loss = 7.605003e-09
epoch 693: mean loss = 7.443084e-09  learning rate = 5.6561592e-05
============================
Start of epoch 694
step 0: mean loss = 2.241461e-09
step 100: mean loss = 6.421653e-09
step 200: mean loss = 6.6690045e-09
step 300: mean loss = 6.252917e-09
epoch 694: mean loss = 6.3813066e-09  learning rate = 5.6561592e-05
============================
Start of epoch 695
step 0: mean loss = 1.3115605e-08
step 100: mean loss = 7.0668755e-09
step 200: mean loss = 7.0354926e-09
step 300: mean loss = 6.8623716e-09
epoch 695: mean loss = 7.1249535e-09  learning rate = 5.6561592e-05
============================
Start of epoch 696
step 0: mean loss = 6.7527797e-09
step 100: mean loss = 7.884479e-09
step 200: mean loss = 6.9840187e-09
step 300: mean loss = 7.489803e-09
epoch 696: mean loss = 7.3430364e-09  learning rate = 5.6561592e-05
============================
Start of epoch 697
step 0: mean loss = 2.5031537e-09
step 100: mean loss = 6.0964656e-09
step 200: mean loss = 6.790283e-09
step 300: mean loss = 7.1074444e-09
epoch 697: mean loss = 7.0324417e-09  learning rate = 5.6561592e-05
============================
Start of epoch 698
step 0: mean loss = 2.0440796e-09
step 100: mean loss = 6.7476638e-09
step 200: mean loss = 7.304123e-09
step 300: mean loss = 6.4164882e-09
epoch 698: mean loss = 6.912814e-09  learning rate = 5.6561592e-05
============================
Start of epoch 699
step 0: mean loss = 2.8409477e-09
step 100: mean loss = 6.277311e-09
step 200: mean loss = 5.6298024e-09
step 300: mean loss = 6.3096364e-09
epoch 699: mean loss = 6.368022e-09  learning rate = 5.6561592e-05
============================
Start of epoch 700
step 0: mean loss = 1.77182e-08
step 100: mean loss = 8.291252e-09
step 200: mean loss = 6.8329618e-09
step 300: mean loss = 7.897251e-09
epoch 700: mean loss = 7.775133e-09  learning rate = 5.3733507e-05
============================
Start of epoch 701
step 0: mean loss = 3.1304956e-09
step 100: mean loss = 2.0351243e-09
step 200: mean loss = 2.6759384e-09
step 300: mean loss = 4.3200545e-09
epoch 701: mean loss = 4.320257e-09  learning rate = 5.3733507e-05
============================
Start of epoch 702
step 0: mean loss = 2.800694e-09
step 100: mean loss = 4.230986e-09
step 200: mean loss = 5.1970237e-09
step 300: mean loss = 5.902793e-09
epoch 702: mean loss = 5.7970815e-09  learning rate = 5.3733507e-05
============================
Start of epoch 703
step 0: mean loss = 2.2854634e-09
step 100: mean loss = 8.386163e-09
step 200: mean loss = 6.897604e-09
step 300: mean loss = 7.3501205e-09
epoch 703: mean loss = 7.1958253e-09  learning rate = 5.3733507e-05
============================
Start of epoch 704
step 0: mean loss = 1.9416688e-09
step 100: mean loss = 4.3634527e-09
step 200: mean loss = 5.292407e-09
step 300: mean loss = 6.43844e-09
epoch 704: mean loss = 6.422821e-09  learning rate = 5.3733507e-05
============================
Start of epoch 705
step 0: mean loss = 6.06095e-09
step 100: mean loss = 4.7456004e-09
step 200: mean loss = 5.788694e-09
step 300: mean loss = 6.0480065e-09
epoch 705: mean loss = 5.933528e-09  learning rate = 5.3733507e-05
============================
Start of epoch 706
step 0: mean loss = 1.9171273e-09
step 100: mean loss = 9.35264e-09
step 200: mean loss = 5.801037e-09
step 300: mean loss = 6.6705943e-09
epoch 706: mean loss = 6.600712e-09  learning rate = 5.3733507e-05
============================
Start of epoch 707
step 0: mean loss = 4.659423e-09
step 100: mean loss = 8.232302e-09
step 200: mean loss = 7.124932e-09
step 300: mean loss = 5.81912e-09
epoch 707: mean loss = 5.7118243e-09  learning rate = 5.3733507e-05
============================
Start of epoch 708
step 0: mean loss = 2.38363e-09
step 100: mean loss = 6.7021104e-09
step 200: mean loss = 7.93051e-09
step 300: mean loss = 6.352943e-09
epoch 708: mean loss = 6.23143e-09  learning rate = 5.3733507e-05
============================
Start of epoch 709
step 0: mean loss = 2.771125e-09
step 100: mean loss = 8.14169e-09
step 200: mean loss = 7.394022e-09
step 300: mean loss = 7.307521e-09
epoch 709: mean loss = 7.1567765e-09  learning rate = 5.3733507e-05
============================
Start of epoch 710
step 0: mean loss = 2.0894009e-09
step 100: mean loss = 4.247878e-09
step 200: mean loss = 6.8864767e-09
step 300: mean loss = 7.1243953e-09
epoch 710: mean loss = 6.9991417e-09  learning rate = 5.3733507e-05
============================
Start of epoch 711
step 0: mean loss = 2.232259e-09
step 100: mean loss = 2.306156e-09
step 200: mean loss = 6.220358e-09
step 300: mean loss = 6.0365415e-09
epoch 711: mean loss = 6.1144423e-09  learning rate = 5.3733507e-05
============================
Start of epoch 712
step 0: mean loss = 3.1540568e-09
step 100: mean loss = 6.9355695e-09
step 200: mean loss = 6.3072223e-09
step 300: mean loss = 7.1203035e-09
epoch 712: mean loss = 6.969369e-09  learning rate = 5.3733507e-05
============================
Start of epoch 713
step 0: mean loss = 1.9203379e-09
step 100: mean loss = 2.6904e-09
step 200: mean loss = 4.124563e-09
step 300: mean loss = 6.880956e-09
epoch 713: mean loss = 7.0176496e-09  learning rate = 5.3733507e-05
============================
Start of epoch 714
step 0: mean loss = 4.1246175e-09
step 100: mean loss = 2.6327975e-09
step 200: mean loss = 5.46055e-09
step 300: mean loss = 4.751848e-09
epoch 714: mean loss = 4.7005098e-09  learning rate = 5.3733507e-05
============================
Start of epoch 715
step 0: mean loss = 2.7517817e-09
step 100: mean loss = 6.34151e-09
step 200: mean loss = 6.5830896e-09
step 300: mean loss = 6.0729524e-09
epoch 715: mean loss = 7.2228974e-09  learning rate = 5.3733507e-05
============================
Start of epoch 716
step 0: mean loss = 4.377416e-08
step 100: mean loss = 7.95889e-09
step 200: mean loss = 5.1994387e-09
step 300: mean loss = 7.1411694e-09
epoch 716: mean loss = 6.989668e-09  learning rate = 5.3733507e-05
============================
Start of epoch 717
step 0: mean loss = 1.9252624e-09
step 100: mean loss = 3.6560748e-09
step 200: mean loss = 6.695294e-09
step 300: mean loss = 5.4319558e-09
epoch 717: mean loss = 5.3298366e-09  learning rate = 5.3733507e-05
============================
Start of epoch 718
step 0: mean loss = 1.904394e-09
step 100: mean loss = 6.3812466e-09
step 200: mean loss = 6.974967e-09
step 300: mean loss = 7.403039e-09
epoch 718: mean loss = 7.2820168e-09  learning rate = 5.3733507e-05
============================
Start of epoch 719
step 0: mean loss = 3.213713e-09
step 100: mean loss = 7.0919937e-09
step 200: mean loss = 4.57226e-09
step 300: mean loss = 5.9509366e-09
epoch 719: mean loss = 5.8337357e-09  learning rate = 5.3733507e-05
============================
Start of epoch 720
step 0: mean loss = 1.8998312e-09
step 100: mean loss = 5.806378e-09
step 200: mean loss = 6.5693255e-09
step 300: mean loss = 5.8886913e-09
epoch 720: mean loss = 6.2693837e-09  learning rate = 5.3733507e-05
============================
Start of epoch 721
step 0: mean loss = 2.5448994e-08
step 100: mean loss = 5.527005e-09
step 200: mean loss = 6.070815e-09
step 300: mean loss = 6.743605e-09
epoch 721: mean loss = 6.6086203e-09  learning rate = 5.3733507e-05
============================
Start of epoch 722
step 0: mean loss = 2.0766266e-09
step 100: mean loss = 7.428601e-09
step 200: mean loss = 7.627439e-09
step 300: mean loss = 5.8668395e-09
epoch 722: mean loss = 5.751471e-09  learning rate = 5.3733507e-05
============================
Start of epoch 723
step 0: mean loss = 1.9076258e-09
step 100: mean loss = 8.273562e-09
step 200: mean loss = 6.764371e-09
step 300: mean loss = 7.3277824e-09
epoch 723: mean loss = 7.1783433e-09  learning rate = 5.3733507e-05
============================
Start of epoch 724
step 0: mean loss = 2.3317528e-09
step 100: mean loss = 4.8761652e-09
step 200: mean loss = 5.712043e-09
step 300: mean loss = 5.928148e-09
epoch 724: mean loss = 5.813943e-09  learning rate = 5.3733507e-05
============================
Start of epoch 725
step 0: mean loss = 2.0464213e-09
step 100: mean loss = 5.1583156e-09
step 200: mean loss = 7.3339814e-09
step 300: mean loss = 6.701048e-09
epoch 725: mean loss = 7.0107102e-09  learning rate = 5.3733507e-05
============================
Start of epoch 726
step 0: mean loss = 1.1463011e-08
step 100: mean loss = 2.7233797e-09
step 200: mean loss = 6.5925927e-09
step 300: mean loss = 6.782918e-09
epoch 726: mean loss = 6.7642207e-09  learning rate = 5.3733507e-05
============================
Start of epoch 727
step 0: mean loss = 5.052986e-09
step 100: mean loss = 2.2680637e-09
step 200: mean loss = 5.8224203e-09
step 300: mean loss = 5.7864216e-09
epoch 727: mean loss = 5.881201e-09  learning rate = 5.3733507e-05
============================
Start of epoch 728
step 0: mean loss = 2.6302542e-09
step 100: mean loss = 5.2061098e-09
step 200: mean loss = 5.7041873e-09
step 300: mean loss = 5.818361e-09
epoch 728: mean loss = 5.7320535e-09  learning rate = 5.3733507e-05
============================
Start of epoch 729
step 0: mean loss = 4.0409587e-09
step 100: mean loss = 5.7764096e-09
step 200: mean loss = 6.653752e-09
step 300: mean loss = 5.9548118e-09
epoch 729: mean loss = 5.840467e-09  learning rate = 5.3733507e-05
============================
Start of epoch 730
step 0: mean loss = 2.3368576e-09
step 100: mean loss = 9.500539e-09
step 200: mean loss = 7.751321e-09
step 300: mean loss = 7.95495e-09
epoch 730: mean loss = 7.78411e-09  learning rate = 5.3733507e-05
============================
Start of epoch 731
step 0: mean loss = 2.0480957e-09
step 100: mean loss = 5.7904805e-09
step 200: mean loss = 7.32174e-09
step 300: mean loss = 5.6315437e-09
epoch 731: mean loss = 5.5247877e-09  learning rate = 5.3733507e-05
============================
Start of epoch 732
step 0: mean loss = 2.1426494e-09
step 100: mean loss = 6.731741e-09
step 200: mean loss = 6.565957e-09
step 300: mean loss = 7.3419324e-09
epoch 732: mean loss = 7.193815e-09  learning rate = 5.3733507e-05
============================
Start of epoch 733
step 0: mean loss = 1.8862765e-09
step 100: mean loss = 4.508523e-09
step 200: mean loss = 4.7539594e-09
step 300: mean loss = 5.5328666e-09
epoch 733: mean loss = 5.441561e-09  learning rate = 5.3733507e-05
============================
Start of epoch 734
step 0: mean loss = 1.8893558e-09
step 100: mean loss = 7.4313697e-09
step 200: mean loss = 6.2846044e-09
step 300: mean loss = 6.8948878e-09
epoch 734: mean loss = 6.794144e-09  learning rate = 5.3733507e-05
============================
Start of epoch 735
step 0: mean loss = 4.531661e-09
step 100: mean loss = 7.1960864e-09
step 200: mean loss = 6.151669e-09
step 300: mean loss = 6.2238996e-09
epoch 735: mean loss = 6.126385e-09  learning rate = 5.3733507e-05
============================
Start of epoch 736
step 0: mean loss = 3.6903913e-09
step 100: mean loss = 7.668083e-09
step 200: mean loss = 5.989638e-09
step 300: mean loss = 6.4751347e-09
epoch 736: mean loss = 6.353799e-09  learning rate = 5.3733507e-05
============================
Start of epoch 737
step 0: mean loss = 2.154965e-09
step 100: mean loss = 6.153404e-09
step 200: mean loss = 6.0715504e-09
step 300: mean loss = 5.893497e-09
epoch 737: mean loss = 6.1305196e-09  learning rate = 5.3733507e-05
============================
Start of epoch 738
step 0: mean loss = 5.972277e-08
step 100: mean loss = 9.024448e-09
step 200: mean loss = 6.9247847e-09
step 300: mean loss = 7.225554e-09
epoch 738: mean loss = 7.077781e-09  learning rate = 5.3733507e-05
============================
Start of epoch 739
step 0: mean loss = 2.0711817e-09
step 100: mean loss = 5.193401e-09
step 200: mean loss = 6.0642478e-09
step 300: mean loss = 6.2201995e-09
epoch 739: mean loss = 6.1021335e-09  learning rate = 5.3733507e-05
============================
Start of epoch 740
step 0: mean loss = 2.1751103e-09
step 100: mean loss = 5.7923533e-09
step 200: mean loss = 7.2546427e-09
step 300: mean loss = 6.8816677e-09
epoch 740: mean loss = 6.7447687e-09  learning rate = 5.3733507e-05
============================
Start of epoch 741
step 0: mean loss = 2.1304127e-09
step 100: mean loss = 9.732321e-09
step 200: mean loss = 5.898649e-09
step 300: mean loss = 4.6088733e-09
epoch 741: mean loss = 4.574223e-09  learning rate = 5.104683e-05
============================
Start of epoch 742
step 0: mean loss = 4.401996e-09
step 100: mean loss = 5.001349e-09
step 200: mean loss = 5.322035e-09
step 300: mean loss = 5.570881e-09
epoch 742: mean loss = 5.475161e-09  learning rate = 5.104683e-05
============================
Start of epoch 743
step 0: mean loss = 3.3249028e-09
step 100: mean loss = 6.814907e-09
step 200: mean loss = 6.80899e-09
step 300: mean loss = 6.4781864e-09
epoch 743: mean loss = 6.3642407e-09  learning rate = 5.104683e-05
============================
Start of epoch 744
step 0: mean loss = 2.1457096e-09
step 100: mean loss = 4.243527e-09
step 200: mean loss = 5.490632e-09
step 300: mean loss = 5.4635976e-09
epoch 744: mean loss = 5.7406946e-09  learning rate = 5.104683e-05
============================
Start of epoch 745
step 0: mean loss = 2.8000104e-09
step 100: mean loss = 7.038935e-09
step 200: mean loss = 6.2074372e-09
step 300: mean loss = 6.2324883e-09
epoch 745: mean loss = 6.1073764e-09  learning rate = 5.104683e-05
============================
Start of epoch 746
step 0: mean loss = 1.9937232e-09
step 100: mean loss = 5.008772e-09
step 200: mean loss = 5.1684883e-09
step 300: mean loss = 5.9640493e-09
epoch 746: mean loss = 6.043565e-09  learning rate = 5.104683e-05
============================
Start of epoch 747
step 0: mean loss = 7.552816e-09
step 100: mean loss = 3.9600345e-09
step 200: mean loss = 5.3057754e-09
step 300: mean loss = 4.9889968e-09
epoch 747: mean loss = 5.575917e-09  learning rate = 5.104683e-05
============================
Start of epoch 748
step 0: mean loss = 1.6597573e-08
step 100: mean loss = 7.371707e-09
step 200: mean loss = 5.5391696e-09
step 300: mean loss = 6.108164e-09
epoch 748: mean loss = 5.992487e-09  learning rate = 5.104683e-05
============================
Start of epoch 749
step 0: mean loss = 2.310272e-09
step 100: mean loss = 4.3281316e-09
step 200: mean loss = 5.854651e-09
step 300: mean loss = 6.1565446e-09
epoch 749: mean loss = 6.04013e-09  learning rate = 5.104683e-05
============================
Start of epoch 750
step 0: mean loss = 1.9185071e-09
step 100: mean loss = 5.1965707e-09
step 200: mean loss = 6.134568e-09
step 300: mean loss = 5.99395e-09
epoch 750: mean loss = 5.8799623e-09  learning rate = 5.104683e-05
============================
Start of epoch 751
step 0: mean loss = 1.98582e-09
step 100: mean loss = 6.6114176e-09
step 200: mean loss = 5.8883844e-09
step 300: mean loss = 6.0115637e-09
epoch 751: mean loss = 6.063738e-09  learning rate = 5.104683e-05
============================
Start of epoch 752
step 0: mean loss = 7.488893e-09
step 100: mean loss = 6.872246e-09
step 200: mean loss = 4.7192636e-09
step 300: mean loss = 5.4093228e-09
epoch 752: mean loss = 6.1101497e-09  learning rate = 5.104683e-05
============================
Start of epoch 753
step 0: mean loss = 2.7399789e-08
step 100: mean loss = 3.3514556e-09
step 200: mean loss = 5.3611626e-09
step 300: mean loss = 5.2426543e-09
epoch 753: mean loss = 5.1449893e-09  learning rate = 5.104683e-05
============================
Start of epoch 754
step 0: mean loss = 1.8817539e-09
step 100: mean loss = 7.387732e-09
step 200: mean loss = 5.9658576e-09
step 300: mean loss = 6.5980297e-09
epoch 754: mean loss = 6.4611045e-09  learning rate = 5.104683e-05
============================
Start of epoch 755
step 0: mean loss = 1.8631168e-09
step 100: mean loss = 4.843271e-09
step 200: mean loss = 5.739294e-09
step 300: mean loss = 5.218548e-09
epoch 755: mean loss = 5.1717284e-09  learning rate = 5.104683e-05
============================
Start of epoch 756
step 0: mean loss = 7.765404e-09
step 100: mean loss = 5.8179386e-09
step 200: mean loss = 7.790759e-09
step 300: mean loss = 5.972735e-09
epoch 756: mean loss = 6.138931e-09  learning rate = 5.104683e-05
============================
Start of epoch 757
step 0: mean loss = 1.6473306e-08
step 100: mean loss = 5.6031753e-09
step 200: mean loss = 6.3273737e-09
step 300: mean loss = 6.547514e-09
epoch 757: mean loss = 6.411717e-09  learning rate = 5.104683e-05
============================
Start of epoch 758
step 0: mean loss = 1.8637505e-09
step 100: mean loss = 5.557823e-09
step 200: mean loss = 5.2230797e-09
step 300: mean loss = 5.4282694e-09
epoch 758: mean loss = 5.6428147e-09  learning rate = 5.104683e-05
============================
Start of epoch 759
step 0: mean loss = 8.0590645e-09
step 100: mean loss = 7.236134e-09
step 200: mean loss = 6.5263155e-09
step 300: mean loss = 6.4043006e-09
epoch 759: mean loss = 6.586455e-09  learning rate = 5.104683e-05
============================
Start of epoch 760
step 0: mean loss = 1.2348096e-08
step 100: mean loss = 2.4695106e-09
step 200: mean loss = 4.9528683e-09
step 300: mean loss = 5.57382e-09
epoch 760: mean loss = 5.4724185e-09  learning rate = 5.104683e-05
============================
Start of epoch 761
step 0: mean loss = 2.0591207e-09
step 100: mean loss = 6.6814914e-09
step 200: mean loss = 4.507745e-09
step 300: mean loss = 5.6665086e-09
epoch 761: mean loss = 5.5823772e-09  learning rate = 5.104683e-05
============================
Start of epoch 762
step 0: mean loss = 5.255519e-09
step 100: mean loss = 5.312485e-09
step 200: mean loss = 5.6721445e-09
step 300: mean loss = 6.452825e-09
epoch 762: mean loss = 6.649714e-09  learning rate = 5.104683e-05
============================
Start of epoch 763
step 0: mean loss = 1.3933828e-08
step 100: mean loss = 2.5232143e-09
step 200: mean loss = 4.654133e-09
step 300: mean loss = 5.1059645e-09
epoch 763: mean loss = 5.0133617e-09  learning rate = 5.104683e-05
============================
Start of epoch 764
step 0: mean loss = 2.2062259e-09
step 100: mean loss = 8.125004e-09
step 200: mean loss = 7.104458e-09
step 300: mean loss = 6.8240626e-09
epoch 764: mean loss = 6.756455e-09  learning rate = 5.104683e-05
============================
Start of epoch 765
step 0: mean loss = 3.187659e-09
step 100: mean loss = 2.5738238e-09
step 200: mean loss = 4.8735083e-09
step 300: mean loss = 5.049244e-09
epoch 765: mean loss = 5.379359e-09  learning rate = 5.104683e-05
============================
Start of epoch 766
step 0: mean loss = 4.0565425e-08
step 100: mean loss = 4.7987725e-09
step 200: mean loss = 6.032597e-09
step 300: mean loss = 5.2592433e-09
epoch 766: mean loss = 5.203256e-09  learning rate = 5.104683e-05
============================
Start of epoch 767
step 0: mean loss = 7.600674e-09
step 100: mean loss = 8.7739e-09
step 200: mean loss = 7.13127e-09
step 300: mean loss = 6.3538e-09
epoch 767: mean loss = 6.2283423e-09  learning rate = 5.104683e-05
============================
Start of epoch 768
step 0: mean loss = 1.9762447e-09
step 100: mean loss = 7.2077144e-09
step 200: mean loss = 5.4557527e-09
step 300: mean loss = 5.676663e-09
epoch 768: mean loss = 5.565924e-09  learning rate = 5.104683e-05
============================
Start of epoch 769
step 0: mean loss = 1.9792625e-09
step 100: mean loss = 8.489522e-09
step 200: mean loss = 6.3859327e-09
step 300: mean loss = 6.2059544e-09
epoch 769: mean loss = 6.101306e-09  learning rate = 5.104683e-05
============================
Start of epoch 770
step 0: mean loss = 5.7915206e-09
step 100: mean loss = 7.2399065e-09
step 200: mean loss = 6.0512058e-09
step 300: mean loss = 6.3975616e-09
epoch 770: mean loss = 6.2656866e-09  learning rate = 5.104683e-05
============================
Start of epoch 771
step 0: mean loss = 1.8410893e-09
step 100: mean loss = 4.769396e-09
step 200: mean loss = 5.7724363e-09
step 300: mean loss = 5.570962e-09
epoch 771: mean loss = 5.4654623e-09  learning rate = 5.104683e-05
============================
Start of epoch 772
step 0: mean loss = 1.873281e-09
step 100: mean loss = 8.947869e-09
step 200: mean loss = 7.120008e-09
step 300: mean loss = 6.587971e-09
epoch 772: mean loss = 6.469463e-09  learning rate = 5.104683e-05
============================
Start of epoch 773
step 0: mean loss = 2.1632434e-09
step 100: mean loss = 3.4791068e-09
step 200: mean loss = 6.611441e-09
step 300: mean loss = 6.30234e-09
epoch 773: mean loss = 6.173281e-09  learning rate = 5.104683e-05
============================
Start of epoch 774
step 0: mean loss = 1.8310083e-09
step 100: mean loss = 8.553678e-09
step 200: mean loss = 5.522823e-09
step 300: mean loss = 5.7381158e-09
epoch 774: mean loss = 5.6250333e-09  learning rate = 5.104683e-05
============================
Start of epoch 775
step 0: mean loss = 1.8342206e-09
step 100: mean loss = 7.1423174e-09
step 200: mean loss = 5.9387464e-09
step 300: mean loss = 5.6040763e-09
epoch 775: mean loss = 5.495085e-09  learning rate = 5.104683e-05
============================
Start of epoch 776
step 0: mean loss = 1.9222377e-09
step 100: mean loss = 6.695728e-09
step 200: mean loss = 5.910574e-09
step 300: mean loss = 6.522839e-09
epoch 776: mean loss = 6.3867756e-09  learning rate = 5.104683e-05
============================
Start of epoch 777
step 0: mean loss = 1.8223267e-09
step 100: mean loss = 6.299122e-09
step 200: mean loss = 6.0233556e-09
step 300: mean loss = 5.6696505e-09
epoch 777: mean loss = 5.5608123e-09  learning rate = 5.104683e-05
============================
Start of epoch 778
step 0: mean loss = 1.8465878e-09
step 100: mean loss = 7.144384e-09
step 200: mean loss = 6.6378933e-09
step 300: mean loss = 6.3074648e-09
epoch 778: mean loss = 6.2152945e-09  learning rate = 5.104683e-05
============================
Start of epoch 779
step 0: mean loss = 1.9013566e-09
step 100: mean loss = 6.7932224e-09
step 200: mean loss = 6.2758283e-09
step 300: mean loss = 5.193414e-09
epoch 779: mean loss = 5.1138387e-09  learning rate = 5.104683e-05
============================
Start of epoch 780
step 0: mean loss = 3.898269e-09
step 100: mean loss = 8.321021e-09
step 200: mean loss = 6.005342e-09
step 300: mean loss = 6.7211365e-09
epoch 780: mean loss = 6.6236563e-09  learning rate = 5.104683e-05
============================
Start of epoch 781
step 0: mean loss = 4.7231663e-09
step 100: mean loss = 5.567921e-09
step 200: mean loss = 5.732109e-09
step 300: mean loss = 4.433462e-09
epoch 781: mean loss = 4.359824e-09  learning rate = 4.849449e-05
============================
Start of epoch 782
step 0: mean loss = 1.922452e-09
step 100: mean loss = 4.7996687e-09
step 200: mean loss = 5.150999e-09
step 300: mean loss = 6.2780243e-09
epoch 782: mean loss = 6.155065e-09  learning rate = 4.849449e-05
============================
Start of epoch 783
step 0: mean loss = 1.8393947e-09
step 100: mean loss = 1.8408318e-09
step 200: mean loss = 5.982346e-09
step 300: mean loss = 5.0217595e-09
epoch 783: mean loss = 5.0128635e-09  learning rate = 4.849449e-05
============================
Start of epoch 784
step 0: mean loss = 5.606507e-09
step 100: mean loss = 4.6403827e-09
step 200: mean loss = 4.7984905e-09
step 300: mean loss = 4.9416418e-09
epoch 784: mean loss = 4.894118e-09  learning rate = 4.849449e-05
============================
Start of epoch 785
step 0: mean loss = 8.855377e-09
step 100: mean loss = 6.555416e-09
step 200: mean loss = 6.470635e-09
step 300: mean loss = 5.684044e-09
epoch 785: mean loss = 5.860225e-09  learning rate = 4.849449e-05
============================
Start of epoch 786
step 0: mean loss = 1.04547375e-08
step 100: mean loss = 5.7916365e-09
step 200: mean loss = 5.2001687e-09
step 300: mean loss = 4.997088e-09
epoch 786: mean loss = 4.9146682e-09  learning rate = 4.849449e-05
============================
Start of epoch 787
step 0: mean loss = 2.8029967e-09
step 100: mean loss = 6.8327495e-09
step 200: mean loss = 5.4120304e-09
step 300: mean loss = 5.98422e-09
epoch 787: mean loss = 5.863105e-09  learning rate = 4.849449e-05
============================
Start of epoch 788
step 0: mean loss = 1.8307156e-09
step 100: mean loss = 7.756361e-09
step 200: mean loss = 6.432129e-09
step 300: mean loss = 6.391624e-09
epoch 788: mean loss = 6.3146275e-09  learning rate = 4.849449e-05
============================
Start of epoch 789
step 0: mean loss = 2.0221036e-09
step 100: mean loss = 3.661212e-09
step 200: mean loss = 4.5424056e-09
step 300: mean loss = 4.931495e-09
epoch 789: mean loss = 4.8474877e-09  learning rate = 4.849449e-05
============================
Start of epoch 790
step 0: mean loss = 2.2030422e-09
step 100: mean loss = 4.989111e-09
step 200: mean loss = 6.07481e-09
step 300: mean loss = 6.40919e-09
epoch 790: mean loss = 6.314535e-09  learning rate = 4.849449e-05
============================
Start of epoch 791
step 0: mean loss = 2.4342028e-09
step 100: mean loss = 1.908437e-09
step 200: mean loss = 4.7901985e-09
step 300: mean loss = 4.2949573e-09
epoch 791: mean loss = 4.332328e-09  learning rate = 4.849449e-05
============================
Start of epoch 792
step 0: mean loss = 9.5156665e-09
step 100: mean loss = 5.5175478e-09
step 200: mean loss = 5.37928e-09
step 300: mean loss = 5.5225464e-09
epoch 792: mean loss = 5.425379e-09  learning rate = 4.849449e-05
============================
Start of epoch 793
step 0: mean loss = 2.059983e-09
step 100: mean loss = 8.582917e-09
step 200: mean loss = 6.3650076e-09
step 300: mean loss = 6.2269976e-09
epoch 793: mean loss = 6.2152536e-09  learning rate = 4.849449e-05
============================
Start of epoch 794
step 0: mean loss = 2.7838647e-09
step 100: mean loss = 3.3772747e-09
step 200: mean loss = 5.0820246e-09
step 300: mean loss = 5.394341e-09
epoch 794: mean loss = 5.3438307e-09  learning rate = 4.849449e-05
============================
Start of epoch 795
step 0: mean loss = 2.0843234e-09
step 100: mean loss = 4.217895e-09
step 200: mean loss = 5.356569e-09
step 300: mean loss = 5.051892e-09
epoch 795: mean loss = 4.9817186e-09  learning rate = 4.849449e-05
============================
Start of epoch 796
step 0: mean loss = 2.095431e-09
step 100: mean loss = 4.462298e-09
step 200: mean loss = 4.6623008e-09
step 300: mean loss = 5.620815e-09
epoch 796: mean loss = 5.716553e-09  learning rate = 4.849449e-05
============================
Start of epoch 797
step 0: mean loss = 2.3158526e-09
step 100: mean loss = 4.302708e-09
step 200: mean loss = 5.5631006e-09
step 300: mean loss = 4.660417e-09
epoch 797: mean loss = 5.2989724e-09  learning rate = 4.849449e-05
============================
Start of epoch 798
step 0: mean loss = 2.7128186e-08
step 100: mean loss = 6.0978835e-09
step 200: mean loss = 6.432387e-09
step 300: mean loss = 5.6166716e-09
epoch 798: mean loss = 5.5056715e-09  learning rate = 4.849449e-05
============================
Start of epoch 799
step 0: mean loss = 1.7922867e-09
step 100: mean loss = 7.284227e-09
step 200: mean loss = 6.3303336e-09
step 300: mean loss = 4.897408e-09
epoch 799: mean loss = 5.2589897e-09  learning rate = 4.849449e-05
saving the weights
Relative Error in the forces is 0.00031922813
++++++++++++++++++++++++++++++
Start of cycle 3
Total number of epochs in this cycle: 1600
Batch size in this cycle: 64
============================
WARNING:tensorflow:9 out of the last 10 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:7 out of the last 9 calls to <function pyramidLayer.call at 0x7fcd14295280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:7 out of the last 9 calls to <function pyramidLayer.call at 0x7fcd142954c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:7 out of the last 9 calls to <function pyramidLayer.call at 0x7fcd14295700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:7 out of the last 9 calls to <function MyDenseLayer.call at 0x7fcd14295940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 11 calls to <function DeepMDsimpleEnergy.call at 0x7fccf0380af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
2020-08-27 22:46:36.311802: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
2020-08-27 22:46:36.311856: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 22:46:36.311872: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 22:46:36.311884: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
WARNING:tensorflow:10 out of the last 11 calls to <function genDistInvPerNlistVec2D at 0x7fcd7f40f670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 10 calls to <function pyramidLayer.call at 0x7fcd14295280> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 10 calls to <function pyramidLayer.call at 0x7fcd142954c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 10 calls to <function pyramidLayer.call at 0x7fcd14295700> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 10 calls to <function MyDenseLayer.call at 0x7fcd14295940> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
WARNING:tensorflow:8 out of the last 11 calls to <function DeepMDsimpleEnergy.call at 0x7fccf0380af0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings is likely due to passing python objects instead of tensors. Also, tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. Please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for more details.
2020-08-27 22:47:01.212139: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 25 in the outer inference context.
2020-08-27 22:47:01.212194: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 24 in the outer inference context.
2020-08-27 22:47:01.212209: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 35 in the outer inference context.
2020-08-27 22:47:01.212243: W tensorflow/core/common_runtime/shape_refiner.cc:88] Function instantiation has undefined input shape at index: 36 in the outer inference context.
Start of epoch 0
step 0: mean loss = 5.0950277e-08
step 100: mean loss = 5.6820477e-09
epoch 0: mean loss = 5.794194e-09  learning rate = 4.849449e-05
============================
Start of epoch 1
step 0: mean loss = 2.0885986e-09
step 100: mean loss = 5.712883e-09
epoch 1: mean loss = 5.1395057e-09  learning rate = 4.849449e-05
============================
Start of epoch 2
step 0: mean loss = 2.4824935e-09
step 100: mean loss = 5.940895e-09
epoch 2: mean loss = 5.063392e-09  learning rate = 4.849449e-05
============================
Start of epoch 3
step 0: mean loss = 4.689989e-09
step 100: mean loss = 7.583661e-09
epoch 3: mean loss = 5.620229e-09  learning rate = 4.849449e-05
============================
Start of epoch 4
step 0: mean loss = 1.9611284e-09
step 100: mean loss = 7.144615e-09
epoch 4: mean loss = 5.5265517e-09  learning rate = 4.849449e-05
============================
Start of epoch 5
step 0: mean loss = 2.2604691e-09
step 100: mean loss = 5.493452e-09
epoch 5: mean loss = 5.8788343e-09  learning rate = 4.849449e-05
============================
Start of epoch 6
step 0: mean loss = 2.9635456e-09
step 100: mean loss = 4.330532e-09
epoch 6: mean loss = 4.724199e-09  learning rate = 4.849449e-05
============================
Start of epoch 7
step 0: mean loss = 5.940019e-09
step 100: mean loss = 5.9752208e-09
epoch 7: mean loss = 5.176298e-09  learning rate = 4.849449e-05
============================
Start of epoch 8
step 0: mean loss = 4.1933794e-09
step 100: mean loss = 6.7610904e-09
epoch 8: mean loss = 5.9126517e-09  learning rate = 4.849449e-05
============================
Start of epoch 9
step 0: mean loss = 3.4801166e-09
step 100: mean loss = 6.8282042e-09
epoch 9: mean loss = 5.0726667e-09  learning rate = 4.849449e-05
============================
Start of epoch 10
step 0: mean loss = 1.7853585e-09
step 100: mean loss = 8.3606615e-09
epoch 10: mean loss = 6.3325833e-09  learning rate = 4.849449e-05
============================
Start of epoch 11
step 0: mean loss = 1.5641877e-08
step 100: mean loss = 4.006e-09
epoch 11: mean loss = 5.6604095e-09  learning rate = 4.849449e-05
============================
Start of epoch 12
step 0: mean loss = 1.909997e-09
step 100: mean loss = 3.4413261e-09
epoch 12: mean loss = 5.1899067e-09  learning rate = 4.849449e-05
============================
Start of epoch 13
step 0: mean loss = 1.986896e-09
step 100: mean loss = 4.570294e-09
epoch 13: mean loss = 6.857356e-09  learning rate = 4.849449e-05
============================
Start of epoch 14
step 0: mean loss = 3.181171e-09
step 100: mean loss = 2.8155882e-09
epoch 14: mean loss = 4.5104835e-09  learning rate = 4.849449e-05
============================
Start of epoch 15
step 0: mean loss = 5.535083e-09
step 100: mean loss = 6.169519e-09
epoch 15: mean loss = 4.754144e-09  learning rate = 4.849449e-05
============================
Start of epoch 16
step 0: mean loss = 1.8156524e-09
step 100: mean loss = 5.6919087e-09
epoch 16: mean loss = 6.0363843e-09  learning rate = 4.849449e-05
============================
Start of epoch 17
step 0: mean loss = 2.0464828e-09
step 100: mean loss = 5.428312e-09
epoch 17: mean loss = 5.4247855e-09  learning rate = 4.849449e-05
============================
Start of epoch 18
step 0: mean loss = 1.849789e-09
step 100: mean loss = 5.258136e-09
epoch 18: mean loss = 4.288741e-09  learning rate = 4.849449e-05
============================
Start of epoch 19
step 0: mean loss = 1.9044213e-09
step 100: mean loss = 5.9932224e-09
epoch 19: mean loss = 6.768205e-09  learning rate = 4.849449e-05
============================
Start of epoch 20
step 0: mean loss = 2.1598117e-09
step 100: mean loss = 3.2076064e-09
epoch 20: mean loss = 6.2414536e-09  learning rate = 4.849449e-05
============================
Start of epoch 21
step 0: mean loss = 3.8643564e-09
step 100: mean loss = 5.917077e-09
epoch 21: mean loss = 4.763491e-09  learning rate = 4.849449e-05
============================
Start of epoch 22
step 0: mean loss = 1.7915747e-09
step 100: mean loss = 6.6407746e-09
epoch 22: mean loss = 5.0000093e-09  learning rate = 4.849449e-05
============================
Start of epoch 23
step 0: mean loss = 1.7996676e-09
step 100: mean loss = 4.72801e-09
epoch 23: mean loss = 5.5414806e-09  learning rate = 4.849449e-05
============================
Start of epoch 24
step 0: mean loss = 2.5359095e-09
step 100: mean loss = 4.022712e-09
epoch 24: mean loss = 5.14005e-09  learning rate = 4.849449e-05
============================
Start of epoch 25
step 0: mean loss = 3.2415273e-09
step 100: mean loss = 5.878578e-09
epoch 25: mean loss = 6.0546905e-09  learning rate = 4.849449e-05
============================
Start of epoch 26
step 0: mean loss = 1.8167419e-09
step 100: mean loss = 4.929148e-09
epoch 26: mean loss = 4.2926587e-09  learning rate = 4.849449e-05
============================
Start of epoch 27
step 0: mean loss = 3.829235e-09
step 100: mean loss = 6.3445316e-09
epoch 27: mean loss = 5.0288524e-09  learning rate = 4.849449e-05
============================
Start of epoch 28
step 0: mean loss = 8.459959e-09
step 100: mean loss = 7.2970017e-09
epoch 28: mean loss = 5.5050284e-09  learning rate = 4.849449e-05
============================
Start of epoch 29
step 0: mean loss = 1.8036803e-09
step 100: mean loss = 5.9477014e-09
epoch 29: mean loss = 6.3546803e-09  learning rate = 4.849449e-05
============================
Start of epoch 30
step 0: mean loss = 1.998868e-09
step 100: mean loss = 4.322589e-09
epoch 30: mean loss = 4.562531e-09  learning rate = 4.849449e-05
============================
Start of epoch 31
step 0: mean loss = 1.8905464e-09
step 100: mean loss = 5.2345714e-09
epoch 31: mean loss = 6.227647e-09  learning rate = 4.849449e-05
============================
Start of epoch 32
step 0: mean loss = 2.9988643e-09
step 100: mean loss = 4.929425e-09
epoch 32: mean loss = 5.889768e-09  learning rate = 4.849449e-05
============================
Start of epoch 33
step 0: mean loss = 1.36187825e-08
step 100: mean loss = 2.6630982e-09
epoch 33: mean loss = 4.780059e-09  learning rate = 4.849449e-05
============================
Start of epoch 34
step 0: mean loss = 2.3000404e-09
step 100: mean loss = 4.680268e-09
epoch 34: mean loss = 6.299347e-09  learning rate = 4.849449e-05
============================
Start of epoch 35
step 0: mean loss = 3.0962222e-09
step 100: mean loss = 3.669637e-09
epoch 35: mean loss = 4.4755812e-09  learning rate = 4.849449e-05
============================
Start of epoch 36
step 0: mean loss = 1.944627e-09
step 100: mean loss = 4.1624264e-09
epoch 36: mean loss = 5.1229416e-09  learning rate = 4.849449e-05
============================
Start of epoch 37
step 0: mean loss = 4.9956075e-09
step 100: mean loss = 6.052455e-09
epoch 37: mean loss = 5.3853446e-09  learning rate = 4.849449e-05
============================
Start of epoch 38
step 0: mean loss = 4.0099685e-08
step 100: mean loss = 4.978004e-09
epoch 38: mean loss = 5.657658e-09  learning rate = 4.849449e-05
============================
Start of epoch 39
step 0: mean loss = 2.1786084e-09
step 100: mean loss = 5.3153233e-09
epoch 39: mean loss = 5.6300737e-09  learning rate = 4.849449e-05
============================
Start of epoch 40
step 0: mean loss = 3.790517e-09
step 100: mean loss = 4.8292907e-09
epoch 40: mean loss = 5.081412e-09  learning rate = 4.849449e-05
============================
Start of epoch 41
step 0: mean loss = 1.9241828e-09
step 100: mean loss = 4.9460582e-09
epoch 41: mean loss = 6.0256213e-09  learning rate = 4.849449e-05
============================
Start of epoch 42
step 0: mean loss = 2.1532419e-08
step 100: mean loss = 4.4944772e-09
epoch 42: mean loss = 3.7577514e-09  learning rate = 4.849449e-05
============================
Start of epoch 43
step 0: mean loss = 4.700487e-09
step 100: mean loss = 7.0096533e-09
epoch 43: mean loss = 5.646641e-09  learning rate = 4.6069767e-05
============================
Start of epoch 44
step 0: mean loss = 2.2642452e-09
step 100: mean loss = 1.8187164e-09
epoch 44: mean loss = 3.8589585e-09  learning rate = 4.6069767e-05
============================
Start of epoch 45
step 0: mean loss = 3.326491e-09
step 100: mean loss = 3.254917e-09
epoch 45: mean loss = 5.3609672e-09  learning rate = 4.6069767e-05
============================
Start of epoch 46
step 0: mean loss = 1.9977642e-09
step 100: mean loss = 5.4898046e-09
epoch 46: mean loss = 4.650998e-09  learning rate = 4.6069767e-05
============================
Start of epoch 47
step 0: mean loss = 2.605568e-09
step 100: mean loss = 4.106972e-09
epoch 47: mean loss = 4.5917834e-09  learning rate = 4.6069767e-05
============================
Start of epoch 48
step 0: mean loss = 2.036469e-09
step 100: mean loss = 6.625147e-09
epoch 48: mean loss = 4.9696895e-09  learning rate = 4.6069767e-05
============================
Start of epoch 49
step 0: mean loss = 3.3455867e-09
step 100: mean loss = 6.0761973e-09
epoch 49: mean loss = 5.332034e-09  learning rate = 4.6069767e-05
============================
Start of epoch 50
step 0: mean loss = 2.9740437e-09
step 100: mean loss = 4.7794684e-09
epoch 50: mean loss = 4.9675433e-09  learning rate = 4.6069767e-05
============================
Start of epoch 51
step 0: mean loss = 2.2088882e-09
step 100: mean loss = 4.749954e-09
epoch 51: mean loss = 4.678202e-09  learning rate = 4.6069767e-05
============================
Start of epoch 52
step 0: mean loss = 7.3545654e-09
step 100: mean loss = 4.2812163e-09
epoch 52: mean loss = 6.158219e-09  learning rate = 4.6069767e-05
============================
Start of epoch 53
step 0: mean loss = 1.962026e-09
step 100: mean loss = 5.634406e-09
epoch 53: mean loss = 4.297513e-09  learning rate = 4.6069767e-05
============================
Start of epoch 54
step 0: mean loss = 1.7610353e-09
step 100: mean loss = 5.3017355e-09
epoch 54: mean loss = 5.843391e-09  learning rate = 4.6069767e-05
============================
Start of epoch 55
step 0: mean loss = 1.9084355e-08
step 100: mean loss = 6.3400947e-09
epoch 55: mean loss = 4.8036335e-09  learning rate = 4.6069767e-05
============================
Start of epoch 56
step 0: mean loss = 1.77034e-09
step 100: mean loss = 5.2753073e-09
epoch 56: mean loss = 4.1525414e-09  learning rate = 4.6069767e-05
============================
Start of epoch 57
step 0: mean loss = 5.6792064e-09
step 100: mean loss = 7.453703e-09
epoch 57: mean loss = 5.5085136e-09  learning rate = 4.6069767e-05
============================
Start of epoch 58
step 0: mean loss = 1.790597e-09
step 100: mean loss = 5.8110095e-09
epoch 58: mean loss = 5.941033e-09  learning rate = 4.6069767e-05
============================
Start of epoch 59
step 0: mean loss = 4.090658e-09
step 100: mean loss = 4.8403757e-09
epoch 59: mean loss = 4.401323e-09  learning rate = 4.6069767e-05
============================
Start of epoch 60
step 0: mean loss = 2.1527204e-09
step 100: mean loss = 4.6180424e-09
epoch 60: mean loss = 5.559546e-09  learning rate = 4.6069767e-05
============================
Start of epoch 61
step 0: mean loss = 2.0149815e-09
step 100: mean loss = 5.9329497e-09
epoch 61: mean loss = 4.848129e-09  learning rate = 4.6069767e-05
============================
Start of epoch 62
step 0: mean loss = 2.645266e-09
step 100: mean loss = 4.659137e-09
epoch 62: mean loss = 5.4824656e-09  learning rate = 4.6069767e-05
============================
Start of epoch 63
step 0: mean loss = 2.1334945e-09
step 100: mean loss = 2.846607e-09
epoch 63: mean loss = 4.851233e-09  learning rate = 4.6069767e-05
============================
Start of epoch 64
step 0: mean loss = 2.1125128e-09
step 100: mean loss = 3.3666285e-09
epoch 64: mean loss = 5.180285e-09  learning rate = 4.6069767e-05
============================
Start of epoch 65
step 0: mean loss = 2.117702e-09
step 100: mean loss = 4.320179e-09
epoch 65: mean loss = 4.1372927e-09  learning rate = 4.6069767e-05
============================
Start of epoch 66
step 0: mean loss = 3.535148e-08
step 100: mean loss = 4.6092756e-09
epoch 66: mean loss = 5.4502203e-09  learning rate = 4.6069767e-05
============================
Start of epoch 67
step 0: mean loss = 2.130443e-09
step 100: mean loss = 4.7255657e-09
epoch 67: mean loss = 5.2925153e-09  learning rate = 4.6069767e-05
============================
Start of epoch 68
step 0: mean loss = 2.320433e-08
step 100: mean loss = 4.9007216e-09
epoch 68: mean loss = 4.0156527e-09  learning rate = 4.6069767e-05
============================
Start of epoch 69
step 0: mean loss = 1.9515012e-09
step 100: mean loss = 6.338105e-09
epoch 69: mean loss = 4.9605333e-09  learning rate = 4.6069767e-05
============================
Start of epoch 70
step 0: mean loss = 4.2816337e-09
step 100: mean loss = 6.0810965e-09
epoch 70: mean loss = 4.9838524e-09  learning rate = 4.6069767e-05
============================
Start of epoch 71
step 0: mean loss = 1.6030922e-08
step 100: mean loss = 5.614515e-09
epoch 71: mean loss = 5.9276317e-09  learning rate = 4.6069767e-05
============================
Start of epoch 72
step 0: mean loss = 4.931187e-09
step 100: mean loss = 4.364932e-09
epoch 72: mean loss = 5.511078e-09  learning rate = 4.6069767e-05
============================
Start of epoch 73
step 0: mean loss = 5.485841e-09
step 100: mean loss = 2.8991156e-09
epoch 73: mean loss = 4.1438337e-09  learning rate = 4.6069767e-05
============================
Start of epoch 74
step 0: mean loss = 3.2622938e-09
step 100: mean loss = 4.0276156e-09
epoch 74: mean loss = 5.19778e-09  learning rate = 4.6069767e-05
============================
Start of epoch 75
step 0: mean loss = 2.1847832e-09
step 100: mean loss = 4.784766e-09
epoch 75: mean loss = 4.6139084e-09  learning rate = 4.6069767e-05
============================
Start of epoch 76
step 0: mean loss = 2.5058113e-09
step 100: mean loss = 5.876814e-09
epoch 76: mean loss = 5.2781233e-09  learning rate = 4.6069767e-05
============================
Start of epoch 77
step 0: mean loss = 1.7081335e-08
step 100: mean loss = 4.323991e-09
epoch 77: mean loss = 5.7956355e-09  learning rate = 4.6069767e-05
============================
Start of epoch 78
step 0: mean loss = 2.959287e-09
step 100: mean loss = 4.2698667e-09
epoch 78: mean loss = 5.665044e-09  learning rate = 4.6069767e-05
============================
Start of epoch 79
step 0: mean loss = 4.724669e-09
step 100: mean loss = 3.1495366e-09
epoch 79: mean loss = 3.351295e-09  learning rate = 4.6069767e-05
============================
Start of epoch 80
step 0: mean loss = 2.359599e-09
step 100: mean loss = 5.48619e-09
epoch 80: mean loss = 6.7099695e-09  learning rate = 4.6069767e-05
============================
Start of epoch 81
step 0: mean loss = 1.8917756e-09
step 100: mean loss = 2.5199607e-09
epoch 81: mean loss = 4.291937e-09  learning rate = 4.6069767e-05
============================
Start of epoch 82
step 0: mean loss = 2.0045727e-09
step 100: mean loss = 3.0443112e-09
epoch 82: mean loss = 4.9943623e-09  learning rate = 4.6069767e-05
============================
Start of epoch 83
step 0: mean loss = 1.7804315e-09
step 100: mean loss = 3.3514385e-09
epoch 83: mean loss = 4.7892206e-09  learning rate = 4.6069767e-05
============================
Start of epoch 84
step 0: mean loss = 2.3631384e-09
step 100: mean loss = 4.753301e-09
epoch 84: mean loss = 3.7947356e-09  learning rate = 4.6069767e-05
============================
Start of epoch 85
step 0: mean loss = 6.6244015e-09
step 100: mean loss = 9.258808e-09
epoch 85: mean loss = 6.724861e-09  learning rate = 4.6069767e-05
============================
Start of epoch 86
step 0: mean loss = 1.7472823e-09
step 100: mean loss = 5.460147e-09
epoch 86: mean loss = 4.223166e-09  learning rate = 4.6069767e-05
============================
Start of epoch 87
step 0: mean loss = 1.7395316e-09
step 100: mean loss = 5.704352e-09
epoch 87: mean loss = 6.180227e-09  learning rate = 4.6069767e-05
============================
Start of epoch 88
step 0: mean loss = 1.8146054e-09
step 100: mean loss = 5.1730105e-09
epoch 88: mean loss = 4.108452e-09  learning rate = 4.6069767e-05
============================
Start of epoch 89
step 0: mean loss = 1.7882124e-09
step 100: mean loss = 4.812747e-09
epoch 89: mean loss = 5.6729053e-09  learning rate = 4.6069767e-05
============================
Start of epoch 90
step 0: mean loss = 1.8399579e-09
step 100: mean loss = 6.292175e-09
epoch 90: mean loss = 4.9513904e-09  learning rate = 4.6069767e-05
============================
Start of epoch 91
step 0: mean loss = 1.7760655e-09
step 100: mean loss = 5.6526703e-09
epoch 91: mean loss = 4.344344e-09  learning rate = 4.6069767e-05
============================
Start of epoch 92
step 0: mean loss = 3.8080414e-09
step 100: mean loss = 4.7312003e-09
epoch 92: mean loss = 5.3207865e-09  learning rate = 4.6069767e-05
============================
Start of epoch 93
step 0: mean loss = 1.9113793e-09
step 100: mean loss = 4.9378133e-09
epoch 93: mean loss = 5.6847e-09  learning rate = 4.6069767e-05
============================
Start of epoch 94
step 0: mean loss = 2.6749873e-09
step 100: mean loss = 4.8568367e-09
epoch 94: mean loss = 3.9766053e-09  learning rate = 4.6069767e-05
============================
Start of epoch 95
step 0: mean loss = 4.1068033e-09
step 100: mean loss = 3.8348027e-09
epoch 95: mean loss = 6.9703563e-09  learning rate = 4.6069767e-05
============================
Start of epoch 96
step 0: mean loss = 2.2804836e-09
step 100: mean loss = 3.730482e-09
epoch 96: mean loss = 4.3725263e-09  learning rate = 4.6069767e-05
============================
Start of epoch 97
step 0: mean loss = 1.8522115e-09
step 100: mean loss = 4.9472493e-09
epoch 97: mean loss = 4.7811604e-09  learning rate = 4.6069767e-05
============================
Start of epoch 98
step 0: mean loss = 1.9432473e-09
step 100: mean loss = 3.4311602e-09
epoch 98: mean loss = 4.934299e-09  learning rate = 4.6069767e-05
============================
Start of epoch 99
step 0: mean loss = 3.1919867e-09
step 100: mean loss = 5.3596354e-09
epoch 99: mean loss = 4.1482204e-09  learning rate = 4.6069767e-05
============================
Start of epoch 100
step 0: mean loss = 3.0192837e-09
step 100: mean loss = 5.612641e-09
epoch 100: mean loss = 5.8073835e-09  learning rate = 4.6069767e-05
============================
Start of epoch 101
step 0: mean loss = 1.2356112e-08
step 100: mean loss = 5.247623e-09
epoch 101: mean loss = 4.0515262e-09  learning rate = 4.6069767e-05
============================
Start of epoch 102
step 0: mean loss = 1.828356e-09
step 100: mean loss = 6.0695573e-09
epoch 102: mean loss = 6.277298e-09  learning rate = 4.6069767e-05
============================
Start of epoch 103
step 0: mean loss = 2.1389346e-09
step 100: mean loss = 3.6663046e-09
epoch 103: mean loss = 4.380739e-09  learning rate = 4.6069767e-05
============================
Start of epoch 104
step 0: mean loss = 4.8706066e-09
step 100: mean loss = 5.2638356e-09
epoch 104: mean loss = 5.8695435e-09  learning rate = 4.6069767e-05
============================
Start of epoch 105
step 0: mean loss = 1.845407e-09
step 100: mean loss = 3.2310812e-09
epoch 105: mean loss = 4.3576667e-09  learning rate = 4.6069767e-05
============================
Start of epoch 106
step 0: mean loss = 2.655649e-09
step 100: mean loss = 4.7711883e-09
epoch 106: mean loss = 4.4301918e-09  learning rate = 4.6069767e-05
============================
Start of epoch 107
step 0: mean loss = 1.1405969e-08
step 100: mean loss = 5.0290145e-09
epoch 107: mean loss = 5.749802e-09  learning rate = 4.6069767e-05
============================
Start of epoch 108
step 0: mean loss = 1.878063e-09
step 100: mean loss = 5.1942277e-09
epoch 108: mean loss = 3.993468e-09  learning rate = 4.6069767e-05
============================
Start of epoch 109
step 0: mean loss = 1.8233192e-09
step 100: mean loss = 5.971288e-09
epoch 109: mean loss = 6.0405796e-09  learning rate = 4.6069767e-05
============================
Start of epoch 110
step 0: mean loss = 2.248273e-09
step 100: mean loss = 5.8136274e-09
epoch 110: mean loss = 5.0019544e-09  learning rate = 4.6069767e-05
============================
Start of epoch 111
step 0: mean loss = 2.0176358e-09
step 100: mean loss = 4.206485e-09
epoch 111: mean loss = 4.872932e-09  learning rate = 4.6069767e-05
============================
Start of epoch 112
step 0: mean loss = 2.2563469e-09
step 100: mean loss = 6.5697243e-09
epoch 112: mean loss = 4.924853e-09  learning rate = 4.6069767e-05
============================
Start of epoch 113
step 0: mean loss = 2.180662e-09
step 100: mean loss = 4.584567e-09
epoch 113: mean loss = 5.331082e-09  learning rate = 4.6069767e-05
============================
Start of epoch 114
step 0: mean loss = 1.8112487e-09
step 100: mean loss = 5.928985e-09
epoch 114: mean loss = 4.6585074e-09  learning rate = 4.6069767e-05
============================
Start of epoch 115
step 0: mean loss = 8.7950065e-09
step 100: mean loss = 4.260556e-09
epoch 115: mean loss = 6.5585004e-09  learning rate = 4.6069767e-05
============================
Start of epoch 116
step 0: mean loss = 3.809664e-09
step 100: mean loss = 2.7406815e-09
epoch 116: mean loss = 3.6708243e-09  learning rate = 4.6069767e-05
============================
Start of epoch 117
step 0: mean loss = 1.7945391e-09
step 100: mean loss = 5.1818487e-09
epoch 117: mean loss = 4.4413873e-09  learning rate = 4.6069767e-05
============================
Start of epoch 118
step 0: mean loss = 1.9574111e-09
step 100: mean loss = 6.5719483e-09
epoch 118: mean loss = 5.3248668e-09  learning rate = 4.6069767e-05
============================
Start of epoch 119
step 0: mean loss = 2.1045126e-09
step 100: mean loss = 5.679059e-09
epoch 119: mean loss = 4.7206106e-09  learning rate = 4.6069767e-05
============================
Start of epoch 120
step 0: mean loss = 7.722116e-09
step 100: mean loss = 6.378133e-09
epoch 120: mean loss = 4.779817e-09  learning rate = 4.6069767e-05
============================
Start of epoch 121
step 0: mean loss = 1.7261715e-09
step 100: mean loss = 7.3998367e-09
epoch 121: mean loss = 7.247995e-09  learning rate = 4.6069767e-05
============================
Start of epoch 122
step 0: mean loss = 1.7563175e-09
step 100: mean loss = 5.3287845e-09
epoch 122: mean loss = 5.0396802e-09  learning rate = 4.6069767e-05
============================
Start of epoch 123
step 0: mean loss = 1.7446805e-09
step 100: mean loss = 1.7673856e-09
epoch 123: mean loss = 4.5597903e-09  learning rate = 4.6069767e-05
============================
Start of epoch 124
step 0: mean loss = 2.1053135e-09
step 100: mean loss = 4.5213016e-09
epoch 124: mean loss = 3.549111e-09  learning rate = 4.376628e-05
============================
Start of epoch 125
step 0: mean loss = 1.7206224e-09
step 100: mean loss = 1.7282585e-09
epoch 125: mean loss = 3.843226e-09  learning rate = 4.376628e-05
============================
Start of epoch 126
step 0: mean loss = 1.929411e-09
step 100: mean loss = 5.308573e-09
epoch 126: mean loss = 4.193754e-09  learning rate = 4.376628e-05
============================
Start of epoch 127
step 0: mean loss = 6.07494e-09
step 100: mean loss = 4.4018256e-09
epoch 127: mean loss = 5.1826055e-09  learning rate = 4.376628e-05
============================
Start of epoch 128
step 0: mean loss = 4.0207953e-09
step 100: mean loss = 5.866095e-09
epoch 128: mean loss = 4.9613353e-09  learning rate = 4.376628e-05
============================
Start of epoch 129
step 0: mean loss = 1.7455528e-09
step 100: mean loss = 5.3425127e-09
epoch 129: mean loss = 4.0820027e-09  learning rate = 4.376628e-05
============================
Start of epoch 130
step 0: mean loss = 1.7228621e-09
step 100: mean loss = 6.4970007e-09
epoch 130: mean loss = 4.8524136e-09  learning rate = 4.376628e-05
============================
Start of epoch 131
step 0: mean loss = 1.885735e-09
step 100: mean loss = 4.65777e-09
epoch 131: mean loss = 5.1680096e-09  learning rate = 4.376628e-05
============================
Start of epoch 132
step 0: mean loss = 2.2615856e-09
step 100: mean loss = 3.5900156e-09
epoch 132: mean loss = 4.1061505e-09  learning rate = 4.376628e-05
============================
Start of epoch 133
step 0: mean loss = 2.1515205e-09
step 100: mean loss = 4.7470037e-09
epoch 133: mean loss = 5.166386e-09  learning rate = 4.376628e-05
============================
Start of epoch 134
step 0: mean loss = 2.2417495e-09
step 100: mean loss = 3.5437315e-09
epoch 134: mean loss = 4.6518163e-09  learning rate = 4.376628e-05
============================
Start of epoch 135
step 0: mean loss = 1.8479153e-09
step 100: mean loss = 5.6340945e-09
epoch 135: mean loss = 5.9671774e-09  learning rate = 4.376628e-05
============================
Start of epoch 136
step 0: mean loss = 1.809197e-09
step 100: mean loss = 5.5575327e-09
epoch 136: mean loss = 4.3690793e-09  learning rate = 4.376628e-05
============================
Start of epoch 137
step 0: mean loss = 1.7180523e-09
step 100: mean loss = 1.7294991e-09
epoch 137: mean loss = 4.463713e-09  learning rate = 4.376628e-05
============================
Start of epoch 138
step 0: mean loss = 2.3436788e-09
step 100: mean loss = 4.455751e-09
epoch 138: mean loss = 3.5598817e-09  learning rate = 4.376628e-05
============================
Start of epoch 139
step 0: mean loss = 1.7190104e-09
step 100: mean loss = 6.355815e-09
epoch 139: mean loss = 4.777025e-09  learning rate = 4.376628e-05
============================
Start of epoch 140
step 0: mean loss = 4.546501e-09
step 100: mean loss = 4.458848e-09
epoch 140: mean loss = 6.9027224e-09  learning rate = 4.376628e-05
============================
Start of epoch 141
step 0: mean loss = 3.018979e-09
step 100: mean loss = 1.8836974e-09
epoch 141: mean loss = 2.912136e-09  learning rate = 4.376628e-05
============================
Start of epoch 142
step 0: mean loss = 1.9285757e-09
step 100: mean loss = 4.9222235e-09
epoch 142: mean loss = 4.9935944e-09  learning rate = 4.376628e-05
============================
Start of epoch 143
step 0: mean loss = 6.8881048e-09
step 100: mean loss = 4.3825175e-09
epoch 143: mean loss = 3.57114e-09  learning rate = 4.376628e-05
============================
Start of epoch 144
step 0: mean loss = 3.0061136e-09
step 100: mean loss = 4.6877764e-09
epoch 144: mean loss = 5.833588e-09  learning rate = 4.376628e-05
============================
Start of epoch 145
step 0: mean loss = 1.8508821e-09
step 100: mean loss = 5.2136615e-09
epoch 145: mean loss = 4.090545e-09  learning rate = 4.376628e-05
============================
Start of epoch 146
step 0: mean loss = 2.2538615e-09
step 100: mean loss = 4.6671134e-09
epoch 146: mean loss = 5.5250995e-09  learning rate = 4.376628e-05
============================
Start of epoch 147
step 0: mean loss = 4.5097885e-09
step 100: mean loss = 4.884503e-09
epoch 147: mean loss = 4.0890704e-09  learning rate = 4.376628e-05
============================
Start of epoch 148
step 0: mean loss = 1.7072546e-09
step 100: mean loss = 6.900381e-09
epoch 148: mean loss = 5.0962137e-09  learning rate = 4.376628e-05
============================
Start of epoch 149
step 0: mean loss = 1.7363304e-09
step 100: mean loss = 5.3025224e-09
epoch 149: mean loss = 4.410525e-09  learning rate = 4.376628e-05
============================
Start of epoch 150
step 0: mean loss = 1.48006745e-08
step 100: mean loss = 3.8955688e-09
epoch 150: mean loss = 6.45902e-09  learning rate = 4.376628e-05
============================
Start of epoch 151
step 0: mean loss = 3.781817e-08
step 100: mean loss = 4.2258272e-09
epoch 151: mean loss = 4.628798e-09  learning rate = 4.376628e-05
============================
Start of epoch 152
step 0: mean loss = 2.5556852e-09
step 100: mean loss = 2.017319e-09
epoch 152: mean loss = 3.1134146e-09  learning rate = 4.376628e-05
============================
Start of epoch 153
step 0: mean loss = 2.9292642e-09
step 100: mean loss = 4.1109454e-09
epoch 153: mean loss = 3.8192494e-09  learning rate = 4.376628e-05
============================
Start of epoch 154
step 0: mean loss = 2.0033744e-09
step 100: mean loss = 6.3916894e-09
epoch 154: mean loss = 6.5902164e-09  learning rate = 4.376628e-05
============================
Start of epoch 155
step 0: mean loss = 2.9199496e-09
step 100: mean loss = 4.799081e-09
epoch 155: mean loss = 4.559411e-09  learning rate = 4.376628e-05
============================
Start of epoch 156
step 0: mean loss = 1.8407355e-09
step 100: mean loss = 3.4672893e-09
epoch 156: mean loss = 4.3777724e-09  learning rate = 4.376628e-05
============================
Start of epoch 157
step 0: mean loss = 2.1824203e-08
step 100: mean loss = 4.852474e-09
epoch 157: mean loss = 3.9444537e-09  learning rate = 4.376628e-05
============================
Start of epoch 158
step 0: mean loss = 1.792817e-09
step 100: mean loss = 4.415251e-09
epoch 158: mean loss = 5.108145e-09  learning rate = 4.376628e-05
============================
Start of epoch 159
step 0: mean loss = 2.219068e-09
step 100: mean loss = 4.82195e-09
epoch 159: mean loss = 3.755018e-09  learning rate = 4.376628e-05
============================
Start of epoch 160
step 0: mean loss = 2.7189924e-09
step 100: mean loss = 5.2006275e-09
epoch 160: mean loss = 6.8852e-09  learning rate = 4.376628e-05
============================
Start of epoch 161
step 0: mean loss = 1.9753572e-09
step 100: mean loss = 3.6740104e-09
epoch 161: mean loss = 3.4037293e-09  learning rate = 4.376628e-05
============================
Start of epoch 162
step 0: mean loss = 1.7345994e-09
step 100: mean loss = 4.353465e-09
epoch 162: mean loss = 4.9517226e-09  learning rate = 4.376628e-05
============================
Start of epoch 163
step 0: mean loss = 9.067944e-09
step 100: mean loss = 5.9679577e-09
epoch 163: mean loss = 4.495812e-09  learning rate = 4.376628e-05
============================
Start of epoch 164
step 0: mean loss = 1.7104381e-09
step 100: mean loss = 5.8267307e-09
epoch 164: mean loss = 4.427957e-09  learning rate = 4.376628e-05
============================
Start of epoch 165
step 0: mean loss = 1.6989307e-09
step 100: mean loss = 4.6399853e-09
epoch 165: mean loss = 6.29295e-09  learning rate = 4.376628e-05
============================
Start of epoch 166
step 0: mean loss = 2.7407965e-09
step 100: mean loss = 1.7893492e-09
epoch 166: mean loss = 4.0785206e-09  learning rate = 4.376628e-05
============================
Start of epoch 167
step 0: mean loss = 1.4549284e-08
step 100: mean loss = 2.7899005e-09
epoch 167: mean loss = 5.898112e-09  learning rate = 4.376628e-05
============================
Start of epoch 168
step 0: mean loss = 7.288878e-09
step 100: mean loss = 2.3254543e-09
epoch 168: mean loss = 3.6728853e-09  learning rate = 4.376628e-05
============================
Start of epoch 169
step 0: mean loss = 2.7463583e-09
step 100: mean loss = 2.1081348e-09
epoch 169: mean loss = 4.027483e-09  learning rate = 4.376628e-05
============================
Start of epoch 170
step 0: mean loss = 1.7153738e-09
step 100: mean loss = 3.9330987e-09
epoch 170: mean loss = 4.9667164e-09  learning rate = 4.376628e-05
============================
Start of epoch 171
step 0: mean loss = 2.2757412e-09
step 100: mean loss = 5.8442895e-09
epoch 171: mean loss = 4.7851954e-09  learning rate = 4.376628e-05
============================
Start of epoch 172
step 0: mean loss = 1.7210559e-09
step 100: mean loss = 4.602832e-09
epoch 172: mean loss = 3.5987122e-09  learning rate = 4.376628e-05
============================
Start of epoch 173
step 0: mean loss = 2.0388753e-09
step 100: mean loss = 5.124914e-09
epoch 173: mean loss = 6.285395e-09  learning rate = 4.376628e-05
============================
Start of epoch 174
step 0: mean loss = 7.3687323e-09
step 100: mean loss = 5.269589e-09
epoch 174: mean loss = 4.1442085e-09  learning rate = 4.376628e-05
============================
Start of epoch 175
step 0: mean loss = 1.7156314e-09
step 100: mean loss = 5.4175913e-09
epoch 175: mean loss = 4.2203703e-09  learning rate = 4.376628e-05
============================
Start of epoch 176
step 0: mean loss = 1.7104447e-09
step 100: mean loss = 4.4269504e-09
epoch 176: mean loss = 5.262981e-09  learning rate = 4.376628e-05
============================
Start of epoch 177
step 0: mean loss = 1.9864737e-09
step 100: mean loss = 5.235787e-09
epoch 177: mean loss = 4.316361e-09  learning rate = 4.376628e-05
============================
Start of epoch 178
step 0: mean loss = 1.7217577e-09
step 100: mean loss = 3.7435637e-09
epoch 178: mean loss = 6.7730666e-09  learning rate = 4.376628e-05
============================
Start of epoch 179
step 0: mean loss = 3.1741296e-09
step 100: mean loss = 2.3435085e-09
epoch 179: mean loss = 3.980625e-09  learning rate = 4.376628e-05
============================
Start of epoch 180
step 0: mean loss = 4.1861528e-09
step 100: mean loss = 1.8838833e-09
epoch 180: mean loss = 3.9591135e-09  learning rate = 4.376628e-05
============================
Start of epoch 181
step 0: mean loss = 1.8051298e-09
step 100: mean loss = 2.6804796e-09
epoch 181: mean loss = 3.9435006e-09  learning rate = 4.376628e-05
============================
Start of epoch 182
step 0: mean loss = 2.011407e-09
step 100: mean loss = 4.4182507e-09
epoch 182: mean loss = 4.3779966e-09  learning rate = 4.376628e-05
============================
Start of epoch 183
step 0: mean loss = 1.8984576e-09
step 100: mean loss = 4.826916e-09
epoch 183: mean loss = 4.255754e-09  learning rate = 4.376628e-05
============================
Start of epoch 184
step 0: mean loss = 8.034272e-09
step 100: mean loss = 5.5904454e-09
epoch 184: mean loss = 6.069764e-09  learning rate = 4.376628e-05
============================
Start of epoch 185
step 0: mean loss = 1.0848054e-08
step 100: mean loss = 2.6256048e-09
epoch 185: mean loss = 4.6877537e-09  learning rate = 4.376628e-05
============================
Start of epoch 186
step 0: mean loss = 1.811761e-09
step 100: mean loss = 4.524381e-09
epoch 186: mean loss = 3.5452081e-09  learning rate = 4.376628e-05
============================
Start of epoch 187
step 0: mean loss = 1.6875069e-09
step 100: mean loss = 6.9256845e-09
epoch 187: mean loss = 5.653161e-09  learning rate = 4.376628e-05
============================
Start of epoch 188
step 0: mean loss = 1.4426599e-08
step 100: mean loss = 2.7631197e-09
epoch 188: mean loss = 4.2238986e-09  learning rate = 4.376628e-05
============================
Start of epoch 189
step 0: mean loss = 1.8177926e-09
step 100: mean loss = 4.0635397e-09
epoch 189: mean loss = 4.9442095e-09  learning rate = 4.376628e-05
============================
Start of epoch 190
step 0: mean loss = 1.888084e-09
step 100: mean loss = 4.7085527e-09
epoch 190: mean loss = 4.69454e-09  learning rate = 4.376628e-05
============================
Start of epoch 191
step 0: mean loss = 1.8502168e-09
step 100: mean loss = 5.2738454e-09
epoch 191: mean loss = 4.517127e-09  learning rate = 4.376628e-05
============================
Start of epoch 192
step 0: mean loss = 1.6828747e-09
step 100: mean loss = 6.219061e-09
epoch 192: mean loss = 4.7140136e-09  learning rate = 4.376628e-05
============================
Start of epoch 193
step 0: mean loss = 1.7698537e-09
step 100: mean loss = 4.1938844e-09
epoch 193: mean loss = 5.0269424e-09  learning rate = 4.376628e-05
============================
Start of epoch 194
step 0: mean loss = 1.1051018e-08
step 100: mean loss = 3.7054668e-09
epoch 194: mean loss = 4.364807e-09  learning rate = 4.376628e-05
============================
Start of epoch 195
step 0: mean loss = 3.5491377e-09
step 100: mean loss = 4.223484e-09
epoch 195: mean loss = 4.8566755e-09  learning rate = 4.376628e-05
============================
Start of epoch 196
step 0: mean loss = 9.067068e-09
step 100: mean loss = 4.6488435e-09
epoch 196: mean loss = 4.0969383e-09  learning rate = 4.376628e-05
============================
Start of epoch 197
step 0: mean loss = 1.3567323e-08
step 100: mean loss = 5.1798152e-09
epoch 197: mean loss = 4.48225e-09  learning rate = 4.376628e-05
============================
Start of epoch 198
step 0: mean loss = 5.4866014e-09
step 100: mean loss = 5.785754e-09
epoch 198: mean loss = 5.3085083e-09  learning rate = 4.376628e-05
============================
Start of epoch 199
step 0: mean loss = 4.6028776e-09
step 100: mean loss = 5.0446847e-09
epoch 199: mean loss = 4.1437285e-09  learning rate = 4.376628e-05
============================
Start of epoch 200
step 0: mean loss = 1.778999e-09
step 100: mean loss = 4.0632457e-09
epoch 200: mean loss = 4.923616e-09  learning rate = 4.376628e-05
============================
Start of epoch 201
step 0: mean loss = 1.7755809e-09
step 100: mean loss = 3.9462202e-09
epoch 201: mean loss = 4.807595e-09  learning rate = 4.376628e-05
============================
Start of epoch 202
step 0: mean loss = 1.999511e-09
step 100: mean loss = 6.0368643e-09
epoch 202: mean loss = 4.69984e-09  learning rate = 4.376628e-05
============================
Start of epoch 203
step 0: mean loss = 1.691794e-09
step 100: mean loss = 5.0090043e-09
epoch 203: mean loss = 3.855005e-09  learning rate = 4.376628e-05
============================
Start of epoch 204
step 0: mean loss = 1.7760887e-09
step 100: mean loss = 4.787746e-09
epoch 204: mean loss = 5.5456537e-09  learning rate = 4.376628e-05
============================
Start of epoch 205
step 0: mean loss = 1.7026739e-09
step 100: mean loss = 1.6993503e-09
epoch 205: mean loss = 1.7758929e-09  learning rate = 4.1577965e-05
============================
Start of epoch 206
step 0: mean loss = 6.4230807e-09
step 100: mean loss = 3.9776027e-09
epoch 206: mean loss = 5.4221005e-09  learning rate = 4.1577965e-05
============================
Start of epoch 207
step 0: mean loss = 1.6759452e-09
step 100: mean loss = 4.249017e-09
epoch 207: mean loss = 3.4096135e-09  learning rate = 4.1577965e-05
============================
Start of epoch 208
step 0: mean loss = 2.8210179e-09
step 100: mean loss = 4.2157047e-09
epoch 208: mean loss = 4.409034e-09  learning rate = 4.1577965e-05
============================
Start of epoch 209
step 0: mean loss = 3.2578575e-09
step 100: mean loss = 4.2534616e-09
epoch 209: mean loss = 4.057437e-09  learning rate = 4.1577965e-05
============================
Start of epoch 210
step 0: mean loss = 1.7288332e-09
step 100: mean loss = 5.813305e-09
epoch 210: mean loss = 5.7223675e-09  learning rate = 4.1577965e-05
============================
Start of epoch 211
step 0: mean loss = 2.8980296e-09
step 100: mean loss = 4.510024e-09
epoch 211: mean loss = 4.2376707e-09  learning rate = 4.1577965e-05
============================
Start of epoch 212
step 0: mean loss = 1.7060257e-09
step 100: mean loss = 3.6745336e-09
epoch 212: mean loss = 3.4407022e-09  learning rate = 4.1577965e-05
============================
Start of epoch 213
step 0: mean loss = 2.749855e-08
step 100: mean loss = 4.4494346e-09
epoch 213: mean loss = 4.9000883e-09  learning rate = 4.1577965e-05
============================
Start of epoch 214
step 0: mean loss = 1.993045e-09
step 100: mean loss = 4.2845425e-09
epoch 214: mean loss = 3.9106216e-09  learning rate = 4.1577965e-05
============================
Start of epoch 215
step 0: mean loss = 5.517669e-09
step 100: mean loss = 4.261925e-09
epoch 215: mean loss = 4.33823e-09  learning rate = 4.1577965e-05
============================
Start of epoch 216
step 0: mean loss = 2.5528424e-09
step 100: mean loss = 3.9682204e-09
epoch 216: mean loss = 4.920877e-09  learning rate = 4.1577965e-05
============================
Start of epoch 217
step 0: mean loss = 2.0411692e-09
step 100: mean loss = 3.0470801e-09
epoch 217: mean loss = 3.7181838e-09  learning rate = 4.1577965e-05
============================
Start of epoch 218
step 0: mean loss = 1.7925598e-09
step 100: mean loss = 5.0871547e-09
epoch 218: mean loss = 4.192842e-09  learning rate = 4.1577965e-05
============================
Start of epoch 219
step 0: mean loss = 9.843507e-09
step 100: mean loss = 5.1505857e-09
epoch 219: mean loss = 4.65854e-09  learning rate = 4.1577965e-05
============================
Start of epoch 220
step 0: mean loss = 1.9552706e-09
step 100: mean loss = 5.7422573e-09
epoch 220: mean loss = 4.3240056e-09  learning rate = 4.1577965e-05
============================
Start of epoch 221
step 0: mean loss = 1.6658407e-09
step 100: mean loss = 6.1623346e-09
epoch 221: mean loss = 4.6064526e-09  learning rate = 4.1577965e-05
============================
Start of epoch 222
step 0: mean loss = 1.711524e-09
step 100: mean loss = 4.3632244e-09
epoch 222: mean loss = 5.702051e-09  learning rate = 4.1577965e-05
============================
Start of epoch 223
step 0: mean loss = 4.7526503e-09
step 100: mean loss = 3.4049783e-09
epoch 223: mean loss = 3.1859446e-09  learning rate = 4.1577965e-05
============================
Start of epoch 224
step 0: mean loss = 2.0145263e-09
step 100: mean loss = 4.0927213e-09
epoch 224: mean loss = 4.7424358e-09  learning rate = 4.1577965e-05
============================
Start of epoch 225
step 0: mean loss = 2.046336e-09
step 100: mean loss = 5.105787e-09
epoch 225: mean loss = 4.130351e-09  learning rate = 4.1577965e-05
============================
Start of epoch 226
step 0: mean loss = 1.7323132e-09
step 100: mean loss = 3.6258447e-09
epoch 226: mean loss = 4.496599e-09  learning rate = 4.1577965e-05
============================
Start of epoch 227
step 0: mean loss = 4.3697113e-09
step 100: mean loss = 2.7741778e-09
epoch 227: mean loss = 4.652576e-09  learning rate = 4.1577965e-05
============================
Start of epoch 228
step 0: mean loss = 2.3955833e-09
step 100: mean loss = 5.5751377e-09
epoch 228: mean loss = 4.2985615e-09  learning rate = 4.1577965e-05
============================
Start of epoch 229
step 0: mean loss = 1.6731532e-09
step 100: mean loss = 3.729035e-09
epoch 229: mean loss = 3.5706136e-09  learning rate = 4.1577965e-05
============================
Start of epoch 230
step 0: mean loss = 1.3269949e-08
step 100: mean loss = 5.909997e-09
epoch 230: mean loss = 5.295738e-09  learning rate = 4.1577965e-05
============================
Start of epoch 231
step 0: mean loss = 1.673072e-09
step 100: mean loss = 3.6685297e-09
epoch 231: mean loss = 3.021664e-09  learning rate = 4.1577965e-05
============================
Start of epoch 232
step 0: mean loss = 3.947824e-09
step 100: mean loss = 4.584232e-09
epoch 232: mean loss = 5.3289746e-09  learning rate = 4.1577965e-05
============================
Start of epoch 233
step 0: mean loss = 2.245657e-09
step 100: mean loss = 3.4803533e-09
epoch 233: mean loss = 4.313328e-09  learning rate = 4.1577965e-05
============================
Start of epoch 234
step 0: mean loss = 3.091169e-09
step 100: mean loss = 3.3993472e-09
epoch 234: mean loss = 3.8475947e-09  learning rate = 4.1577965e-05
============================
Start of epoch 235
step 0: mean loss = 2.426097e-09
step 100: mean loss = 5.278821e-09
epoch 235: mean loss = 5.1735998e-09  learning rate = 4.1577965e-05
============================
Start of epoch 236
step 0: mean loss = 6.880092e-09
step 100: mean loss = 2.1666406e-09
epoch 236: mean loss = 4.5631765e-09  learning rate = 4.1577965e-05
============================
Start of epoch 237
step 0: mean loss = 2.1165985e-09
step 100: mean loss = 3.7872785e-09
epoch 237: mean loss = 3.0935854e-09  learning rate = 4.1577965e-05
============================
Start of epoch 238
step 0: mean loss = 2.171298e-09
step 100: mean loss = 4.1354595e-09
epoch 238: mean loss = 5.111812e-09  learning rate = 4.1577965e-05
============================
Start of epoch 239
step 0: mean loss = 2.1110325e-09
step 100: mean loss = 4.8628936e-09
epoch 239: mean loss = 3.7794696e-09  learning rate = 4.1577965e-05
============================
Start of epoch 240
step 0: mean loss = 1.855768e-09
step 100: mean loss = 4.3943427e-09
epoch 240: mean loss = 5.1693085e-09  learning rate = 4.1577965e-05
============================
Start of epoch 241
step 0: mean loss = 2.7957045e-08
step 100: mean loss = 3.4422019e-09
epoch 241: mean loss = 4.2382085e-09  learning rate = 4.1577965e-05
============================
Start of epoch 242
step 0: mean loss = 2.140486e-09
step 100: mean loss = 4.1559765e-09
epoch 242: mean loss = 3.299964e-09  learning rate = 4.1577965e-05
============================
Start of epoch 243
step 0: mean loss = 1.6802314e-09
step 100: mean loss = 6.517363e-09
epoch 243: mean loss = 4.826499e-09  learning rate = 4.1577965e-05
============================
Start of epoch 244
step 0: mean loss = 1.6540886e-09
step 100: mean loss = 6.4465127e-09
epoch 244: mean loss = 4.78035e-09  learning rate = 4.1577965e-05
============================
Start of epoch 245
step 0: mean loss = 1.6617997e-09
step 100: mean loss = 3.9505865e-09
epoch 245: mean loss = 3.5998322e-09  learning rate = 4.1577965e-05
============================
Start of epoch 246
step 0: mean loss = 1.7611018e-09
step 100: mean loss = 5.743868e-09
epoch 246: mean loss = 4.5273336e-09  learning rate = 4.1577965e-05
============================
Start of epoch 247
step 0: mean loss = 1.6821603e-09
step 100: mean loss = 4.175917e-09
epoch 247: mean loss = 4.946684e-09  learning rate = 4.1577965e-05
============================
Start of epoch 248
step 0: mean loss = 1.9277728e-09
step 100: mean loss = 4.614824e-09
epoch 248: mean loss = 3.5908467e-09  learning rate = 4.1577965e-05
============================
Start of epoch 249
step 0: mean loss = 1.6936788e-09
step 100: mean loss = 6.1764736e-09
epoch 249: mean loss = 4.6207957e-09  learning rate = 4.1577965e-05
============================
Start of epoch 250
step 0: mean loss = 2.3477205e-09
step 100: mean loss = 4.7032294e-09
epoch 250: mean loss = 3.7164836e-09  learning rate = 4.1577965e-05
============================
Start of epoch 251
step 0: mean loss = 6.5337087e-09
step 100: mean loss = 5.5686344e-09
epoch 251: mean loss = 5.8612675e-09  learning rate = 4.1577965e-05
============================
Start of epoch 252
step 0: mean loss = 1.8755228e-09
step 100: mean loss = 3.4888568e-09
epoch 252: mean loss = 3.4599628e-09  learning rate = 4.1577965e-05
============================
Start of epoch 253
step 0: mean loss = 2.5063387e-09
step 100: mean loss = 4.4600164e-09
epoch 253: mean loss = 5.1203295e-09  learning rate = 4.1577965e-05
============================
Start of epoch 254
step 0: mean loss = 1.6610124e-09
step 100: mean loss = 3.085189e-09
epoch 254: mean loss = 4.2277684e-09  learning rate = 4.1577965e-05
============================
Start of epoch 255
step 0: mean loss = 4.324725e-09
step 100: mean loss = 4.7422177e-09
epoch 255: mean loss = 3.8714547e-09  learning rate = 4.1577965e-05
============================
Start of epoch 256
step 0: mean loss = 1.8965145e-09
step 100: mean loss = 4.0130472e-09
epoch 256: mean loss = 4.569532e-09  learning rate = 4.1577965e-05
============================
Start of epoch 257
step 0: mean loss = 3.383313e-09
step 100: mean loss = 2.8565152e-09
epoch 257: mean loss = 4.6344804e-09  learning rate = 4.1577965e-05
============================
Start of epoch 258
step 0: mean loss = 1.7584953e-09
step 100: mean loss = 2.6319043e-09
epoch 258: mean loss = 3.8389127e-09  learning rate = 4.1577965e-05
============================
Start of epoch 259
step 0: mean loss = 1.6478426e-09
step 100: mean loss = 5.150194e-09
epoch 259: mean loss = 4.0084305e-09  learning rate = 4.1577965e-05
============================
Start of epoch 260
step 0: mean loss = 6.1185608e-09
step 100: mean loss = 4.558056e-09
epoch 260: mean loss = 4.8545417e-09  learning rate = 4.1577965e-05
============================
Start of epoch 261
step 0: mean loss = 1.8025388e-09
step 100: mean loss = 4.1179242e-09
epoch 261: mean loss = 4.6030686e-09  learning rate = 4.1577965e-05
============================
Start of epoch 262
step 0: mean loss = 1.8090929e-09
step 100: mean loss = 5.0414783e-09
epoch 262: mean loss = 4.0264254e-09  learning rate = 4.1577965e-05
============================
Start of epoch 263
step 0: mean loss = 1.6618898e-09
step 100: mean loss = 4.3689954e-09
epoch 263: mean loss = 5.598159e-09  learning rate = 4.1577965e-05
============================
Start of epoch 264
step 0: mean loss = 2.9087794e-09
step 100: mean loss = 1.8829203e-09
epoch 264: mean loss = 3.7940793e-09  learning rate = 4.1577965e-05
============================
Start of epoch 265
step 0: mean loss = 1.6545789e-09
step 100: mean loss = 3.5655507e-09
epoch 265: mean loss = 2.932082e-09  learning rate = 4.1577965e-05
============================
Start of epoch 266
step 0: mean loss = 1.8086729e-09
step 100: mean loss = 5.0422746e-09
epoch 266: mean loss = 5.761692e-09  learning rate = 4.1577965e-05
============================
Start of epoch 267
step 0: mean loss = 1.7005197e-09
step 100: mean loss = 4.446414e-09
epoch 267: mean loss = 3.5861263e-09  learning rate = 4.1577965e-05
============================
Start of epoch 268
step 0: mean loss = 1.680005e-09
step 100: mean loss = 4.2693262e-09
epoch 268: mean loss = 4.235868e-09  learning rate = 4.1577965e-05
============================
Start of epoch 269
step 0: mean loss = 2.2003874e-09
step 100: mean loss = 3.5503906e-09
epoch 269: mean loss = 4.644168e-09  learning rate = 4.1577965e-05
============================
Start of epoch 270
step 0: mean loss = 1.6612145e-09
step 100: mean loss = 4.6184416e-09
epoch 270: mean loss = 5.3838143e-09  learning rate = 4.1577965e-05
============================
Start of epoch 271
step 0: mean loss = 1.391883e-08
step 100: mean loss = 2.3062832e-09
epoch 271: mean loss = 3.7202825e-09  learning rate = 4.1577965e-05
============================
Start of epoch 272
step 0: mean loss = 1.1435885e-08
step 100: mean loss = 3.9059604e-09
epoch 272: mean loss = 3.1875684e-09  learning rate = 4.1577965e-05
============================
Start of epoch 273
step 0: mean loss = 1.6910416e-09
step 100: mean loss = 5.3864446e-09
epoch 273: mean loss = 5.464303e-09  learning rate = 4.1577965e-05
============================
Start of epoch 274
step 0: mean loss = 1.7751225e-09
step 100: mean loss = 3.9016737e-09
epoch 274: mean loss = 3.160219e-09  learning rate = 4.1577965e-05
============================
Start of epoch 275
step 0: mean loss = 1.8432206e-09
step 100: mean loss = 6.0945045e-09
epoch 275: mean loss = 4.5540824e-09  learning rate = 4.1577965e-05
============================
Start of epoch 276
step 0: mean loss = 1.6510995e-09
step 100: mean loss = 4.7830806e-09
epoch 276: mean loss = 5.1491114e-09  learning rate = 4.1577965e-05
============================
Start of epoch 277
step 0: mean loss = 1.6537317e-09
step 100: mean loss = 4.8910556e-09
epoch 277: mean loss = 3.8845416e-09  learning rate = 4.1577965e-05
============================
Start of epoch 278
step 0: mean loss = 2.0283977e-09
step 100: mean loss = 4.6335127e-09
epoch 278: mean loss = 4.1836072e-09  learning rate = 4.1577965e-05
============================
Start of epoch 279
step 0: mean loss = 2.1887785e-09
step 100: mean loss = 4.453921e-09
epoch 279: mean loss = 4.451709e-09  learning rate = 4.1577965e-05
============================
Start of epoch 280
step 0: mean loss = 1.7081012e-09
step 100: mean loss = 5.3793205e-09
epoch 280: mean loss = 4.1170076e-09  learning rate = 4.1577965e-05
============================
Start of epoch 281
step 0: mean loss = 2.5531646e-09
step 100: mean loss = 4.22535e-09
epoch 281: mean loss = 5.5999028e-09  learning rate = 4.1577965e-05
============================
Start of epoch 282
step 0: mean loss = 1.641776e-09
step 100: mean loss = 3.6665229e-09
epoch 282: mean loss = 3.5745393e-09  learning rate = 4.1577965e-05
============================
Start of epoch 283
step 0: mean loss = 1.6664862e-09
step 100: mean loss = 4.683808e-09
epoch 283: mean loss = 3.6412184e-09  learning rate = 4.1577965e-05
============================
Start of epoch 284
step 0: mean loss = 2.1738191e-09
step 100: mean loss = 4.7579927e-09
epoch 284: mean loss = 4.74136e-09  learning rate = 4.1577965e-05
============================
Start of epoch 285
step 0: mean loss = 1.832484e-09
step 100: mean loss = 5.523995e-09
epoch 285: mean loss = 4.172205e-09  learning rate = 3.9499064e-05
============================
Start of epoch 286
step 0: mean loss = 1.633654e-09
step 100: mean loss = 2.205454e-09
epoch 286: mean loss = 3.7446872e-09  learning rate = 3.9499064e-05
============================
Start of epoch 287
step 0: mean loss = 1.7170413e-09
step 100: mean loss = 1.645625e-09
epoch 287: mean loss = 4.082298e-09  learning rate = 3.9499064e-05
============================
Start of epoch 288
step 0: mean loss = 2.00437e-09
step 100: mean loss = 3.564874e-09
epoch 288: mean loss = 3.0756508e-09  learning rate = 3.9499064e-05
============================
Start of epoch 289
step 0: mean loss = 1.6670074e-09
step 100: mean loss = 4.132954e-09
epoch 289: mean loss = 3.566844e-09  learning rate = 3.9499064e-05
============================
Start of epoch 290
step 0: mean loss = 2.178694e-08
step 100: mean loss = 6.0772036e-09
epoch 290: mean loss = 5.1498854e-09  learning rate = 3.9499064e-05
============================
Start of epoch 291
step 0: mean loss = 1.6472775e-09
step 100: mean loss = 4.1815293e-09
epoch 291: mean loss = 3.5385963e-09  learning rate = 3.9499064e-05
============================
Start of epoch 292
step 0: mean loss = 1.8792636e-09
step 100: mean loss = 3.3861918e-09
epoch 292: mean loss = 4.115089e-09  learning rate = 3.9499064e-05
============================
Start of epoch 293
step 0: mean loss = 2.122365e-09
step 100: mean loss = 4.0487698e-09
epoch 293: mean loss = 4.2287405e-09  learning rate = 3.9499064e-05
============================
Start of epoch 294
step 0: mean loss = 1.9273942e-09
step 100: mean loss = 4.1422017e-09
epoch 294: mean loss = 3.3164589e-09  learning rate = 3.9499064e-05
============================
Start of epoch 295
step 0: mean loss = 4.2022554e-09
step 100: mean loss = 4.940837e-09
epoch 295: mean loss = 3.917263e-09  learning rate = 3.9499064e-05
============================
Start of epoch 296
step 0: mean loss = 6.987689e-09
step 100: mean loss = 4.6056226e-09
epoch 296: mean loss = 5.132727e-09  learning rate = 3.9499064e-05
============================
Start of epoch 297
step 0: mean loss = 2.8241756e-09
step 100: mean loss = 3.1239482e-09
epoch 297: mean loss = 3.7544825e-09  learning rate = 3.9499064e-05
============================
Start of epoch 298
step 0: mean loss = 2.629749e-09
step 100: mean loss = 4.4488826e-09
epoch 298: mean loss = 4.312105e-09  learning rate = 3.9499064e-05
============================
Start of epoch 299
step 0: mean loss = 4.486397e-09
step 100: mean loss = 4.204143e-09
epoch 299: mean loss = 3.406903e-09  learning rate = 3.9499064e-05
============================
Start of epoch 300
step 0: mean loss = 2.0272215e-09
step 100: mean loss = 4.9468225e-09
epoch 300: mean loss = 4.1205324e-09  learning rate = 3.9499064e-05
============================
Start of epoch 301
step 0: mean loss = 1.7210867e-09
step 100: mean loss = 4.0009236e-09
epoch 301: mean loss = 4.524239e-09  learning rate = 3.9499064e-05
============================
Start of epoch 302
step 0: mean loss = 1.9011175e-09
step 100: mean loss = 3.4482965e-09
epoch 302: mean loss = 3.3616432e-09  learning rate = 3.9499064e-05
============================
Start of epoch 303
step 0: mean loss = 1.9115574e-09
step 100: mean loss = 3.8315817e-09
epoch 303: mean loss = 4.5065276e-09  learning rate = 3.9499064e-05
============================
Start of epoch 304
step 0: mean loss = 1.8307307e-09
step 100: mean loss = 6.7338632e-09
epoch 304: mean loss = 5.0753184e-09  learning rate = 3.9499064e-05
============================
Start of epoch 305
step 0: mean loss = 1.6340255e-09
step 100: mean loss = 3.7216348e-09
epoch 305: mean loss = 3.022477e-09  learning rate = 3.9499064e-05
============================
Start of epoch 306
step 0: mean loss = 1.9348834e-09
step 100: mean loss = 3.6044643e-09
epoch 306: mean loss = 4.025994e-09  learning rate = 3.9499064e-05
============================
Start of epoch 307
step 0: mean loss = 2.1613185e-09
step 100: mean loss = 3.2925538e-09
epoch 307: mean loss = 4.6496607e-09  learning rate = 3.9499064e-05
============================
Start of epoch 308
step 0: mean loss = 1.6624542e-09
step 100: mean loss = 3.832541e-09
epoch 308: mean loss = 3.6162926e-09  learning rate = 3.9499064e-05
============================
Start of epoch 309
step 0: mean loss = 3.7368877e-09
step 100: mean loss = 3.66691e-09
epoch 309: mean loss = 4.8414117e-09  learning rate = 3.9499064e-05
============================
Start of epoch 310
step 0: mean loss = 3.3883896e-09
step 100: mean loss = 2.2774707e-09
epoch 310: mean loss = 3.07274e-09  learning rate = 3.9499064e-05
============================
Start of epoch 311
step 0: mean loss = 1.6593773e-09
step 100: mean loss = 3.3120375e-09
epoch 311: mean loss = 4.194412e-09  learning rate = 3.9499064e-05
============================
Start of epoch 312
step 0: mean loss = 1.7630718e-09
step 100: mean loss = 4.6044004e-09
epoch 312: mean loss = 3.590816e-09  learning rate = 3.9499064e-05
============================
Start of epoch 313
step 0: mean loss = 2.4785434e-09
step 100: mean loss = 4.1154316e-09
epoch 313: mean loss = 5.0833857e-09  learning rate = 3.9499064e-05
============================
Start of epoch 314
step 0: mean loss = 4.24278e-09
step 100: mean loss = 3.614745e-09
epoch 314: mean loss = 3.027101e-09  learning rate = 3.9499064e-05
============================
Start of epoch 315
step 0: mean loss = 1.8594558e-09
step 100: mean loss = 4.0069925e-09
epoch 315: mean loss = 4.1875756e-09  learning rate = 3.9499064e-05
============================
Start of epoch 316
step 0: mean loss = 2.0255924e-09
step 100: mean loss = 4.072588e-09
epoch 316: mean loss = 4.052067e-09  learning rate = 3.9499064e-05
============================
Start of epoch 317
step 0: mean loss = 5.838456e-09
step 100: mean loss = 4.2063917e-09
epoch 317: mean loss = 3.9481285e-09  learning rate = 3.9499064e-05
============================
Start of epoch 318
step 0: mean loss = 2.0939621e-09
step 100: mean loss = 4.4605093e-09
epoch 318: mean loss = 4.4150337e-09  learning rate = 3.9499064e-05
============================
Start of epoch 319
step 0: mean loss = 2.5679328e-09
step 100: mean loss = 4.202397e-09
epoch 319: mean loss = 3.311077e-09  learning rate = 3.9499064e-05
============================
Start of epoch 320
step 0: mean loss = 1.6202548e-09
step 100: mean loss = 5.0872853e-09
epoch 320: mean loss = 5.3592517e-09  learning rate = 3.9499064e-05
============================
Start of epoch 321
step 0: mean loss = 1.8050335e-09
step 100: mean loss = 2.3817786e-09
epoch 321: mean loss = 2.979817e-09  learning rate = 3.9499064e-05
============================
Start of epoch 322
step 0: mean loss = 2.0507942e-09
step 100: mean loss = 4.694066e-09
epoch 322: mean loss = 3.8012193e-09  learning rate = 3.9499064e-05
============================
Start of epoch 323
step 0: mean loss = 1.7136673e-09
step 100: mean loss = 4.5971182e-09
epoch 323: mean loss = 5.411083e-09  learning rate = 3.9499064e-05
============================
Start of epoch 324
step 0: mean loss = 1.7051175e-09
step 100: mean loss = 3.2475407e-09
epoch 324: mean loss = 3.2071665e-09  learning rate = 3.9499064e-05
============================
Start of epoch 325
step 0: mean loss = 1.6677055e-09
step 100: mean loss = 3.7381374e-09
epoch 325: mean loss = 3.6906669e-09  learning rate = 3.9499064e-05
============================
Start of epoch 326
step 0: mean loss = 2.1300595e-09
step 100: mean loss = 4.871637e-09
epoch 326: mean loss = 3.9704022e-09  learning rate = 3.9499064e-05
============================
Start of epoch 327
step 0: mean loss = 1.6314665e-09
step 100: mean loss = 5.8166307e-09
epoch 327: mean loss = 4.4570205e-09  learning rate = 3.9499064e-05
============================
Start of epoch 328
step 0: mean loss = 1.6354974e-09
step 100: mean loss = 4.9943907e-09
epoch 328: mean loss = 3.828225e-09  learning rate = 3.9499064e-05
============================
Start of epoch 329
step 0: mean loss = 1.6929163e-09
step 100: mean loss = 5.5641096e-09
epoch 329: mean loss = 4.590995e-09  learning rate = 3.9499064e-05
============================
Start of epoch 330
step 0: mean loss = 1.6645183e-09
step 100: mean loss = 3.1493488e-09
epoch 330: mean loss = 3.73596e-09  learning rate = 3.9499064e-05
============================
Start of epoch 331
step 0: mean loss = 3.1655947e-09
step 100: mean loss = 4.109821e-09
epoch 331: mean loss = 4.3761363e-09  learning rate = 3.9499064e-05
============================
Start of epoch 332
step 0: mean loss = 2.2283446e-09
step 100: mean loss = 2.916673e-09
epoch 332: mean loss = 3.3669956e-09  learning rate = 3.9499064e-05
============================
Start of epoch 333
step 0: mean loss = 1.9067374e-09
step 100: mean loss = 4.0915507e-09
epoch 333: mean loss = 4.3529673e-09  learning rate = 3.9499064e-05
============================
Start of epoch 334
step 0: mean loss = 2.1106041e-09
step 100: mean loss = 4.9176614e-09
epoch 334: mean loss = 3.772342e-09  learning rate = 3.9499064e-05
============================
Start of epoch 335
step 0: mean loss = 1.642531e-09
step 100: mean loss = 5.152291e-09
epoch 335: mean loss = 3.971843e-09  learning rate = 3.9499064e-05
============================
Start of epoch 336
step 0: mean loss = 1.6496037e-09
step 100: mean loss = 4.3307216e-09
epoch 336: mean loss = 3.9517407e-09  learning rate = 3.9499064e-05
============================
Start of epoch 337
step 0: mean loss = 1.6225737e-09
step 100: mean loss = 4.3941597e-09
epoch 337: mean loss = 4.439747e-09  learning rate = 3.9499064e-05
============================
Start of epoch 338
step 0: mean loss = 1.8645512e-09
step 100: mean loss = 3.665162e-09
epoch 338: mean loss = 3.7370436e-09  learning rate = 3.9499064e-05
============================
Start of epoch 339
step 0: mean loss = 1.00818145e-08
step 100: mean loss = 5.282993e-09
epoch 339: mean loss = 4.184506e-09  learning rate = 3.9499064e-05
============================
Start of epoch 340
step 0: mean loss = 1.6327146e-09
step 100: mean loss = 3.570218e-09
epoch 340: mean loss = 4.533193e-09  learning rate = 3.9499064e-05
============================
Start of epoch 341
step 0: mean loss = 1.6299336e-09
step 100: mean loss = 4.702123e-09
epoch 341: mean loss = 4.697493e-09  learning rate = 3.9499064e-05
============================
Start of epoch 342
step 0: mean loss = 1.6442434e-09
step 100: mean loss = 4.6519135e-09
epoch 342: mean loss = 3.6490662e-09  learning rate = 3.9499064e-05
============================
Start of epoch 343
step 0: mean loss = 1.6041508e-09
step 100: mean loss = 4.612687e-09
epoch 343: mean loss = 3.7069963e-09  learning rate = 3.9499064e-05
============================
Start of epoch 344
step 0: mean loss = 1.6073628e-09
step 100: mean loss = 3.5475602e-09
epoch 344: mean loss = 4.577582e-09  learning rate = 3.9499064e-05
============================
Start of epoch 345
step 0: mean loss = 2.0149975e-09
step 100: mean loss = 1.871274e-09
epoch 345: mean loss = 4.083066e-09  learning rate = 3.9499064e-05
============================
Start of epoch 346
step 0: mean loss = 1.8306836e-09
step 100: mean loss = 4.656855e-09
epoch 346: mean loss = 4.49493e-09  learning rate = 3.9499064e-05
============================
Start of epoch 347
step 0: mean loss = 1.7563724e-09
step 100: mean loss = 2.9856753e-09
epoch 347: mean loss = 2.85675e-09  learning rate = 3.9499064e-05
============================
Start of epoch 348
step 0: mean loss = 1.6187833e-09
step 100: mean loss = 4.981429e-09
epoch 348: mean loss = 3.8644496e-09  learning rate = 3.9499064e-05
============================
Start of epoch 349
step 0: mean loss = 4.137613e-09
step 100: mean loss = 4.0755608e-09
epoch 349: mean loss = 4.5240474e-09  learning rate = 3.9499064e-05
============================
Start of epoch 350
step 0: mean loss = 1.6030556e-09
step 100: mean loss = 4.2539186e-09
epoch 350: mean loss = 4.24032e-09  learning rate = 3.9499064e-05
============================
Start of epoch 351
step 0: mean loss = 3.0342266e-09
step 100: mean loss = 3.6250578e-09
epoch 351: mean loss = 4.1297494e-09  learning rate = 3.9499064e-05
============================
Start of epoch 352
step 0: mean loss = 1.929872e-09
step 100: mean loss = 2.5034201e-09
epoch 352: mean loss = 3.768669e-09  learning rate = 3.9499064e-05
============================
Start of epoch 353
step 0: mean loss = 4.1407113e-09
step 100: mean loss = 4.358416e-09
epoch 353: mean loss = 3.8632284e-09  learning rate = 3.9499064e-05
============================
Start of epoch 354
step 0: mean loss = 1.7257613e-09
step 100: mean loss = 3.0547063e-09
epoch 354: mean loss = 3.9395878e-09  learning rate = 3.9499064e-05
============================
Start of epoch 355
step 0: mean loss = 1.6609935e-09
step 100: mean loss = 3.3956613e-09
epoch 355: mean loss = 4.6941797e-09  learning rate = 3.9499064e-05
============================
Start of epoch 356
step 0: mean loss = 2.124645e-09
step 100: mean loss = 2.7010527e-09
epoch 356: mean loss = 2.9815002e-09  learning rate = 3.9499064e-05
============================
Start of epoch 357
step 0: mean loss = 3.3517455e-09
step 100: mean loss = 4.6562287e-09
epoch 357: mean loss = 4.010271e-09  learning rate = 3.9499064e-05
============================
Start of epoch 358
step 0: mean loss = 2.4661864e-08
step 100: mean loss = 4.078211e-09
epoch 358: mean loss = 5.4558935e-09  learning rate = 3.9499064e-05
============================
Start of epoch 359
step 0: mean loss = 1.8232734e-09
step 100: mean loss = 1.7574866e-09
epoch 359: mean loss = 3.497574e-09  learning rate = 3.9499064e-05
============================
Start of epoch 360
step 0: mean loss = 1.7306848e-09
step 100: mean loss = 3.956828e-09
epoch 360: mean loss = 3.1425484e-09  learning rate = 3.9499064e-05
============================
Start of epoch 361
step 0: mean loss = 1.595821e-09
step 100: mean loss = 5.6271663e-09
epoch 361: mean loss = 5.5007803e-09  learning rate = 3.9499064e-05
============================
Start of epoch 362
step 0: mean loss = 6.311668e-09
step 100: mean loss = 1.9964073e-09
epoch 362: mean loss = 2.9672307e-09  learning rate = 3.9499064e-05
============================
Start of epoch 363
step 0: mean loss = 1.8108417e-09
step 100: mean loss = 4.5030895e-09
epoch 363: mean loss = 3.5502499e-09  learning rate = 3.9499064e-05
============================
Start of epoch 364
step 0: mean loss = 1.9550344e-09
step 100: mean loss = 5.6754366e-09
epoch 364: mean loss = 4.861594e-09  learning rate = 3.9499064e-05
============================
Start of epoch 365
step 0: mean loss = 1.6277304e-09
step 100: mean loss = 5.7714433e-09
epoch 365: mean loss = 4.4613464e-09  learning rate = 3.9499064e-05
============================
Start of epoch 366
step 0: mean loss = 1.6163761e-09
step 100: mean loss = 3.3852026e-09
epoch 366: mean loss = 2.7641127e-09  learning rate = 3.752411e-05
============================
Start of epoch 367
step 0: mean loss = 1.5926218e-09
step 100: mean loss = 1.6007398e-09
epoch 367: mean loss = 3.3917376e-09  learning rate = 3.752411e-05
============================
Start of epoch 368
step 0: mean loss = 2.6143807e-09
step 100: mean loss = 2.896189e-09
epoch 368: mean loss = 3.2902614e-09  learning rate = 3.752411e-05
============================
Start of epoch 369
step 0: mean loss = 1.3038308e-08
step 100: mean loss = 3.5542547e-09
epoch 369: mean loss = 3.3178844e-09  learning rate = 3.752411e-05
============================
Start of epoch 370
step 0: mean loss = 3.5865718e-08
step 100: mean loss = 5.7569536e-09
epoch 370: mean loss = 4.450157e-09  learning rate = 3.752411e-05
============================
Start of epoch 371
step 0: mean loss = 8.9618695e-09
step 100: mean loss = 3.1003586e-09
epoch 371: mean loss = 3.901342e-09  learning rate = 3.752411e-05
============================
Start of epoch 372
step 0: mean loss = 2.7388536e-09
step 100: mean loss = 3.6960714e-09
epoch 372: mean loss = 3.1672707e-09  learning rate = 3.752411e-05
============================
Start of epoch 373
step 0: mean loss = 1.0321221e-08
step 100: mean loss = 4.5821147e-09
epoch 373: mean loss = 3.6372336e-09  learning rate = 3.752411e-05
============================
Start of epoch 374
step 0: mean loss = 2.912523e-09
step 100: mean loss = 4.3126804e-09
epoch 374: mean loss = 4.1326187e-09  learning rate = 3.752411e-05
============================
Start of epoch 375
step 0: mean loss = 6.1764536e-09
step 100: mean loss = 3.4307783e-09
epoch 375: mean loss = 4.490847e-09  learning rate = 3.752411e-05
============================
Start of epoch 376
step 0: mean loss = 1.9577924e-09
step 100: mean loss = 2.3661781e-09
epoch 376: mean loss = 3.4962635e-09  learning rate = 3.752411e-05
============================
Start of epoch 377
step 0: mean loss = 2.9304925e-09
step 100: mean loss = 3.0267355e-09
epoch 377: mean loss = 3.757807e-09  learning rate = 3.752411e-05
============================
Start of epoch 378
step 0: mean loss = 1.9673703e-09
step 100: mean loss = 3.8099186e-09
epoch 378: mean loss = 3.879424e-09  learning rate = 3.752411e-05
============================
Start of epoch 379
step 0: mean loss = 2.9452332e-09
step 100: mean loss = 4.3801025e-09
epoch 379: mean loss = 4.059103e-09  learning rate = 3.752411e-05
============================
Start of epoch 380
step 0: mean loss = 1.5957382e-09
step 100: mean loss = 3.767665e-09
epoch 380: mean loss = 3.0273268e-09  learning rate = 3.752411e-05
============================
Start of epoch 381
step 0: mean loss = 1.5922663e-09
step 100: mean loss = 4.745642e-09
epoch 381: mean loss = 3.6502361e-09  learning rate = 3.752411e-05
============================
Start of epoch 382
step 0: mean loss = 1.6024887e-09
step 100: mean loss = 5.9888414e-09
epoch 382: mean loss = 4.464979e-09  learning rate = 3.752411e-05
============================
Start of epoch 383
step 0: mean loss = 1.9477733e-09
step 100: mean loss = 3.729491e-09
epoch 383: mean loss = 4.0693418e-09  learning rate = 3.752411e-05
============================
Start of epoch 384
step 0: mean loss = 2.6761375e-09
step 100: mean loss = 2.6941644e-09
epoch 384: mean loss = 3.1968874e-09  learning rate = 3.752411e-05
============================
Start of epoch 385
step 0: mean loss = 1.6590903e-09
step 100: mean loss = 4.3570156e-09
epoch 385: mean loss = 4.2709614e-09  learning rate = 3.752411e-05
============================
Start of epoch 386
step 0: mean loss = 4.327527e-09
step 100: mean loss = 3.7310692e-09
epoch 386: mean loss = 3.3465768e-09  learning rate = 3.752411e-05
============================
Start of epoch 387
step 0: mean loss = 3.0748835e-09
step 100: mean loss = 3.924782e-09
epoch 387: mean loss = 3.423235e-09  learning rate = 3.752411e-05
============================
Start of epoch 388
step 0: mean loss = 4.101712e-09
step 100: mean loss = 3.9238865e-09
epoch 388: mean loss = 3.5811456e-09  learning rate = 3.752411e-05
============================
Start of epoch 389
step 0: mean loss = 3.0767275e-09
step 100: mean loss = 5.099411e-09
epoch 389: mean loss = 4.304799e-09  learning rate = 3.752411e-05
============================
Start of epoch 390
step 0: mean loss = 1.5821364e-09
step 100: mean loss = 4.5570188e-09
epoch 390: mean loss = 3.522774e-09  learning rate = 3.752411e-05
============================
Start of epoch 391
step 0: mean loss = 1.5922939e-09
step 100: mean loss = 4.4815547e-09
epoch 391: mean loss = 4.8520166e-09  learning rate = 3.752411e-05
============================
Start of epoch 392
step 0: mean loss = 2.3047428e-09
step 100: mean loss = 1.6799752e-09
epoch 392: mean loss = 3.6013512e-09  learning rate = 3.752411e-05
============================
Start of epoch 393
step 0: mean loss = 1.6445134e-09
step 100: mean loss = 3.5048524e-09
epoch 393: mean loss = 2.861141e-09  learning rate = 3.752411e-05
============================
Start of epoch 394
step 0: mean loss = 2.2154942e-09
step 100: mean loss = 4.1220907e-09
epoch 394: mean loss = 4.342455e-09  learning rate = 3.752411e-05
============================
Start of epoch 395
step 0: mean loss = 1.6649051e-09
step 100: mean loss = 2.9998537e-09
epoch 395: mean loss = 4.215255e-09  learning rate = 3.752411e-05
============================
Start of epoch 396
step 0: mean loss = 3.2268315e-09
step 100: mean loss = 2.8421259e-09
epoch 396: mean loss = 2.5700786e-09  learning rate = 3.752411e-05
============================
Start of epoch 397
step 0: mean loss = 5.666064e-09
step 100: mean loss = 4.564908e-09
epoch 397: mean loss = 4.4341393e-09  learning rate = 3.752411e-05
============================
Start of epoch 398
step 0: mean loss = 7.134915e-09
step 100: mean loss = 5.281172e-09
epoch 398: mean loss = 4.0740593e-09  learning rate = 3.752411e-05
============================
Start of epoch 399
step 0: mean loss = 1.5781737e-09
step 100: mean loss = 4.8916844e-09
epoch 399: mean loss = 3.7835677e-09  learning rate = 3.752411e-05
============================
Start of epoch 400
step 0: mean loss = 1.590339e-09
step 100: mean loss = 3.6009846e-09
epoch 400: mean loss = 2.9114604e-09  learning rate = 3.752411e-05
============================
Start of epoch 401
step 0: mean loss = 2.2771316e-09
step 100: mean loss = 4.8859747e-09
epoch 401: mean loss = 4.633984e-09  learning rate = 3.752411e-05
============================
Start of epoch 402
step 0: mean loss = 1.6291972e-09
step 100: mean loss = 3.7936223e-09
epoch 402: mean loss = 3.145846e-09  learning rate = 3.752411e-05
============================
Start of epoch 403
step 0: mean loss = 6.8845143e-09
step 100: mean loss = 5.250167e-09
epoch 403: mean loss = 4.4061057e-09  learning rate = 3.752411e-05
============================
Start of epoch 404
step 0: mean loss = 1.5818594e-09
step 100: mean loss = 4.169049e-09
epoch 404: mean loss = 3.2804597e-09  learning rate = 3.752411e-05
============================
Start of epoch 405
step 0: mean loss = 1.6383314e-09
step 100: mean loss = 5.117381e-09
epoch 405: mean loss = 3.885426e-09  learning rate = 3.752411e-05
============================
Start of epoch 406
step 0: mean loss = 1.5977002e-09
step 100: mean loss = 4.170777e-09
epoch 406: mean loss = 4.833211e-09  learning rate = 3.752411e-05
============================
Start of epoch 407
step 0: mean loss = 2.7847427e-09
step 100: mean loss = 1.7600945e-09
epoch 407: mean loss = 3.227888e-09  learning rate = 3.752411e-05
============================
Start of epoch 408
step 0: mean loss = 1.7628422e-09
step 100: mean loss = 3.8592174e-09
epoch 408: mean loss = 3.5950698e-09  learning rate = 3.752411e-05
============================
Start of epoch 409
step 0: mean loss = 3.9182217e-09
step 100: mean loss = 3.5967365e-09
epoch 409: mean loss = 3.1085723e-09  learning rate = 3.752411e-05
============================
Start of epoch 410
step 0: mean loss = 1.0219496e-08
step 100: mean loss = 4.871115e-09
epoch 410: mean loss = 3.7425e-09  learning rate = 3.752411e-05
============================
Start of epoch 411
step 0: mean loss = 1.6464596e-09
step 100: mean loss = 4.5492867e-09
epoch 411: mean loss = 5.161187e-09  learning rate = 3.752411e-05
============================
Start of epoch 412
step 0: mean loss = 2.0355722e-09
step 100: mean loss = 3.576648e-09
epoch 412: mean loss = 3.677158e-09  learning rate = 3.752411e-05
============================
Start of epoch 413
step 0: mean loss = 1.7327334e-09
step 100: mean loss = 2.196158e-09
epoch 413: mean loss = 3.0505212e-09  learning rate = 3.752411e-05
============================
Start of epoch 414
step 0: mean loss = 1.9927688e-09
step 100: mean loss = 3.838629e-09
epoch 414: mean loss = 3.7571777e-09  learning rate = 3.752411e-05
============================
Start of epoch 415
step 0: mean loss = 1.8352913e-09
step 100: mean loss = 2.859786e-09
epoch 415: mean loss = 4.470694e-09  learning rate = 3.752411e-05
============================
Start of epoch 416
step 0: mean loss = 2.0656443e-09
step 100: mean loss = 3.2409209e-09
epoch 416: mean loss = 2.8314986e-09  learning rate = 3.752411e-05
============================
Start of epoch 417
step 0: mean loss = 2.8265075e-09
step 100: mean loss = 4.250619e-09
epoch 417: mean loss = 3.3655352e-09  learning rate = 3.752411e-05
============================
Start of epoch 418
step 0: mean loss = 3.83688e-09
step 100: mean loss = 4.5636352e-09
epoch 418: mean loss = 5.5164913e-09  learning rate = 3.752411e-05
============================
Start of epoch 419
step 0: mean loss = 4.0431267e-09
step 100: mean loss = 2.1633668e-09
epoch 419: mean loss = 2.8310987e-09  learning rate = 3.752411e-05
============================
Start of epoch 420
step 0: mean loss = 1.5849616e-09
step 100: mean loss = 3.8505648e-09
epoch 420: mean loss = 4.1315285e-09  learning rate = 3.752411e-05
============================
Start of epoch 421
step 0: mean loss = 5.1650226e-09
step 100: mean loss = 3.5131558e-09
epoch 421: mean loss = 3.720633e-09  learning rate = 3.752411e-05
============================
Start of epoch 422
step 0: mean loss = 1.7666751e-09
step 100: mean loss = 2.5603448e-09
epoch 422: mean loss = 3.2933878e-09  learning rate = 3.752411e-05
============================
Start of epoch 423
step 0: mean loss = 1.7492182e-09
step 100: mean loss = 2.9327096e-09
epoch 423: mean loss = 4.054366e-09  learning rate = 3.752411e-05
============================
Start of epoch 424
step 0: mean loss = 1.824771e-09
step 100: mean loss = 6.2622907e-09
epoch 424: mean loss = 5.212213e-09  learning rate = 3.752411e-05
============================
Start of epoch 425
step 0: mean loss = 1.648213e-09
step 100: mean loss = 2.61201e-09
epoch 425: mean loss = 2.6465625e-09  learning rate = 3.752411e-05
============================
Start of epoch 426
step 0: mean loss = 1.5734699e-09
step 100: mean loss = 4.304879e-09
epoch 426: mean loss = 3.8287618e-09  learning rate = 3.752411e-05
============================
Start of epoch 427
step 0: mean loss = 1.5996171e-09
step 100: mean loss = 4.956732e-09
epoch 427: mean loss = 3.7890886e-09  learning rate = 3.752411e-05
============================
Start of epoch 428
step 0: mean loss = 1.5810658e-09
step 100: mean loss = 4.278088e-09
epoch 428: mean loss = 3.4756802e-09  learning rate = 3.752411e-05
============================
Start of epoch 429
step 0: mean loss = 2.6676714e-09
step 100: mean loss = 3.057099e-09
epoch 429: mean loss = 4.1471577e-09  learning rate = 3.752411e-05
============================
Start of epoch 430
step 0: mean loss = 6.5885057e-09
step 100: mean loss = 2.4221813e-09
epoch 430: mean loss = 4.212503e-09  learning rate = 3.752411e-05
============================
Start of epoch 431
step 0: mean loss = 1.6945743e-09
step 100: mean loss = 3.6449401e-09
epoch 431: mean loss = 3.0678167e-09  learning rate = 3.752411e-05
============================
Start of epoch 432
step 0: mean loss = 1.5669712e-09
step 100: mean loss = 3.942322e-09
epoch 432: mean loss = 4.0284127e-09  learning rate = 3.752411e-05
============================
Start of epoch 433
step 0: mean loss = 6.710987e-09
step 100: mean loss = 3.753455e-09
epoch 433: mean loss = 3.1270584e-09  learning rate = 3.752411e-05
============================
Start of epoch 434
step 0: mean loss = 1.602891e-09
step 100: mean loss = 4.094823e-09
epoch 434: mean loss = 4.700255e-09  learning rate = 3.752411e-05
============================
Start of epoch 435
step 0: mean loss = 2.0195805e-09
step 100: mean loss = 3.299347e-09
epoch 435: mean loss = 3.0402079e-09  learning rate = 3.752411e-05
============================
Start of epoch 436
step 0: mean loss = 1.6767068e-09
step 100: mean loss = 3.04372e-09
epoch 436: mean loss = 4.5783803e-09  learning rate = 3.752411e-05
============================
Start of epoch 437
step 0: mean loss = 1.5668519e-09
step 100: mean loss = 2.9741536e-09
epoch 437: mean loss = 2.6450564e-09  learning rate = 3.752411e-05
============================
Start of epoch 438
step 0: mean loss = 5.1448485e-09
step 100: mean loss = 3.840576e-09
epoch 438: mean loss = 4.463616e-09  learning rate = 3.752411e-05
============================
Start of epoch 439
step 0: mean loss = 2.9791583e-09
step 100: mean loss = 3.9588866e-09
epoch 439: mean loss = 3.1371798e-09  learning rate = 3.752411e-05
============================
Start of epoch 440
step 0: mean loss = 1.6014116e-09
step 100: mean loss = 4.609782e-09
epoch 440: mean loss = 4.0760613e-09  learning rate = 3.752411e-05
============================
Start of epoch 441
step 0: mean loss = 1.6057774e-09
step 100: mean loss = 3.1911065e-09
epoch 441: mean loss = 4.162975e-09  learning rate = 3.752411e-05
============================
Start of epoch 442
step 0: mean loss = 1.807343e-09
step 100: mean loss = 2.8878249e-09
epoch 442: mean loss = 3.3314143e-09  learning rate = 3.752411e-05
============================
Start of epoch 443
step 0: mean loss = 2.5621687e-09
step 100: mean loss = 3.5546681e-09
epoch 443: mean loss = 3.8917736e-09  learning rate = 3.752411e-05
============================
Start of epoch 444
step 0: mean loss = 3.5591523e-09
step 100: mean loss = 3.2869771e-09
epoch 444: mean loss = 3.818072e-09  learning rate = 3.752411e-05
============================
Start of epoch 445
step 0: mean loss = 6.0649006e-09
step 100: mean loss = 3.7946943e-09
epoch 445: mean loss = 3.0584704e-09  learning rate = 3.752411e-05
============================
Start of epoch 446
step 0: mean loss = 1.8399183e-09
step 100: mean loss = 5.0613953e-09
epoch 446: mean loss = 3.870442e-09  learning rate = 3.752411e-05
============================
Start of epoch 447
step 0: mean loss = 1.5705558e-09
step 100: mean loss = 1.5982837e-09
epoch 447: mean loss = 3.2378793e-09  learning rate = 3.5647903e-05
============================
Start of epoch 448
step 0: mean loss = 4.0442445e-09
step 100: mean loss = 3.1603253e-09
epoch 448: mean loss = 2.90287e-09  learning rate = 3.5647903e-05
============================
Start of epoch 449
step 0: mean loss = 1.5652535e-09
step 100: mean loss = 3.6213093e-09
epoch 449: mean loss = 2.9126237e-09  learning rate = 3.5647903e-05
============================
Start of epoch 450
step 0: mean loss = 1.8307531e-09
step 100: mean loss = 4.48264e-09
epoch 450: mean loss = 3.8606056e-09  learning rate = 3.5647903e-05
============================
Start of epoch 451
step 0: mean loss = 2.754834e-08
step 100: mean loss = 4.2656474e-09
epoch 451: mean loss = 3.5768506e-09  learning rate = 3.5647903e-05
============================
Start of epoch 452
step 0: mean loss = 1.9105175e-09
step 100: mean loss = 3.8972328e-09
epoch 452: mean loss = 3.3826646e-09  learning rate = 3.5647903e-05
============================
Start of epoch 453
step 0: mean loss = 1.4402599e-08
step 100: mean loss = 4.7479958e-09
epoch 453: mean loss = 3.6712033e-09  learning rate = 3.5647903e-05
============================
Start of epoch 454
step 0: mean loss = 1.573025e-09
step 100: mean loss = 4.054395e-09
epoch 454: mean loss = 3.9954924e-09  learning rate = 3.5647903e-05
============================
Start of epoch 455
step 0: mean loss = 2.3504672e-09
step 100: mean loss = 2.940164e-09
epoch 455: mean loss = 3.041333e-09  learning rate = 3.5647903e-05
============================
Start of epoch 456
step 0: mean loss = 1.741226e-09
step 100: mean loss = 3.974559e-09
epoch 456: mean loss = 4.199763e-09  learning rate = 3.5647903e-05
============================
Start of epoch 457
step 0: mean loss = 1.0482913e-08
step 100: mean loss = 2.402122e-09
epoch 457: mean loss = 3.843257e-09  learning rate = 3.5647903e-05
============================
Start of epoch 458
step 0: mean loss = 1.6420081e-09
step 100: mean loss = 3.1969547e-09
epoch 458: mean loss = 2.8789346e-09  learning rate = 3.5647903e-05
============================
Start of epoch 459
step 0: mean loss = 1.6212992e-09
step 100: mean loss = 3.6789978e-09
epoch 459: mean loss = 3.534771e-09  learning rate = 3.5647903e-05
============================
Start of epoch 460
step 0: mean loss = 2.204623e-08
step 100: mean loss = 4.132401e-09
epoch 460: mean loss = 3.3564778e-09  learning rate = 3.5647903e-05
============================
Start of epoch 461
step 0: mean loss = 1.5873499e-09
step 100: mean loss = 4.6577036e-09
epoch 461: mean loss = 3.6080003e-09  learning rate = 3.5647903e-05
============================
Start of epoch 462
step 0: mean loss = 2.2547348e-09
step 100: mean loss = 2.7602072e-09
epoch 462: mean loss = 4.4600803e-09  learning rate = 3.5647903e-05
============================
Start of epoch 463
step 0: mean loss = 1.9166717e-09
step 100: mean loss = 1.98633e-09
epoch 463: mean loss = 3.2123184e-09  learning rate = 3.5647903e-05
============================
Start of epoch 464
step 0: mean loss = 1.5502982e-09
step 100: mean loss = 3.2506244e-09
epoch 464: mean loss = 3.436819e-09  learning rate = 3.5647903e-05
============================
Start of epoch 465
step 0: mean loss = 1.5579452e-08
step 100: mean loss = 2.333326e-09
epoch 465: mean loss = 3.3161414e-09  learning rate = 3.5647903e-05
============================
Start of epoch 466
step 0: mean loss = 1.7281198e-09
step 100: mean loss = 3.5219792e-09
epoch 466: mean loss = 3.9749435e-09  learning rate = 3.5647903e-05
============================
Start of epoch 467
step 0: mean loss = 2.3458748e-09
step 100: mean loss = 2.4328508e-09
epoch 467: mean loss = 3.276561e-09  learning rate = 3.5647903e-05
============================
Start of epoch 468
step 0: mean loss = 1.6208221e-09
step 100: mean loss = 3.817355e-09
epoch 468: mean loss = 3.0806904e-09  learning rate = 3.5647903e-05
============================
Start of epoch 469
step 0: mean loss = 4.446324e-09
step 100: mean loss = 4.2991095e-09
epoch 469: mean loss = 3.3461505e-09  learning rate = 3.5647903e-05
============================
Start of epoch 470
step 0: mean loss = 1.609253e-09
step 100: mean loss = 4.0325907e-09
epoch 470: mean loss = 4.03741e-09  learning rate = 3.5647903e-05
============================
Start of epoch 471
step 0: mean loss = 1.6220176e-09
step 100: mean loss = 3.7057888e-09
epoch 471: mean loss = 2.974445e-09  learning rate = 3.5647903e-05
============================
Start of epoch 472
step 0: mean loss = 1.8284722e-09
step 100: mean loss = 4.7249014e-09
epoch 472: mean loss = 4.338101e-09  learning rate = 3.5647903e-05
============================
Start of epoch 473
step 0: mean loss = 1.6111474e-09
step 100: mean loss = 3.720827e-09
epoch 473: mean loss = 2.9865381e-09  learning rate = 3.5647903e-05
============================
Start of epoch 474
step 0: mean loss = 1.5526311e-09
step 100: mean loss = 3.8278727e-09
epoch 474: mean loss = 4.2040433e-09  learning rate = 3.5647903e-05
============================
Start of epoch 475
step 0: mean loss = 1.5466665e-09
step 100: mean loss = 3.784121e-09
epoch 475: mean loss = 3.131392e-09  learning rate = 3.5647903e-05
============================
Start of epoch 476
step 0: mean loss = 1.6006196e-09
step 100: mean loss = 2.602451e-09
epoch 476: mean loss = 4.406908e-09  learning rate = 3.5647903e-05
============================
Start of epoch 477
step 0: mean loss = 2.1674322e-09
step 100: mean loss = 3.1916683e-09
epoch 477: mean loss = 3.0371872e-09  learning rate = 3.5647903e-05
============================
Start of epoch 478
step 0: mean loss = 1.5456447e-09
step 100: mean loss = 4.2514747e-09
epoch 478: mean loss = 3.3905787e-09  learning rate = 3.5647903e-05
============================
Start of epoch 479
step 0: mean loss = 1.5460033e-09
step 100: mean loss = 3.7869845e-09
epoch 479: mean loss = 3.0485734e-09  learning rate = 3.5647903e-05
============================
Start of epoch 480
step 0: mean loss = 3.0739153e-09
step 100: mean loss = 4.1666777e-09
epoch 480: mean loss = 3.2904635e-09  learning rate = 3.5647903e-05
============================
Start of epoch 481
step 0: mean loss = 2.9035436e-09
step 100: mean loss = 4.582944e-09
epoch 481: mean loss = 3.816121e-09  learning rate = 3.5647903e-05
============================
Start of epoch 482
step 0: mean loss = 1.5553749e-09
step 100: mean loss = 5.724943e-09
epoch 482: mean loss = 4.275297e-09  learning rate = 3.5647903e-05
============================
Start of epoch 483
step 0: mean loss = 1.5421244e-09
step 100: mean loss = 2.9249834e-09
epoch 483: mean loss = 2.8197544e-09  learning rate = 3.5647903e-05
============================
Start of epoch 484
step 0: mean loss = 1.2548039e-08
step 100: mean loss = 3.3381433e-09
epoch 484: mean loss = 3.969124e-09  learning rate = 3.5647903e-05
============================
Start of epoch 485
step 0: mean loss = 1.705757e-09
step 100: mean loss = 2.986598e-09
epoch 485: mean loss = 3.225972e-09  learning rate = 3.5647903e-05
============================
Start of epoch 486
step 0: mean loss = 1.7528323e-09
step 100: mean loss = 3.3423972e-09
epoch 486: mean loss = 3.6466792e-09  learning rate = 3.5647903e-05
============================
Start of epoch 487
step 0: mean loss = 1.537016e-09
step 100: mean loss = 4.777685e-09
epoch 487: mean loss = 3.658551e-09  learning rate = 3.5647903e-05
============================
Start of epoch 488
step 0: mean loss = 1.5558378e-09
step 100: mean loss = 3.102917e-09
epoch 488: mean loss = 3.879937e-09  learning rate = 3.5647903e-05
============================
Start of epoch 489
step 0: mean loss = 2.0410824e-09
step 100: mean loss = 3.5767291e-09
epoch 489: mean loss = 3.4156158e-09  learning rate = 3.5647903e-05
============================
Start of epoch 490
step 0: mean loss = 1.5434471e-09
step 100: mean loss = 3.0439073e-09
epoch 490: mean loss = 3.5608294e-09  learning rate = 3.5647903e-05
============================
Start of epoch 491
step 0: mean loss = 7.421328e-09
step 100: mean loss = 2.4513591e-09
epoch 491: mean loss = 3.3565202e-09  learning rate = 3.5647903e-05
============================
Start of epoch 492
step 0: mean loss = 2.4188844e-09
step 100: mean loss = 4.5124056e-09
epoch 492: mean loss = 3.4903802e-09  learning rate = 3.5647903e-05
============================
Start of epoch 493
step 0: mean loss = 1.5730187e-09
step 100: mean loss = 2.966738e-09
epoch 493: mean loss = 3.3190994e-09  learning rate = 3.5647903e-05
============================
Start of epoch 494
step 0: mean loss = 2.2204987e-09
step 100: mean loss = 3.2318277e-09
epoch 494: mean loss = 4.1549537e-09  learning rate = 3.5647903e-05
============================
Start of epoch 495
step 0: mean loss = 1.5369486e-09
step 100: mean loss = 3.6186298e-09
epoch 495: mean loss = 2.9720093e-09  learning rate = 3.5647903e-05
============================
Start of epoch 496
step 0: mean loss = 1.5354971e-09
step 100: mean loss = 2.987257e-09
epoch 496: mean loss = 3.445588e-09  learning rate = 3.5647903e-05
============================
Start of epoch 497
step 0: mean loss = 1.6373036e-09
step 100: mean loss = 3.443244e-09
epoch 497: mean loss = 3.69546e-09  learning rate = 3.5647903e-05
============================
Start of epoch 498
step 0: mean loss = 1.5546301e-09
step 100: mean loss = 3.6076941e-09
epoch 498: mean loss = 3.3754928e-09  learning rate = 3.5647903e-05
============================
Start of epoch 499
step 0: mean loss = 1.1377792e-08
step 100: mean loss = 4.943163e-09
epoch 499: mean loss = 3.819304e-09  learning rate = 3.5647903e-05
============================
Start of epoch 500
step 0: mean loss = 1.5586836e-09
step 100: mean loss = 3.722479e-09
epoch 500: mean loss = 2.9680682e-09  learning rate = 3.5647903e-05
============================
Start of epoch 501
step 0: mean loss = 1.6809737e-09
step 100: mean loss = 4.259661e-09
epoch 501: mean loss = 3.3154723e-09  learning rate = 3.5647903e-05
============================
Start of epoch 502
step 0: mean loss = 1.8098933e-09
step 100: mean loss = 4.9289786e-09
epoch 502: mean loss = 4.84365e-09  learning rate = 3.5647903e-05
============================
Start of epoch 503
step 0: mean loss = 2.3319755e-09
step 100: mean loss = 2.685199e-09
epoch 503: mean loss = 3.1176848e-09  learning rate = 3.5647903e-05
============================
Start of epoch 504
step 0: mean loss = 1.5736187e-09
step 100: mean loss = 3.4312373e-09
epoch 504: mean loss = 3.6758319e-09  learning rate = 3.5647903e-05
============================
Start of epoch 505
step 0: mean loss = 5.9734897e-09
step 100: mean loss = 1.9903774e-09
epoch 505: mean loss = 3.456524e-09  learning rate = 3.5647903e-05
============================
Start of epoch 506
step 0: mean loss = 1.7386449e-09
step 100: mean loss = 2.8394864e-09
epoch 506: mean loss = 3.5991985e-09  learning rate = 3.5647903e-05
============================
Start of epoch 507
step 0: mean loss = 9.21901e-09
step 100: mean loss = 3.6939634e-09
epoch 507: mean loss = 3.0932736e-09  learning rate = 3.5647903e-05
============================
Start of epoch 508
step 0: mean loss = 1.5714322e-09
step 100: mean loss = 4.484448e-09
epoch 508: mean loss = 3.4586636e-09  learning rate = 3.5647903e-05
============================
Start of epoch 509
step 0: mean loss = 1.52885e-09
step 100: mean loss = 4.0463775e-09
epoch 509: mean loss = 4.1610124e-09  learning rate = 3.5647903e-05
============================
Start of epoch 510
step 0: mean loss = 2.2900801e-09
step 100: mean loss = 3.0644163e-09
epoch 510: mean loss = 3.1247476e-09  learning rate = 3.5647903e-05
============================
Start of epoch 511
step 0: mean loss = 1.6960865e-09
step 100: mean loss = 2.6091465e-09
epoch 511: mean loss = 3.4827041e-09  learning rate = 3.5647903e-05
============================
Start of epoch 512
step 0: mean loss = 2.3389564e-09
step 100: mean loss = 3.2467022e-09
epoch 512: mean loss = 3.2426113e-09  learning rate = 3.5647903e-05
============================
Start of epoch 513
step 0: mean loss = 1.7407217e-09
step 100: mean loss = 3.63231e-09
epoch 513: mean loss = 3.4470726e-09  learning rate = 3.5647903e-05
============================
Start of epoch 514
step 0: mean loss = 1.6058981e-09
step 100: mean loss = 4.3413313e-09
epoch 514: mean loss = 3.4429468e-09  learning rate = 3.5647903e-05
============================
Start of epoch 515
step 0: mean loss = 1.6292142e-09
step 100: mean loss = 3.8243764e-09
epoch 515: mean loss = 4.018193e-09  learning rate = 3.5647903e-05
============================
Start of epoch 516
step 0: mean loss = 1.6150729e-09
step 100: mean loss = 2.9599787e-09
epoch 516: mean loss = 3.00481e-09  learning rate = 3.5647903e-05
============================
Start of epoch 517
step 0: mean loss = 2.0494357e-09
step 100: mean loss = 3.979664e-09
epoch 517: mean loss = 3.938689e-09  learning rate = 3.5647903e-05
============================
Start of epoch 518
step 0: mean loss = 2.1792743e-09
step 100: mean loss = 4.0405532e-09
epoch 518: mean loss = 3.340148e-09  learning rate = 3.5647903e-05
============================
Start of epoch 519
step 0: mean loss = 4.4703627e-09
step 100: mean loss = 3.257853e-09
epoch 519: mean loss = 3.2052851e-09  learning rate = 3.5647903e-05
============================
Start of epoch 520
step 0: mean loss = 1.6416851e-09
step 100: mean loss = 3.7392227e-09
epoch 520: mean loss = 4.2868686e-09  learning rate = 3.5647903e-05
============================
Start of epoch 521
step 0: mean loss = 2.8292226e-09
step 100: mean loss = 3.5744538e-09
epoch 521: mean loss = 2.949794e-09  learning rate = 3.5647903e-05
============================
Start of epoch 522
step 0: mean loss = 1.5371523e-09
step 100: mean loss = 3.5697718e-09
epoch 522: mean loss = 4.125429e-09  learning rate = 3.5647903e-05
============================
Start of epoch 523
step 0: mean loss = 1.0433338e-08
step 100: mean loss = 3.4787542e-09
epoch 523: mean loss = 2.8687381e-09  learning rate = 3.5647903e-05
============================
Start of epoch 524
step 0: mean loss = 1.5570221e-09
step 100: mean loss = 3.3856717e-09
epoch 524: mean loss = 4.1499266e-09  learning rate = 3.5647903e-05
============================
Start of epoch 525
step 0: mean loss = 2.5978637e-09
step 100: mean loss = 4.661399e-09
epoch 525: mean loss = 3.9053702e-09  learning rate = 3.5647903e-05
============================
Start of epoch 526
step 0: mean loss = 1.5733853e-09
step 100: mean loss = 2.5873337e-09
epoch 526: mean loss = 2.2457727e-09  learning rate = 3.5647903e-05
============================
Start of epoch 527
step 0: mean loss = 1.6793729e-09
step 100: mean loss = 4.0890753e-09
epoch 527: mean loss = 3.491997e-09  learning rate = 3.3865508e-05
============================
Start of epoch 528
step 0: mean loss = 1.6227729e-09
step 100: mean loss = 1.5281617e-09
epoch 528: mean loss = 2.9003666e-09  learning rate = 3.3865508e-05
============================
Start of epoch 529
step 0: mean loss = 1.9225188e-09
step 100: mean loss = 3.0327614e-09
epoch 529: mean loss = 2.5103604e-09  learning rate = 3.3865508e-05
============================
Start of epoch 530
step 0: mean loss = 1.5345811e-09
step 100: mean loss = 4.805157e-09
epoch 530: mean loss = 3.7134291e-09  learning rate = 3.3865508e-05
============================
Start of epoch 531
step 0: mean loss = 4.8371147e-09
step 100: mean loss = 3.1013254e-09
epoch 531: mean loss = 3.4719612e-09  learning rate = 3.3865508e-05
============================
Start of epoch 532
step 0: mean loss = 2.4171158e-09
step 100: mean loss = 2.8505132e-09
epoch 532: mean loss = 2.95073e-09  learning rate = 3.3865508e-05
============================
Start of epoch 533
step 0: mean loss = 1.8655135e-09
step 100: mean loss = 3.2837928e-09
epoch 533: mean loss = 3.7210108e-09  learning rate = 3.3865508e-05
============================
Start of epoch 534
step 0: mean loss = 2.8251341e-09
step 100: mean loss = 3.5700676e-09
epoch 534: mean loss = 2.928925e-09  learning rate = 3.3865508e-05
============================
Start of epoch 535
step 0: mean loss = 2.8910758e-09
step 100: mean loss = 4.8667625e-09
epoch 535: mean loss = 3.768118e-09  learning rate = 3.3865508e-05
============================
Start of epoch 536
step 0: mean loss = 1.5273435e-09
step 100: mean loss = 2.700831e-09
epoch 536: mean loss = 2.3291806e-09  learning rate = 3.3865508e-05
============================
Start of epoch 537
step 0: mean loss = 5.0219393e-09
step 100: mean loss = 5.4526925e-09
epoch 537: mean loss = 4.1888373e-09  learning rate = 3.3865508e-05
============================
Start of epoch 538
step 0: mean loss = 5.592254e-09
step 100: mean loss = 3.1327503e-09
epoch 538: mean loss = 3.0921192e-09  learning rate = 3.3865508e-05
============================
Start of epoch 539
step 0: mean loss = 1.1073195e-08
step 100: mean loss = 3.1468992e-09
epoch 539: mean loss = 3.872014e-09  learning rate = 3.3865508e-05
============================
Start of epoch 540
step 0: mean loss = 1.153484e-08
step 100: mean loss = 3.8704395e-09
epoch 540: mean loss = 3.1339116e-09  learning rate = 3.3865508e-05
============================
Start of epoch 541
step 0: mean loss = 1.5179543e-09
step 100: mean loss = 2.4206148e-09
epoch 541: mean loss = 3.2158067e-09  learning rate = 3.3865508e-05
============================
Start of epoch 542
step 0: mean loss = 1.601281e-08
step 100: mean loss = 3.1425398e-09
epoch 542: mean loss = 2.724958e-09  learning rate = 3.3865508e-05
============================
Start of epoch 543
step 0: mean loss = 2.0704307e-09
step 100: mean loss = 3.9690002e-09
epoch 543: mean loss = 3.273921e-09  learning rate = 3.3865508e-05
============================
Start of epoch 544
step 0: mean loss = 5.4070632e-09
step 100: mean loss = 3.388363e-09
epoch 544: mean loss = 3.7845194e-09  learning rate = 3.3865508e-05
============================
Start of epoch 545
step 0: mean loss = 1.563634e-09
step 100: mean loss = 2.9001364e-09
epoch 545: mean loss = 3.888897e-09  learning rate = 3.3865508e-05
============================
Start of epoch 546
step 0: mean loss = 2.1440025e-09
step 100: mean loss = 2.1123743e-09
epoch 546: mean loss = 2.2886903e-09  learning rate = 3.3865508e-05
============================
Start of epoch 547
step 0: mean loss = 2.9062874e-09
step 100: mean loss = 4.165238e-09
epoch 547: mean loss = 3.5222376e-09  learning rate = 3.3865508e-05
============================
Start of epoch 548
step 0: mean loss = 1.5594545e-09
step 100: mean loss = 3.5892431e-09
epoch 548: mean loss = 3.4154009e-09  learning rate = 3.3865508e-05
============================
Start of epoch 549
step 0: mean loss = 1.3097195e-08
step 100: mean loss = 4.6202753e-09
epoch 549: mean loss = 3.8220342e-09  learning rate = 3.3865508e-05
============================
Start of epoch 550
step 0: mean loss = 1.5262864e-09
step 100: mean loss = 3.1632643e-09
epoch 550: mean loss = 2.595336e-09  learning rate = 3.3865508e-05
============================
Start of epoch 551
step 0: mean loss = 1.5443501e-09
step 100: mean loss = 3.6629964e-09
epoch 551: mean loss = 3.6573709e-09  learning rate = 3.3865508e-05
============================
Start of epoch 552
step 0: mean loss = 2.2116826e-09
step 100: mean loss = 3.4540524e-09
epoch 552: mean loss = 2.7877312e-09  learning rate = 3.3865508e-05
============================
Start of epoch 553
step 0: mean loss = 1.6313159e-09
step 100: mean loss = 4.0346952e-09
epoch 553: mean loss = 3.818167e-09  learning rate = 3.3865508e-05
============================
Start of epoch 554
step 0: mean loss = 1.5415023e-09
step 100: mean loss = 4.0602997e-09
epoch 554: mean loss = 3.2195742e-09  learning rate = 3.3865508e-05
============================
Start of epoch 555
step 0: mean loss = 1.5264e-09
step 100: mean loss = 5.810185e-09
epoch 555: mean loss = 4.3463517e-09  learning rate = 3.3865508e-05
============================
Start of epoch 556
step 0: mean loss = 1.5123812e-09
step 100: mean loss = 2.6839788e-09
epoch 556: mean loss = 2.3244788e-09  learning rate = 3.3865508e-05
============================
Start of epoch 557
step 0: mean loss = 1.51663e-09
step 100: mean loss = 4.472363e-09
epoch 557: mean loss = 3.475246e-09  learning rate = 3.3865508e-05
============================
Start of epoch 558
step 0: mean loss = 1.8444148e-09
step 100: mean loss = 2.4823046e-09
epoch 558: mean loss = 3.3878582e-09  learning rate = 3.3865508e-05
============================
Start of epoch 559
step 0: mean loss = 1.758043e-09
step 100: mean loss = 4.2081285e-09
epoch 559: mean loss = 3.2848895e-09  learning rate = 3.3865508e-05
============================
Start of epoch 560
step 0: mean loss = 1.5114128e-09
step 100: mean loss = 3.7588013e-09
epoch 560: mean loss = 2.9763043e-09  learning rate = 3.3865508e-05
============================
Start of epoch 561
step 0: mean loss = 1.5062313e-09
step 100: mean loss = 5.0576268e-09
epoch 561: mean loss = 3.8277737e-09  learning rate = 3.3865508e-05
============================
Start of epoch 562
step 0: mean loss = 1.5088837e-09
step 100: mean loss = 3.3016538e-09
epoch 562: mean loss = 2.6803408e-09  learning rate = 3.3865508e-05
============================
Start of epoch 563
step 0: mean loss = 1.5399657e-09
step 100: mean loss = 3.9654764e-09
epoch 563: mean loss = 4.280769e-09  learning rate = 3.3865508e-05
============================
Start of epoch 564
step 0: mean loss = 1.9524138e-09
step 100: mean loss = 3.3577872e-09
epoch 564: mean loss = 2.7785965e-09  learning rate = 3.3865508e-05
============================
Start of epoch 565
step 0: mean loss = 1.5158436e-09
step 100: mean loss = 3.3780925e-09
epoch 565: mean loss = 3.3192487e-09  learning rate = 3.3865508e-05
============================
Start of epoch 566
step 0: mean loss = 1.6921023e-09
step 100: mean loss = 3.3687693e-09
epoch 566: mean loss = 3.3091192e-09  learning rate = 3.3865508e-05
============================
Start of epoch 567
step 0: mean loss = 3.8842005e-09
step 100: mean loss = 4.494799e-09
epoch 567: mean loss = 3.4927918e-09  learning rate = 3.3865508e-05
============================
Start of epoch 568
step 0: mean loss = 1.5129313e-09
step 100: mean loss = 3.1813692e-09
epoch 568: mean loss = 2.6063098e-09  learning rate = 3.3865508e-05
============================
Start of epoch 569
step 0: mean loss = 2.085045e-09
step 100: mean loss = 4.39988e-09
epoch 569: mean loss = 4.103737e-09  learning rate = 3.3865508e-05
============================
Start of epoch 570
step 0: mean loss = 1.9295223e-09
step 100: mean loss = 3.156275e-09
epoch 570: mean loss = 2.8551166e-09  learning rate = 3.3865508e-05
============================
Start of epoch 571
step 0: mean loss = 3.7855936e-09
step 100: mean loss = 3.4998529e-09
epoch 571: mean loss = 3.842695e-09  learning rate = 3.3865508e-05
============================
Start of epoch 572
step 0: mean loss = 3.7347396e-09
step 100: mean loss = 2.0700621e-09
epoch 572: mean loss = 3.0877012e-09  learning rate = 3.3865508e-05
============================
Start of epoch 573
step 0: mean loss = 1.8407462e-09
step 100: mean loss = 3.648362e-09
epoch 573: mean loss = 3.0515928e-09  learning rate = 3.3865508e-05
============================
Start of epoch 574
step 0: mean loss = 1.5616216e-09
step 100: mean loss = 2.9394325e-09
epoch 574: mean loss = 3.281349e-09  learning rate = 3.3865508e-05
============================
Start of epoch 575
step 0: mean loss = 1.5991517e-09
step 100: mean loss = 2.9746452e-09
epoch 575: mean loss = 3.6508108e-09  learning rate = 3.3865508e-05
============================
Start of epoch 576
step 0: mean loss = 1.69073e-09
step 100: mean loss = 3.2326009e-09
epoch 576: mean loss = 2.6465008e-09  learning rate = 3.3865508e-05
============================
Start of epoch 577
step 0: mean loss = 1.5475017e-09
step 100: mean loss = 3.6462344e-09
epoch 577: mean loss = 3.6832144e-09  learning rate = 3.3865508e-05
============================
Start of epoch 578
step 0: mean loss = 1.6346619e-09
step 100: mean loss = 3.2728626e-09
epoch 578: mean loss = 3.2664362e-09  learning rate = 3.3865508e-05
============================
Start of epoch 579
step 0: mean loss = 5.5880918e-09
step 100: mean loss = 3.0039737e-09
epoch 579: mean loss = 3.537519e-09  learning rate = 3.3865508e-05
============================
Start of epoch 580
step 0: mean loss = 7.754672e-09
step 100: mean loss = 2.9357627e-09
epoch 580: mean loss = 2.67782e-09  learning rate = 3.3865508e-05
============================
Start of epoch 581
step 0: mean loss = 8.999882e-09
step 100: mean loss = 3.6518126e-09
epoch 581: mean loss = 3.8719605e-09  learning rate = 3.3865508e-05
============================
Start of epoch 582
step 0: mean loss = 1.5805703e-09
step 100: mean loss = 2.4986855e-09
epoch 582: mean loss = 3.3330607e-09  learning rate = 3.3865508e-05
============================
Start of epoch 583
step 0: mean loss = 1.5582402e-09
step 100: mean loss = 3.4505068e-09
epoch 583: mean loss = 2.779731e-09  learning rate = 3.3865508e-05
============================
Start of epoch 584
step 0: mean loss = 1.5009455e-09
step 100: mean loss = 4.0275974e-09
epoch 584: mean loss = 3.5382337e-09  learning rate = 3.3865508e-05
============================
Start of epoch 585
step 0: mean loss = 2.4421503e-09
step 100: mean loss = 3.3990293e-09
epoch 585: mean loss = 2.9030267e-09  learning rate = 3.3865508e-05
============================
Start of epoch 586
step 0: mean loss = 6.2614385e-09
step 100: mean loss = 2.942604e-09
epoch 586: mean loss = 4.056146e-09  learning rate = 3.3865508e-05
============================
Start of epoch 587
step 0: mean loss = 2.5975941e-09
step 100: mean loss = 2.8446565e-09
epoch 587: mean loss = 2.4319051e-09  learning rate = 3.3865508e-05
============================
Start of epoch 588
step 0: mean loss = 1.5366244e-09
step 100: mean loss = 4.112531e-09
epoch 588: mean loss = 3.9304258e-09  learning rate = 3.3865508e-05
============================
Start of epoch 589
step 0: mean loss = 2.6407813e-08
step 100: mean loss = 2.8248535e-09
epoch 589: mean loss = 3.1673517e-09  learning rate = 3.3865508e-05
============================
Start of epoch 590
step 0: mean loss = 7.2532655e-09
step 100: mean loss = 3.0863962e-09
epoch 590: mean loss = 3.319543e-09  learning rate = 3.3865508e-05
============================
Start of epoch 591
step 0: mean loss = 1.5239925e-09
step 100: mean loss = 3.1623195e-09
epoch 591: mean loss = 3.194573e-09  learning rate = 3.3865508e-05
============================
Start of epoch 592
step 0: mean loss = 1.7393905e-09
step 100: mean loss = 4.1097508e-09
epoch 592: mean loss = 3.210321e-09  learning rate = 3.3865508e-05
============================
Start of epoch 593
step 0: mean loss = 1.5046553e-09
step 100: mean loss = 3.868649e-09
epoch 593: mean loss = 3.929783e-09  learning rate = 3.3865508e-05
============================
Start of epoch 594
step 0: mean loss = 1.993619e-09
step 100: mean loss = 1.9682058e-09
epoch 594: mean loss = 3.2104672e-09  learning rate = 3.3865508e-05
============================
Start of epoch 595
step 0: mean loss = 2.4987599e-09
step 100: mean loss = 2.7617988e-09
epoch 595: mean loss = 2.786843e-09  learning rate = 3.3865508e-05
============================
Start of epoch 596
step 0: mean loss = 1.3212511e-08
step 100: mean loss = 2.8080114e-09
epoch 596: mean loss = 3.3745922e-09  learning rate = 3.3865508e-05
============================
Start of epoch 597
step 0: mean loss = 1.5017947e-09
step 100: mean loss = 4.111441e-09
epoch 597: mean loss = 3.2376648e-09  learning rate = 3.3865508e-05
============================
Start of epoch 598
step 0: mean loss = 1.8579766e-09
step 100: mean loss = 2.8966347e-09
epoch 598: mean loss = 3.6017667e-09  learning rate = 3.3865508e-05
============================
Start of epoch 599
step 0: mean loss = 3.6801082e-09
step 100: mean loss = 2.7307843e-09
epoch 599: mean loss = 3.2518876e-09  learning rate = 3.3865508e-05
============================
Start of epoch 600
step 0: mean loss = 1.9018819e-08
step 100: mean loss = 3.4565264e-09
epoch 600: mean loss = 2.995961e-09  learning rate = 3.3865508e-05
============================
Start of epoch 601
step 0: mean loss = 1.5327863e-09
step 100: mean loss = 4.5936703e-09
epoch 601: mean loss = 3.526742e-09  learning rate = 3.3865508e-05
============================
Start of epoch 602
step 0: mean loss = 1.4911297e-09
step 100: mean loss = 3.0079688e-09
epoch 602: mean loss = 2.7396254e-09  learning rate = 3.3865508e-05
============================
Start of epoch 603
step 0: mean loss = 1.954677e-08
step 100: mean loss = 4.110675e-09
epoch 603: mean loss = 3.3991758e-09  learning rate = 3.3865508e-05
============================
Start of epoch 604
step 0: mean loss = 1.5861926e-09
step 100: mean loss = 3.9251553e-09
epoch 604: mean loss = 3.124477e-09  learning rate = 3.3865508e-05
============================
Start of epoch 605
step 0: mean loss = 1.5240995e-09
step 100: mean loss = 3.960503e-09
epoch 605: mean loss = 3.9682106e-09  learning rate = 3.3865508e-05
============================
Start of epoch 606
step 0: mean loss = 1.9112294e-09
step 100: mean loss = 3.9382484e-09
epoch 606: mean loss = 3.1379368e-09  learning rate = 3.3865508e-05
============================
Start of epoch 607
step 0: mean loss = 1.4888677e-09
step 100: mean loss = 3.0932221e-09
epoch 607: mean loss = 3.4301482e-09  learning rate = 3.3865508e-05
============================
Start of epoch 608
step 0: mean loss = 3.1785816e-09
step 100: mean loss = 1.6074582e-09
epoch 608: mean loss = 1.5670144e-09  learning rate = 3.217223e-05
============================
Start of epoch 609
step 0: mean loss = 1.4934328e-09
step 100: mean loss = 3.479247e-09
epoch 609: mean loss = 3.438425e-09  learning rate = 3.217223e-05
============================
Start of epoch 610
step 0: mean loss = 1.8540233e-09
step 100: mean loss = 2.8774785e-09
epoch 610: mean loss = 3.2391636e-09  learning rate = 3.217223e-05
============================
Start of epoch 611
step 0: mean loss = 2.7260825e-09
step 100: mean loss = 3.1784355e-09
epoch 611: mean loss = 2.6284719e-09  learning rate = 3.217223e-05
============================
Start of epoch 612
step 0: mean loss = 1.8680593e-09
step 100: mean loss = 3.0263931e-09
epoch 612: mean loss = 3.2464094e-09  learning rate = 3.217223e-05
============================
Start of epoch 613
step 0: mean loss = 1.6728996e-09
step 100: mean loss = 3.0337384e-09
epoch 613: mean loss = 3.0844516e-09  learning rate = 3.217223e-05
============================
Start of epoch 614
step 0: mean loss = 1.0371416e-08
step 100: mean loss = 3.4869005e-09
epoch 614: mean loss = 3.191659e-09  learning rate = 3.217223e-05
============================
Start of epoch 615
step 0: mean loss = 3.3803165e-09
step 100: mean loss = 3.729431e-09
epoch 615: mean loss = 2.9944387e-09  learning rate = 3.217223e-05
============================
Start of epoch 616
step 0: mean loss = 1.5916372e-09
step 100: mean loss = 3.1503695e-09
epoch 616: mean loss = 3.1577212e-09  learning rate = 3.217223e-05
============================
Start of epoch 617
step 0: mean loss = 2.1927717e-09
step 100: mean loss = 2.6504499e-09
epoch 617: mean loss = 3.6630952e-09  learning rate = 3.217223e-05
============================
Start of epoch 618
step 0: mean loss = 2.1116913e-09
step 100: mean loss = 3.3769583e-09
epoch 618: mean loss = 2.812576e-09  learning rate = 3.217223e-05
============================
Start of epoch 619
step 0: mean loss = 1.4851832e-09
step 100: mean loss = 4.2174735e-09
epoch 619: mean loss = 3.554679e-09  learning rate = 3.217223e-05
============================
Start of epoch 620
step 0: mean loss = 1.4953424e-09
step 100: mean loss = 2.9964726e-09
epoch 620: mean loss = 2.496721e-09  learning rate = 3.217223e-05
============================
Start of epoch 621
step 0: mean loss = 1.4844107e-09
step 100: mean loss = 3.3225083e-09
epoch 621: mean loss = 2.9870117e-09  learning rate = 3.217223e-05
============================
Start of epoch 622
step 0: mean loss = 4.476578e-09
step 100: mean loss = 3.292456e-09
epoch 622: mean loss = 3.2692777e-09  learning rate = 3.217223e-05
============================
Start of epoch 623
step 0: mean loss = 1.6733316e-09
step 100: mean loss = 2.7585827e-09
epoch 623: mean loss = 2.6384466e-09  learning rate = 3.217223e-05
============================
Start of epoch 624
step 0: mean loss = 1.7283242e-09
step 100: mean loss = 3.0966414e-09
epoch 624: mean loss = 3.480462e-09  learning rate = 3.217223e-05
============================
Start of epoch 625
step 0: mean loss = 1.5810108e-09
step 100: mean loss = 3.6388201e-09
epoch 625: mean loss = 2.8888838e-09  learning rate = 3.217223e-05
============================
Start of epoch 626
step 0: mean loss = 1.4977348e-09
step 100: mean loss = 3.534362e-09
epoch 626: mean loss = 3.4397474e-09  learning rate = 3.217223e-05
============================
Start of epoch 627
step 0: mean loss = 1.5556978e-09
step 100: mean loss = 3.3632017e-09
epoch 627: mean loss = 2.8974032e-09  learning rate = 3.217223e-05
============================
Start of epoch 628
step 0: mean loss = 2.3988371e-09
step 100: mean loss = 2.5716398e-09
epoch 628: mean loss = 3.6567547e-09  learning rate = 3.217223e-05
============================
Start of epoch 629
step 0: mean loss = 1.6527857e-09
step 100: mean loss = 2.604012e-09
epoch 629: mean loss = 2.468235e-09  learning rate = 3.217223e-05
============================
Start of epoch 630
step 0: mean loss = 1.9477813e-09
step 100: mean loss = 3.1430702e-09
epoch 630: mean loss = 3.5589691e-09  learning rate = 3.217223e-05
============================
Start of epoch 631
step 0: mean loss = 8.397936e-09
step 100: mean loss = 2.0867053e-09
epoch 631: mean loss = 3.3192193e-09  learning rate = 3.217223e-05
============================
Start of epoch 632
step 0: mean loss = 1.826841e-09
step 100: mean loss = 2.7564964e-09
epoch 632: mean loss = 2.332579e-09  learning rate = 3.217223e-05
============================
Start of epoch 633
step 0: mean loss = 1.5077246e-09
step 100: mean loss = 4.0079975e-09
epoch 633: mean loss = 3.1709595e-09  learning rate = 3.217223e-05
============================
Start of epoch 634
step 0: mean loss = 3.6440013e-09
step 100: mean loss = 3.1672323e-09
epoch 634: mean loss = 3.600873e-09  learning rate = 3.217223e-05
============================
Start of epoch 635
step 0: mean loss = 1.4863056e-09
step 100: mean loss = 2.9878795e-09
epoch 635: mean loss = 2.5186409e-09  learning rate = 3.217223e-05
============================
Start of epoch 636
step 0: mean loss = 2.8205884e-09
step 100: mean loss = 3.1558778e-09
epoch 636: mean loss = 3.536771e-09  learning rate = 3.217223e-05
============================
Start of epoch 637
step 0: mean loss = 1.5359771e-09
step 100: mean loss = 2.934156e-09
epoch 637: mean loss = 2.450129e-09  learning rate = 3.217223e-05
============================
Start of epoch 638
step 0: mean loss = 2.8378235e-09
step 100: mean loss = 3.812705e-09
epoch 638: mean loss = 3.4592018e-09  learning rate = 3.217223e-05
============================
Start of epoch 639
step 0: mean loss = 1.7387655e-09
step 100: mean loss = 2.9555187e-09
epoch 639: mean loss = 3.023649e-09  learning rate = 3.217223e-05
============================
Start of epoch 640
step 0: mean loss = 1.9002286e-09
step 100: mean loss = 3.6442358e-09
epoch 640: mean loss = 3.0738936e-09  learning rate = 3.217223e-05
============================
Start of epoch 641
step 0: mean loss = 7.77295e-09
step 100: mean loss = 3.818989e-09
epoch 641: mean loss = 3.1251999e-09  learning rate = 3.217223e-05
============================
Start of epoch 642
step 0: mean loss = 2.3335993e-09
step 100: mean loss = 3.4747707e-09
epoch 642: mean loss = 3.1878742e-09  learning rate = 3.217223e-05
============================
Start of epoch 643
step 0: mean loss = 1.7099048e-08
step 100: mean loss = 2.891413e-09
epoch 643: mean loss = 2.8185507e-09  learning rate = 3.217223e-05
============================
Start of epoch 644
step 0: mean loss = 2.9375917e-09
step 100: mean loss = 2.8649305e-09
epoch 644: mean loss = 3.8267616e-09  learning rate = 3.217223e-05
============================
Start of epoch 645
step 0: mean loss = 1.8336624e-09
step 100: mean loss = 3.0802678e-09
epoch 645: mean loss = 2.5825686e-09  learning rate = 3.217223e-05
============================
Start of epoch 646
step 0: mean loss = 1.4771468e-09
step 100: mean loss = 3.849211e-09
epoch 646: mean loss = 3.020615e-09  learning rate = 3.217223e-05
============================
Start of epoch 647
step 0: mean loss = 1.483233e-09
step 100: mean loss = 3.414106e-09
epoch 647: mean loss = 3.3445244e-09  learning rate = 3.217223e-05
============================
Start of epoch 648
step 0: mean loss = 1.5824816e-09
step 100: mean loss = 2.697275e-09
epoch 648: mean loss = 2.647582e-09  learning rate = 3.217223e-05
============================
Start of epoch 649
step 0: mean loss = 7.650261e-09
step 100: mean loss = 3.725952e-09
epoch 649: mean loss = 3.1087402e-09  learning rate = 3.217223e-05
============================
Start of epoch 650
step 0: mean loss = 1.7834294e-09
step 100: mean loss = 4.366212e-09
epoch 650: mean loss = 3.431258e-09  learning rate = 3.217223e-05
============================
Start of epoch 651
step 0: mean loss = 1.9473203e-09
step 100: mean loss = 3.000648e-09
epoch 651: mean loss = 2.9502296e-09  learning rate = 3.217223e-05
============================
Start of epoch 652
step 0: mean loss = 1.5253232e-09
step 100: mean loss = 3.6286272e-09
epoch 652: mean loss = 3.384774e-09  learning rate = 3.217223e-05
============================
Start of epoch 653
step 0: mean loss = 1.641302e-09
step 100: mean loss = 3.3153147e-09
epoch 653: mean loss = 2.801757e-09  learning rate = 3.217223e-05
============================
Start of epoch 654
step 0: mean loss = 1.5246903e-09
step 100: mean loss = 2.9095482e-09
epoch 654: mean loss = 3.8106287e-09  learning rate = 3.217223e-05
============================
Start of epoch 655
step 0: mean loss = 2.2019722e-09
step 100: mean loss = 1.9044286e-09
epoch 655: mean loss = 2.289048e-09  learning rate = 3.217223e-05
============================
Start of epoch 656
step 0: mean loss = 4.5341255e-09
step 100: mean loss = 3.0966285e-09
epoch 656: mean loss = 3.3938639e-09  learning rate = 3.217223e-05
============================
Start of epoch 657
step 0: mean loss = 2.0944954e-08
step 100: mean loss = 4.0985513e-09
epoch 657: mean loss = 3.6074466e-09  learning rate = 3.217223e-05
============================
Start of epoch 658
step 0: mean loss = 1.4814171e-09
step 100: mean loss = 2.0702053e-09
epoch 658: mean loss = 2.5025235e-09  learning rate = 3.217223e-05
============================
Start of epoch 659
step 0: mean loss = 1.4933397e-09
step 100: mean loss = 2.5670794e-09
epoch 659: mean loss = 3.654078e-09  learning rate = 3.217223e-05
============================
Start of epoch 660
step 0: mean loss = 1.5122543e-09
step 100: mean loss = 2.7348188e-09
epoch 660: mean loss = 2.319128e-09  learning rate = 3.217223e-05
============================
Start of epoch 661
step 0: mean loss = 1.4737835e-09
step 100: mean loss = 3.6583891e-09
epoch 661: mean loss = 2.908915e-09  learning rate = 3.217223e-05
============================
Start of epoch 662
step 0: mean loss = 1.4774523e-09
step 100: mean loss = 4.4810715e-09
epoch 662: mean loss = 3.6290086e-09  learning rate = 3.217223e-05
============================
Start of epoch 663
step 0: mean loss = 2.1631985e-09
step 100: mean loss = 2.3423044e-09
epoch 663: mean loss = 2.996294e-09  learning rate = 3.217223e-05
============================
Start of epoch 664
step 0: mean loss = 1.6809426e-09
step 100: mean loss = 2.662079e-09
epoch 664: mean loss = 3.1015248e-09  learning rate = 3.217223e-05
============================
Start of epoch 665
step 0: mean loss = 1.6354513e-09
step 100: mean loss = 3.6052024e-09
epoch 665: mean loss = 2.9097333e-09  learning rate = 3.217223e-05
============================
Start of epoch 666
step 0: mean loss = 1.4806671e-09
step 100: mean loss = 3.4139207e-09
epoch 666: mean loss = 3.167756e-09  learning rate = 3.217223e-05
============================
Start of epoch 667
step 0: mean loss = 3.2365417e-09
step 100: mean loss = 2.687176e-09
epoch 667: mean loss = 3.1397294e-09  learning rate = 3.217223e-05
============================
Start of epoch 668
step 0: mean loss = 2.630214e-09
step 100: mean loss = 2.8928377e-09
epoch 668: mean loss = 3.0244964e-09  learning rate = 3.217223e-05
============================
Start of epoch 669
step 0: mean loss = 1.9815811e-09
step 100: mean loss = 2.611215e-09
epoch 669: mean loss = 3.6355452e-09  learning rate = 3.217223e-05
============================
Start of epoch 670
step 0: mean loss = 4.2146495e-09
step 100: mean loss = 1.6822326e-09
epoch 670: mean loss = 2.958561e-09  learning rate = 3.217223e-05
============================
Start of epoch 671
step 0: mean loss = 1.6382239e-09
step 100: mean loss = 2.6966054e-09
epoch 671: mean loss = 2.5665154e-09  learning rate = 3.217223e-05
============================
Start of epoch 672
step 0: mean loss = 3.755477e-09
step 100: mean loss = 3.121464e-09
epoch 672: mean loss = 2.8404061e-09  learning rate = 3.217223e-05
============================
Start of epoch 673
step 0: mean loss = 1.6377106e-09
step 100: mean loss = 3.4915284e-09
epoch 673: mean loss = 3.0043807e-09  learning rate = 3.217223e-05
============================
Start of epoch 674
step 0: mean loss = 2.348315e-09
step 100: mean loss = 3.2104244e-09
epoch 674: mean loss = 3.6274561e-09  learning rate = 3.217223e-05
============================
Start of epoch 675
step 0: mean loss = 1.8395755e-09
step 100: mean loss = 4.3873625e-09
epoch 675: mean loss = 3.3935803e-09  learning rate = 3.217223e-05
============================
Start of epoch 676
step 0: mean loss = 1.4667099e-09
step 100: mean loss = 2.1402309e-09
epoch 676: mean loss = 2.9305731e-09  learning rate = 3.217223e-05
============================
Start of epoch 677
step 0: mean loss = 2.687103e-09
step 100: mean loss = 3.069939e-09
epoch 677: mean loss = 2.6029277e-09  learning rate = 3.217223e-05
============================
Start of epoch 678
step 0: mean loss = 3.4865486e-09
step 100: mean loss = 3.2001226e-09
epoch 678: mean loss = 3.0446416e-09  learning rate = 3.217223e-05
============================
Start of epoch 679
step 0: mean loss = 2.0783075e-09
step 100: mean loss = 2.7302702e-09
epoch 679: mean loss = 3.5464824e-09  learning rate = 3.217223e-05
============================
Start of epoch 680
step 0: mean loss = 2.1481517e-09
step 100: mean loss = 3.449778e-09
epoch 680: mean loss = 2.762476e-09  learning rate = 3.217223e-05
============================
Start of epoch 681
step 0: mean loss = 1.4629417e-09
step 100: mean loss = 3.6328716e-09
epoch 681: mean loss = 2.960408e-09  learning rate = 3.217223e-05
============================
Start of epoch 682
step 0: mean loss = 7.800481e-09
step 100: mean loss = 3.07211e-09
epoch 682: mean loss = 3.751576e-09  learning rate = 3.217223e-05
============================
Start of epoch 683
step 0: mean loss = 1.5844297e-09
step 100: mean loss = 2.6409506e-09
epoch 683: mean loss = 2.4400455e-09  learning rate = 3.217223e-05
============================
Start of epoch 684
step 0: mean loss = 8.183238e-09
step 100: mean loss = 3.272405e-09
epoch 684: mean loss = 3.1407041e-09  learning rate = 3.217223e-05
============================
Start of epoch 685
step 0: mean loss = 3.1031526e-09
step 100: mean loss = 3.0945317e-09
epoch 685: mean loss = 3.1559642e-09  learning rate = 3.217223e-05
============================
Start of epoch 686
step 0: mean loss = 1.6786025e-09
step 100: mean loss = 3.2680316e-09
epoch 686: mean loss = 3.1049057e-09  learning rate = 3.217223e-05
============================
Start of epoch 687
step 0: mean loss = 2.298992e-09
step 100: mean loss = 2.9720224e-09
epoch 687: mean loss = 2.8955092e-09  learning rate = 3.217223e-05
============================
Start of epoch 688
step 0: mean loss = 1.8716215e-09
step 100: mean loss = 2.8929172e-09
epoch 688: mean loss = 3.0390486e-09  learning rate = 3.217223e-05
============================
Start of epoch 689
step 0: mean loss = 1.9958382e-09
step 100: mean loss = 1.5257872e-09
epoch 689: mean loss = 2.2905708e-09  learning rate = 3.056362e-05
============================
Start of epoch 690
step 0: mean loss = 5.5404796e-09
step 100: mean loss = 2.0099247e-09
epoch 690: mean loss = 2.7592728e-09  learning rate = 3.056362e-05
============================
Start of epoch 691
step 0: mean loss = 1.4945701e-09
step 100: mean loss = 2.8124831e-09
epoch 691: mean loss = 2.5965994e-09  learning rate = 3.056362e-05
============================
Start of epoch 692
step 0: mean loss = 1.3813109e-08
step 100: mean loss = 2.871597e-09
epoch 692: mean loss = 3.3565908e-09  learning rate = 3.056362e-05
============================
Start of epoch 693
step 0: mean loss = 1.6021866e-09
step 100: mean loss = 2.7619524e-09
epoch 693: mean loss = 2.4477744e-09  learning rate = 3.056362e-05
============================
Start of epoch 694
step 0: mean loss = 8.056533e-09
step 100: mean loss = 2.7323477e-09
epoch 694: mean loss = 3.2941476e-09  learning rate = 3.056362e-05
============================
Start of epoch 695
step 0: mean loss = 1.8715087e-09
step 100: mean loss = 2.4619797e-09
epoch 695: mean loss = 2.7884939e-09  learning rate = 3.056362e-05
============================
Start of epoch 696
step 0: mean loss = 1.4686441e-09
step 100: mean loss = 3.2791787e-09
epoch 696: mean loss = 3.1989682e-09  learning rate = 3.056362e-05
============================
Start of epoch 697
step 0: mean loss = 3.4461343e-09
step 100: mean loss = 3.0887515e-09
epoch 697: mean loss = 2.8189346e-09  learning rate = 3.056362e-05
============================
Start of epoch 698
step 0: mean loss = 1.5920483e-09
step 100: mean loss = 2.704811e-09
epoch 698: mean loss = 2.843294e-09  learning rate = 3.056362e-05
============================
Start of epoch 699
step 0: mean loss = 1.48285e-09
step 100: mean loss = 2.8131015e-09
epoch 699: mean loss = 2.6708675e-09  learning rate = 3.056362e-05
============================
Start of epoch 700
step 0: mean loss = 1.4696121e-09
step 100: mean loss = 2.999004e-09
epoch 700: mean loss = 3.318452e-09  learning rate = 3.056362e-05
============================
Start of epoch 701
step 0: mean loss = 2.1479343e-09
step 100: mean loss = 2.8587872e-09
epoch 701: mean loss = 2.4818214e-09  learning rate = 3.056362e-05
============================
Start of epoch 702
step 0: mean loss = 1.6173631e-09
step 100: mean loss = 2.7672544e-09
epoch 702: mean loss = 2.927963e-09  learning rate = 3.056362e-05
============================
Start of epoch 703
step 0: mean loss = 1.5827026e-09
step 100: mean loss = 3.7368344e-09
epoch 703: mean loss = 2.9678366e-09  learning rate = 3.056362e-05
============================
Start of epoch 704
step 0: mean loss = 2.170688e-09
step 100: mean loss = 2.5973357e-09
epoch 704: mean loss = 3.386812e-09  learning rate = 3.056362e-05
============================
Start of epoch 705
step 0: mean loss = 1.9497834e-09
step 100: mean loss = 2.5520421e-09
epoch 705: mean loss = 2.205462e-09  learning rate = 3.056362e-05
============================
Start of epoch 706
step 0: mean loss = 1.4812024e-09
step 100: mean loss = 3.8596726e-09
epoch 706: mean loss = 3.4691956e-09  learning rate = 3.056362e-05
============================
Start of epoch 707
step 0: mean loss = 2.833218e-09
step 100: mean loss = 2.8735776e-09
epoch 707: mean loss = 2.8903528e-09  learning rate = 3.056362e-05
============================
Start of epoch 708
step 0: mean loss = 1.4599842e-09
step 100: mean loss = 2.3891775e-09
epoch 708: mean loss = 2.7931122e-09  learning rate = 3.056362e-05
============================
Start of epoch 709
step 0: mean loss = 2.133276e-09
step 100: mean loss = 2.7041267e-09
epoch 709: mean loss = 3.4977938e-09  learning rate = 3.056362e-05
============================
Start of epoch 710
step 0: mean loss = 4.809599e-09
step 100: mean loss = 1.7461197e-09
epoch 710: mean loss = 2.7418248e-09  learning rate = 3.056362e-05
============================
Start of epoch 711
step 0: mean loss = 1.907253e-09
step 100: mean loss = 2.6642195e-09
epoch 711: mean loss = 2.4569786e-09  learning rate = 3.056362e-05
============================
Start of epoch 712
step 0: mean loss = 1.4510333e-09
step 100: mean loss = 2.9567282e-09
epoch 712: mean loss = 3.085351e-09  learning rate = 3.056362e-05
============================
Start of epoch 713
step 0: mean loss = 2.7515825e-09
step 100: mean loss = 2.1744095e-09
epoch 713: mean loss = 2.619157e-09  learning rate = 3.056362e-05
============================
Start of epoch 714
step 0: mean loss = 1.8139663e-09
step 100: mean loss = 2.5169529e-09
epoch 714: mean loss = 3.4946213e-09  learning rate = 3.056362e-05
============================
Start of epoch 715
step 0: mean loss = 1.4533081e-09
step 100: mean loss = 1.4969525e-09
epoch 715: mean loss = 2.6611797e-09  learning rate = 3.056362e-05
============================
Start of epoch 716
step 0: mean loss = 1.4581082e-09
step 100: mean loss = 3.0925027e-09
epoch 716: mean loss = 2.522285e-09  learning rate = 3.056362e-05
============================
Start of epoch 717
step 0: mean loss = 1.4450902e-09
step 100: mean loss = 3.6518795e-09
epoch 717: mean loss = 3.2525274e-09  learning rate = 3.056362e-05
============================
Start of epoch 718
step 0: mean loss = 6.755914e-09
step 100: mean loss = 2.8767209e-09
epoch 718: mean loss = 2.568322e-09  learning rate = 3.056362e-05
============================
Start of epoch 719
step 0: mean loss = 3.007636e-09
step 100: mean loss = 3.2772538e-09
epoch 719: mean loss = 3.3274006e-09  learning rate = 3.056362e-05
============================
Start of epoch 720
step 0: mean loss = 1.4770295e-09
step 100: mean loss = 3.1463412e-09
epoch 720: mean loss = 2.613398e-09  learning rate = 3.056362e-05
============================
Start of epoch 721
step 0: mean loss = 1.4469683e-09
step 100: mean loss = 2.7573612e-09
epoch 721: mean loss = 2.9788252e-09  learning rate = 3.056362e-05
============================
Start of epoch 722
step 0: mean loss = 1.4921078e-09
step 100: mean loss = 2.9211147e-09
epoch 722: mean loss = 2.9217064e-09  learning rate = 3.056362e-05
============================
Start of epoch 723
step 0: mean loss = 1.8273377e-09
step 100: mean loss = 2.5232447e-09
epoch 723: mean loss = 3.061221e-09  learning rate = 3.056362e-05
============================
Start of epoch 724
step 0: mean loss = 9.575159e-09
step 100: mean loss = 2.0953939e-09
epoch 724: mean loss = 2.769353e-09  learning rate = 3.056362e-05
============================
Start of epoch 725
step 0: mean loss = 1.6404197e-09
step 100: mean loss = 2.639957e-09
epoch 725: mean loss = 3.3666865e-09  learning rate = 3.056362e-05
============================
Start of epoch 726
step 0: mean loss = 2.115892e-09
step 100: mean loss = 1.6117647e-09
epoch 726: mean loss = 2.5526539e-09  learning rate = 3.056362e-05
============================
Start of epoch 727
step 0: mean loss = 1.5238819e-09
step 100: mean loss = 2.7229743e-09
epoch 727: mean loss = 3.0602942e-09  learning rate = 3.056362e-05
============================
Start of epoch 728
step 0: mean loss = 3.2598733e-09
step 100: mean loss = 1.9015587e-09
epoch 728: mean loss = 2.4467735e-09  learning rate = 3.056362e-05
============================
Start of epoch 729
step 0: mean loss = 1.483325e-09
step 100: mean loss = 3.1491232e-09
epoch 729: mean loss = 2.6677192e-09  learning rate = 3.056362e-05
============================
Start of epoch 730
step 0: mean loss = 1.4458398e-09
step 100: mean loss = 3.799847e-09
epoch 730: mean loss = 2.98748e-09  learning rate = 3.056362e-05
============================
Start of epoch 731
step 0: mean loss = 1.4711639e-09
step 100: mean loss = 3.1428986e-09
epoch 731: mean loss = 3.2463827e-09  learning rate = 3.056362e-05
============================
Start of epoch 732
step 0: mean loss = 2.142134e-09
step 100: mean loss = 2.7104918e-09
epoch 732: mean loss = 2.2850122e-09  learning rate = 3.056362e-05
============================
Start of epoch 733
step 0: mean loss = 2.2977977e-09
step 100: mean loss = 3.555155e-09
epoch 733: mean loss = 3.2519398e-09  learning rate = 3.056362e-05
============================
Start of epoch 734
step 0: mean loss = 1.4514382e-09
step 100: mean loss = 3.2243535e-09
epoch 734: mean loss = 2.9157816e-09  learning rate = 3.056362e-05
============================
Start of epoch 735
step 0: mean loss = 1.5487223e-09
step 100: mean loss = 2.8112506e-09
epoch 735: mean loss = 3.1829246e-09  learning rate = 3.056362e-05
============================
Start of epoch 736
step 0: mean loss = 1.7103443e-09
step 100: mean loss = 2.6259397e-09
epoch 736: mean loss = 2.2659834e-09  learning rate = 3.056362e-05
============================
Start of epoch 737
step 0: mean loss = 2.9285605e-09
step 100: mean loss = 4.310874e-09
epoch 737: mean loss = 3.3134266e-09  learning rate = 3.056362e-05
============================
Start of epoch 738
step 0: mean loss = 1.5994841e-09
step 100: mean loss = 2.7811171e-09
epoch 738: mean loss = 3.525761e-09  learning rate = 3.056362e-05
============================
Start of epoch 739
step 0: mean loss = 3.4675174e-09
step 100: mean loss = 2.7693752e-09
epoch 739: mean loss = 2.6872595e-09  learning rate = 3.056362e-05
============================
Start of epoch 740
step 0: mean loss = 1.4632322e-09
step 100: mean loss = 2.6298264e-09
epoch 740: mean loss = 2.3388451e-09  learning rate = 3.056362e-05
============================
Start of epoch 741
step 0: mean loss = 5.019237e-09
step 100: mean loss = 2.8561935e-09
epoch 741: mean loss = 3.1332845e-09  learning rate = 3.056362e-05
============================
Start of epoch 742
step 0: mean loss = 1.4930914e-09
step 100: mean loss = 3.1333e-09
epoch 742: mean loss = 2.902575e-09  learning rate = 3.056362e-05
============================
Start of epoch 743
step 0: mean loss = 1.5105078e-09
step 100: mean loss = 2.9084692e-09
epoch 743: mean loss = 2.8963556e-09  learning rate = 3.056362e-05
============================
Start of epoch 744
step 0: mean loss = 1.7719985e-08
step 100: mean loss = 2.4734077e-09
epoch 744: mean loss = 3.3467964e-09  learning rate = 3.056362e-05
============================
Start of epoch 745
step 0: mean loss = 1.709619e-09
step 100: mean loss = 2.5815554e-09
epoch 745: mean loss = 2.2178557e-09  learning rate = 3.056362e-05
============================
Start of epoch 746
step 0: mean loss = 2.68236e-09
step 100: mean loss = 3.021698e-09
epoch 746: mean loss = 3.4154402e-09  learning rate = 3.056362e-05
============================
Start of epoch 747
step 0: mean loss = 3.826641e-09
step 100: mean loss = 3.153311e-09
epoch 747: mean loss = 2.5747295e-09  learning rate = 3.056362e-05
============================
Start of epoch 748
step 0: mean loss = 1.4338962e-09
step 100: mean loss = 3.765356e-09
epoch 748: mean loss = 2.9600893e-09  learning rate = 3.056362e-05
============================
Start of epoch 749
step 0: mean loss = 1.6929081e-09
step 100: mean loss = 2.9346687e-09
epoch 749: mean loss = 2.4560785e-09  learning rate = 3.056362e-05
============================
Start of epoch 750
step 0: mean loss = 4.30937e-09
step 100: mean loss = 3.8326293e-09
epoch 750: mean loss = 3.803303e-09  learning rate = 3.056362e-05
============================
Start of epoch 751
step 0: mean loss = 1.4398143e-09
step 100: mean loss = 2.5776346e-09
epoch 751: mean loss = 2.2168332e-09  learning rate = 3.056362e-05
============================
Start of epoch 752
step 0: mean loss = 1.4702534e-09
step 100: mean loss = 3.062575e-09
epoch 752: mean loss = 3.3543617e-09  learning rate = 3.056362e-05
============================
Start of epoch 753
step 0: mean loss = 1.5000572e-09
step 100: mean loss = 2.7293852e-09
epoch 753: mean loss = 2.8004699e-09  learning rate = 3.056362e-05
============================
Start of epoch 754
step 0: mean loss = 8.7499705e-09
step 100: mean loss = 3.130289e-09
epoch 754: mean loss = 2.5757583e-09  learning rate = 3.056362e-05
============================
Start of epoch 755
step 0: mean loss = 1.4584813e-09
step 100: mean loss = 3.1346588e-09
epoch 755: mean loss = 3.4189802e-09  learning rate = 3.056362e-05
============================
Start of epoch 756
step 0: mean loss = 1.6324918e-09
step 100: mean loss = 2.387574e-09
epoch 756: mean loss = 2.1610693e-09  learning rate = 3.056362e-05
============================
Start of epoch 757
step 0: mean loss = 3.867245e-09
step 100: mean loss = 3.562558e-09
epoch 757: mean loss = 3.557476e-09  learning rate = 3.056362e-05
============================
Start of epoch 758
step 0: mean loss = 5.151162e-09
step 100: mean loss = 2.3718576e-09
epoch 758: mean loss = 2.5073899e-09  learning rate = 3.056362e-05
============================
Start of epoch 759
step 0: mean loss = 2.0704491e-09
step 100: mean loss = 2.6361473e-09
epoch 759: mean loss = 3.5112568e-09  learning rate = 3.056362e-05
============================
Start of epoch 760
step 0: mean loss = 1.5586883e-09
step 100: mean loss = 2.7729912e-09
epoch 760: mean loss = 2.355583e-09  learning rate = 3.056362e-05
============================
Start of epoch 761
step 0: mean loss = 1.4245657e-09
step 100: mean loss = 3.0425125e-09
epoch 761: mean loss = 3.4262924e-09  learning rate = 3.056362e-05
============================
Start of epoch 762
step 0: mean loss = 6.576087e-09
step 100: mean loss = 2.824396e-09
epoch 762: mean loss = 2.591609e-09  learning rate = 3.056362e-05
============================
Start of epoch 763
step 0: mean loss = 1.463884e-09
step 100: mean loss = 2.7083282e-09
epoch 763: mean loss = 2.550901e-09  learning rate = 3.056362e-05
============================
Start of epoch 764
step 0: mean loss = 1.5281676e-08
step 100: mean loss = 3.664525e-09
epoch 764: mean loss = 3.0535887e-09  learning rate = 3.056362e-05
============================
Start of epoch 765
step 0: mean loss = 1.4440116e-09
step 100: mean loss = 2.7744627e-09
epoch 765: mean loss = 3.1786318e-09  learning rate = 3.056362e-05
============================
Start of epoch 766
step 0: mean loss = 5.5544844e-09
step 100: mean loss = 3.1211556e-09
epoch 766: mean loss = 2.6096714e-09  learning rate = 3.056362e-05
============================
Start of epoch 767
step 0: mean loss = 2.3499473e-09
step 100: mean loss = 2.7259748e-09
epoch 767: mean loss = 2.7158529e-09  learning rate = 3.056362e-05
============================
Start of epoch 768
step 0: mean loss = 2.3584141e-09
step 100: mean loss = 2.8965192e-09
epoch 768: mean loss = 3.4076697e-09  learning rate = 3.056362e-05
============================
Start of epoch 769
step 0: mean loss = 1.8184377e-09
step 100: mean loss = 3.0115925e-09
epoch 769: mean loss = 2.46957e-09  learning rate = 2.9035442e-05
============================
Start of epoch 770
step 0: mean loss = 1.4225265e-09
step 100: mean loss = 1.4630132e-09
epoch 770: mean loss = 1.7376336e-09  learning rate = 2.9035442e-05
============================
Start of epoch 771
step 0: mean loss = 2.6713105e-09
step 100: mean loss = 3.267116e-09
epoch 771: mean loss = 3.2325664e-09  learning rate = 2.9035442e-05
============================
Start of epoch 772
step 0: mean loss = 3.2070766e-09
step 100: mean loss = 2.1397477e-09
epoch 772: mean loss = 2.3477678e-09  learning rate = 2.9035442e-05
============================
Start of epoch 773
step 0: mean loss = 6.883054e-09
step 100: mean loss = 2.439645e-09
epoch 773: mean loss = 2.6989282e-09  learning rate = 2.9035442e-05
============================
Start of epoch 774
step 0: mean loss = 1.4886372e-09
step 100: mean loss = 3.0156746e-09
epoch 774: mean loss = 2.6135156e-09  learning rate = 2.9035442e-05
============================
Start of epoch 775
step 0: mean loss = 1.5910052e-09
step 100: mean loss = 2.8254654e-09
epoch 775: mean loss = 2.9752845e-09  learning rate = 2.9035442e-05
============================
Start of epoch 776
step 0: mean loss = 1.478078e-09
step 100: mean loss = 2.6956382e-09
epoch 776: mean loss = 2.6820564e-09  learning rate = 2.9035442e-05
============================
Start of epoch 777
step 0: mean loss = 1.6424386e-09
step 100: mean loss = 3.2000005e-09
epoch 777: mean loss = 2.591004e-09  learning rate = 2.9035442e-05
============================
Start of epoch 778
step 0: mean loss = 1.4376412e-09
step 100: mean loss = 3.0739782e-09
epoch 778: mean loss = 3.0912408e-09  learning rate = 2.9035442e-05
============================
Start of epoch 779
step 0: mean loss = 1.6909576e-09
step 100: mean loss = 2.1324416e-09
epoch 779: mean loss = 2.4702238e-09  learning rate = 2.9035442e-05
============================
Start of epoch 780
step 0: mean loss = 1.7228508e-09
step 100: mean loss = 3.0174778e-09
epoch 780: mean loss = 2.4845368e-09  learning rate = 2.9035442e-05
============================
Start of epoch 781
step 0: mean loss = 1.8041928e-09
step 100: mean loss = 3.2214935e-09
epoch 781: mean loss = 3.0802914e-09  learning rate = 2.9035442e-05
============================
Start of epoch 782
step 0: mean loss = 1.4698641e-09
step 100: mean loss = 2.4535356e-09
epoch 782: mean loss = 2.7863833e-09  learning rate = 2.9035442e-05
============================
Start of epoch 783
step 0: mean loss = 1.6493681e-09
step 100: mean loss = 2.7243632e-09
epoch 783: mean loss = 2.7511151e-09  learning rate = 2.9035442e-05
============================
Start of epoch 784
step 0: mean loss = 1.7833024e-09
step 100: mean loss = 2.892346e-09
epoch 784: mean loss = 2.4000497e-09  learning rate = 2.9035442e-05
============================
Start of epoch 785
step 0: mean loss = 1.4747725e-09
step 100: mean loss = 3.115578e-09
epoch 785: mean loss = 3.3762397e-09  learning rate = 2.9035442e-05
============================
Start of epoch 786
step 0: mean loss = 2.1215747e-09
step 100: mean loss = 1.8602644e-09
epoch 786: mean loss = 2.3691225e-09  learning rate = 2.9035442e-05
============================
Start of epoch 787
step 0: mean loss = 2.1416735e-09
step 100: mean loss = 2.6183509e-09
epoch 787: mean loss = 2.6549951e-09  learning rate = 2.9035442e-05
============================
Start of epoch 788
step 0: mean loss = 3.3423941e-09
step 100: mean loss = 2.4368922e-09
epoch 788: mean loss = 2.4979674e-09  learning rate = 2.9035442e-05
============================
Start of epoch 789
step 0: mean loss = 3.064718e-09
step 100: mean loss = 3.2314724e-09
epoch 789: mean loss = 2.779533e-09  learning rate = 2.9035442e-05
============================
Start of epoch 790
step 0: mean loss = 1.4133178e-09
step 100: mean loss = 3.158426e-09
epoch 790: mean loss = 3.1178125e-09  learning rate = 2.9035442e-05
============================
Start of epoch 791
step 0: mean loss = 1.4323078e-09
step 100: mean loss = 3.0594494e-09
epoch 791: mean loss = 2.5664686e-09  learning rate = 2.9035442e-05
============================
Start of epoch 792
step 0: mean loss = 1.4309023e-09
step 100: mean loss = 2.4469964e-09
epoch 792: mean loss = 3.162443e-09  learning rate = 2.9035442e-05
============================
Start of epoch 793
step 0: mean loss = 4.1685184e-09
step 100: mean loss = 2.1835902e-09
epoch 793: mean loss = 1.9833155e-09  learning rate = 2.9035442e-05
============================
Start of epoch 794
step 0: mean loss = 3.232722e-09
step 100: mean loss = 3.6995167e-09
epoch 794: mean loss = 2.9368106e-09  learning rate = 2.9035442e-05
============================
Start of epoch 795
step 0: mean loss = 1.4306974e-09
step 100: mean loss = 2.5474831e-09
epoch 795: mean loss = 2.7192992e-09  learning rate = 2.9035442e-05
============================
Start of epoch 796
step 0: mean loss = 4.7037387e-09
step 100: mean loss = 2.4413713e-09
epoch 796: mean loss = 3.0527882e-09  learning rate = 2.9035442e-05
============================
Start of epoch 797
step 0: mean loss = 1.8676098e-09
step 100: mean loss = 2.432694e-09
epoch 797: mean loss = 2.2627689e-09  learning rate = 2.9035442e-05
============================
Start of epoch 798
step 0: mean loss = 2.4478768e-09
step 100: mean loss = 3.1808443e-09
epoch 798: mean loss = 3.0572809e-09  learning rate = 2.9035442e-05
============================
Start of epoch 799
step 0: mean loss = 1.4418942e-09
step 100: mean loss = 2.521097e-09
epoch 799: mean loss = 2.940424e-09  learning rate = 2.9035442e-05
============================
Start of epoch 800
step 0: mean loss = 7.615536e-09
step 100: mean loss = 2.7414824e-09
epoch 800: mean loss = 2.2973938e-09  learning rate = 2.9035442e-05
============================
Start of epoch 801
step 0: mean loss = 1.440018e-09
step 100: mean loss = 2.6024325e-09
epoch 801: mean loss = 3.2490426e-09  learning rate = 2.9035442e-05
============================
Start of epoch 802
step 0: mean loss = 2.0513418e-09
step 100: mean loss = 1.9350297e-09
epoch 802: mean loss = 2.6409148e-09  learning rate = 2.9035442e-05
============================
Start of epoch 803
step 0: mean loss = 1.4569818e-09
step 100: mean loss = 2.0424444e-09
epoch 803: mean loss = 2.8696001e-09  learning rate = 2.9035442e-05
============================
Start of epoch 804
step 0: mean loss = 1.9716049e-09
step 100: mean loss = 2.551622e-09
epoch 804: mean loss = 2.34978e-09  learning rate = 2.9035442e-05
============================
Start of epoch 805
step 0: mean loss = 1.7369757e-09
step 100: mean loss = 3.3256295e-09
epoch 805: mean loss = 3.1000185e-09  learning rate = 2.9035442e-05
============================
Start of epoch 806
step 0: mean loss = 1.4276168e-09
step 100: mean loss = 2.3377449e-09
epoch 806: mean loss = 2.0662534e-09  learning rate = 2.9035442e-05
============================
Start of epoch 807
step 0: mean loss = 4.0497743e-09
step 100: mean loss = 3.0112095e-09
epoch 807: mean loss = 2.8427989e-09  learning rate = 2.9035442e-05
============================
Start of epoch 808
step 0: mean loss = 4.478606e-09
step 100: mean loss = 3.051664e-09
epoch 808: mean loss = 3.3840761e-09  learning rate = 2.9035442e-05
============================
Start of epoch 809
step 0: mean loss = 1.8504898e-09
step 100: mean loss = 1.8907702e-09
epoch 809: mean loss = 2.0509887e-09  learning rate = 2.9035442e-05
============================
Start of epoch 810
step 0: mean loss = 2.7832292e-09
step 100: mean loss = 2.8635767e-09
epoch 810: mean loss = 2.9734613e-09  learning rate = 2.9035442e-05
============================
Start of epoch 811
step 0: mean loss = 3.6741903e-09
step 100: mean loss = 3.008836e-09
epoch 811: mean loss = 2.4763673e-09  learning rate = 2.9035442e-05
============================
Start of epoch 812
step 0: mean loss = 1.4769904e-09
step 100: mean loss = 2.79495e-09
epoch 812: mean loss = 3.0902012e-09  learning rate = 2.9035442e-05
============================
Start of epoch 813
step 0: mean loss = 1.6016692e-09
step 100: mean loss = 2.979031e-09
epoch 813: mean loss = 2.4442666e-09  learning rate = 2.9035442e-05
============================
Start of epoch 814
step 0: mean loss = 1.4047972e-09
step 100: mean loss = 3.0760439e-09
epoch 814: mean loss = 3.5160639e-09  learning rate = 2.9035442e-05
============================
Start of epoch 815
step 0: mean loss = 4.044135e-09
step 100: mean loss = 1.5564705e-09
epoch 815: mean loss = 2.3743008e-09  learning rate = 2.9035442e-05
============================
Start of epoch 816
step 0: mean loss = 2.872986e-09
step 100: mean loss = 3.1551257e-09
epoch 816: mean loss = 2.7577283e-09  learning rate = 2.9035442e-05
============================
Start of epoch 817
step 0: mean loss = 1.529163e-09
step 100: mean loss = 1.995703e-09
epoch 817: mean loss = 2.4865516e-09  learning rate = 2.9035442e-05
============================
Start of epoch 818
step 0: mean loss = 1.6437198e-09
step 100: mean loss = 2.612573e-09
epoch 818: mean loss = 2.97202e-09  learning rate = 2.9035442e-05
============================
Start of epoch 819
step 0: mean loss = 2.1904745e-09
step 100: mean loss = 2.4193605e-09
epoch 819: mean loss = 2.4823954e-09  learning rate = 2.9035442e-05
============================
Start of epoch 820
step 0: mean loss = 2.1426585e-09
step 100: mean loss = 2.783217e-09
epoch 820: mean loss = 2.582903e-09  learning rate = 2.9035442e-05
============================
Start of epoch 821
step 0: mean loss = 1.6438512e-09
step 100: mean loss = 2.354054e-09
epoch 821: mean loss = 2.8997567e-09  learning rate = 2.9035442e-05
============================
Start of epoch 822
step 0: mean loss = 1.7518146e-09
step 100: mean loss = 2.6205988e-09
epoch 822: mean loss = 2.5833402e-09  learning rate = 2.9035442e-05
============================
Start of epoch 823
step 0: mean loss = 4.460944e-09
step 100: mean loss = 2.8876876e-09
epoch 823: mean loss = 2.7202045e-09  learning rate = 2.9035442e-05
============================
Start of epoch 824
step 0: mean loss = 1.4836228e-09
step 100: mean loss = 3.045937e-09
epoch 824: mean loss = 2.8047074e-09  learning rate = 2.9035442e-05
============================
Start of epoch 825
step 0: mean loss = 1.242201e-08
step 100: mean loss = 2.766448e-09
epoch 825: mean loss = 2.7626645e-09  learning rate = 2.9035442e-05
============================
Start of epoch 826
step 0: mean loss = 1.4122725e-09
step 100: mean loss = 2.4337814e-09
epoch 826: mean loss = 2.9302827e-09  learning rate = 2.9035442e-05
============================
Start of epoch 827
step 0: mean loss = 1.929059e-09
step 100: mean loss = 2.379135e-09
epoch 827: mean loss = 2.5313114e-09  learning rate = 2.9035442e-05
============================
Start of epoch 828
step 0: mean loss = 2.2442286e-09
step 100: mean loss = 2.3578073e-09
epoch 828: mean loss = 2.677885e-09  learning rate = 2.9035442e-05
============================
Start of epoch 829
step 0: mean loss = 2.9632221e-09
step 100: mean loss = 2.5631886e-09
epoch 829: mean loss = 2.5093e-09  learning rate = 2.9035442e-05
============================
Start of epoch 830
step 0: mean loss = 3.1933352e-09
step 100: mean loss = 2.7764249e-09
epoch 830: mean loss = 2.7491351e-09  learning rate = 2.9035442e-05
============================
Start of epoch 831
step 0: mean loss = 1.8863187e-09
step 100: mean loss = 2.4758624e-09
epoch 831: mean loss = 2.9586027e-09  learning rate = 2.9035442e-05
============================
Start of epoch 832
step 0: mean loss = 1.5568148e-09
step 100: mean loss = 3.1243235e-09
epoch 832: mean loss = 2.5488163e-09  learning rate = 2.9035442e-05
============================
Start of epoch 833
step 0: mean loss = 1.4102777e-09
step 100: mean loss = 2.9366287e-09
epoch 833: mean loss = 3.1537466e-09  learning rate = 2.9035442e-05
============================
Start of epoch 834
step 0: mean loss = 2.7195848e-09
step 100: mean loss = 1.4866592e-09
epoch 834: mean loss = 2.7706646e-09  learning rate = 2.9035442e-05
============================
Start of epoch 835
step 0: mean loss = 1.894446e-09
step 100: mean loss = 2.1610378e-09
epoch 835: mean loss = 2.2444804e-09  learning rate = 2.9035442e-05
============================
Start of epoch 836
step 0: mean loss = 2.0884656e-09
step 100: mean loss = 2.2742428e-09
epoch 836: mean loss = 2.9154037e-09  learning rate = 2.9035442e-05
============================
Start of epoch 837
step 0: mean loss = 1.8966193e-09
step 100: mean loss = 3.0181626e-09
epoch 837: mean loss = 2.484218e-09  learning rate = 2.9035442e-05
============================
Start of epoch 838
step 0: mean loss = 1.6531942e-09
step 100: mean loss = 2.9239968e-09
epoch 838: mean loss = 2.5117735e-09  learning rate = 2.9035442e-05
============================
Start of epoch 839
step 0: mean loss = 2.164452e-09
step 100: mean loss = 2.6334608e-09
epoch 839: mean loss = 3.0643494e-09  learning rate = 2.9035442e-05
============================
Start of epoch 840
step 0: mean loss = 1.4099777e-09
step 100: mean loss = 2.9245013e-09
epoch 840: mean loss = 2.4037925e-09  learning rate = 2.9035442e-05
============================
Start of epoch 841
step 0: mean loss = 1.4276677e-09
step 100: mean loss = 2.7396128e-09
epoch 841: mean loss = 3.3395988e-09  learning rate = 2.9035442e-05
============================
Start of epoch 842
step 0: mean loss = 1.3995234e-09
step 100: mean loss = 2.508712e-09
epoch 842: mean loss = 2.447427e-09  learning rate = 2.9035442e-05
============================
Start of epoch 843
step 0: mean loss = 1.4945263e-09
step 100: mean loss = 2.313571e-09
epoch 843: mean loss = 3.0744631e-09  learning rate = 2.9035442e-05
============================
Start of epoch 844
step 0: mean loss = 1.509735e-09
step 100: mean loss = 2.4551603e-09
epoch 844: mean loss = 2.152257e-09  learning rate = 2.9035442e-05
============================
Start of epoch 845
step 0: mean loss = 1.4050917e-09
step 100: mean loss = 2.9507026e-09
epoch 845: mean loss = 3.2089225e-09  learning rate = 2.9035442e-05
============================
Start of epoch 846
step 0: mean loss = 2.018041e-09
step 100: mean loss = 1.5195969e-09
epoch 846: mean loss = 2.956081e-09  learning rate = 2.9035442e-05
============================
Start of epoch 847
step 0: mean loss = 1.5436386e-09
step 100: mean loss = 2.7352662e-09
epoch 847: mean loss = 2.3563769e-09  learning rate = 2.9035442e-05
============================
Start of epoch 848
step 0: mean loss = 1.4280228e-09
step 100: mean loss = 2.2067443e-09
epoch 848: mean loss = 2.4290263e-09  learning rate = 2.9035442e-05
============================
Start of epoch 849
step 0: mean loss = 1.4136984e-09
step 100: mean loss = 2.375158e-09
epoch 849: mean loss = 3.1558733e-09  learning rate = 2.9035442e-05
============================
Start of epoch 850
step 0: mean loss = 1.6074708e-09
step 100: mean loss = 1.4392997e-09
epoch 850: mean loss = 1.4232343e-09  learning rate = 2.7583666e-05
============================
Start of epoch 851
step 0: mean loss = 1.3929489e-09
step 100: mean loss = 3.2358098e-09
epoch 851: mean loss = 2.5958167e-09  learning rate = 2.7583666e-05
============================
Start of epoch 852
step 0: mean loss = 1.3942651e-09
step 100: mean loss = 3.7009873e-09
epoch 852: mean loss = 2.8993854e-09  learning rate = 2.7583666e-05
============================
Start of epoch 853
step 0: mean loss = 1.3945196e-09
step 100: mean loss = 2.9394427e-09
epoch 853: mean loss = 2.5197577e-09  learning rate = 2.7583666e-05
============================
Start of epoch 854
step 0: mean loss = 1.4447274e-09
step 100: mean loss = 2.4335574e-09
epoch 854: mean loss = 2.643951e-09  learning rate = 2.7583666e-05
============================
Start of epoch 855
step 0: mean loss = 2.3770206e-09
step 100: mean loss = 2.876231e-09
epoch 855: mean loss = 2.4025955e-09  learning rate = 2.7583666e-05
============================
Start of epoch 856
step 0: mean loss = 1.3923068e-09
step 100: mean loss = 2.5140006e-09
epoch 856: mean loss = 2.8897034e-09  learning rate = 2.7583666e-05
============================
Start of epoch 857
step 0: mean loss = 1.4082638e-09
step 100: mean loss = 2.7738885e-09
epoch 857: mean loss = 2.3757696e-09  learning rate = 2.7583666e-05
============================
Start of epoch 858
step 0: mean loss = 1.687953e-09
step 100: mean loss = 2.6051759e-09
epoch 858: mean loss = 2.316629e-09  learning rate = 2.7583666e-05
============================
Start of epoch 859
step 0: mean loss = 1.3951523e-09
step 100: mean loss = 3.2399476e-09
epoch 859: mean loss = 2.8801028e-09  learning rate = 2.7583666e-05
============================
Start of epoch 860
step 0: mean loss = 1.4283191e-09
step 100: mean loss = 2.4093922e-09
epoch 860: mean loss = 2.2359392e-09  learning rate = 2.7583666e-05
============================
Start of epoch 861
step 0: mean loss = 1.5285474e-09
step 100: mean loss = 3.0245855e-09
epoch 861: mean loss = 2.842528e-09  learning rate = 2.7583666e-05
============================
Start of epoch 862
step 0: mean loss = 1.4035586e-09
step 100: mean loss = 2.6736484e-09
epoch 862: mean loss = 2.4738596e-09  learning rate = 2.7583666e-05
============================
Start of epoch 863
step 0: mean loss = 1.9621555e-09
step 100: mean loss = 2.1612854e-09
epoch 863: mean loss = 2.8024933e-09  learning rate = 2.7583666e-05
============================
Start of epoch 864
step 0: mean loss = 1.4283575e-09
step 100: mean loss = 2.9155949e-09
epoch 864: mean loss = 2.3845166e-09  learning rate = 2.7583666e-05
============================
Start of epoch 865
step 0: mean loss = 1.3894156e-09
step 100: mean loss = 2.953249e-09
epoch 865: mean loss = 2.4379978e-09  learning rate = 2.7583666e-05
============================
Start of epoch 866
step 0: mean loss = 3.426986e-09
step 100: mean loss = 2.6576006e-09
epoch 866: mean loss = 3.6059187e-09  learning rate = 2.7583666e-05
============================
Start of epoch 867
step 0: mean loss = 1.495853e-09
step 100: mean loss = 1.4966229e-09
epoch 867: mean loss = 1.8085825e-09  learning rate = 2.7583666e-05
============================
Start of epoch 868
step 0: mean loss = 4.398408e-09
step 100: mean loss = 2.852867e-09
epoch 868: mean loss = 2.7068314e-09  learning rate = 2.7583666e-05
============================
Start of epoch 869
step 0: mean loss = 2.1576496e-09
step 100: mean loss = 2.3914803e-09
epoch 869: mean loss = 2.2675528e-09  learning rate = 2.7583666e-05
============================
Start of epoch 870
step 0: mean loss = 2.523139e-09
step 100: mean loss = 2.7627698e-09
epoch 870: mean loss = 3.0871312e-09  learning rate = 2.7583666e-05
============================
Start of epoch 871
step 0: mean loss = 1.4266209e-09
step 100: mean loss = 1.8223858e-09
epoch 871: mean loss = 2.3561189e-09  learning rate = 2.7583666e-05
============================
Start of epoch 872
step 0: mean loss = 1.4208836e-09
step 100: mean loss = 2.520936e-09
epoch 872: mean loss = 2.1376914e-09  learning rate = 2.7583666e-05
============================
Start of epoch 873
step 0: mean loss = 1.6822955e-09
step 100: mean loss = 3.0485543e-09
epoch 873: mean loss = 3.0280543e-09  learning rate = 2.7583666e-05
============================
Start of epoch 874
step 0: mean loss = 1.5502347e-09
step 100: mean loss = 2.799434e-09
epoch 874: mean loss = 2.334211e-09  learning rate = 2.7583666e-05
============================
Start of epoch 875
step 0: mean loss = 1.4759804e-09
step 100: mean loss = 3.3505418e-09
epoch 875: mean loss = 2.8184504e-09  learning rate = 2.7583666e-05
============================
Start of epoch 876
step 0: mean loss = 1.4032338e-09
step 100: mean loss = 2.456745e-09
epoch 876: mean loss = 2.4088935e-09  learning rate = 2.7583666e-05
============================
Start of epoch 877
step 0: mean loss = 3.8981263e-09
step 100: mean loss = 2.4689413e-09
epoch 877: mean loss = 2.6757239e-09  learning rate = 2.7583666e-05
============================
Start of epoch 878
step 0: mean loss = 1.6176077e-09
step 100: mean loss = 2.4324636e-09
epoch 878: mean loss = 2.332107e-09  learning rate = 2.7583666e-05
============================
Start of epoch 879
step 0: mean loss = 2.5366302e-09
step 100: mean loss = 2.8210712e-09
epoch 879: mean loss = 2.433864e-09  learning rate = 2.7583666e-05
============================
Start of epoch 880
step 0: mean loss = 2.2360205e-09
step 100: mean loss = 3.2966845e-09
epoch 880: mean loss = 2.7878886e-09  learning rate = 2.7583666e-05
============================
Start of epoch 881
step 0: mean loss = 1.5181603e-09
step 100: mean loss = 2.2990538e-09
epoch 881: mean loss = 2.790191e-09  learning rate = 2.7583666e-05
============================
Start of epoch 882
step 0: mean loss = 1.5086892e-09
step 100: mean loss = 2.61279e-09
epoch 882: mean loss = 2.3931415e-09  learning rate = 2.7583666e-05
============================
Start of epoch 883
step 0: mean loss = 6.5599477e-09
step 100: mean loss = 2.4918851e-09
epoch 883: mean loss = 2.525387e-09  learning rate = 2.7583666e-05
============================
Start of epoch 884
step 0: mean loss = 1.5766619e-09
step 100: mean loss = 2.3496136e-09
epoch 884: mean loss = 2.868353e-09  learning rate = 2.7583666e-05
============================
Start of epoch 885
step 0: mean loss = 1.8639987e-09
step 100: mean loss = 2.7200586e-09
epoch 885: mean loss = 2.3885034e-09  learning rate = 2.7583666e-05
============================
Start of epoch 886
step 0: mean loss = 1.6398733e-09
step 100: mean loss = 2.4074842e-09
epoch 886: mean loss = 3.0410476e-09  learning rate = 2.7583666e-05
============================
Start of epoch 887
step 0: mean loss = 5.815319e-09
step 100: mean loss = 1.7346607e-09
epoch 887: mean loss = 2.4081832e-09  learning rate = 2.7583666e-05
============================
Start of epoch 888
step 0: mean loss = 1.4326116e-09
step 100: mean loss = 2.6950462e-09
epoch 888: mean loss = 2.2966928e-09  learning rate = 2.7583666e-05
============================
Start of epoch 889
step 0: mean loss = 1.6145143e-09
step 100: mean loss = 2.8878449e-09
epoch 889: mean loss = 2.4179156e-09  learning rate = 2.7583666e-05
============================
Start of epoch 890
step 0: mean loss = 2.1845463e-09
step 100: mean loss = 2.5551208e-09
epoch 890: mean loss = 3.195629e-09  learning rate = 2.7583666e-05
============================
Start of epoch 891
step 0: mean loss = 1.8633828e-09
step 100: mean loss = 2.0893234e-09
epoch 891: mean loss = 1.9446296e-09  learning rate = 2.7583666e-05
============================
Start of epoch 892
step 0: mean loss = 1.3804707e-09
step 100: mean loss = 3.1577234e-09
epoch 892: mean loss = 2.9654537e-09  learning rate = 2.7583666e-05
============================
Start of epoch 893
step 0: mean loss = 1.475631e-09
step 100: mean loss = 2.6286748e-09
epoch 893: mean loss = 2.3983218e-09  learning rate = 2.7583666e-05
============================
Start of epoch 894
step 0: mean loss = 4.38968e-09
step 100: mean loss = 2.9398743e-09
epoch 894: mean loss = 2.9672302e-09  learning rate = 2.7583666e-05
============================
Start of epoch 895
step 0: mean loss = 1.40333e-09
step 100: mean loss = 2.3412874e-09
epoch 895: mean loss = 2.0324302e-09  learning rate = 2.7583666e-05
============================
Start of epoch 896
step 0: mean loss = 1.5427846e-09
step 100: mean loss = 2.6345313e-09
epoch 896: mean loss = 2.6054903e-09  learning rate = 2.7583666e-05
============================
Start of epoch 897
step 0: mean loss = 9.976834e-09
step 100: mean loss = 3.4136312e-09
epoch 897: mean loss = 2.8898475e-09  learning rate = 2.7583666e-05
============================
Start of epoch 898
step 0: mean loss = 1.3792012e-09
step 100: mean loss = 2.3733209e-09
epoch 898: mean loss = 2.2544786e-09  learning rate = 2.7583666e-05
============================
Start of epoch 899
step 0: mean loss = 3.631813e-09
step 100: mean loss = 2.7382592e-09
epoch 899: mean loss = 3.0237979e-09  learning rate = 2.7583666e-05
============================
Start of epoch 900
step 0: mean loss = 1.8878352e-09
step 100: mean loss = 2.4295368e-09
epoch 900: mean loss = 2.4394091e-09  learning rate = 2.7583666e-05
============================
Start of epoch 901
step 0: mean loss = 1.5205438e-09
step 100: mean loss = 1.9032442e-09
epoch 901: mean loss = 2.609005e-09  learning rate = 2.7583666e-05
============================
Start of epoch 902
step 0: mean loss = 2.5368951e-09
step 100: mean loss = 2.480537e-09
epoch 902: mean loss = 2.121277e-09  learning rate = 2.7583666e-05
============================
Start of epoch 903
step 0: mean loss = 1.3763022e-09
step 100: mean loss = 2.8017502e-09
epoch 903: mean loss = 2.6040385e-09  learning rate = 2.7583666e-05
============================
Start of epoch 904
step 0: mean loss = 5.8091096e-09
step 100: mean loss = 3.0445502e-09
epoch 904: mean loss = 2.5179685e-09  learning rate = 2.7583666e-05
============================
Start of epoch 905
step 0: mean loss = 1.5120335e-09
step 100: mean loss = 2.963433e-09
epoch 905: mean loss = 2.888592e-09  learning rate = 2.7583666e-05
============================
Start of epoch 906
step 0: mean loss = 3.5758307e-09
step 100: mean loss = 2.6354008e-09
epoch 906: mean loss = 2.6254336e-09  learning rate = 2.7583666e-05
============================
Start of epoch 907
step 0: mean loss = 2.039766e-09
step 100: mean loss = 2.6199187e-09
epoch 907: mean loss = 2.3111049e-09  learning rate = 2.7583666e-05
============================
Start of epoch 908
step 0: mean loss = 1.5471545e-09
step 100: mean loss = 2.3402256e-09
epoch 908: mean loss = 2.8632332e-09  learning rate = 2.7583666e-05
============================
Start of epoch 909
step 0: mean loss = 1.8690083e-09
step 100: mean loss = 2.2686766e-09
epoch 909: mean loss = 2.578124e-09  learning rate = 2.7583666e-05
============================
Start of epoch 910
step 0: mean loss = 1.1688947e-08
step 100: mean loss = 1.9816468e-09
epoch 910: mean loss = 2.57004e-09  learning rate = 2.7583666e-05
============================
Start of epoch 911
step 0: mean loss = 1.504557e-09
step 100: mean loss = 2.311441e-09
epoch 911: mean loss = 2.318096e-09  learning rate = 2.7583666e-05
============================
Start of epoch 912
step 0: mean loss = 1.2078348e-08
step 100: mean loss = 2.6540037e-09
epoch 912: mean loss = 2.7136249e-09  learning rate = 2.7583666e-05
============================
Start of epoch 913
step 0: mean loss = 2.4993836e-09
step 100: mean loss = 2.4416755e-09
epoch 913: mean loss = 2.3445348e-09  learning rate = 2.7583666e-05
============================
Start of epoch 914
step 0: mean loss = 1.5033551e-09
step 100: mean loss = 2.7640155e-09
epoch 914: mean loss = 2.6119586e-09  learning rate = 2.7583666e-05
============================
Start of epoch 915
step 0: mean loss = 1.3966784e-09
step 100: mean loss = 3.3684326e-09
epoch 915: mean loss = 2.8074854e-09  learning rate = 2.7583666e-05
============================
Start of epoch 916
step 0: mean loss = 2.0517426e-09
step 100: mean loss = 2.6248816e-09
epoch 916: mean loss = 2.255269e-09  learning rate = 2.7583666e-05
============================
Start of epoch 917
step 0: mean loss = 2.855589e-09
step 100: mean loss = 2.3538134e-09
epoch 917: mean loss = 3.0469636e-09  learning rate = 2.7583666e-05
============================
Start of epoch 918
step 0: mean loss = 1.8392063e-09
step 100: mean loss = 2.6191267e-09
epoch 918: mean loss = 2.4572158e-09  learning rate = 2.7583666e-05
============================
Start of epoch 919
step 0: mean loss = 1.3899486e-09
step 100: mean loss = 2.4787066e-09
epoch 919: mean loss = 2.1022517e-09  learning rate = 2.7583666e-05
============================
Start of epoch 920
step 0: mean loss = 1.5370457e-09
step 100: mean loss = 3.0300202e-09
epoch 920: mean loss = 2.9434297e-09  learning rate = 2.7583666e-05
============================
Start of epoch 921
step 0: mean loss = 1.3775083e-09
step 100: mean loss = 2.8877047e-09
epoch 921: mean loss = 2.3819737e-09  learning rate = 2.7583666e-05
============================
Start of epoch 922
step 0: mean loss = 1.4863025e-09
step 100: mean loss = 2.4897893e-09
epoch 922: mean loss = 2.9473877e-09  learning rate = 2.7583666e-05
============================
Start of epoch 923
step 0: mean loss = 1.7022341e-09
step 100: mean loss = 1.8973436e-09
epoch 923: mean loss = 1.990872e-09  learning rate = 2.7583666e-05
============================
Start of epoch 924
step 0: mean loss = 1.845222e-09
step 100: mean loss = 3.1817315e-09
epoch 924: mean loss = 2.720576e-09  learning rate = 2.7583666e-05
============================
Start of epoch 925
step 0: mean loss = 1.4356977e-09
step 100: mean loss = 2.7474374e-09
epoch 925: mean loss = 2.5968634e-09  learning rate = 2.7583666e-05
============================
Start of epoch 926
step 0: mean loss = 1.3769952e-09
step 100: mean loss = 2.7824836e-09
epoch 926: mean loss = 2.6302176e-09  learning rate = 2.7583666e-05
============================
Start of epoch 927
step 0: mean loss = 1.4139075e-09
step 100: mean loss = 2.4420335e-09
epoch 927: mean loss = 2.6831481e-09  learning rate = 2.7583666e-05
============================
Start of epoch 928
step 0: mean loss = 4.7502993e-09
step 100: mean loss = 2.137128e-09
epoch 928: mean loss = 2.3642748e-09  learning rate = 2.7583666e-05
============================
Start of epoch 929
step 0: mean loss = 2.1362387e-09
step 100: mean loss = 2.6393718e-09
epoch 929: mean loss = 2.8208733e-09  learning rate = 2.7583666e-05
============================
Start of epoch 930
step 0: mean loss = 1.6056574e-09
step 100: mean loss = 2.1251632e-09
epoch 930: mean loss = 2.1056534e-09  learning rate = 2.6204483e-05
============================
Start of epoch 931
step 0: mean loss = 1.4613781e-09
step 100: mean loss = 1.4097203e-09
epoch 931: mean loss = 1.9050224e-09  learning rate = 2.6204483e-05
============================
Start of epoch 932
step 0: mean loss = 1.4531714e-09
step 100: mean loss = 2.7390614e-09
epoch 932: mean loss = 2.297462e-09  learning rate = 2.6204483e-05
============================
Start of epoch 933
step 0: mean loss = 3.6614085e-09
step 100: mean loss = 2.5711449e-09
epoch 933: mean loss = 2.952196e-09  learning rate = 2.6204483e-05
============================
Start of epoch 934
step 0: mean loss = 1.4729196e-09
step 100: mean loss = 2.9688743e-09
epoch 934: mean loss = 2.5028561e-09  learning rate = 2.6204483e-05
============================
Start of epoch 935
step 0: mean loss = 1.3674861e-09
step 100: mean loss = 2.21446e-09
epoch 935: mean loss = 2.0496576e-09  learning rate = 2.6204483e-05
============================
Start of epoch 936
step 0: mean loss = 1.3842851e-09
step 100: mean loss = 2.5440243e-09
epoch 936: mean loss = 2.7888927e-09  learning rate = 2.6204483e-05
============================
Start of epoch 937
step 0: mean loss = 1.8348413e-09
step 100: mean loss = 2.028227e-09
epoch 937: mean loss = 1.9867499e-09  learning rate = 2.6204483e-05
============================
Start of epoch 938
step 0: mean loss = 2.5545597e-09
step 100: mean loss = 2.660738e-09
epoch 938: mean loss = 2.6897142e-09  learning rate = 2.6204483e-05
============================
Start of epoch 939
step 0: mean loss = 1.728615e-09
step 100: mean loss = 3.1574732e-09
epoch 939: mean loss = 2.7413152e-09  learning rate = 2.6204483e-05
============================
Start of epoch 940
step 0: mean loss = 1.4281819e-09
step 100: mean loss = 1.6652018e-09
epoch 940: mean loss = 2.0237432e-09  learning rate = 2.6204483e-05
============================
Start of epoch 941
step 0: mean loss = 1.9884687e-09
step 100: mean loss = 2.2122204e-09
epoch 941: mean loss = 2.513001e-09  learning rate = 2.6204483e-05
============================
Start of epoch 942
step 0: mean loss = 1.5772528e-09
step 100: mean loss = 2.3514408e-09
epoch 942: mean loss = 2.4588118e-09  learning rate = 2.6204483e-05
============================
Start of epoch 943
step 0: mean loss = 1.6222554e-09
step 100: mean loss = 2.2020101e-09
epoch 943: mean loss = 2.3057423e-09  learning rate = 2.6204483e-05
============================
Start of epoch 944
step 0: mean loss = 1.2073202e-08
step 100: mean loss = 2.6406248e-09
epoch 944: mean loss = 2.6721991e-09  learning rate = 2.6204483e-05
============================
Start of epoch 945
step 0: mean loss = 1.435919e-09
step 100: mean loss = 1.6533551e-09
epoch 945: mean loss = 2.4714177e-09  learning rate = 2.6204483e-05
============================
Start of epoch 946
step 0: mean loss = 1.3789383e-09
step 100: mean loss = 2.1451274e-09
epoch 946: mean loss = 1.9699518e-09  learning rate = 2.6204483e-05
============================
Start of epoch 947
step 0: mean loss = 5.4142997e-09
step 100: mean loss = 2.691305e-09
epoch 947: mean loss = 2.758916e-09  learning rate = 2.6204483e-05
============================
Start of epoch 948
step 0: mean loss = 3.5491343e-09
step 100: mean loss = 2.550803e-09
epoch 948: mean loss = 2.4713576e-09  learning rate = 2.6204483e-05
============================
Start of epoch 949
step 0: mean loss = 1.7649023e-09
step 100: mean loss = 2.113873e-09
epoch 949: mean loss = 2.165296e-09  learning rate = 2.6204483e-05
============================
Start of epoch 950
step 0: mean loss = 3.4972312e-09
step 100: mean loss = 1.9486674e-09
epoch 950: mean loss = 3.6808225e-09  learning rate = 2.6204483e-05
============================
Start of epoch 951
step 0: mean loss = 1.7270375e-09
step 100: mean loss = 1.3992942e-09
epoch 951: mean loss = 1.7181081e-09  learning rate = 2.6204483e-05
============================
Start of epoch 952
step 0: mean loss = 1.4492184e-09
step 100: mean loss = 2.1020008e-09
epoch 952: mean loss = 1.8502063e-09  learning rate = 2.6204483e-05
============================
Start of epoch 953
step 0: mean loss = 1.4776951e-09
step 100: mean loss = 3.0906402e-09
epoch 953: mean loss = 3.1536054e-09  learning rate = 2.6204483e-05
============================
Start of epoch 954
step 0: mean loss = 5.434091e-09
step 100: mean loss = 1.6253198e-09
epoch 954: mean loss = 2.3700502e-09  learning rate = 2.6204483e-05
============================
Start of epoch 955
step 0: mean loss = 1.3833279e-09
step 100: mean loss = 2.3362896e-09
epoch 955: mean loss = 2.0931135e-09  learning rate = 2.6204483e-05
============================
Start of epoch 956
step 0: mean loss = 1.4584718e-09
step 100: mean loss = 2.199273e-09
epoch 956: mean loss = 2.6685067e-09  learning rate = 2.6204483e-05
============================
Start of epoch 957
step 0: mean loss = 1.8414167e-09
step 100: mean loss = 1.8920892e-09
epoch 957: mean loss = 2.152103e-09  learning rate = 2.6204483e-05
============================
Start of epoch 958
step 0: mean loss = 1.4778223e-09
step 100: mean loss = 2.1664335e-09
epoch 958: mean loss = 2.5061813e-09  learning rate = 2.6204483e-05
============================
Start of epoch 959
step 0: mean loss = 1.3586943e-09
step 100: mean loss = 2.1039082e-09
epoch 959: mean loss = 2.5588873e-09  learning rate = 2.6204483e-05
============================
Start of epoch 960
step 0: mean loss = 1.7379267e-09
step 100: mean loss = 2.2830453e-09
epoch 960: mean loss = 2.2500293e-09  learning rate = 2.6204483e-05
============================
Start of epoch 961
step 0: mean loss = 1.3674872e-09
step 100: mean loss = 2.1338016e-09
epoch 961: mean loss = 2.584516e-09  learning rate = 2.6204483e-05
============================
Start of epoch 962
step 0: mean loss = 1.7992124e-09
step 100: mean loss = 1.9526842e-09
epoch 962: mean loss = 2.4486075e-09  learning rate = 2.6204483e-05
============================
Start of epoch 963
step 0: mean loss = 1.4386594e-09
step 100: mean loss = 3.015759e-09
epoch 963: mean loss = 2.605124e-09  learning rate = 2.6204483e-05
============================
Start of epoch 964
step 0: mean loss = 1.4729651e-09
step 100: mean loss = 2.0190585e-09
epoch 964: mean loss = 1.8577313e-09  learning rate = 2.6204483e-05
============================
Start of epoch 965
step 0: mean loss = 5.079855e-09
step 100: mean loss = 3.405484e-09
epoch 965: mean loss = 2.7542495e-09  learning rate = 2.6204483e-05
============================
Start of epoch 966
step 0: mean loss = 1.3555677e-09
step 100: mean loss = 2.3731856e-09
epoch 966: mean loss = 2.5540905e-09  learning rate = 2.6204483e-05
============================
Start of epoch 967
step 0: mean loss = 1.4379015e-09
step 100: mean loss = 2.277187e-09
epoch 967: mean loss = 2.017643e-09  learning rate = 2.6204483e-05
============================
Start of epoch 968
step 0: mean loss = 3.8021715e-09
step 100: mean loss = 3.0522274e-09
epoch 968: mean loss = 2.5294544e-09  learning rate = 2.6204483e-05
============================
Start of epoch 969
step 0: mean loss = 1.68095e-09
step 100: mean loss = 2.7546683e-09
epoch 969: mean loss = 2.3224964e-09  learning rate = 2.6204483e-05
============================
Start of epoch 970
step 0: mean loss = 1.3591733e-09
step 100: mean loss = 2.9355172e-09
epoch 970: mean loss = 3.3325807e-09  learning rate = 2.6204483e-05
============================
Start of epoch 971
step 0: mean loss = 1.7233934e-09
step 100: mean loss = 1.405367e-09
epoch 971: mean loss = 1.9495472e-09  learning rate = 2.6204483e-05
============================
Start of epoch 972
step 0: mean loss = 2.0510544e-09
step 100: mean loss = 2.3304287e-09
epoch 972: mean loss = 2.4947566e-09  learning rate = 2.6204483e-05
============================
Start of epoch 973
step 0: mean loss = 2.3647502e-08
step 100: mean loss = 2.5363505e-09
epoch 973: mean loss = 2.1339475e-09  learning rate = 2.6204483e-05
============================
Start of epoch 974
step 0: mean loss = 1.6270368e-09
step 100: mean loss = 2.3870734e-09
epoch 974: mean loss = 2.910728e-09  learning rate = 2.6204483e-05
============================
Start of epoch 975
step 0: mean loss = 1.3499394e-09
step 100: mean loss = 2.5430942e-09
epoch 975: mean loss = 2.1533504e-09  learning rate = 2.6204483e-05
============================
Start of epoch 976
step 0: mean loss = 1.3558876e-09
step 100: mean loss = 2.137856e-09
epoch 976: mean loss = 2.5589666e-09  learning rate = 2.6204483e-05
============================
Start of epoch 977
step 0: mean loss = 1.5262942e-09
step 100: mean loss = 2.1295563e-09
epoch 977: mean loss = 2.091574e-09  learning rate = 2.6204483e-05
============================
Start of epoch 978
step 0: mean loss = 1.3616993e-09
step 100: mean loss = 2.6787765e-09
epoch 978: mean loss = 3.079835e-09  learning rate = 2.6204483e-05
============================
Start of epoch 979
step 0: mean loss = 1.4291923e-09
step 100: mean loss = 1.8105346e-09
epoch 979: mean loss = 2.0216493e-09  learning rate = 2.6204483e-05
============================
Start of epoch 980
step 0: mean loss = 1.419549e-09
step 100: mean loss = 2.714003e-09
epoch 980: mean loss = 2.2485032e-09  learning rate = 2.6204483e-05
============================
Start of epoch 981
step 0: mean loss = 1.3690166e-09
step 100: mean loss = 3.0303178e-09
epoch 981: mean loss = 2.741863e-09  learning rate = 2.6204483e-05
============================
Start of epoch 982
step 0: mean loss = 1.3788071e-09
step 100: mean loss = 2.926016e-09
epoch 982: mean loss = 2.6064815e-09  learning rate = 2.6204483e-05
============================
Start of epoch 983
step 0: mean loss = 1.3584672e-09
step 100: mean loss = 1.4755281e-09
epoch 983: mean loss = 2.232803e-09  learning rate = 2.6204483e-05
============================
Start of epoch 984
step 0: mean loss = 1.5553513e-09
step 100: mean loss = 2.7046516e-09
epoch 984: mean loss = 2.2355295e-09  learning rate = 2.6204483e-05
============================
Start of epoch 985
step 0: mean loss = 1.3654977e-09
step 100: mean loss = 2.490281e-09
epoch 985: mean loss = 2.4966271e-09  learning rate = 2.6204483e-05
============================
Start of epoch 986
step 0: mean loss = 1.4340918e-09
step 100: mean loss = 2.8138378e-09
epoch 986: mean loss = 2.3272917e-09  learning rate = 2.6204483e-05
============================
Start of epoch 987
step 0: mean loss = 1.3564736e-09
step 100: mean loss = 3.4228846e-09
epoch 987: mean loss = 2.7163205e-09  learning rate = 2.6204483e-05
============================
Start of epoch 988
step 0: mean loss = 1.736107e-09
step 100: mean loss = 1.956313e-09
epoch 988: mean loss = 2.2513778e-09  learning rate = 2.6204483e-05
============================
Start of epoch 989
step 0: mean loss = 1.7062973e-09
step 100: mean loss = 2.1182263e-09
epoch 989: mean loss = 2.4639046e-09  learning rate = 2.6204483e-05
============================
Start of epoch 990
step 0: mean loss = 1.4316686e-09
step 100: mean loss = 2.160787e-09
epoch 990: mean loss = 2.7008447e-09  learning rate = 2.6204483e-05
============================
Start of epoch 991
step 0: mean loss = 3.179781e-09
step 100: mean loss = 2.346235e-09
epoch 991: mean loss = 2.0300883e-09  learning rate = 2.6204483e-05
============================
Start of epoch 992
step 0: mean loss = 1.3591425e-09
step 100: mean loss = 2.782754e-09
epoch 992: mean loss = 2.581007e-09  learning rate = 2.6204483e-05
============================
Start of epoch 993
step 0: mean loss = 4.9187974e-09
step 100: mean loss = 2.8884066e-09
epoch 993: mean loss = 2.3958133e-09  learning rate = 2.6204483e-05
============================
Start of epoch 994
step 0: mean loss = 2.2815618e-09
step 100: mean loss = 1.9749649e-09
epoch 994: mean loss = 2.5675726e-09  learning rate = 2.6204483e-05
============================
Start of epoch 995
step 0: mean loss = 1.4758474e-09
step 100: mean loss = 2.1799436e-09
epoch 995: mean loss = 2.4322346e-09  learning rate = 2.6204483e-05
============================
Start of epoch 996
step 0: mean loss = 3.5311951e-09
step 100: mean loss = 2.2911917e-09
epoch 996: mean loss = 2.4332636e-09  learning rate = 2.6204483e-05
============================
Start of epoch 997
step 0: mean loss = 1.7390944e-09
step 100: mean loss = 2.2007431e-09
epoch 997: mean loss = 2.296889e-09  learning rate = 2.6204483e-05
============================
Start of epoch 998
step 0: mean loss = 1.93863e-09
step 100: mean loss = 2.5877718e-09
epoch 998: mean loss = 2.587605e-09  learning rate = 2.6204483e-05
============================
Start of epoch 999
step 0: mean loss = 2.808394e-09
step 100: mean loss = 1.8067803e-09
epoch 999: mean loss = 2.3491602e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1000
step 0: mean loss = 1.3502417e-09
step 100: mean loss = 2.2419178e-09
epoch 1000: mean loss = 2.495735e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1001
step 0: mean loss = 1.9623614e-09
step 100: mean loss = 2.261033e-09
epoch 1001: mean loss = 2.1054376e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1002
step 0: mean loss = 2.2672808e-09
step 100: mean loss = 2.867237e-09
epoch 1002: mean loss = 2.5213283e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1003
step 0: mean loss = 7.426584e-09
step 100: mean loss = 1.852815e-09
epoch 1003: mean loss = 3.154632e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1004
step 0: mean loss = 1.4169335e-09
step 100: mean loss = 2.0376352e-09
epoch 1004: mean loss = 1.9196225e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1005
step 0: mean loss = 1.3518331e-09
step 100: mean loss = 2.1086828e-09
epoch 1005: mean loss = 2.4660947e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1006
step 0: mean loss = 2.325787e-09
step 100: mean loss = 2.3912161e-09
epoch 1006: mean loss = 2.1884938e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1007
step 0: mean loss = 1.5534661e-09
step 100: mean loss = 2.5286977e-09
epoch 1007: mean loss = 2.2316982e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1008
step 0: mean loss = 1.3677895e-09
step 100: mean loss = 2.8814306e-09
epoch 1008: mean loss = 2.9389478e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1009
step 0: mean loss = 2.8646325e-09
step 100: mean loss = 2.039271e-09
epoch 1009: mean loss = 1.8718078e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1010
step 0: mean loss = 1.8871409e-09
step 100: mean loss = 2.4047977e-09
epoch 1010: mean loss = 2.7107212e-09  learning rate = 2.6204483e-05
============================
Start of epoch 1011
step 0: mean loss = 1.528481e-09
step 100: mean loss = 2.0694566e-09
epoch 1011: mean loss = 1.8193664e-09  learning rate = 2.489426e-05
============================
Start of epoch 1012
step 0: mean loss = 1.3375018e-09
step 100: mean loss = 2.466575e-09
epoch 1012: mean loss = 2.1773068e-09  learning rate = 2.489426e-05
============================
Start of epoch 1013
step 0: mean loss = 1.4607773e-09
step 100: mean loss = 1.930317e-09
epoch 1013: mean loss = 2.3638993e-09  learning rate = 2.489426e-05
============================
Start of epoch 1014
step 0: mean loss = 1.4164283e-09
step 100: mean loss = 2.0193658e-09
epoch 1014: mean loss = 2.367153e-09  learning rate = 2.489426e-05
============================
Start of epoch 1015
step 0: mean loss = 1.857212e-09
step 100: mean loss = 1.9023316e-09
epoch 1015: mean loss = 2.0185122e-09  learning rate = 2.489426e-05
============================
Start of epoch 1016
step 0: mean loss = 1.3815417e-09
step 100: mean loss = 2.503245e-09
epoch 1016: mean loss = 2.5056741e-09  learning rate = 2.489426e-05
============================
Start of epoch 1017
step 0: mean loss = 1.4820594e-09
step 100: mean loss = 2.5871134e-09
epoch 1017: mean loss = 2.1783824e-09  learning rate = 2.489426e-05
============================
Start of epoch 1018
step 0: mean loss = 1.3842782e-09
step 100: mean loss = 2.6111497e-09
epoch 1018: mean loss = 2.3054842e-09  learning rate = 2.489426e-05
============================
Start of epoch 1019
step 0: mean loss = 1.6044845e-09
step 100: mean loss = 2.2461233e-09
epoch 1019: mean loss = 2.0569086e-09  learning rate = 2.489426e-05
============================
Start of epoch 1020
step 0: mean loss = 4.4335473e-09
step 100: mean loss = 2.7774198e-09
epoch 1020: mean loss = 2.9186145e-09  learning rate = 2.489426e-05
============================
Start of epoch 1021
step 0: mean loss = 2.2241762e-09
step 100: mean loss = 1.7049985e-09
epoch 1021: mean loss = 1.8837787e-09  learning rate = 2.489426e-05
============================
Start of epoch 1022
step 0: mean loss = 1.4968944e-09
step 100: mean loss = 2.252815e-09
epoch 1022: mean loss = 2.26945e-09  learning rate = 2.489426e-05
============================
Start of epoch 1023
step 0: mean loss = 2.4188642e-09
step 100: mean loss = 2.2465567e-09
epoch 1023: mean loss = 2.6973006e-09  learning rate = 2.489426e-05
============================
Start of epoch 1024
step 0: mean loss = 1.4066365e-09
step 100: mean loss = 1.868538e-09
epoch 1024: mean loss = 2.261013e-09  learning rate = 2.489426e-05
============================
Start of epoch 1025
step 0: mean loss = 1.8213356e-09
step 100: mean loss = 2.2302726e-09
epoch 1025: mean loss = 1.9280957e-09  learning rate = 2.489426e-05
============================
Start of epoch 1026
step 0: mean loss = 1.3354808e-09
step 100: mean loss = 2.729717e-09
epoch 1026: mean loss = 2.4817601e-09  learning rate = 2.489426e-05
============================
Start of epoch 1027
step 0: mean loss = 1.3899075e-09
step 100: mean loss = 2.285731e-09
epoch 1027: mean loss = 1.9962474e-09  learning rate = 2.489426e-05
============================
Start of epoch 1028
step 0: mean loss = 5.1043436e-09
step 100: mean loss = 3.5422258e-09
epoch 1028: mean loss = 2.7727447e-09  learning rate = 2.489426e-05
============================
Start of epoch 1029
step 0: mean loss = 1.3365011e-09
step 100: mean loss = 2.9960658e-09
epoch 1029: mean loss = 2.4166917e-09  learning rate = 2.489426e-05
============================
Start of epoch 1030
step 0: mean loss = 1.3357035e-09
step 100: mean loss = 2.5610414e-09
epoch 1030: mean loss = 2.17309e-09  learning rate = 2.489426e-05
============================
Start of epoch 1031
step 0: mean loss = 1.7572571e-09
step 100: mean loss = 2.4579818e-09
epoch 1031: mean loss = 2.1924305e-09  learning rate = 2.489426e-05
============================
Start of epoch 1032
step 0: mean loss = 1.6179088e-09
step 100: mean loss = 2.7660259e-09
epoch 1032: mean loss = 2.2966051e-09  learning rate = 2.489426e-05
============================
Start of epoch 1033
step 0: mean loss = 1.4992838e-09
step 100: mean loss = 2.5105968e-09
epoch 1033: mean loss = 2.2922775e-09  learning rate = 2.489426e-05
============================
Start of epoch 1034
step 0: mean loss = 6.2086842e-09
step 100: mean loss = 2.5155062e-09
epoch 1034: mean loss = 2.3014577e-09  learning rate = 2.489426e-05
============================
Start of epoch 1035
step 0: mean loss = 1.3602812e-09
step 100: mean loss = 2.5277767e-09
epoch 1035: mean loss = 2.5722011e-09  learning rate = 2.489426e-05
============================
Start of epoch 1036
step 0: mean loss = 3.5527046e-09
step 100: mean loss = 2.1823845e-09
epoch 1036: mean loss = 2.0069941e-09  learning rate = 2.489426e-05
============================
Start of epoch 1037
step 0: mean loss = 1.4305722e-09
step 100: mean loss = 2.7952405e-09
epoch 1037: mean loss = 2.3358309e-09  learning rate = 2.489426e-05
============================
Start of epoch 1038
step 0: mean loss = 1.3518883e-09
step 100: mean loss = 2.2955402e-09
epoch 1038: mean loss = 2.2989453e-09  learning rate = 2.489426e-05
============================
Start of epoch 1039
step 0: mean loss = 2.622542e-09
step 100: mean loss = 2.3725435e-09
epoch 1039: mean loss = 2.2159437e-09  learning rate = 2.489426e-05
============================
Start of epoch 1040
step 0: mean loss = 6.719971e-09
step 100: mean loss = 2.7398583e-09
epoch 1040: mean loss = 2.5249678e-09  learning rate = 2.489426e-05
============================
Start of epoch 1041
step 0: mean loss = 1.5535426e-09
step 100: mean loss = 2.085781e-09
epoch 1041: mean loss = 2.0242517e-09  learning rate = 2.489426e-05
============================
Start of epoch 1042
step 0: mean loss = 1.4721226e-09
step 100: mean loss = 3.0523166e-09
epoch 1042: mean loss = 2.4868432e-09  learning rate = 2.489426e-05
============================
Start of epoch 1043
step 0: mean loss = 1.3789574e-09
step 100: mean loss = 2.3362006e-09
epoch 1043: mean loss = 2.191099e-09  learning rate = 2.489426e-05
============================
Start of epoch 1044
step 0: mean loss = 1.9037623e-09
step 100: mean loss = 2.6288904e-09
epoch 1044: mean loss = 2.5366935e-09  learning rate = 2.489426e-05
============================
Start of epoch 1045
step 0: mean loss = 5.8298064e-09
step 100: mean loss = 2.738172e-09
epoch 1045: mean loss = 2.5496454e-09  learning rate = 2.489426e-05
============================
Start of epoch 1046
step 0: mean loss = 1.333672e-09
step 100: mean loss = 2.1301758e-09
epoch 1046: mean loss = 1.8576037e-09  learning rate = 2.489426e-05
============================
Start of epoch 1047
step 0: mean loss = 1.4695357e-09
step 100: mean loss = 2.1873692e-09
epoch 1047: mean loss = 2.4507876e-09  learning rate = 2.489426e-05
============================
Start of epoch 1048
step 0: mean loss = 1.3749784e-09
step 100: mean loss = 2.0071993e-09
epoch 1048: mean loss = 2.1383288e-09  learning rate = 2.489426e-05
============================
Start of epoch 1049
step 0: mean loss = 1.3481803e-09
step 100: mean loss = 2.5292093e-09
epoch 1049: mean loss = 2.6723685e-09  learning rate = 2.489426e-05
============================
Start of epoch 1050
step 0: mean loss = 3.1229743e-09
step 100: mean loss = 2.3670075e-09
epoch 1050: mean loss = 2.0390787e-09  learning rate = 2.489426e-05
============================
Start of epoch 1051
step 0: mean loss = 1.5516284e-09
step 100: mean loss = 2.1263769e-09
epoch 1051: mean loss = 2.1253563e-09  learning rate = 2.489426e-05
============================
Start of epoch 1052
step 0: mean loss = 1.7571602e-09
step 100: mean loss = 2.3035382e-09
epoch 1052: mean loss = 2.4153999e-09  learning rate = 2.489426e-05
============================
Start of epoch 1053
step 0: mean loss = 1.5228193e-09
step 100: mean loss = 2.2499345e-09
epoch 1053: mean loss = 2.2509745e-09  learning rate = 2.489426e-05
============================
Start of epoch 1054
step 0: mean loss = 1.577369e-09
step 100: mean loss = 2.8480682e-09
epoch 1054: mean loss = 2.5923965e-09  learning rate = 2.489426e-05
============================
Start of epoch 1055
step 0: mean loss = 1.3574939e-09
step 100: mean loss = 2.1259041e-09
epoch 1055: mean loss = 2.1917168e-09  learning rate = 2.489426e-05
============================
Start of epoch 1056
step 0: mean loss = 3.9904733e-09
step 100: mean loss = 2.0953623e-09
epoch 1056: mean loss = 2.2608817e-09  learning rate = 2.489426e-05
============================
Start of epoch 1057
step 0: mean loss = 1.7305354e-09
step 100: mean loss = 2.1267448e-09
epoch 1057: mean loss = 2.4578342e-09  learning rate = 2.489426e-05
============================
Start of epoch 1058
step 0: mean loss = 1.9457755e-09
step 100: mean loss = 2.2468016e-09
epoch 1058: mean loss = 2.0818547e-09  learning rate = 2.489426e-05
============================
Start of epoch 1059
step 0: mean loss = 2.813378e-09
step 100: mean loss = 2.0647575e-09
epoch 1059: mean loss = 2.1912798e-09  learning rate = 2.489426e-05
============================
Start of epoch 1060
step 0: mean loss = 1.5869267e-09
step 100: mean loss = 1.9835587e-09
epoch 1060: mean loss = 2.6560167e-09  learning rate = 2.489426e-05
============================
Start of epoch 1061
step 0: mean loss = 1.3993471e-09
step 100: mean loss = 2.1636506e-09
epoch 1061: mean loss = 1.8738904e-09  learning rate = 2.489426e-05
============================
Start of epoch 1062
step 0: mean loss = 1.3913651e-09
step 100: mean loss = 2.5109728e-09
epoch 1062: mean loss = 2.3388314e-09  learning rate = 2.489426e-05
============================
Start of epoch 1063
step 0: mean loss = 1.357808e-09
step 100: mean loss = 2.4300593e-09
epoch 1063: mean loss = 2.7741995e-09  learning rate = 2.489426e-05
============================
Start of epoch 1064
step 0: mean loss = 2.215912e-09
step 100: mean loss = 2.4496798e-09
epoch 1064: mean loss = 2.0718547e-09  learning rate = 2.489426e-05
============================
Start of epoch 1065
step 0: mean loss = 1.3259955e-09
step 100: mean loss = 2.4327447e-09
epoch 1065: mean loss = 2.0636848e-09  learning rate = 2.489426e-05
============================
Start of epoch 1066
step 0: mean loss = 1.705141e-09
step 100: mean loss = 2.4920914e-09
epoch 1066: mean loss = 2.6191038e-09  learning rate = 2.489426e-05
============================
Start of epoch 1067
step 0: mean loss = 1.3703471e-09
step 100: mean loss = 2.9475915e-09
epoch 1067: mean loss = 2.5825833e-09  learning rate = 2.489426e-05
============================
Start of epoch 1068
step 0: mean loss = 1.3190481e-09
step 100: mean loss = 2.5064497e-09
epoch 1068: mean loss = 2.1484858e-09  learning rate = 2.489426e-05
============================
Start of epoch 1069
step 0: mean loss = 1.3190902e-09
step 100: mean loss = 2.982686e-09
epoch 1069: mean loss = 2.455331e-09  learning rate = 2.489426e-05
============================
Start of epoch 1070
step 0: mean loss = 1.3256808e-09
step 100: mean loss = 1.912729e-09
epoch 1070: mean loss = 1.758945e-09  learning rate = 2.489426e-05
============================
Start of epoch 1071
step 0: mean loss = 1.6106583e-09
step 100: mean loss = 2.3079378e-09
epoch 1071: mean loss = 2.481013e-09  learning rate = 2.489426e-05
============================
Start of epoch 1072
step 0: mean loss = 1.473548e-09
step 100: mean loss = 2.29123e-09
epoch 1072: mean loss = 2.3031197e-09  learning rate = 2.489426e-05
============================
Start of epoch 1073
step 0: mean loss = 6.232761e-09
step 100: mean loss = 2.6581197e-09
epoch 1073: mean loss = 2.2402173e-09  learning rate = 2.489426e-05
============================
Start of epoch 1074
step 0: mean loss = 1.5519782e-09
step 100: mean loss = 2.4324078e-09
epoch 1074: mean loss = 2.0783377e-09  learning rate = 2.489426e-05
============================
Start of epoch 1075
step 0: mean loss = 1.8302692e-09
step 100: mean loss = 3.409405e-09
epoch 1075: mean loss = 2.7007665e-09  learning rate = 2.489426e-05
============================
Start of epoch 1076
step 0: mean loss = 1.317041e-09
step 100: mean loss = 1.8204931e-09
epoch 1076: mean loss = 2.2399511e-09  learning rate = 2.489426e-05
============================
Start of epoch 1077
step 0: mean loss = 1.6303663e-09
step 100: mean loss = 2.281462e-09
epoch 1077: mean loss = 1.9514508e-09  learning rate = 2.489426e-05
============================
Start of epoch 1078
step 0: mean loss = 1.4684051e-09
step 100: mean loss = 2.741843e-09
epoch 1078: mean loss = 2.7402998e-09  learning rate = 2.489426e-05
============================
Start of epoch 1079
step 0: mean loss = 1.536816e-09
step 100: mean loss = 2.2948836e-09
epoch 1079: mean loss = 1.9706798e-09  learning rate = 2.489426e-05
============================
Start of epoch 1080
step 0: mean loss = 1.3262467e-09
step 100: mean loss = 2.9837492e-09
epoch 1080: mean loss = 2.7824107e-09  learning rate = 2.489426e-05
============================
Start of epoch 1081
step 0: mean loss = 1.3173738e-09
step 100: mean loss = 1.4752566e-09
epoch 1081: mean loss = 2.2437947e-09  learning rate = 2.489426e-05
============================
Start of epoch 1082
step 0: mean loss = 1.517894e-09
step 100: mean loss = 1.662669e-09
epoch 1082: mean loss = 2.0833246e-09  learning rate = 2.489426e-05
============================
Start of epoch 1083
step 0: mean loss = 1.45983e-09
step 100: mean loss = 2.46535e-09
epoch 1083: mean loss = 2.150572e-09  learning rate = 2.489426e-05
============================
Start of epoch 1084
step 0: mean loss = 2.2536044e-09
step 100: mean loss = 2.8865927e-09
epoch 1084: mean loss = 2.411032e-09  learning rate = 2.489426e-05
============================
Start of epoch 1085
step 0: mean loss = 1.3557748e-09
step 100: mean loss = 2.392686e-09
epoch 1085: mean loss = 2.5509894e-09  learning rate = 2.489426e-05
============================
Start of epoch 1086
step 0: mean loss = 1.5092325e-09
step 100: mean loss = 2.3540725e-09
epoch 1086: mean loss = 2.1550293e-09  learning rate = 2.489426e-05
============================
Start of epoch 1087
step 0: mean loss = 1.4949595e-09
step 100: mean loss = 1.6306402e-09
epoch 1087: mean loss = 2.431749e-09  learning rate = 2.489426e-05
============================
Start of epoch 1088
step 0: mean loss = 1.492706e-09
step 100: mean loss = 2.289166e-09
epoch 1088: mean loss = 1.9988788e-09  learning rate = 2.489426e-05
============================
Start of epoch 1089
step 0: mean loss = 1.3247949e-09
step 100: mean loss = 3.001069e-09
epoch 1089: mean loss = 2.4190325e-09  learning rate = 2.489426e-05
============================
Start of epoch 1090
step 0: mean loss = 1.314468e-09
step 100: mean loss = 2.4559035e-09
epoch 1090: mean loss = 2.0629816e-09  learning rate = 2.489426e-05
============================
Start of epoch 1091
step 0: mean loss = 1.507718e-09
step 100: mean loss = 2.5732456e-09
epoch 1091: mean loss = 2.3836422e-09  learning rate = 2.489426e-05
============================
Start of epoch 1092
step 0: mean loss = 1.4795185e-09
step 100: mean loss = 2.224502e-09
epoch 1092: mean loss = 1.9075728e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1093
step 0: mean loss = 1.3147777e-09
step 100: mean loss = 2.2217577e-09
epoch 1093: mean loss = 1.931606e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1094
step 0: mean loss = 2.0459847e-09
step 100: mean loss = 2.3917677e-09
epoch 1094: mean loss = 2.283373e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1095
step 0: mean loss = 1.6709854e-09
step 100: mean loss = 2.47022e-09
epoch 1095: mean loss = 2.082492e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1096
step 0: mean loss = 1.66986e-09
step 100: mean loss = 2.4811018e-09
epoch 1096: mean loss = 2.1716267e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1097
step 0: mean loss = 1.5461188e-09
step 100: mean loss = 2.0940822e-09
epoch 1097: mean loss = 2.4869693e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1098
step 0: mean loss = 1.973862e-09
step 100: mean loss = 2.087238e-09
epoch 1098: mean loss = 2.1019024e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1099
step 0: mean loss = 1.8683892e-09
step 100: mean loss = 2.0935673e-09
epoch 1099: mean loss = 1.9538666e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1100
step 0: mean loss = 7.625797e-09
step 100: mean loss = 2.9466547e-09
epoch 1100: mean loss = 2.3909283e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1101
step 0: mean loss = 1.3173367e-09
step 100: mean loss = 2.3204616e-09
epoch 1101: mean loss = 2.0922184e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1102
step 0: mean loss = 6.2291288e-09
step 100: mean loss = 2.4589255e-09
epoch 1102: mean loss = 2.1511495e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1103
step 0: mean loss = 1.3560362e-09
step 100: mean loss = 2.0164865e-09
epoch 1103: mean loss = 2.6251599e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1104
step 0: mean loss = 1.4915463e-09
step 100: mean loss = 2.239221e-09
epoch 1104: mean loss = 1.93315e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1105
step 0: mean loss = 1.3116532e-09
step 100: mean loss = 2.27634e-09
epoch 1105: mean loss = 1.9480013e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1106
step 0: mean loss = 1.3648664e-09
step 100: mean loss = 2.4417826e-09
epoch 1106: mean loss = 2.2120044e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1107
step 0: mean loss = 1.4483171e-09
step 100: mean loss = 2.3528806e-09
epoch 1107: mean loss = 2.2208275e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1108
step 0: mean loss = 1.3389057e-09
step 100: mean loss = 2.4534539e-09
epoch 1108: mean loss = 2.567169e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1109
step 0: mean loss = 2.0776398e-09
step 100: mean loss = 1.4540571e-09
epoch 1109: mean loss = 2.1704192e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1110
step 0: mean loss = 1.3964442e-09
step 100: mean loss = 1.7279647e-09
epoch 1110: mean loss = 2.0529414e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1111
step 0: mean loss = 2.0026472e-09
step 100: mean loss = 2.040995e-09
epoch 1111: mean loss = 1.967601e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1112
step 0: mean loss = 1.8705089e-09
step 100: mean loss = 2.5120903e-09
epoch 1112: mean loss = 2.2266744e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1113
step 0: mean loss = 4.9597073e-09
step 100: mean loss = 2.518946e-09
epoch 1113: mean loss = 2.285408e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1114
step 0: mean loss = 1.6364124e-09
step 100: mean loss = 1.9086324e-09
epoch 1114: mean loss = 1.99401e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1115
step 0: mean loss = 1.4404381e-09
step 100: mean loss = 2.6161227e-09
epoch 1115: mean loss = 2.240611e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1116
step 0: mean loss = 1.3106589e-09
step 100: mean loss = 2.3534148e-09
epoch 1116: mean loss = 2.18529e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1117
step 0: mean loss = 1.3391245e-09
step 100: mean loss = 2.6304672e-09
epoch 1117: mean loss = 2.1713844e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1118
step 0: mean loss = 1.3271282e-09
step 100: mean loss = 2.1279138e-09
epoch 1118: mean loss = 2.370498e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1119
step 0: mean loss = 1.5055379e-09
step 100: mean loss = 1.8798711e-09
epoch 1119: mean loss = 2.4300568e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1120
step 0: mean loss = 1.5797477e-09
step 100: mean loss = 1.444014e-09
epoch 1120: mean loss = 1.8005646e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1121
step 0: mean loss = 2.1638256e-09
step 100: mean loss = 2.0694384e-09
epoch 1121: mean loss = 2.140007e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1122
step 0: mean loss = 1.3206365e-09
step 100: mean loss = 2.246605e-09
epoch 1122: mean loss = 2.491049e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1123
step 0: mean loss = 1.3127213e-08
step 100: mean loss = 1.986573e-09
epoch 1123: mean loss = 2.076743e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1124
step 0: mean loss = 1.3257389e-09
step 100: mean loss = 1.9039221e-09
epoch 1124: mean loss = 2.1821542e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1125
step 0: mean loss = 1.3847784e-09
step 100: mean loss = 2.2003102e-09
epoch 1125: mean loss = 1.8938164e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1126
step 0: mean loss = 1.3922743e-09
step 100: mean loss = 2.8321474e-09
epoch 1126: mean loss = 2.4327746e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1127
step 0: mean loss = 1.3181776e-09
step 100: mean loss = 2.1741937e-09
epoch 1127: mean loss = 1.8873125e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1128
step 0: mean loss = 1.8242433e-09
step 100: mean loss = 3.0054916e-09
epoch 1128: mean loss = 2.4576454e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1129
step 0: mean loss = 1.3456236e-09
step 100: mean loss = 2.4453102e-09
epoch 1129: mean loss = 2.1874025e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1130
step 0: mean loss = 1.6170639e-09
step 100: mean loss = 2.1373956e-09
epoch 1130: mean loss = 2.014658e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1131
step 0: mean loss = 1.4456295e-09
step 100: mean loss = 2.0802202e-09
epoch 1131: mean loss = 2.4798574e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1132
step 0: mean loss = 1.3995616e-09
step 100: mean loss = 1.9343178e-09
epoch 1132: mean loss = 1.7897446e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1133
step 0: mean loss = 7.4164013e-09
step 100: mean loss = 2.8728717e-09
epoch 1133: mean loss = 2.81354e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1134
step 0: mean loss = 1.4320021e-09
step 100: mean loss = 1.4703003e-09
epoch 1134: mean loss = 1.692812e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1135
step 0: mean loss = 1.5490478e-09
step 100: mean loss = 2.4497573e-09
epoch 1135: mean loss = 2.1070239e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1136
step 0: mean loss = 1.3947971e-09
step 100: mean loss = 2.469501e-09
epoch 1136: mean loss = 2.4641884e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1137
step 0: mean loss = 4.05192e-09
step 100: mean loss = 2.4025946e-09
epoch 1137: mean loss = 2.0278546e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1138
step 0: mean loss = 1.3393049e-09
step 100: mean loss = 2.8969482e-09
epoch 1138: mean loss = 2.3463125e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1139
step 0: mean loss = 1.3341502e-09
step 100: mean loss = 1.8804485e-09
epoch 1139: mean loss = 2.3091529e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1140
step 0: mean loss = 1.7697395e-09
step 100: mean loss = 1.7649014e-09
epoch 1140: mean loss = 2.0526931e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1141
step 0: mean loss = 2.120885e-09
step 100: mean loss = 2.05935e-09
epoch 1141: mean loss = 2.1131294e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1142
step 0: mean loss = 8.824101e-09
step 100: mean loss = 1.9600446e-09
epoch 1142: mean loss = 2.2554714e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1143
step 0: mean loss = 1.3371546e-09
step 100: mean loss = 2.2106614e-09
epoch 1143: mean loss = 2.3162487e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1144
step 0: mean loss = 3.2227843e-09
step 100: mean loss = 1.9612836e-09
epoch 1144: mean loss = 1.8559236e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1145
step 0: mean loss = 1.7266273e-09
step 100: mean loss = 2.2420765e-09
epoch 1145: mean loss = 2.1136255e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1146
step 0: mean loss = 3.197745e-09
step 100: mean loss = 2.6868776e-09
epoch 1146: mean loss = 2.2065474e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1147
step 0: mean loss = 1.4634659e-09
step 100: mean loss = 2.3552762e-09
epoch 1147: mean loss = 2.7265015e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1148
step 0: mean loss = 2.4856917e-09
step 100: mean loss = 1.9920943e-09
epoch 1148: mean loss = 1.9709836e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1149
step 0: mean loss = 1.3052395e-09
step 100: mean loss = 2.449547e-09
epoch 1149: mean loss = 2.1186075e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1150
step 0: mean loss = 1.3913052e-09
step 100: mean loss = 1.9042528e-09
epoch 1150: mean loss = 2.058813e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1151
step 0: mean loss = 1.387829e-09
step 100: mean loss = 2.4392026e-09
epoch 1151: mean loss = 2.3148972e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1152
step 0: mean loss = 2.5075821e-09
step 100: mean loss = 1.9041408e-09
epoch 1152: mean loss = 1.8618364e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1153
step 0: mean loss = 4.5272013e-09
step 100: mean loss = 2.2561841e-09
epoch 1153: mean loss = 2.393154e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1154
step 0: mean loss = 1.397261e-09
step 100: mean loss = 2.0867108e-09
epoch 1154: mean loss = 2.3330144e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1155
step 0: mean loss = 1.9305202e-09
step 100: mean loss = 2.0088677e-09
epoch 1155: mean loss = 1.8598204e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1156
step 0: mean loss = 1.958483e-09
step 100: mean loss = 2.1179605e-09
epoch 1156: mean loss = 2.324538e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1157
step 0: mean loss = 1.410427e-09
step 100: mean loss = 2.0772604e-09
epoch 1157: mean loss = 2.0435151e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1158
step 0: mean loss = 2.6091858e-09
step 100: mean loss = 2.840631e-09
epoch 1158: mean loss = 2.3390947e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1159
step 0: mean loss = 1.3062791e-09
step 100: mean loss = 2.1561943e-09
epoch 1159: mean loss = 1.8760438e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1160
step 0: mean loss = 3.1883183e-09
step 100: mean loss = 2.8150502e-09
epoch 1160: mean loss = 2.9215865e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1161
step 0: mean loss = 6.606681e-09
step 100: mean loss = 1.607407e-09
epoch 1161: mean loss = 2.0794642e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1162
step 0: mean loss = 2.4658044e-09
step 100: mean loss = 1.5353354e-09
epoch 1162: mean loss = 1.720372e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1163
step 0: mean loss = 3.736164e-09
step 100: mean loss = 2.7177829e-09
epoch 1163: mean loss = 2.5186964e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1164
step 0: mean loss = 8.641273e-09
step 100: mean loss = 1.7048816e-09
epoch 1164: mean loss = 2.1193292e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1165
step 0: mean loss = 1.9804378e-09
step 100: mean loss = 1.7112985e-09
epoch 1165: mean loss = 1.907093e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1166
step 0: mean loss = 1.3350275e-09
step 100: mean loss = 2.250901e-09
epoch 1166: mean loss = 2.5049098e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1167
step 0: mean loss = 1.5777195e-09
step 100: mean loss = 1.8813036e-09
epoch 1167: mean loss = 1.8165491e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1168
step 0: mean loss = 1.6887934e-09
step 100: mean loss = 2.1300388e-09
epoch 1168: mean loss = 2.712824e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1169
step 0: mean loss = 1.5323803e-09
step 100: mean loss = 1.9192643e-09
epoch 1169: mean loss = 1.7115546e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1170
step 0: mean loss = 1.298905e-09
step 100: mean loss = 2.339436e-09
epoch 1170: mean loss = 2.1276276e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1171
step 0: mean loss = 1.1100169e-08
step 100: mean loss = 2.3065434e-09
epoch 1171: mean loss = 2.5206055e-09  learning rate = 2.3649545e-05
============================
Start of epoch 1172
step 0: mean loss = 1.3562417e-09
step 100: mean loss = 2.2378168e-09
epoch 1172: mean loss = 2.1498352e-09  learning rate = 2.246707e-05
============================
Start of epoch 1173
step 0: mean loss = 1.3058116e-09
step 100: mean loss = 1.2947501e-09
epoch 1173: mean loss = 1.3245611e-09  learning rate = 2.246707e-05
============================
Start of epoch 1174
step 0: mean loss = 2.8515794e-09
step 100: mean loss = 1.9111634e-09
epoch 1174: mean loss = 2.6916247e-09  learning rate = 2.246707e-05
============================
Start of epoch 1175
step 0: mean loss = 2.4004592e-09
step 100: mean loss = 1.3594862e-09
epoch 1175: mean loss = 1.8251782e-09  learning rate = 2.246707e-05
============================
Start of epoch 1176
step 0: mean loss = 1.5030754e-09
step 100: mean loss = 1.9205393e-09
epoch 1176: mean loss = 1.8661566e-09  learning rate = 2.246707e-05
============================
Start of epoch 1177
step 0: mean loss = 1.3406088e-09
step 100: mean loss = 1.9307118e-09
epoch 1177: mean loss = 2.0846256e-09  learning rate = 2.246707e-05
============================
Start of epoch 1178
step 0: mean loss = 1.3563429e-09
step 100: mean loss = 1.8191656e-09
epoch 1178: mean loss = 1.9384458e-09  learning rate = 2.246707e-05
============================
Start of epoch 1179
step 0: mean loss = 1.3479778e-09
step 100: mean loss = 2.0411985e-09
epoch 1179: mean loss = 2.2492113e-09  learning rate = 2.246707e-05
============================
Start of epoch 1180
step 0: mean loss = 1.3387222e-09
step 100: mean loss = 1.9627597e-09
epoch 1180: mean loss = 2.1508537e-09  learning rate = 2.246707e-05
============================
Start of epoch 1181
step 0: mean loss = 3.2606722e-09
step 100: mean loss = 1.9754596e-09
epoch 1181: mean loss = 1.7675784e-09  learning rate = 2.246707e-05
============================
Start of epoch 1182
step 0: mean loss = 1.3175859e-09
step 100: mean loss = 3.170859e-09
epoch 1182: mean loss = 2.5181455e-09  learning rate = 2.246707e-05
============================
Start of epoch 1183
step 0: mean loss = 1.2875816e-09
step 100: mean loss = 2.1007491e-09
epoch 1183: mean loss = 1.8191079e-09  learning rate = 2.246707e-05
============================
Start of epoch 1184
step 0: mean loss = 1.2924357e-09
step 100: mean loss = 1.9543227e-09
epoch 1184: mean loss = 2.3244215e-09  learning rate = 2.246707e-05
============================
Start of epoch 1185
step 0: mean loss = 1.5889987e-09
step 100: mean loss = 2.0479372e-09
epoch 1185: mean loss = 1.8695483e-09  learning rate = 2.246707e-05
============================
Start of epoch 1186
step 0: mean loss = 1.7608249e-09
step 100: mean loss = 1.883634e-09
epoch 1186: mean loss = 2.067193e-09  learning rate = 2.246707e-05
============================
Start of epoch 1187
step 0: mean loss = 1.4604626e-09
step 100: mean loss = 1.9111452e-09
epoch 1187: mean loss = 2.0626978e-09  learning rate = 2.246707e-05
============================
Start of epoch 1188
step 0: mean loss = 1.5352675e-09
step 100: mean loss = 2.0990263e-09
epoch 1188: mean loss = 2.0486177e-09  learning rate = 2.246707e-05
============================
Start of epoch 1189
step 0: mean loss = 9.002351e-09
step 100: mean loss = 2.0774082e-09
epoch 1189: mean loss = 2.1952522e-09  learning rate = 2.246707e-05
============================
Start of epoch 1190
step 0: mean loss = 1.5277188e-09
step 100: mean loss = 2.1168127e-09
epoch 1190: mean loss = 1.8806134e-09  learning rate = 2.246707e-05
============================
Start of epoch 1191
step 0: mean loss = 5.5687455e-09
step 100: mean loss = 2.3774973e-09
epoch 1191: mean loss = 2.3505338e-09  learning rate = 2.246707e-05
============================
Start of epoch 1192
step 0: mean loss = 1.4286025e-09
step 100: mean loss = 2.1149191e-09
epoch 1192: mean loss = 1.8550588e-09  learning rate = 2.246707e-05
============================
Start of epoch 1193
step 0: mean loss = 1.410408e-09
step 100: mean loss = 2.0675388e-09
epoch 1193: mean loss = 2.25478e-09  learning rate = 2.246707e-05
============================
Start of epoch 1194
step 0: mean loss = 1.4111475e-09
step 100: mean loss = 1.8476253e-09
epoch 1194: mean loss = 2.4465316e-09  learning rate = 2.246707e-05
============================
Start of epoch 1195
step 0: mean loss = 1.8530806e-09
step 100: mean loss = 1.380077e-09
epoch 1195: mean loss = 2.1127189e-09  learning rate = 2.246707e-05
============================
Start of epoch 1196
step 0: mean loss = 1.3188164e-09
step 100: mean loss = 1.2881484e-09
epoch 1196: mean loss = 1.8841861e-09  learning rate = 2.246707e-05
============================
Start of epoch 1197
step 0: mean loss = 1.908763e-09
step 100: mean loss = 1.5767379e-09
epoch 1197: mean loss = 1.6700094e-09  learning rate = 2.246707e-05
============================
Start of epoch 1198
step 0: mean loss = 1.442521e-09
step 100: mean loss = 2.4801194e-09
epoch 1198: mean loss = 2.2077586e-09  learning rate = 2.246707e-05
============================
Start of epoch 1199
step 0: mean loss = 1.2988841e-09
step 100: mean loss = 2.0226327e-09
epoch 1199: mean loss = 2.0732907e-09  learning rate = 2.246707e-05
============================
Start of epoch 1200
step 0: mean loss = 1.3719105e-09
step 100: mean loss = 1.9948185e-09
epoch 1200: mean loss = 2.14865e-09  learning rate = 2.246707e-05
============================
Start of epoch 1201
step 0: mean loss = 1.4317277e-09
step 100: mean loss = 1.8741657e-09
epoch 1201: mean loss = 1.9196493e-09  learning rate = 2.246707e-05
============================
Start of epoch 1202
step 0: mean loss = 1.2942658e-09
step 100: mean loss = 2.042099e-09
epoch 1202: mean loss = 2.318674e-09  learning rate = 2.246707e-05
============================
Start of epoch 1203
step 0: mean loss = 1.3635355e-09
step 100: mean loss = 2.098784e-09
epoch 1203: mean loss = 1.820431e-09  learning rate = 2.246707e-05
============================
Start of epoch 1204
step 0: mean loss = 1.2836725e-09
step 100: mean loss = 2.3115527e-09
epoch 1204: mean loss = 2.4760929e-09  learning rate = 2.246707e-05
============================
Start of epoch 1205
step 0: mean loss = 1.3765401e-09
step 100: mean loss = 1.9977506e-09
epoch 1205: mean loss = 1.9263013e-09  learning rate = 2.246707e-05
============================
Start of epoch 1206
step 0: mean loss = 1.2887861e-09
step 100: mean loss = 2.0273643e-09
epoch 1206: mean loss = 1.7728787e-09  learning rate = 2.246707e-05
============================
Start of epoch 1207
step 0: mean loss = 1.4309647e-09
step 100: mean loss = 2.4108686e-09
epoch 1207: mean loss = 2.7837628e-09  learning rate = 2.246707e-05
============================
Start of epoch 1208
step 0: mean loss = 1.8939526e-09
step 100: mean loss = 1.3234223e-09
epoch 1208: mean loss = 1.8219689e-09  learning rate = 2.246707e-05
============================
Start of epoch 1209
step 0: mean loss = 1.4551353e-09
step 100: mean loss = 1.9777522e-09
epoch 1209: mean loss = 1.8251699e-09  learning rate = 2.246707e-05
============================
Start of epoch 1210
step 0: mean loss = 2.1660955e-09
step 100: mean loss = 2.2118773e-09
epoch 1210: mean loss = 2.1677655e-09  learning rate = 2.246707e-05
============================
Start of epoch 1211
step 0: mean loss = 1.2774709e-09
step 100: mean loss = 2.5174058e-09
epoch 1211: mean loss = 2.0968562e-09  learning rate = 2.246707e-05
============================
Start of epoch 1212
step 0: mean loss = 1.2777636e-09
step 100: mean loss = 2.3688187e-09
epoch 1212: mean loss = 1.990973e-09  learning rate = 2.246707e-05
============================
Start of epoch 1213
step 0: mean loss = 1.2774873e-09
step 100: mean loss = 1.8690198e-09
epoch 1213: mean loss = 2.2296283e-09  learning rate = 2.246707e-05
============================
Start of epoch 1214
step 0: mean loss = 1.3267227e-09
step 100: mean loss = 2.4444027e-09
epoch 1214: mean loss = 2.0412045e-09  learning rate = 2.246707e-05
============================
Start of epoch 1215
step 0: mean loss = 1.2809395e-09
step 100: mean loss = 1.9477233e-09
epoch 1215: mean loss = 2.0793434e-09  learning rate = 2.246707e-05
============================
Start of epoch 1216
step 0: mean loss = 2.0068354e-09
step 100: mean loss = 2.1412827e-09
epoch 1216: mean loss = 2.0259223e-09  learning rate = 2.246707e-05
============================
Start of epoch 1217
step 0: mean loss = 1.8930764e-09
step 100: mean loss = 2.2797497e-09
epoch 1217: mean loss = 1.969956e-09  learning rate = 2.246707e-05
============================
Start of epoch 1218
step 0: mean loss = 1.2808775e-09
step 100: mean loss = 2.034383e-09
epoch 1218: mean loss = 2.2077102e-09  learning rate = 2.246707e-05
============================
Start of epoch 1219
step 0: mean loss = 1.3701882e-09
step 100: mean loss = 2.5473945e-09
epoch 1219: mean loss = 2.1752422e-09  learning rate = 2.246707e-05
============================
Start of epoch 1220
step 0: mean loss = 1.2857284e-09
step 100: mean loss = 1.8900126e-09
epoch 1220: mean loss = 1.6839061e-09  learning rate = 2.246707e-05
============================
Start of epoch 1221
step 0: mean loss = 1.7042994e-09
step 100: mean loss = 2.5964344e-09
epoch 1221: mean loss = 2.1460576e-09  learning rate = 2.246707e-05
============================
Start of epoch 1222
step 0: mean loss = 1.982911e-09
step 100: mean loss = 2.6690268e-09
epoch 1222: mean loss = 2.3243327e-09  learning rate = 2.246707e-05
============================
Start of epoch 1223
step 0: mean loss = 3.827787e-09
step 100: mean loss = 2.0948399e-09
epoch 1223: mean loss = 2.3058555e-09  learning rate = 2.246707e-05
============================
Start of epoch 1224
step 0: mean loss = 2.0562085e-09
step 100: mean loss = 1.4341988e-09
epoch 1224: mean loss = 1.9000996e-09  learning rate = 2.246707e-05
============================
Start of epoch 1225
step 0: mean loss = 1.310599e-09
step 100: mean loss = 1.6595424e-09
epoch 1225: mean loss = 2.3224247e-09  learning rate = 2.246707e-05
============================
Start of epoch 1226
step 0: mean loss = 1.4539876e-09
step 100: mean loss = 1.5965939e-09
epoch 1226: mean loss = 1.7214039e-09  learning rate = 2.246707e-05
============================
Start of epoch 1227
step 0: mean loss = 2.0069775e-09
step 100: mean loss = 2.0463722e-09
epoch 1227: mean loss = 2.109502e-09  learning rate = 2.246707e-05
============================
Start of epoch 1228
step 0: mean loss = 1.4577713e-09
step 100: mean loss = 2.0539541e-09
epoch 1228: mean loss = 2.1288566e-09  learning rate = 2.246707e-05
============================
Start of epoch 1229
step 0: mean loss = 4.034436e-09
step 100: mean loss = 2.0599449e-09
epoch 1229: mean loss = 1.8142753e-09  learning rate = 2.246707e-05
============================
Start of epoch 1230
step 0: mean loss = 1.2808828e-09
step 100: mean loss = 2.3141675e-09
epoch 1230: mean loss = 2.2981286e-09  learning rate = 2.246707e-05
============================
Start of epoch 1231
step 0: mean loss = 1.4961148e-09
step 100: mean loss = 2.2475872e-09
epoch 1231: mean loss = 1.9680593e-09  learning rate = 2.246707e-05
============================
Start of epoch 1232
step 0: mean loss = 2.8267544e-09
step 100: mean loss = 2.334733e-09
epoch 1232: mean loss = 2.173859e-09  learning rate = 2.246707e-05
============================
Start of epoch 1233
step 0: mean loss = 1.9729542e-09
step 100: mean loss = 2.1409887e-09
epoch 1233: mean loss = 2.1206172e-09  learning rate = 2.246707e-05
============================
Start of epoch 1234
step 0: mean loss = 1.8976865e-09
step 100: mean loss = 2.2376636e-09
epoch 1234: mean loss = 1.9185749e-09  learning rate = 2.246707e-05
============================
Start of epoch 1235
step 0: mean loss = 1.2848812e-09
step 100: mean loss = 1.906389e-09
epoch 1235: mean loss = 2.2766207e-09  learning rate = 2.246707e-05
============================
Start of epoch 1236
step 0: mean loss = 1.307597e-09
step 100: mean loss = 1.9119144e-09
epoch 1236: mean loss = 1.990226e-09  learning rate = 2.246707e-05
============================
Start of epoch 1237
step 0: mean loss = 1.2732406e-09
step 100: mean loss = 2.1375965e-09
epoch 1237: mean loss = 2.0546176e-09  learning rate = 2.246707e-05
============================
Start of epoch 1238
step 0: mean loss = 2.3766793e-09
step 100: mean loss = 1.6974375e-09
epoch 1238: mean loss = 1.9170285e-09  learning rate = 2.246707e-05
============================
Start of epoch 1239
step 0: mean loss = 1.7445564e-09
step 100: mean loss = 2.5280014e-09
epoch 1239: mean loss = 2.1791082e-09  learning rate = 2.246707e-05
============================
Start of epoch 1240
step 0: mean loss = 1.4178783e-09
step 100: mean loss = 2.0175843e-09
epoch 1240: mean loss = 1.8746495e-09  learning rate = 2.246707e-05
============================
Start of epoch 1241
step 0: mean loss = 1.5389102e-09
step 100: mean loss = 2.4211495e-09
epoch 1241: mean loss = 2.093789e-09  learning rate = 2.246707e-05
============================
Start of epoch 1242
step 0: mean loss = 1.3075947e-09
step 100: mean loss = 2.3131719e-09
epoch 1242: mean loss = 2.1187223e-09  learning rate = 2.246707e-05
============================
Start of epoch 1243
step 0: mean loss = 1.4607925e-09
step 100: mean loss = 2.0850062e-09
epoch 1243: mean loss = 1.9748434e-09  learning rate = 2.246707e-05
============================
Start of epoch 1244
step 0: mean loss = 1.6335846e-09
step 100: mean loss = 2.4685582e-09
epoch 1244: mean loss = 2.3481357e-09  learning rate = 2.246707e-05
============================
Start of epoch 1245
step 0: mean loss = 8.543372e-09
step 100: mean loss = 1.6720237e-09
epoch 1245: mean loss = 1.9220088e-09  learning rate = 2.246707e-05
============================
Start of epoch 1246
step 0: mean loss = 1.3585769e-09
step 100: mean loss = 1.8633055e-09
epoch 1246: mean loss = 2.3378746e-09  learning rate = 2.246707e-05
============================
Start of epoch 1247
step 0: mean loss = 2.4536764e-09
step 100: mean loss = 1.8480233e-09
epoch 1247: mean loss = 1.7005927e-09  learning rate = 2.246707e-05
============================
Start of epoch 1248
step 0: mean loss = 1.429271e-09
step 100: mean loss = 1.9841835e-09
epoch 1248: mean loss = 2.0695108e-09  learning rate = 2.246707e-05
============================
Start of epoch 1249
step 0: mean loss = 1.2917667e-09
step 100: mean loss = 2.0184847e-09
epoch 1249: mean loss = 2.2596696e-09  learning rate = 2.246707e-05
============================
Start of epoch 1250
step 0: mean loss = 1.2795011e-09
step 100: mean loss = 2.0245368e-09
epoch 1250: mean loss = 1.906242e-09  learning rate = 2.246707e-05
============================
Start of epoch 1251
step 0: mean loss = 2.3046338e-09
step 100: mean loss = 2.0029862e-09
epoch 1251: mean loss = 2.3198174e-09  learning rate = 2.246707e-05
============================
Start of epoch 1252
step 0: mean loss = 1.7953465e-09
step 100: mean loss = 1.4199424e-09
epoch 1252: mean loss = 1.9275275e-09  learning rate = 2.246707e-05
============================
Start of epoch 1253
step 0: mean loss = 2.929027e-09
step 100: mean loss = 2.0494149e-09
epoch 1253: mean loss = 1.7794571e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1254
step 0: mean loss = 1.2648728e-09
step 100: mean loss = 1.2672671e-09
epoch 1254: mean loss = 1.8058889e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1255
step 0: mean loss = 1.4214793e-09
step 100: mean loss = 1.9201825e-09
epoch 1255: mean loss = 1.6964653e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1256
step 0: mean loss = 1.2891909e-09
step 100: mean loss = 2.0889923e-09
epoch 1256: mean loss = 2.2216855e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1257
step 0: mean loss = 1.3251554e-09
step 100: mean loss = 1.7585496e-09
epoch 1257: mean loss = 2.0041733e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1258
step 0: mean loss = 1.2986638e-09
step 100: mean loss = 2.0573714e-09
epoch 1258: mean loss = 1.7867544e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1259
step 0: mean loss = 1.2848528e-09
step 100: mean loss = 2.5433844e-09
epoch 1259: mean loss = 2.101152e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1260
step 0: mean loss = 1.456901e-09
step 100: mean loss = 1.957152e-09
epoch 1260: mean loss = 1.7728005e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1261
step 0: mean loss = 5.29265e-09
step 100: mean loss = 2.5225384e-09
epoch 1261: mean loss = 2.2269302e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1262
step 0: mean loss = 1.3095817e-09
step 100: mean loss = 1.9951762e-09
epoch 1262: mean loss = 1.9230908e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1263
step 0: mean loss = 1.3088675e-09
step 100: mean loss = 1.9738828e-09
epoch 1263: mean loss = 1.9094446e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1264
step 0: mean loss = 1.5982706e-09
step 100: mean loss = 1.9916655e-09
epoch 1264: mean loss = 2.2798496e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1265
step 0: mean loss = 1.2635142e-09
step 100: mean loss = 1.789292e-09
epoch 1265: mean loss = 1.6160373e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1266
step 0: mean loss = 1.3366224e-09
step 100: mean loss = 2.1492153e-09
epoch 1266: mean loss = 2.0371678e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1267
step 0: mean loss = 1.4543534e-09
step 100: mean loss = 1.994208e-09
epoch 1267: mean loss = 2.0997624e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1268
step 0: mean loss = 1.2647976e-09
step 100: mean loss = 1.8260327e-09
epoch 1268: mean loss = 1.8631563e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1269
step 0: mean loss = 2.4458373e-09
step 100: mean loss = 2.1121098e-09
epoch 1269: mean loss = 2.004619e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1270
step 0: mean loss = 2.9589282e-09
step 100: mean loss = 2.158265e-09
epoch 1270: mean loss = 1.863888e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1271
step 0: mean loss = 1.3132347e-09
step 100: mean loss = 2.311598e-09
epoch 1271: mean loss = 1.9866484e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1272
step 0: mean loss = 1.3058314e-09
step 100: mean loss = 2.1875302e-09
epoch 1272: mean loss = 2.2701916e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1273
step 0: mean loss = 2.1075168e-09
step 100: mean loss = 2.5301319e-09
epoch 1273: mean loss = 2.3040887e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1274
step 0: mean loss = 1.2695862e-09
step 100: mean loss = 1.2606256e-09
epoch 1274: mean loss = 1.7097498e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1275
step 0: mean loss = 1.6310715e-09
step 100: mean loss = 2.1532696e-09
epoch 1275: mean loss = 1.8935167e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1276
step 0: mean loss = 1.4335209e-09
step 100: mean loss = 1.8063648e-09
epoch 1276: mean loss = 1.8535041e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1277
step 0: mean loss = 1.6181556e-09
step 100: mean loss = 2.623845e-09
epoch 1277: mean loss = 2.305915e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1278
step 0: mean loss = 1.2700663e-09
step 100: mean loss = 1.9531623e-09
epoch 1278: mean loss = 1.7236357e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1279
step 0: mean loss = 1.3334035e-09
step 100: mean loss = 1.8798831e-09
epoch 1279: mean loss = 1.9220123e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1280
step 0: mean loss = 1.2574916e-09
step 100: mean loss = 2.297264e-09
epoch 1280: mean loss = 2.0571027e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1281
step 0: mean loss = 7.0735235e-09
step 100: mean loss = 1.8265345e-09
epoch 1281: mean loss = 1.989649e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1282
step 0: mean loss = 1.3067004e-09
step 100: mean loss = 1.8752864e-09
epoch 1282: mean loss = 1.8486439e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1283
step 0: mean loss = 1.2992183e-09
step 100: mean loss = 2.614693e-09
epoch 1283: mean loss = 2.144992e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1284
step 0: mean loss = 1.2621583e-09
step 100: mean loss = 2.1856505e-09
epoch 1284: mean loss = 1.8650974e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1285
step 0: mean loss = 1.2616695e-09
step 100: mean loss = 2.2662057e-09
epoch 1285: mean loss = 2.2661333e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1286
step 0: mean loss = 1.9115907e-09
step 100: mean loss = 1.4853658e-09
epoch 1286: mean loss = 1.8322046e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1287
step 0: mean loss = 1.283827e-09
step 100: mean loss = 1.744198e-09
epoch 1287: mean loss = 1.9376791e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1288
step 0: mean loss = 1.3434435e-09
step 100: mean loss = 2.032733e-09
epoch 1288: mean loss = 1.9692903e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1289
step 0: mean loss = 1.4153891e-09
step 100: mean loss = 2.0976145e-09
epoch 1289: mean loss = 2.195168e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1290
step 0: mean loss = 1.9567687e-09
step 100: mean loss = 1.5116595e-09
epoch 1290: mean loss = 1.8411634e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1291
step 0: mean loss = 1.3197464e-09
step 100: mean loss = 1.9494597e-09
epoch 1291: mean loss = 1.770439e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1292
step 0: mean loss = 4.0913433e-09
step 100: mean loss = 1.9995832e-09
epoch 1292: mean loss = 2.0694926e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1293
step 0: mean loss = 1.3046868e-09
step 100: mean loss = 2.1014392e-09
epoch 1293: mean loss = 2.1246174e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1294
step 0: mean loss = 1.6314372e-09
step 100: mean loss = 2.0483981e-09
epoch 1294: mean loss = 1.8640989e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1295
step 0: mean loss = 2.6409692e-09
step 100: mean loss = 1.7566516e-09
epoch 1295: mean loss = 1.9988786e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1296
step 0: mean loss = 1.3691959e-09
step 100: mean loss = 2.3770939e-09
epoch 1296: mean loss = 1.989892e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1297
step 0: mean loss = 1.2532625e-09
step 100: mean loss = 2.0606588e-09
epoch 1297: mean loss = 1.9064201e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1298
step 0: mean loss = 1.2570424e-09
step 100: mean loss = 1.8974908e-09
epoch 1298: mean loss = 2.2013962e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1299
step 0: mean loss = 1.6624293e-09
step 100: mean loss = 2.3120168e-09
epoch 1299: mean loss = 1.9959103e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1300
step 0: mean loss = 1.2513865e-09
step 100: mean loss = 1.6250022e-09
epoch 1300: mean loss = 1.8309892e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1301
step 0: mean loss = 2.1861493e-09
step 100: mean loss = 1.8200693e-09
epoch 1301: mean loss = 2.0267776e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1302
step 0: mean loss = 2.0809532e-09
step 100: mean loss = 1.8813826e-09
epoch 1302: mean loss = 1.7553506e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1303
step 0: mean loss = 5.5674128e-09
step 100: mean loss = 2.0384825e-09
epoch 1303: mean loss = 2.2184523e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1304
step 0: mean loss = 1.3165957e-09
step 100: mean loss = 1.955209e-09
epoch 1304: mean loss = 1.81125e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1305
step 0: mean loss = 3.765533e-09
step 100: mean loss = 1.9767439e-09
epoch 1305: mean loss = 1.938919e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1306
step 0: mean loss = 1.3275736e-09
step 100: mean loss = 1.9276871e-09
epoch 1306: mean loss = 2.1189634e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1307
step 0: mean loss = 2.1726543e-09
step 100: mean loss = 2.3506534e-09
epoch 1307: mean loss = 1.9958082e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1308
step 0: mean loss = 1.2790906e-09
step 100: mean loss = 2.0250346e-09
epoch 1308: mean loss = 1.766004e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1309
step 0: mean loss = 1.5213157e-09
step 100: mean loss = 2.353973e-09
epoch 1309: mean loss = 2.103546e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1310
step 0: mean loss = 1.3263249e-09
step 100: mean loss = 1.7676118e-09
epoch 1310: mean loss = 2.080438e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1311
step 0: mean loss = 2.1042519e-09
step 100: mean loss = 1.5580421e-09
epoch 1311: mean loss = 2.1146866e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1312
step 0: mean loss = 2.8119878e-09
step 100: mean loss = 2.0558686e-09
epoch 1312: mean loss = 1.8296928e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1313
step 0: mean loss = 1.2531917e-09
step 100: mean loss = 1.819591e-09
epoch 1313: mean loss = 1.754915e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1314
step 0: mean loss = 1.6052414e-09
step 100: mean loss = 2.0791466e-09
epoch 1314: mean loss = 2.260338e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1315
step 0: mean loss = 1.5694884e-09
step 100: mean loss = 1.7320544e-09
epoch 1315: mean loss = 1.5820278e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1316
step 0: mean loss = 1.2514128e-09
step 100: mean loss = 2.2833104e-09
epoch 1316: mean loss = 2.1780844e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1317
step 0: mean loss = 1.3422466e-09
step 100: mean loss = 1.8374997e-09
epoch 1317: mean loss = 2.0276947e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1318
step 0: mean loss = 1.3038967e-09
step 100: mean loss = 1.7059637e-09
epoch 1318: mean loss = 1.9571205e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1319
step 0: mean loss = 1.5744474e-09
step 100: mean loss = 1.6125662e-09
epoch 1319: mean loss = 2.075906e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1320
step 0: mean loss = 1.8657118e-09
step 100: mean loss = 1.8311793e-09
epoch 1320: mean loss = 1.6346022e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1321
step 0: mean loss = 1.2681413e-09
step 100: mean loss = 2.2625641e-09
epoch 1321: mean loss = 2.1168323e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1322
step 0: mean loss = 1.2991191e-09
step 100: mean loss = 1.7038343e-09
epoch 1322: mean loss = 2.1842437e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1323
step 0: mean loss = 2.4078586e-09
step 100: mean loss = 1.3309265e-09
epoch 1323: mean loss = 1.8984339e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1324
step 0: mean loss = 1.3604188e-09
step 100: mean loss = 1.6880908e-09
epoch 1324: mean loss = 1.8289018e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1325
step 0: mean loss = 1.4175577e-09
step 100: mean loss = 1.9742623e-09
epoch 1325: mean loss = 2.0086801e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1326
step 0: mean loss = 1.6162062e-09
step 100: mean loss = 1.966135e-09
epoch 1326: mean loss = 1.7308239e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1327
step 0: mean loss = 2.1364563e-09
step 100: mean loss = 2.340369e-09
epoch 1327: mean loss = 2.0117963e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1328
step 0: mean loss = 1.342122e-09
step 100: mean loss = 1.9660253e-09
epoch 1328: mean loss = 2.0112074e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1329
step 0: mean loss = 1.2916926e-09
step 100: mean loss = 2.0293083e-09
epoch 1329: mean loss = 2.1125677e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1330
step 0: mean loss = 2.3776103e-09
step 100: mean loss = 1.8424235e-09
epoch 1330: mean loss = 1.8414781e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1331
step 0: mean loss = 1.2667641e-09
step 100: mean loss = 2.1409479e-09
epoch 1331: mean loss = 1.8355274e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1332
step 0: mean loss = 1.278151e-09
step 100: mean loss = 2.5462275e-09
epoch 1332: mean loss = 2.1045723e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1333
step 0: mean loss = 1.2808303e-09
step 100: mean loss = 1.8628123e-09
epoch 1333: mean loss = 1.9704525e-09  learning rate = 2.1343712e-05
============================
Start of epoch 1334
step 0: mean loss = 1.4767739e-09
step 100: mean loss = 1.7842895e-09
epoch 1334: mean loss = 1.596461e-09  learning rate = 2.027653e-05
============================
Start of epoch 1335
step 0: mean loss = 1.2440189e-09
step 100: mean loss = 2.1893145e-09
epoch 1335: mean loss = 1.988916e-09  learning rate = 2.027653e-05
============================
Start of epoch 1336
step 0: mean loss = 1.2506157e-09
step 100: mean loss = 1.8993127e-09
epoch 1336: mean loss = 1.7581225e-09  learning rate = 2.027653e-05
============================
Start of epoch 1337
step 0: mean loss = 1.2847216e-09
step 100: mean loss = 1.6435843e-09
epoch 1337: mean loss = 1.8765665e-09  learning rate = 2.027653e-05
============================
Start of epoch 1338
step 0: mean loss = 1.2586828e-09
step 100: mean loss = 1.8178163e-09
epoch 1338: mean loss = 1.7202969e-09  learning rate = 2.027653e-05
============================
Start of epoch 1339
step 0: mean loss = 1.2494376e-09
step 100: mean loss = 2.1620663e-09
epoch 1339: mean loss = 2.1247237e-09  learning rate = 2.027653e-05
============================
Start of epoch 1340
step 0: mean loss = 1.5367647e-09
step 100: mean loss = 2.0192141e-09
epoch 1340: mean loss = 1.8399953e-09  learning rate = 2.027653e-05
============================
Start of epoch 1341
step 0: mean loss = 1.6047628e-09
step 100: mean loss = 1.9333677e-09
epoch 1341: mean loss = 1.9558197e-09  learning rate = 2.027653e-05
============================
Start of epoch 1342
step 0: mean loss = 1.844543e-09
step 100: mean loss = 2.02368e-09
epoch 1342: mean loss = 1.7824514e-09  learning rate = 2.027653e-05
============================
Start of epoch 1343
step 0: mean loss = 1.2544423e-09
step 100: mean loss = 2.139397e-09
epoch 1343: mean loss = 1.9770157e-09  learning rate = 2.027653e-05
============================
Start of epoch 1344
step 0: mean loss = 6.2234937e-09
step 100: mean loss = 1.6446832e-09
epoch 1344: mean loss = 1.8015647e-09  learning rate = 2.027653e-05
============================
Start of epoch 1345
step 0: mean loss = 1.4331758e-09
step 100: mean loss = 1.733021e-09
epoch 1345: mean loss = 2.015093e-09  learning rate = 2.027653e-05
============================
Start of epoch 1346
step 0: mean loss = 1.8065367e-09
step 100: mean loss = 2.1317088e-09
epoch 1346: mean loss = 1.8242393e-09  learning rate = 2.027653e-05
============================
Start of epoch 1347
step 0: mean loss = 1.2394697e-09
step 100: mean loss = 2.2636e-09
epoch 1347: mean loss = 1.921295e-09  learning rate = 2.027653e-05
============================
Start of epoch 1348
step 0: mean loss = 1.4161183e-09
step 100: mean loss = 1.6527308e-09
epoch 1348: mean loss = 1.7298418e-09  learning rate = 2.027653e-05
============================
Start of epoch 1349
step 0: mean loss = 1.4243449e-09
step 100: mean loss = 1.8764688e-09
epoch 1349: mean loss = 1.9213446e-09  learning rate = 2.027653e-05
============================
Start of epoch 1350
step 0: mean loss = 1.5122492e-09
step 100: mean loss = 2.3305495e-09
epoch 1350: mean loss = 2.0461186e-09  learning rate = 2.027653e-05
============================
Start of epoch 1351
step 0: mean loss = 1.2432779e-09
step 100: mean loss = 1.7686015e-09
epoch 1351: mean loss = 1.6881536e-09  learning rate = 2.027653e-05
============================
Start of epoch 1352
step 0: mean loss = 3.9779264e-09
step 100: mean loss = 2.0386146e-09
epoch 1352: mean loss = 2.0050848e-09  learning rate = 2.027653e-05
============================
Start of epoch 1353
step 0: mean loss = 1.341066e-09
step 100: mean loss = 1.8250967e-09
epoch 1353: mean loss = 1.8241563e-09  learning rate = 2.027653e-05
============================
Start of epoch 1354
step 0: mean loss = 1.4605155e-09
step 100: mean loss = 2.1606534e-09
epoch 1354: mean loss = 1.8530463e-09  learning rate = 2.027653e-05
============================
Start of epoch 1355
step 0: mean loss = 1.3030502e-09
step 100: mean loss = 1.9079112e-09
epoch 1355: mean loss = 2.0042912e-09  learning rate = 2.027653e-05
============================
Start of epoch 1356
step 0: mean loss = 1.4448949e-09
step 100: mean loss = 1.8505835e-09
epoch 1356: mean loss = 1.885879e-09  learning rate = 2.027653e-05
============================
Start of epoch 1357
step 0: mean loss = 1.5530148e-09
step 100: mean loss = 2.1717854e-09
epoch 1357: mean loss = 1.8850623e-09  learning rate = 2.027653e-05
============================
Start of epoch 1358
step 0: mean loss = 1.557259e-09
step 100: mean loss = 1.7426993e-09
epoch 1358: mean loss = 1.9650088e-09  learning rate = 2.027653e-05
============================
Start of epoch 1359
step 0: mean loss = 1.5888207e-09
step 100: mean loss = 1.9059956e-09
epoch 1359: mean loss = 1.8587243e-09  learning rate = 2.027653e-05
============================
Start of epoch 1360
step 0: mean loss = 1.2685559e-09
step 100: mean loss = 1.7225303e-09
epoch 1360: mean loss = 1.6408089e-09  learning rate = 2.027653e-05
============================
Start of epoch 1361
step 0: mean loss = 8.00247e-09
step 100: mean loss = 2.3917217e-09
epoch 1361: mean loss = 1.9934072e-09  learning rate = 2.027653e-05
============================
Start of epoch 1362
step 0: mean loss = 1.6442879e-09
step 100: mean loss = 2.3892301e-09
epoch 1362: mean loss = 1.9893565e-09  learning rate = 2.027653e-05
============================
Start of epoch 1363
step 0: mean loss = 1.2344884e-09
step 100: mean loss = 2.1505957e-09
epoch 1363: mean loss = 1.8418874e-09  learning rate = 2.027653e-05
============================
Start of epoch 1364
step 0: mean loss = 1.4444913e-09
step 100: mean loss = 1.892185e-09
epoch 1364: mean loss = 1.9408783e-09  learning rate = 2.027653e-05
============================
Start of epoch 1365
step 0: mean loss = 1.2646498e-09
step 100: mean loss = 1.9327824e-09
epoch 1365: mean loss = 1.919885e-09  learning rate = 2.027653e-05
============================
Start of epoch 1366
step 0: mean loss = 1.2579151e-09
step 100: mean loss = 1.9286155e-09
epoch 1366: mean loss = 1.7981343e-09  learning rate = 2.027653e-05
============================
Start of epoch 1367
step 0: mean loss = 7.3477464e-09
step 100: mean loss = 2.1005928e-09
epoch 1367: mean loss = 1.8882216e-09  learning rate = 2.027653e-05
============================
Start of epoch 1368
step 0: mean loss = 1.2450602e-09
step 100: mean loss = 2.109937e-09
epoch 1368: mean loss = 1.8660007e-09  learning rate = 2.027653e-05
============================
Start of epoch 1369
step 0: mean loss = 1.2795156e-09
step 100: mean loss = 1.9725643e-09
epoch 1369: mean loss = 2.0024251e-09  learning rate = 2.027653e-05
============================
Start of epoch 1370
step 0: mean loss = 1.2554131e-09
step 100: mean loss = 1.857562e-09
epoch 1370: mean loss = 1.9251254e-09  learning rate = 2.027653e-05
============================
Start of epoch 1371
step 0: mean loss = 2.636276e-09
step 100: mean loss = 1.9219641e-09
epoch 1371: mean loss = 1.69879e-09  learning rate = 2.027653e-05
============================
Start of epoch 1372
step 0: mean loss = 1.2394861e-09
step 100: mean loss = 2.22084e-09
epoch 1372: mean loss = 2.1687248e-09  learning rate = 2.027653e-05
============================
Start of epoch 1373
step 0: mean loss = 1.90548e-09
step 100: mean loss = 1.8205073e-09
epoch 1373: mean loss = 1.6967163e-09  learning rate = 2.027653e-05
============================
Start of epoch 1374
step 0: mean loss = 1.2489645e-09
step 100: mean loss = 1.762862e-09
epoch 1374: mean loss = 1.7928096e-09  learning rate = 2.027653e-05
============================
Start of epoch 1375
step 0: mean loss = 1.4551914e-09
step 100: mean loss = 1.9288853e-09
epoch 1375: mean loss = 2.0173783e-09  learning rate = 2.027653e-05
============================
Start of epoch 1376
step 0: mean loss = 1.256636e-09
step 100: mean loss = 1.9565785e-09
epoch 1376: mean loss = 2.0203914e-09  learning rate = 2.027653e-05
============================
Start of epoch 1377
step 0: mean loss = 1.8677198e-09
step 100: mean loss = 1.8789874e-09
epoch 1377: mean loss = 1.8638942e-09  learning rate = 2.027653e-05
============================
Start of epoch 1378
step 0: mean loss = 1.2532928e-09
step 100: mean loss = 1.7930503e-09
epoch 1378: mean loss = 1.6029779e-09  learning rate = 2.027653e-05
============================
Start of epoch 1379
step 0: mean loss = 1.3771505e-09
step 100: mean loss = 2.0750608e-09
epoch 1379: mean loss = 2.0327435e-09  learning rate = 2.027653e-05
============================
Start of epoch 1380
step 0: mean loss = 1.2525447e-09
step 100: mean loss = 2.099144e-09
epoch 1380: mean loss = 1.8033349e-09  learning rate = 2.027653e-05
============================
Start of epoch 1381
step 0: mean loss = 1.3027536e-09
step 100: mean loss = 1.8433353e-09
epoch 1381: mean loss = 2.091237e-09  learning rate = 2.027653e-05
============================
Start of epoch 1382
step 0: mean loss = 1.271858e-09
step 100: mean loss = 1.8096603e-09
epoch 1382: mean loss = 1.6671525e-09  learning rate = 2.027653e-05
============================
Start of epoch 1383
step 0: mean loss = 4.749195e-09
step 100: mean loss = 2.1106519e-09
epoch 1383: mean loss = 2.0055608e-09  learning rate = 2.027653e-05
============================
Start of epoch 1384
step 0: mean loss = 1.2465411e-09
step 100: mean loss = 1.8004053e-09
epoch 1384: mean loss = 1.820848e-09  learning rate = 2.027653e-05
============================
Start of epoch 1385
step 0: mean loss = 1.2839565e-09
step 100: mean loss = 1.9413817e-09
epoch 1385: mean loss = 1.91582e-09  learning rate = 2.027653e-05
============================
Start of epoch 1386
step 0: mean loss = 1.2762222e-09
step 100: mean loss = 1.7224315e-09
epoch 1386: mean loss = 2.0789581e-09  learning rate = 2.027653e-05
============================
Start of epoch 1387
step 0: mean loss = 1.5787981e-09
step 100: mean loss = 1.6722898e-09
epoch 1387: mean loss = 1.5728684e-09  learning rate = 2.027653e-05
============================
Start of epoch 1388
step 0: mean loss = 2.3084232e-09
step 100: mean loss = 2.329742e-09
epoch 1388: mean loss = 1.9539437e-09  learning rate = 2.027653e-05
============================
Start of epoch 1389
step 0: mean loss = 1.2650999e-09
step 100: mean loss = 2.0725852e-09
epoch 1389: mean loss = 1.8036929e-09  learning rate = 2.027653e-05
============================
Start of epoch 1390
step 0: mean loss = 2.4362896e-09
step 100: mean loss = 1.9719884e-09
epoch 1390: mean loss = 1.9733997e-09  learning rate = 2.027653e-05
============================
Start of epoch 1391
step 0: mean loss = 1.2501761e-09
step 100: mean loss = 1.8234695e-09
epoch 1391: mean loss = 1.8400037e-09  learning rate = 2.027653e-05
============================
Start of epoch 1392
step 0: mean loss = 1.5586598e-09
step 100: mean loss = 1.9465074e-09
epoch 1392: mean loss = 2.098661e-09  learning rate = 2.027653e-05
============================
Start of epoch 1393
step 0: mean loss = 1.2600561e-09
step 100: mean loss = 1.7951927e-09
epoch 1393: mean loss = 1.6917904e-09  learning rate = 2.027653e-05
============================
Start of epoch 1394
step 0: mean loss = 1.4338971e-09
step 100: mean loss = 1.9921347e-09
epoch 1394: mean loss = 1.9590345e-09  learning rate = 2.027653e-05
============================
Start of epoch 1395
step 0: mean loss = 1.399565e-09
step 100: mean loss = 1.7593845e-09
epoch 1395: mean loss = 1.8126362e-09  learning rate = 2.027653e-05
============================
Start of epoch 1396
step 0: mean loss = 3.3561478e-09
step 100: mean loss = 2.1034274e-09
epoch 1396: mean loss = 2.0341748e-09  learning rate = 2.027653e-05
============================
Start of epoch 1397
step 0: mean loss = 1.4511055e-09
step 100: mean loss = 1.8066997e-09
epoch 1397: mean loss = 1.6278962e-09  learning rate = 2.027653e-05
============================
Start of epoch 1398
step 0: mean loss = 1.4745574e-09
step 100: mean loss = 2.1232713e-09
epoch 1398: mean loss = 1.9394264e-09  learning rate = 2.027653e-05
============================
Start of epoch 1399
step 0: mean loss = 3.1237604e-09
step 100: mean loss = 2.0810889e-09
epoch 1399: mean loss = 1.9118773e-09  learning rate = 2.027653e-05
============================
Start of epoch 1400
step 0: mean loss = 1.2358525e-09
step 100: mean loss = 2.0086588e-09
epoch 1400: mean loss = 1.7436536e-09  learning rate = 2.027653e-05
============================
Start of epoch 1401
step 0: mean loss = 1.3715191e-09
step 100: mean loss = 2.493425e-09
epoch 1401: mean loss = 2.070828e-09  learning rate = 2.027653e-05
============================
Start of epoch 1402
step 0: mean loss = 1.2644809e-09
step 100: mean loss = 1.7284022e-09
epoch 1402: mean loss = 1.7936364e-09  learning rate = 2.027653e-05
============================
Start of epoch 1403
step 0: mean loss = 1.2940979e-09
step 100: mean loss = 2.1821327e-09
epoch 1403: mean loss = 1.8749673e-09  learning rate = 2.027653e-05
============================
Start of epoch 1404
step 0: mean loss = 2.0415842e-09
step 100: mean loss = 1.6314581e-09
epoch 1404: mean loss = 2.1240327e-09  learning rate = 2.027653e-05
============================
Start of epoch 1405
step 0: mean loss = 1.2823108e-09
step 100: mean loss = 1.433637e-09
epoch 1405: mean loss = 1.5973409e-09  learning rate = 2.027653e-05
============================
Start of epoch 1406
step 0: mean loss = 1.3236908e-09
step 100: mean loss = 2.0086421e-09
epoch 1406: mean loss = 1.9040567e-09  learning rate = 2.027653e-05
============================
Start of epoch 1407
step 0: mean loss = 2.1858184e-09
step 100: mean loss = 2.2287423e-09
epoch 1407: mean loss = 1.8978044e-09  learning rate = 2.027653e-05
============================
Start of epoch 1408
step 0: mean loss = 1.2383135e-09
step 100: mean loss = 1.7646413e-09
epoch 1408: mean loss = 2.066039e-09  learning rate = 2.027653e-05
============================
Start of epoch 1409
step 0: mean loss = 2.0574649e-09
step 100: mean loss = 1.5998718e-09
epoch 1409: mean loss = 1.7193145e-09  learning rate = 2.027653e-05
============================
Start of epoch 1410
step 0: mean loss = 2.6342895e-09
step 100: mean loss = 2.2096573e-09
epoch 1410: mean loss = 1.9078208e-09  learning rate = 2.027653e-05
============================
Start of epoch 1411
step 0: mean loss = 1.2227238e-09
step 100: mean loss = 1.8694097e-09
epoch 1411: mean loss = 1.7312302e-09  learning rate = 2.027653e-05
============================
Start of epoch 1412
step 0: mean loss = 2.8210438e-09
step 100: mean loss = 2.0459914e-09
epoch 1412: mean loss = 1.8002787e-09  learning rate = 2.027653e-05
============================
Start of epoch 1413
step 0: mean loss = 1.4805847e-09
step 100: mean loss = 2.0683129e-09
epoch 1413: mean loss = 1.9569792e-09  learning rate = 2.027653e-05
============================
Start of epoch 1414
step 0: mean loss = 1.619776e-09
step 100: mean loss = 2.1095083e-09
epoch 1414: mean loss = 1.9437698e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1415
step 0: mean loss = 1.2471751e-09
step 100: mean loss = 1.2363991e-09
epoch 1415: mean loss = 1.533992e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1416
step 0: mean loss = 2.4586226e-09
step 100: mean loss = 1.5741723e-09
epoch 1416: mean loss = 1.5095871e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1417
step 0: mean loss = 1.3604464e-09
step 100: mean loss = 2.1843258e-09
epoch 1417: mean loss = 2.059951e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1418
step 0: mean loss = 6.72296e-09
step 100: mean loss = 1.5277315e-09
epoch 1418: mean loss = 1.8741142e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1419
step 0: mean loss = 1.3528045e-09
step 100: mean loss = 1.5088681e-09
epoch 1419: mean loss = 1.5345334e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1420
step 0: mean loss = 1.4577382e-09
step 100: mean loss = 1.8846102e-09
epoch 1420: mean loss = 2.1897906e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1421
step 0: mean loss = 1.2345249e-09
step 100: mean loss = 1.461092e-09
epoch 1421: mean loss = 1.4973102e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1422
step 0: mean loss = 1.9925053e-09
step 100: mean loss = 1.9461e-09
epoch 1422: mean loss = 1.8427934e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1423
step 0: mean loss = 1.0123517e-08
step 100: mean loss = 1.920257e-09
epoch 1423: mean loss = 1.9347874e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1424
step 0: mean loss = 1.4546799e-09
step 100: mean loss = 1.5602536e-09
epoch 1424: mean loss = 1.6589023e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1425
step 0: mean loss = 3.348111e-09
step 100: mean loss = 1.8315328e-09
epoch 1425: mean loss = 1.8391697e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1426
step 0: mean loss = 1.2343674e-09
step 100: mean loss = 1.899375e-09
epoch 1426: mean loss = 1.7496469e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1427
step 0: mean loss = 1.6642261e-09
step 100: mean loss = 1.8853852e-09
epoch 1427: mean loss = 1.893859e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1428
step 0: mean loss = 1.3199235e-09
step 100: mean loss = 1.783058e-09
epoch 1428: mean loss = 1.8304442e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1429
step 0: mean loss = 1.9845736e-09
step 100: mean loss = 1.6390156e-09
epoch 1429: mean loss = 1.6716462e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1430
step 0: mean loss = 1.3989799e-09
step 100: mean loss = 1.7741003e-09
epoch 1430: mean loss = 1.8190155e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1431
step 0: mean loss = 1.3035989e-09
step 100: mean loss = 1.6947139e-09
epoch 1431: mean loss = 1.878841e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1432
step 0: mean loss = 1.2571476e-09
step 100: mean loss = 1.6145566e-09
epoch 1432: mean loss = 1.9870932e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1433
step 0: mean loss = 3.0475844e-09
step 100: mean loss = 1.5241188e-09
epoch 1433: mean loss = 1.6814691e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1434
step 0: mean loss = 1.2305528e-09
step 100: mean loss = 1.8937487e-09
epoch 1434: mean loss = 1.6843704e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1435
step 0: mean loss = 1.2177708e-09
step 100: mean loss = 2.0181425e-09
epoch 1435: mean loss = 1.9560944e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1436
step 0: mean loss = 1.3508255e-09
step 100: mean loss = 1.7887638e-09
epoch 1436: mean loss = 1.6420477e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1437
step 0: mean loss = 2.9322147e-09
step 100: mean loss = 1.9419053e-09
epoch 1437: mean loss = 1.8004956e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1438
step 0: mean loss = 1.3865042e-09
step 100: mean loss = 1.7261469e-09
epoch 1438: mean loss = 1.780194e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1439
step 0: mean loss = 1.7323828e-09
step 100: mean loss = 1.7936509e-09
epoch 1439: mean loss = 1.964391e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1440
step 0: mean loss = 1.2684428e-09
step 100: mean loss = 1.7162688e-09
epoch 1440: mean loss = 1.5621734e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1441
step 0: mean loss = 1.3897311e-09
step 100: mean loss = 2.2498317e-09
epoch 1441: mean loss = 1.9150237e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1442
step 0: mean loss = 1.2484898e-09
step 100: mean loss = 1.9253728e-09
epoch 1442: mean loss = 1.7778812e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1443
step 0: mean loss = 4.9755133e-09
step 100: mean loss = 1.8212885e-09
epoch 1443: mean loss = 1.7147194e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1444
step 0: mean loss = 2.657839e-09
step 100: mean loss = 1.9403525e-09
epoch 1444: mean loss = 1.98483e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1445
step 0: mean loss = 1.2453865e-09
step 100: mean loss = 2.064335e-09
epoch 1445: mean loss = 1.7777424e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1446
step 0: mean loss = 1.3460931e-09
step 100: mean loss = 1.6163665e-09
epoch 1446: mean loss = 2.0934394e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1447
step 0: mean loss = 2.0889672e-09
step 100: mean loss = 1.6889782e-09
epoch 1447: mean loss = 1.5833183e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1448
step 0: mean loss = 1.2618725e-09
step 100: mean loss = 1.6642264e-09
epoch 1448: mean loss = 1.7105353e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1449
step 0: mean loss = 6.2047576e-09
step 100: mean loss = 2.1731714e-09
epoch 1449: mean loss = 1.9089548e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1450
step 0: mean loss = 1.2254233e-09
step 100: mean loss = 1.5950193e-09
epoch 1450: mean loss = 1.9310011e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1451
step 0: mean loss = 3.7074621e-09
step 100: mean loss = 1.4391239e-09
epoch 1451: mean loss = 1.6289393e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1452
step 0: mean loss = 1.2619935e-09
step 100: mean loss = 1.7605882e-09
epoch 1452: mean loss = 1.6952995e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1453
step 0: mean loss = 1.3539742e-09
step 100: mean loss = 1.8324411e-09
epoch 1453: mean loss = 1.7954157e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1454
step 0: mean loss = 1.584244e-09
step 100: mean loss = 2.010532e-09
epoch 1454: mean loss = 1.8478264e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1455
step 0: mean loss = 1.6333638e-09
step 100: mean loss = 1.7366913e-09
epoch 1455: mean loss = 1.7084182e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1456
step 0: mean loss = 1.2408711e-09
step 100: mean loss = 1.9185211e-09
epoch 1456: mean loss = 1.8434579e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1457
step 0: mean loss = 2.6303182e-09
step 100: mean loss = 1.9437425e-09
epoch 1457: mean loss = 1.7457517e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1458
step 0: mean loss = 3.0085168e-09
step 100: mean loss = 1.746794e-09
epoch 1458: mean loss = 2.000938e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1459
step 0: mean loss = 1.2438879e-09
step 100: mean loss = 1.5841983e-09
epoch 1459: mean loss = 1.8017369e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1460
step 0: mean loss = 1.4062596e-09
step 100: mean loss = 1.426022e-09
epoch 1460: mean loss = 1.7495121e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1461
step 0: mean loss = 1.5474828e-09
step 100: mean loss = 1.5588677e-09
epoch 1461: mean loss = 1.6640429e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1462
step 0: mean loss = 1.4890267e-09
step 100: mean loss = 1.7439298e-09
epoch 1462: mean loss = 1.8728805e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1463
step 0: mean loss = 1.2275262e-09
step 100: mean loss = 1.6496153e-09
epoch 1463: mean loss = 1.8409333e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1464
step 0: mean loss = 1.2579452e-09
step 100: mean loss = 2.0949278e-09
epoch 1464: mean loss = 1.8141507e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1465
step 0: mean loss = 1.2411518e-09
step 100: mean loss = 1.5661935e-09
epoch 1465: mean loss = 1.7946691e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1466
step 0: mean loss = 1.3513305e-09
step 100: mean loss = 1.8370294e-09
epoch 1466: mean loss = 1.624207e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1467
step 0: mean loss = 1.411591e-09
step 100: mean loss = 1.824849e-09
epoch 1467: mean loss = 1.9106985e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1468
step 0: mean loss = 1.2581607e-09
step 100: mean loss = 1.9664115e-09
epoch 1468: mean loss = 1.723061e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1469
step 0: mean loss = 1.6650636e-09
step 100: mean loss = 1.9693804e-09
epoch 1469: mean loss = 1.918626e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1470
step 0: mean loss = 1.4874693e-09
step 100: mean loss = 1.6173006e-09
epoch 1470: mean loss = 1.9205095e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1471
step 0: mean loss = 1.6651482e-09
step 100: mean loss = 1.6444297e-09
epoch 1471: mean loss = 1.5906338e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1472
step 0: mean loss = 4.0991472e-09
step 100: mean loss = 1.8322899e-09
epoch 1472: mean loss = 1.7494886e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1473
step 0: mean loss = 3.6323862e-09
step 100: mean loss = 1.7712555e-09
epoch 1473: mean loss = 2.2625646e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1474
step 0: mean loss = 1.8606738e-09
step 100: mean loss = 1.3361517e-09
epoch 1474: mean loss = 1.875688e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1475
step 0: mean loss = 1.3188028e-09
step 100: mean loss = 1.2190865e-09
epoch 1475: mean loss = 1.4367653e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1476
step 0: mean loss = 3.7322834e-09
step 100: mean loss = 1.7225918e-09
epoch 1476: mean loss = 1.6573608e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1477
step 0: mean loss = 4.5943467e-09
step 100: mean loss = 1.9772481e-09
epoch 1477: mean loss = 1.7916992e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1478
step 0: mean loss = 4.0046775e-09
step 100: mean loss = 2.0616198e-09
epoch 1478: mean loss = 1.8332672e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1479
step 0: mean loss = 1.6011871e-09
step 100: mean loss = 1.8572681e-09
epoch 1479: mean loss = 1.8535409e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1480
step 0: mean loss = 2.0069741e-09
step 100: mean loss = 1.7198427e-09
epoch 1480: mean loss = 1.6765423e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1481
step 0: mean loss = 1.3588901e-09
step 100: mean loss = 2.0399853e-09
epoch 1481: mean loss = 1.8141704e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1482
step 0: mean loss = 2.5856537e-09
step 100: mean loss = 2.1761148e-09
epoch 1482: mean loss = 1.8848805e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1483
step 0: mean loss = 1.2088606e-09
step 100: mean loss = 1.5309602e-09
epoch 1483: mean loss = 1.871207e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1484
step 0: mean loss = 1.397678e-09
step 100: mean loss = 1.91162e-09
epoch 1484: mean loss = 1.680886e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1485
step 0: mean loss = 1.2645114e-09
step 100: mean loss = 1.9537503e-09
epoch 1485: mean loss = 1.6966331e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1486
step 0: mean loss = 1.3140542e-09
step 100: mean loss = 1.8970931e-09
epoch 1486: mean loss = 1.8145696e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1487
step 0: mean loss = 1.4919282e-09
step 100: mean loss = 2.4991293e-09
epoch 1487: mean loss = 2.0501425e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1488
step 0: mean loss = 1.21004e-09
step 100: mean loss = 1.8795485e-09
epoch 1488: mean loss = 1.6718722e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1489
step 0: mean loss = 1.2231667e-09
step 100: mean loss = 1.7367947e-09
epoch 1489: mean loss = 1.891355e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1490
step 0: mean loss = 1.2161047e-09
step 100: mean loss = 1.8474821e-09
epoch 1490: mean loss = 1.6816231e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1491
step 0: mean loss = 1.213603e-09
step 100: mean loss = 1.7538986e-09
epoch 1491: mean loss = 1.9305315e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1492
step 0: mean loss = 1.3133632e-09
step 100: mean loss = 2.0325472e-09
epoch 1492: mean loss = 1.8390054e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1493
step 0: mean loss = 1.2083586e-09
step 100: mean loss = 1.6326495e-09
epoch 1493: mean loss = 1.5905276e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1494
step 0: mean loss = 4.8842277e-09
step 100: mean loss = 1.962584e-09
epoch 1494: mean loss = 1.8565882e-09  learning rate = 1.9262703e-05
============================
Start of epoch 1495
step 0: mean loss = 6.132025e-09
step 100: mean loss = 1.5213563e-09
epoch 1495: mean loss = 1.4267849e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1496
step 0: mean loss = 1.3155369e-09
step 100: mean loss = 1.4115105e-09
epoch 1496: mean loss = 1.8275235e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1497
step 0: mean loss = 1.2170028e-09
step 100: mean loss = 1.7976527e-09
epoch 1497: mean loss = 1.6022502e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1498
step 0: mean loss = 1.2223778e-09
step 100: mean loss = 1.729512e-09
epoch 1498: mean loss = 1.7476465e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1499
step 0: mean loss = 1.7690652e-09
step 100: mean loss = 1.6818558e-09
epoch 1499: mean loss = 2.0256008e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1500
step 0: mean loss = 2.9559373e-09
step 100: mean loss = 1.578498e-09
epoch 1500: mean loss = 1.4508047e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1501
step 0: mean loss = 1.277239e-09
step 100: mean loss = 1.6298494e-09
epoch 1501: mean loss = 1.7830162e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1502
step 0: mean loss = 1.9190873e-09
step 100: mean loss = 1.740548e-09
epoch 1502: mean loss = 1.7269522e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1503
step 0: mean loss = 1.3808102e-09
step 100: mean loss = 1.5778987e-09
epoch 1503: mean loss = 1.9159612e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1504
step 0: mean loss = 1.7009053e-09
step 100: mean loss = 1.5464148e-09
epoch 1504: mean loss = 1.4731684e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1505
step 0: mean loss = 1.2086889e-09
step 100: mean loss = 1.5965224e-09
epoch 1505: mean loss = 1.6818691e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1506
step 0: mean loss = 1.4304925e-09
step 100: mean loss = 1.8052848e-09
epoch 1506: mean loss = 1.83734e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1507
step 0: mean loss = 1.5753855e-09
step 100: mean loss = 1.5020768e-09
epoch 1507: mean loss = 1.7709717e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1508
step 0: mean loss = 1.5698469e-09
step 100: mean loss = 1.5038111e-09
epoch 1508: mean loss = 1.6065588e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1509
step 0: mean loss = 1.221626e-09
step 100: mean loss = 1.6245661e-09
epoch 1509: mean loss = 1.7315352e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1510
step 0: mean loss = 1.2085505e-09
step 100: mean loss = 1.8032991e-09
epoch 1510: mean loss = 1.6113122e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1511
step 0: mean loss = 1.6635003e-09
step 100: mean loss = 1.9069044e-09
epoch 1511: mean loss = 1.7622346e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1512
step 0: mean loss = 1.2231287e-09
step 100: mean loss = 1.8356896e-09
epoch 1512: mean loss = 1.9148994e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1513
step 0: mean loss = 1.3356994e-09
step 100: mean loss = 1.6486593e-09
epoch 1513: mean loss = 1.507423e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1514
step 0: mean loss = 1.2828992e-09
step 100: mean loss = 2.111029e-09
epoch 1514: mean loss = 1.8564147e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1515
step 0: mean loss = 1.2018976e-09
step 100: mean loss = 1.6649773e-09
epoch 1515: mean loss = 1.7007756e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1516
step 0: mean loss = 1.3520051e-09
step 100: mean loss = 1.5202335e-09
epoch 1516: mean loss = 1.9611195e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1517
step 0: mean loss = 1.3691104e-09
step 100: mean loss = 1.3093564e-09
epoch 1517: mean loss = 1.544033e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1518
step 0: mean loss = 1.2424226e-09
step 100: mean loss = 1.581456e-09
epoch 1518: mean loss = 1.7267986e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1519
step 0: mean loss = 1.2132989e-09
step 100: mean loss = 1.4852259e-09
epoch 1519: mean loss = 1.884374e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1520
step 0: mean loss = 1.2445005e-09
step 100: mean loss = 1.459781e-09
epoch 1520: mean loss = 1.5679722e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1521
step 0: mean loss = 1.3255462e-09
step 100: mean loss = 1.8793846e-09
epoch 1521: mean loss = 1.7265009e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1522
step 0: mean loss = 1.9708215e-09
step 100: mean loss = 1.7742796e-09
epoch 1522: mean loss = 1.8740725e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1523
step 0: mean loss = 1.2623055e-09
step 100: mean loss = 1.504419e-09
epoch 1523: mean loss = 1.4255578e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1524
step 0: mean loss = 1.363401e-09
step 100: mean loss = 2.0424706e-09
epoch 1524: mean loss = 1.8529263e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1525
step 0: mean loss = 1.2216941e-09
step 100: mean loss = 1.9798825e-09
epoch 1525: mean loss = 1.7151858e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1526
step 0: mean loss = 1.2339558e-09
step 100: mean loss = 1.7582685e-09
epoch 1526: mean loss = 1.8281026e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1527
step 0: mean loss = 1.3302821e-09
step 100: mean loss = 1.5573037e-09
epoch 1527: mean loss = 1.7596066e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1528
step 0: mean loss = 1.8163739e-09
step 100: mean loss = 1.7711488e-09
epoch 1528: mean loss = 1.5774276e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1529
step 0: mean loss = 1.2082819e-09
step 100: mean loss = 1.6895216e-09
epoch 1529: mean loss = 1.7742927e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1530
step 0: mean loss = 1.2916175e-09
step 100: mean loss = 1.4976193e-09
epoch 1530: mean loss = 1.9042925e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1531
step 0: mean loss = 1.2239996e-09
step 100: mean loss = 1.3976402e-09
epoch 1531: mean loss = 1.4893636e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1532
step 0: mean loss = 1.4688877e-09
step 100: mean loss = 1.8130217e-09
epoch 1532: mean loss = 1.8738207e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1533
step 0: mean loss = 3.2664145e-09
step 100: mean loss = 1.4096511e-09
epoch 1533: mean loss = 1.615893e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1534
step 0: mean loss = 1.2077944e-09
step 100: mean loss = 1.744714e-09
epoch 1534: mean loss = 1.6207513e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1535
step 0: mean loss = 1.7745075e-09
step 100: mean loss = 2.0322755e-09
epoch 1535: mean loss = 1.7583454e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1536
step 0: mean loss = 1.3728584e-09
step 100: mean loss = 1.7903135e-09
epoch 1536: mean loss = 1.8109736e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1537
step 0: mean loss = 2.6838916e-09
step 100: mean loss = 1.5190086e-09
epoch 1537: mean loss = 1.7386621e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1538
step 0: mean loss = 1.2881304e-09
step 100: mean loss = 1.4941028e-09
epoch 1538: mean loss = 1.8581306e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1539
step 0: mean loss = 1.5664593e-09
step 100: mean loss = 1.5928843e-09
epoch 1539: mean loss = 1.4848277e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1540
step 0: mean loss = 1.3153432e-09
step 100: mean loss = 1.6827654e-09
epoch 1540: mean loss = 1.8049333e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1541
step 0: mean loss = 1.2563492e-09
step 100: mean loss = 1.5346495e-09
epoch 1541: mean loss = 1.7591221e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1542
step 0: mean loss = 1.3115462e-09
step 100: mean loss = 1.8654591e-09
epoch 1542: mean loss = 1.7278801e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1543
step 0: mean loss = 1.4270967e-09
step 100: mean loss = 1.8489758e-09
epoch 1543: mean loss = 1.7529291e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1544
step 0: mean loss = 1.1985855e-09
step 100: mean loss = 1.4592062e-09
epoch 1544: mean loss = 1.6616533e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1545
step 0: mean loss = 1.2921672e-09
step 100: mean loss = 2.0292077e-09
epoch 1545: mean loss = 1.743328e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1546
step 0: mean loss = 1.2199094e-09
step 100: mean loss = 1.7014475e-09
epoch 1546: mean loss = 1.6067015e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1547
step 0: mean loss = 4.698522e-09
step 100: mean loss = 1.6942139e-09
epoch 1547: mean loss = 1.8145128e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1548
step 0: mean loss = 1.3804446e-09
step 100: mean loss = 1.6513598e-09
epoch 1548: mean loss = 1.6337103e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1549
step 0: mean loss = 1.3757164e-09
step 100: mean loss = 1.7031346e-09
epoch 1549: mean loss = 2.0788695e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1550
step 0: mean loss = 2.0117998e-09
step 100: mean loss = 1.4623154e-09
epoch 1550: mean loss = 1.4423499e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1551
step 0: mean loss = 1.1927568e-09
step 100: mean loss = 2.0246176e-09
epoch 1551: mean loss = 1.7738129e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1552
step 0: mean loss = 1.1897909e-09
step 100: mean loss = 1.7183569e-09
epoch 1552: mean loss = 1.7705509e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1553
step 0: mean loss = 5.8359593e-09
step 100: mean loss = 1.5079618e-09
epoch 1553: mean loss = 1.7441427e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1554
step 0: mean loss = 1.196889e-09
step 100: mean loss = 1.5765166e-09
epoch 1554: mean loss = 1.4650802e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1555
step 0: mean loss = 2.0993816e-09
step 100: mean loss = 2.0674955e-09
epoch 1555: mean loss = 1.7798102e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1556
step 0: mean loss = 1.2220464e-09
step 100: mean loss = 1.8157055e-09
epoch 1556: mean loss = 1.8547762e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1557
step 0: mean loss = 1.2609322e-09
step 100: mean loss = 1.6920291e-09
epoch 1557: mean loss = 1.6271468e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1558
step 0: mean loss = 4.7177284e-09
step 100: mean loss = 1.7278073e-09
epoch 1558: mean loss = 1.8091701e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1559
step 0: mean loss = 1.6329063e-09
step 100: mean loss = 1.4350089e-09
epoch 1559: mean loss = 1.9109927e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1560
step 0: mean loss = 1.55521e-09
step 100: mean loss = 1.3653311e-09
epoch 1560: mean loss = 1.5049187e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1561
step 0: mean loss = 2.1412456e-09
step 100: mean loss = 1.6719739e-09
epoch 1561: mean loss = 1.6934868e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1562
step 0: mean loss = 1.4399538e-09
step 100: mean loss = 1.8233267e-09
epoch 1562: mean loss = 1.7705355e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1563
step 0: mean loss = 1.6659456e-09
step 100: mean loss = 1.8732706e-09
epoch 1563: mean loss = 1.6877126e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1564
step 0: mean loss = 1.1864735e-09
step 100: mean loss = 1.7273802e-09
epoch 1564: mean loss = 1.8591509e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1565
step 0: mean loss = 1.5151457e-09
step 100: mean loss = 1.4771204e-09
epoch 1565: mean loss = 1.6022441e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1566
step 0: mean loss = 1.2700202e-09
step 100: mean loss = 1.5544849e-09
epoch 1566: mean loss = 1.7506602e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1567
step 0: mean loss = 1.283724e-09
step 100: mean loss = 1.5335108e-09
epoch 1567: mean loss = 1.6593483e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1568
step 0: mean loss = 1.257402e-09
step 100: mean loss = 1.719307e-09
epoch 1568: mean loss = 1.6885514e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1569
step 0: mean loss = 1.4737642e-09
step 100: mean loss = 1.6516375e-09
epoch 1569: mean loss = 1.8440145e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1570
step 0: mean loss = 2.5550413e-09
step 100: mean loss = 1.2777415e-09
epoch 1570: mean loss = 1.8817086e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1571
step 0: mean loss = 1.3461487e-09
step 100: mean loss = 1.5390864e-09
epoch 1571: mean loss = 1.5004044e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1572
step 0: mean loss = 1.7466734e-09
step 100: mean loss = 1.3917876e-09
epoch 1572: mean loss = 2.1163136e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1573
step 0: mean loss = 1.2328111e-09
step 100: mean loss = 1.1973003e-09
epoch 1573: mean loss = 1.4217401e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1574
step 0: mean loss = 1.3223433e-09
step 100: mean loss = 1.5792272e-09
epoch 1574: mean loss = 1.6248433e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1575
step 0: mean loss = 1.2074503e-09
step 100: mean loss = 1.5299705e-09
epoch 1575: mean loss = 1.7723032e-09  learning rate = 1.8299566e-05
============================
Start of epoch 1576
step 0: mean loss = 1.192875e-09
step 100: mean loss = 1.1980439e-09
epoch 1576: mean loss = 1.2051331e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1577
step 0: mean loss = 1.3026684e-09
step 100: mean loss = 1.6430763e-09
epoch 1577: mean loss = 1.6671342e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1578
step 0: mean loss = 1.5245456e-09
step 100: mean loss = 1.5246885e-09
epoch 1578: mean loss = 1.7502083e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1579
step 0: mean loss = 1.1925387e-09
step 100: mean loss = 1.7666254e-09
epoch 1579: mean loss = 1.5683321e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1580
step 0: mean loss = 1.4370408e-09
step 100: mean loss = 1.5411541e-09
epoch 1580: mean loss = 1.7506233e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1581
step 0: mean loss = 1.265505e-09
step 100: mean loss = 1.436252e-09
epoch 1581: mean loss = 1.5984483e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1582
step 0: mean loss = 1.4339904e-09
step 100: mean loss = 1.6392915e-09
epoch 1582: mean loss = 1.6649255e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1583
step 0: mean loss = 1.1992973e-09
step 100: mean loss = 1.6913202e-09
epoch 1583: mean loss = 1.5366146e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1584
step 0: mean loss = 1.6510613e-09
step 100: mean loss = 1.9458688e-09
epoch 1584: mean loss = 1.7225866e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1585
step 0: mean loss = 2.5518836e-09
step 100: mean loss = 1.6983661e-09
epoch 1585: mean loss = 1.6545088e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1586
step 0: mean loss = 1.3728331e-09
step 100: mean loss = 1.6205605e-09
epoch 1586: mean loss = 1.6935936e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1587
step 0: mean loss = 1.7723937e-09
step 100: mean loss = 1.8183105e-09
epoch 1587: mean loss = 1.6673782e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1588
step 0: mean loss = 1.2023946e-09
step 100: mean loss = 1.5788014e-09
epoch 1588: mean loss = 1.7283746e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1589
step 0: mean loss = 1.2196611e-09
step 100: mean loss = 1.7809557e-09
epoch 1589: mean loss = 1.6718071e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1590
step 0: mean loss = 1.6348031e-09
step 100: mean loss = 1.4486993e-09
epoch 1590: mean loss = 1.6297126e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1591
step 0: mean loss = 1.3458964e-09
step 100: mean loss = 1.622411e-09
epoch 1591: mean loss = 1.5977801e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1592
step 0: mean loss = 1.3656937e-09
step 100: mean loss = 1.7862267e-09
epoch 1592: mean loss = 1.6186811e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1593
step 0: mean loss = 1.6434663e-09
step 100: mean loss = 1.7000146e-09
epoch 1593: mean loss = 1.714262e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1594
step 0: mean loss = 1.7513933e-09
step 100: mean loss = 1.5221485e-09
epoch 1594: mean loss = 1.6133893e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1595
step 0: mean loss = 1.3303331e-09
step 100: mean loss = 1.7429846e-09
epoch 1595: mean loss = 1.6251764e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1596
step 0: mean loss = 3.5059988e-09
step 100: mean loss = 1.7489569e-09
epoch 1596: mean loss = 1.6461322e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1597
step 0: mean loss = 1.4572185e-09
step 100: mean loss = 2.0108093e-09
epoch 1597: mean loss = 1.7407312e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1598
step 0: mean loss = 1.2908337e-09
step 100: mean loss = 1.7936514e-09
epoch 1598: mean loss = 1.7918197e-09  learning rate = 1.7384587e-05
============================
Start of epoch 1599
step 0: mean loss = 1.929632e-09
step 100: mean loss = 1.3657435e-09
epoch 1599: mean loss = 1.5554074e-09  learning rate = 1.7384587e-05
saving the weights
Relative Error in the forces is 5.232553e-05
